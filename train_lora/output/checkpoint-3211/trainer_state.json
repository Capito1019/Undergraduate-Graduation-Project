{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.30006541444724794,
  "eval_steps": 6421,
  "global_step": 3211,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015886365760209326,
      "grad_norm": 0.30615234375,
      "learning_rate": 1.0585305105853052e-07,
      "loss": 0.3677,
      "step": 17
    },
    {
      "epoch": 0.003177273152041865,
      "grad_norm": 1.23828125,
      "learning_rate": 2.1170610211706104e-07,
      "loss": 0.5717,
      "step": 34
    },
    {
      "epoch": 0.004765909728062798,
      "grad_norm": 0.280029296875,
      "learning_rate": 3.1755915317559156e-07,
      "loss": 0.8085,
      "step": 51
    },
    {
      "epoch": 0.00635454630408373,
      "grad_norm": 0.34228515625,
      "learning_rate": 4.234122042341221e-07,
      "loss": 0.3141,
      "step": 68
    },
    {
      "epoch": 0.007943182880104663,
      "grad_norm": 0.6669921875,
      "learning_rate": 5.292652552926527e-07,
      "loss": 0.6057,
      "step": 85
    },
    {
      "epoch": 0.009531819456125596,
      "grad_norm": 0.106689453125,
      "learning_rate": 6.351183063511831e-07,
      "loss": 0.7759,
      "step": 102
    },
    {
      "epoch": 0.011120456032146528,
      "grad_norm": 0.41064453125,
      "learning_rate": 7.409713574097137e-07,
      "loss": 0.3873,
      "step": 119
    },
    {
      "epoch": 0.01270909260816746,
      "grad_norm": 0.52392578125,
      "learning_rate": 8.468244084682442e-07,
      "loss": 0.6285,
      "step": 136
    },
    {
      "epoch": 0.014297729184188394,
      "grad_norm": 0.1488037109375,
      "learning_rate": 9.526774595267747e-07,
      "loss": 0.7612,
      "step": 153
    },
    {
      "epoch": 0.015886365760209326,
      "grad_norm": 0.352294921875,
      "learning_rate": 1.0585305105853053e-06,
      "loss": 0.3533,
      "step": 170
    },
    {
      "epoch": 0.01747500233623026,
      "grad_norm": 0.74755859375,
      "learning_rate": 1.1643835616438357e-06,
      "loss": 0.6135,
      "step": 187
    },
    {
      "epoch": 0.019063638912251192,
      "grad_norm": 0.15283203125,
      "learning_rate": 1.2702366127023662e-06,
      "loss": 0.7373,
      "step": 204
    },
    {
      "epoch": 0.020652275488272125,
      "grad_norm": 0.59130859375,
      "learning_rate": 1.3760896637608966e-06,
      "loss": 0.4345,
      "step": 221
    },
    {
      "epoch": 0.022240912064293055,
      "grad_norm": 0.5458984375,
      "learning_rate": 1.4819427148194274e-06,
      "loss": 0.6566,
      "step": 238
    },
    {
      "epoch": 0.02382954864031399,
      "grad_norm": 0.29541015625,
      "learning_rate": 1.5877957658779578e-06,
      "loss": 0.7509,
      "step": 255
    },
    {
      "epoch": 0.02541818521633492,
      "grad_norm": 0.490478515625,
      "learning_rate": 1.6936488169364883e-06,
      "loss": 0.4075,
      "step": 272
    },
    {
      "epoch": 0.027006821792355855,
      "grad_norm": 0.796875,
      "learning_rate": 1.799501867995019e-06,
      "loss": 0.6673,
      "step": 289
    },
    {
      "epoch": 0.028595458368376788,
      "grad_norm": 0.1600341796875,
      "learning_rate": 1.9053549190535495e-06,
      "loss": 0.6821,
      "step": 306
    },
    {
      "epoch": 0.03018409494439772,
      "grad_norm": 0.4326171875,
      "learning_rate": 2.01120797011208e-06,
      "loss": 0.3543,
      "step": 323
    },
    {
      "epoch": 0.03177273152041865,
      "grad_norm": 0.75732421875,
      "learning_rate": 2.1170610211706106e-06,
      "loss": 0.6114,
      "step": 340
    },
    {
      "epoch": 0.03336136809643959,
      "grad_norm": 0.20703125,
      "learning_rate": 2.2229140722291408e-06,
      "loss": 0.5834,
      "step": 357
    },
    {
      "epoch": 0.03495000467246052,
      "grad_norm": 0.326416015625,
      "learning_rate": 2.3287671232876713e-06,
      "loss": 0.3978,
      "step": 374
    },
    {
      "epoch": 0.03653864124848145,
      "grad_norm": 0.62646484375,
      "learning_rate": 2.434620174346202e-06,
      "loss": 0.6366,
      "step": 391
    },
    {
      "epoch": 0.038127277824502384,
      "grad_norm": 0.259765625,
      "learning_rate": 2.5404732254047325e-06,
      "loss": 0.6095,
      "step": 408
    },
    {
      "epoch": 0.039715914400523314,
      "grad_norm": 0.82861328125,
      "learning_rate": 2.646326276463263e-06,
      "loss": 0.4376,
      "step": 425
    },
    {
      "epoch": 0.04130455097654425,
      "grad_norm": 0.97509765625,
      "learning_rate": 2.7521793275217932e-06,
      "loss": 0.7023,
      "step": 442
    },
    {
      "epoch": 0.04289318755256518,
      "grad_norm": 0.2115478515625,
      "learning_rate": 2.858032378580324e-06,
      "loss": 0.5356,
      "step": 459
    },
    {
      "epoch": 0.04448182412858611,
      "grad_norm": 0.83154296875,
      "learning_rate": 2.963885429638855e-06,
      "loss": 0.4777,
      "step": 476
    },
    {
      "epoch": 0.04607046070460705,
      "grad_norm": 0.7978515625,
      "learning_rate": 3.069738480697385e-06,
      "loss": 0.6041,
      "step": 493
    },
    {
      "epoch": 0.04765909728062798,
      "grad_norm": 0.41748046875,
      "learning_rate": 3.1755915317559155e-06,
      "loss": 0.4227,
      "step": 510
    },
    {
      "epoch": 0.04924773385664891,
      "grad_norm": 0.8466796875,
      "learning_rate": 3.281444582814446e-06,
      "loss": 0.443,
      "step": 527
    },
    {
      "epoch": 0.05083637043266984,
      "grad_norm": 0.9345703125,
      "learning_rate": 3.3872976338729767e-06,
      "loss": 0.6736,
      "step": 544
    },
    {
      "epoch": 0.05242500700869078,
      "grad_norm": 0.5810546875,
      "learning_rate": 3.4931506849315072e-06,
      "loss": 0.384,
      "step": 561
    },
    {
      "epoch": 0.05401364358471171,
      "grad_norm": 0.68017578125,
      "learning_rate": 3.599003735990038e-06,
      "loss": 0.3962,
      "step": 578
    },
    {
      "epoch": 0.05560228016073264,
      "grad_norm": 1.443359375,
      "learning_rate": 3.704856787048568e-06,
      "loss": 0.6065,
      "step": 595
    },
    {
      "epoch": 0.057190916736753576,
      "grad_norm": 0.67578125,
      "learning_rate": 3.810709838107099e-06,
      "loss": 0.4176,
      "step": 612
    },
    {
      "epoch": 0.058779553312774506,
      "grad_norm": 0.6826171875,
      "learning_rate": 3.916562889165629e-06,
      "loss": 0.4848,
      "step": 629
    },
    {
      "epoch": 0.06036818988879544,
      "grad_norm": 1.1982421875,
      "learning_rate": 4.02241594022416e-06,
      "loss": 0.6994,
      "step": 646
    },
    {
      "epoch": 0.06195682646481637,
      "grad_norm": 0.52587890625,
      "learning_rate": 4.12826899128269e-06,
      "loss": 0.3928,
      "step": 663
    },
    {
      "epoch": 0.0635454630408373,
      "grad_norm": 1.2802734375,
      "learning_rate": 4.234122042341221e-06,
      "loss": 0.4216,
      "step": 680
    },
    {
      "epoch": 0.06513409961685823,
      "grad_norm": 1.1298828125,
      "learning_rate": 4.339975093399751e-06,
      "loss": 0.618,
      "step": 697
    },
    {
      "epoch": 0.06672273619287918,
      "grad_norm": 0.7412109375,
      "learning_rate": 4.4458281444582815e-06,
      "loss": 0.3223,
      "step": 714
    },
    {
      "epoch": 0.0683113727689001,
      "grad_norm": 1.58984375,
      "learning_rate": 4.5516811955168125e-06,
      "loss": 0.5041,
      "step": 731
    },
    {
      "epoch": 0.06990000934492104,
      "grad_norm": 1.41796875,
      "learning_rate": 4.657534246575343e-06,
      "loss": 0.6834,
      "step": 748
    },
    {
      "epoch": 0.07148864592094197,
      "grad_norm": 0.86083984375,
      "learning_rate": 4.763387297633874e-06,
      "loss": 0.2818,
      "step": 765
    },
    {
      "epoch": 0.0730772824969629,
      "grad_norm": 0.94189453125,
      "learning_rate": 4.869240348692404e-06,
      "loss": 0.431,
      "step": 782
    },
    {
      "epoch": 0.07466591907298384,
      "grad_norm": 1.87109375,
      "learning_rate": 4.975093399750934e-06,
      "loss": 0.632,
      "step": 799
    },
    {
      "epoch": 0.07625455564900477,
      "grad_norm": 0.83203125,
      "learning_rate": 5.080946450809465e-06,
      "loss": 0.3002,
      "step": 816
    },
    {
      "epoch": 0.0778431922250257,
      "grad_norm": 1.318359375,
      "learning_rate": 5.186799501867995e-06,
      "loss": 0.4234,
      "step": 833
    },
    {
      "epoch": 0.07943182880104663,
      "grad_norm": 1.84375,
      "learning_rate": 5.292652552926526e-06,
      "loss": 0.6675,
      "step": 850
    },
    {
      "epoch": 0.08102046537706756,
      "grad_norm": 0.9638671875,
      "learning_rate": 5.398505603985057e-06,
      "loss": 0.2349,
      "step": 867
    },
    {
      "epoch": 0.0826091019530885,
      "grad_norm": 0.955078125,
      "learning_rate": 5.5043586550435864e-06,
      "loss": 0.4604,
      "step": 884
    },
    {
      "epoch": 0.08419773852910943,
      "grad_norm": 0.29052734375,
      "learning_rate": 5.6102117061021174e-06,
      "loss": 0.5977,
      "step": 901
    },
    {
      "epoch": 0.08578637510513036,
      "grad_norm": 0.7275390625,
      "learning_rate": 5.716064757160648e-06,
      "loss": 0.2387,
      "step": 918
    },
    {
      "epoch": 0.08737501168115129,
      "grad_norm": 1.1982421875,
      "learning_rate": 5.821917808219179e-06,
      "loss": 0.4467,
      "step": 935
    },
    {
      "epoch": 0.08896364825717222,
      "grad_norm": 0.444091796875,
      "learning_rate": 5.92777085927771e-06,
      "loss": 0.5707,
      "step": 952
    },
    {
      "epoch": 0.09055228483319316,
      "grad_norm": 0.982421875,
      "learning_rate": 6.033623910336239e-06,
      "loss": 0.3508,
      "step": 969
    },
    {
      "epoch": 0.0921409214092141,
      "grad_norm": 1.3583984375,
      "learning_rate": 6.13947696139477e-06,
      "loss": 0.4969,
      "step": 986
    },
    {
      "epoch": 0.09372955798523502,
      "grad_norm": 0.222412109375,
      "learning_rate": 6.245330012453301e-06,
      "loss": 0.5931,
      "step": 1003
    },
    {
      "epoch": 0.09531819456125595,
      "grad_norm": 0.84619140625,
      "learning_rate": 6.351183063511831e-06,
      "loss": 0.3055,
      "step": 1020
    },
    {
      "epoch": 0.09690683113727688,
      "grad_norm": 1.484375,
      "learning_rate": 6.457036114570362e-06,
      "loss": 0.5078,
      "step": 1037
    },
    {
      "epoch": 0.09849546771329783,
      "grad_norm": 0.6533203125,
      "learning_rate": 6.562889165628892e-06,
      "loss": 0.5422,
      "step": 1054
    },
    {
      "epoch": 0.10008410428931876,
      "grad_norm": 1.162109375,
      "learning_rate": 6.668742216687422e-06,
      "loss": 0.2925,
      "step": 1071
    },
    {
      "epoch": 0.10167274086533969,
      "grad_norm": 1.6494140625,
      "learning_rate": 6.774595267745953e-06,
      "loss": 0.4744,
      "step": 1088
    },
    {
      "epoch": 0.10326137744136062,
      "grad_norm": 0.85009765625,
      "learning_rate": 6.8804483188044835e-06,
      "loss": 0.5842,
      "step": 1105
    },
    {
      "epoch": 0.10485001401738156,
      "grad_norm": 0.99853515625,
      "learning_rate": 6.9863013698630145e-06,
      "loss": 0.361,
      "step": 1122
    },
    {
      "epoch": 0.10643865059340249,
      "grad_norm": 2.166015625,
      "learning_rate": 7.092154420921545e-06,
      "loss": 0.4835,
      "step": 1139
    },
    {
      "epoch": 0.10802728716942342,
      "grad_norm": 0.6533203125,
      "learning_rate": 7.198007471980076e-06,
      "loss": 0.4625,
      "step": 1156
    },
    {
      "epoch": 0.10961592374544435,
      "grad_norm": 0.9951171875,
      "learning_rate": 7.303860523038606e-06,
      "loss": 0.3469,
      "step": 1173
    },
    {
      "epoch": 0.11120456032146528,
      "grad_norm": 3.162109375,
      "learning_rate": 7.409713574097136e-06,
      "loss": 0.5231,
      "step": 1190
    },
    {
      "epoch": 0.11279319689748622,
      "grad_norm": 0.455078125,
      "learning_rate": 7.515566625155667e-06,
      "loss": 0.4403,
      "step": 1207
    },
    {
      "epoch": 0.11438183347350715,
      "grad_norm": 1.091796875,
      "learning_rate": 7.621419676214198e-06,
      "loss": 0.3341,
      "step": 1224
    },
    {
      "epoch": 0.11597047004952808,
      "grad_norm": 2.255859375,
      "learning_rate": 7.727272727272727e-06,
      "loss": 0.5361,
      "step": 1241
    },
    {
      "epoch": 0.11755910662554901,
      "grad_norm": 0.5732421875,
      "learning_rate": 7.833125778331258e-06,
      "loss": 0.4021,
      "step": 1258
    },
    {
      "epoch": 0.11914774320156994,
      "grad_norm": 0.9658203125,
      "learning_rate": 7.93897882938979e-06,
      "loss": 0.3574,
      "step": 1275
    },
    {
      "epoch": 0.12073637977759089,
      "grad_norm": 1.7958984375,
      "learning_rate": 8.04483188044832e-06,
      "loss": 0.5173,
      "step": 1292
    },
    {
      "epoch": 0.12232501635361182,
      "grad_norm": 0.71923828125,
      "learning_rate": 8.150684931506851e-06,
      "loss": 0.4297,
      "step": 1309
    },
    {
      "epoch": 0.12391365292963274,
      "grad_norm": 1.091796875,
      "learning_rate": 8.25653798256538e-06,
      "loss": 0.3493,
      "step": 1326
    },
    {
      "epoch": 0.12550228950565367,
      "grad_norm": 3.525390625,
      "learning_rate": 8.362391033623912e-06,
      "loss": 0.5447,
      "step": 1343
    },
    {
      "epoch": 0.1270909260816746,
      "grad_norm": 0.63623046875,
      "learning_rate": 8.468244084682442e-06,
      "loss": 0.3913,
      "step": 1360
    },
    {
      "epoch": 0.12867956265769553,
      "grad_norm": 1.380859375,
      "learning_rate": 8.574097135740972e-06,
      "loss": 0.3514,
      "step": 1377
    },
    {
      "epoch": 0.13026819923371646,
      "grad_norm": 1.703125,
      "learning_rate": 8.679950186799503e-06,
      "loss": 0.5447,
      "step": 1394
    },
    {
      "epoch": 0.13185683580973742,
      "grad_norm": 0.5234375,
      "learning_rate": 8.785803237858032e-06,
      "loss": 0.3191,
      "step": 1411
    },
    {
      "epoch": 0.13344547238575835,
      "grad_norm": 1.115234375,
      "learning_rate": 8.891656288916563e-06,
      "loss": 0.3458,
      "step": 1428
    },
    {
      "epoch": 0.13503410896177928,
      "grad_norm": 1.392578125,
      "learning_rate": 8.997509339975094e-06,
      "loss": 0.5391,
      "step": 1445
    },
    {
      "epoch": 0.1366227455378002,
      "grad_norm": 0.60888671875,
      "learning_rate": 9.103362391033625e-06,
      "loss": 0.2989,
      "step": 1462
    },
    {
      "epoch": 0.13821138211382114,
      "grad_norm": 1.1220703125,
      "learning_rate": 9.209215442092156e-06,
      "loss": 0.3724,
      "step": 1479
    },
    {
      "epoch": 0.13980001868984207,
      "grad_norm": 2.53125,
      "learning_rate": 9.315068493150685e-06,
      "loss": 0.5454,
      "step": 1496
    },
    {
      "epoch": 0.141388655265863,
      "grad_norm": 0.6748046875,
      "learning_rate": 9.420921544209216e-06,
      "loss": 0.3114,
      "step": 1513
    },
    {
      "epoch": 0.14297729184188393,
      "grad_norm": 1.4423828125,
      "learning_rate": 9.526774595267747e-06,
      "loss": 0.3943,
      "step": 1530
    },
    {
      "epoch": 0.14456592841790486,
      "grad_norm": 2.107421875,
      "learning_rate": 9.632627646326277e-06,
      "loss": 0.62,
      "step": 1547
    },
    {
      "epoch": 0.1461545649939258,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.738480697384808e-06,
      "loss": 0.2803,
      "step": 1564
    },
    {
      "epoch": 0.14774320156994675,
      "grad_norm": 1.455078125,
      "learning_rate": 9.844333748443339e-06,
      "loss": 0.3949,
      "step": 1581
    },
    {
      "epoch": 0.14933183814596768,
      "grad_norm": 2.21875,
      "learning_rate": 9.950186799501868e-06,
      "loss": 0.6392,
      "step": 1598
    },
    {
      "epoch": 0.1509204747219886,
      "grad_norm": 0.765625,
      "learning_rate": 9.999997851128222e-06,
      "loss": 0.2648,
      "step": 1615
    },
    {
      "epoch": 0.15250911129800954,
      "grad_norm": 1.33984375,
      "learning_rate": 9.999982066215332e-06,
      "loss": 0.3933,
      "step": 1632
    },
    {
      "epoch": 0.15409774787403047,
      "grad_norm": 2.046875,
      "learning_rate": 9.999950947435717e-06,
      "loss": 0.6,
      "step": 1649
    },
    {
      "epoch": 0.1556863844500514,
      "grad_norm": 0.65966796875,
      "learning_rate": 9.999904494884808e-06,
      "loss": 0.2117,
      "step": 1666
    },
    {
      "epoch": 0.15727502102607233,
      "grad_norm": 1.177734375,
      "learning_rate": 9.999842708705073e-06,
      "loss": 0.3763,
      "step": 1683
    },
    {
      "epoch": 0.15886365760209326,
      "grad_norm": 2.9765625,
      "learning_rate": 9.999765589085988e-06,
      "loss": 0.5906,
      "step": 1700
    },
    {
      "epoch": 0.16045229417811419,
      "grad_norm": 0.90185546875,
      "learning_rate": 9.999673136264067e-06,
      "loss": 0.265,
      "step": 1717
    },
    {
      "epoch": 0.16204093075413512,
      "grad_norm": 1.48046875,
      "learning_rate": 9.999565350522841e-06,
      "loss": 0.4085,
      "step": 1734
    },
    {
      "epoch": 0.16362956733015607,
      "grad_norm": 0.5478515625,
      "learning_rate": 9.999442232192867e-06,
      "loss": 0.5989,
      "step": 1751
    },
    {
      "epoch": 0.165218203906177,
      "grad_norm": 1.064453125,
      "learning_rate": 9.999303781651722e-06,
      "loss": 0.2099,
      "step": 1768
    },
    {
      "epoch": 0.16680684048219793,
      "grad_norm": 1.28125,
      "learning_rate": 9.999149999324002e-06,
      "loss": 0.4079,
      "step": 1785
    },
    {
      "epoch": 0.16839547705821886,
      "grad_norm": 0.37451171875,
      "learning_rate": 9.998980885681328e-06,
      "loss": 0.5364,
      "step": 1802
    },
    {
      "epoch": 0.1699841136342398,
      "grad_norm": 1.296875,
      "learning_rate": 9.998796441242333e-06,
      "loss": 0.2434,
      "step": 1819
    },
    {
      "epoch": 0.17157275021026072,
      "grad_norm": 1.68359375,
      "learning_rate": 9.998596666572668e-06,
      "loss": 0.4581,
      "step": 1836
    },
    {
      "epoch": 0.17316138678628165,
      "grad_norm": 0.09356689453125,
      "learning_rate": 9.998381562284999e-06,
      "loss": 0.5137,
      "step": 1853
    },
    {
      "epoch": 0.17475002336230258,
      "grad_norm": 1.197265625,
      "learning_rate": 9.998151129039005e-06,
      "loss": 0.2999,
      "step": 1870
    },
    {
      "epoch": 0.1763386599383235,
      "grad_norm": 1.2822265625,
      "learning_rate": 9.997905367541374e-06,
      "loss": 0.4893,
      "step": 1887
    },
    {
      "epoch": 0.17792729651434444,
      "grad_norm": 0.406005859375,
      "learning_rate": 9.997644278545805e-06,
      "loss": 0.4657,
      "step": 1904
    },
    {
      "epoch": 0.1795159330903654,
      "grad_norm": 1.0361328125,
      "learning_rate": 9.997367862853e-06,
      "loss": 0.2577,
      "step": 1921
    },
    {
      "epoch": 0.18110456966638633,
      "grad_norm": 1.94921875,
      "learning_rate": 9.997076121310668e-06,
      "loss": 0.4479,
      "step": 1938
    },
    {
      "epoch": 0.18269320624240726,
      "grad_norm": 0.51708984375,
      "learning_rate": 9.996769054813517e-06,
      "loss": 0.4454,
      "step": 1955
    },
    {
      "epoch": 0.1842818428184282,
      "grad_norm": 1.0224609375,
      "learning_rate": 9.996446664303252e-06,
      "loss": 0.2745,
      "step": 1972
    },
    {
      "epoch": 0.18587047939444912,
      "grad_norm": 1.5078125,
      "learning_rate": 9.996108950768579e-06,
      "loss": 0.5063,
      "step": 1989
    },
    {
      "epoch": 0.18745911597047005,
      "grad_norm": 0.59130859375,
      "learning_rate": 9.995755915245187e-06,
      "loss": 0.4971,
      "step": 2006
    },
    {
      "epoch": 0.18904775254649098,
      "grad_norm": 1.302734375,
      "learning_rate": 9.995387558815764e-06,
      "loss": 0.2852,
      "step": 2023
    },
    {
      "epoch": 0.1906363891225119,
      "grad_norm": 1.7626953125,
      "learning_rate": 9.99500388260998e-06,
      "loss": 0.4934,
      "step": 2040
    },
    {
      "epoch": 0.19222502569853284,
      "grad_norm": 0.47216796875,
      "learning_rate": 9.994604887804484e-06,
      "loss": 0.4508,
      "step": 2057
    },
    {
      "epoch": 0.19381366227455377,
      "grad_norm": 1.041015625,
      "learning_rate": 9.99419057562291e-06,
      "loss": 0.3276,
      "step": 2074
    },
    {
      "epoch": 0.19540229885057472,
      "grad_norm": 1.5029296875,
      "learning_rate": 9.993760947335863e-06,
      "loss": 0.5077,
      "step": 2091
    },
    {
      "epoch": 0.19699093542659565,
      "grad_norm": 0.638671875,
      "learning_rate": 9.99331600426092e-06,
      "loss": 0.4407,
      "step": 2108
    },
    {
      "epoch": 0.19857957200261658,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.992855747762625e-06,
      "loss": 0.3315,
      "step": 2125
    },
    {
      "epoch": 0.2001682085786375,
      "grad_norm": 1.5556640625,
      "learning_rate": 9.992380179252487e-06,
      "loss": 0.5101,
      "step": 2142
    },
    {
      "epoch": 0.20175684515465844,
      "grad_norm": 0.708984375,
      "learning_rate": 9.991889300188971e-06,
      "loss": 0.4032,
      "step": 2159
    },
    {
      "epoch": 0.20334548173067937,
      "grad_norm": 1.126953125,
      "learning_rate": 9.991383112077498e-06,
      "loss": 0.3304,
      "step": 2176
    },
    {
      "epoch": 0.2049341183067003,
      "grad_norm": 1.6201171875,
      "learning_rate": 9.990861616470434e-06,
      "loss": 0.5363,
      "step": 2193
    },
    {
      "epoch": 0.20652275488272123,
      "grad_norm": 0.74267578125,
      "learning_rate": 9.990324814967101e-06,
      "loss": 0.4124,
      "step": 2210
    },
    {
      "epoch": 0.20811139145874216,
      "grad_norm": 1.119140625,
      "learning_rate": 9.989772709213747e-06,
      "loss": 0.3725,
      "step": 2227
    },
    {
      "epoch": 0.20970002803476312,
      "grad_norm": 1.853515625,
      "learning_rate": 9.989205300903563e-06,
      "loss": 0.5147,
      "step": 2244
    },
    {
      "epoch": 0.21128866461078405,
      "grad_norm": 0.66015625,
      "learning_rate": 9.98862259177667e-06,
      "loss": 0.328,
      "step": 2261
    },
    {
      "epoch": 0.21287730118680498,
      "grad_norm": 1.2216796875,
      "learning_rate": 9.988024583620108e-06,
      "loss": 0.3662,
      "step": 2278
    },
    {
      "epoch": 0.2144659377628259,
      "grad_norm": 1.9306640625,
      "learning_rate": 9.987411278267842e-06,
      "loss": 0.5264,
      "step": 2295
    },
    {
      "epoch": 0.21605457433884684,
      "grad_norm": 0.82861328125,
      "learning_rate": 9.986782677600747e-06,
      "loss": 0.3458,
      "step": 2312
    },
    {
      "epoch": 0.21764321091486777,
      "grad_norm": 1.4697265625,
      "learning_rate": 9.986138783546603e-06,
      "loss": 0.4036,
      "step": 2329
    },
    {
      "epoch": 0.2192318474908887,
      "grad_norm": 2.091796875,
      "learning_rate": 9.985479598080095e-06,
      "loss": 0.561,
      "step": 2346
    },
    {
      "epoch": 0.22082048406690963,
      "grad_norm": 0.64453125,
      "learning_rate": 9.984805123222804e-06,
      "loss": 0.2843,
      "step": 2363
    },
    {
      "epoch": 0.22240912064293056,
      "grad_norm": 1.4150390625,
      "learning_rate": 9.9841153610432e-06,
      "loss": 0.3401,
      "step": 2380
    },
    {
      "epoch": 0.2239977572189515,
      "grad_norm": 1.7470703125,
      "learning_rate": 9.983410313656633e-06,
      "loss": 0.5495,
      "step": 2397
    },
    {
      "epoch": 0.22558639379497245,
      "grad_norm": 0.7314453125,
      "learning_rate": 9.98268998322533e-06,
      "loss": 0.2932,
      "step": 2414
    },
    {
      "epoch": 0.22717503037099337,
      "grad_norm": 1.6337890625,
      "learning_rate": 9.981954371958392e-06,
      "loss": 0.4074,
      "step": 2431
    },
    {
      "epoch": 0.2287636669470143,
      "grad_norm": 2.181640625,
      "learning_rate": 9.981203482111779e-06,
      "loss": 0.5556,
      "step": 2448
    },
    {
      "epoch": 0.23035230352303523,
      "grad_norm": 0.88818359375,
      "learning_rate": 9.980437315988307e-06,
      "loss": 0.2335,
      "step": 2465
    },
    {
      "epoch": 0.23194094009905616,
      "grad_norm": 1.58984375,
      "learning_rate": 9.979655875937644e-06,
      "loss": 0.4066,
      "step": 2482
    },
    {
      "epoch": 0.2335295766750771,
      "grad_norm": 3.404296875,
      "learning_rate": 9.978859164356298e-06,
      "loss": 0.5986,
      "step": 2499
    },
    {
      "epoch": 0.23511821325109802,
      "grad_norm": 0.970703125,
      "learning_rate": 9.97804718368761e-06,
      "loss": 0.2273,
      "step": 2516
    },
    {
      "epoch": 0.23670684982711895,
      "grad_norm": 1.6474609375,
      "learning_rate": 9.977219936421749e-06,
      "loss": 0.3798,
      "step": 2533
    },
    {
      "epoch": 0.23829548640313988,
      "grad_norm": 2.923828125,
      "learning_rate": 9.976377425095708e-06,
      "loss": 0.5819,
      "step": 2550
    },
    {
      "epoch": 0.2398841229791608,
      "grad_norm": 0.83837890625,
      "learning_rate": 9.975519652293284e-06,
      "loss": 0.2694,
      "step": 2567
    },
    {
      "epoch": 0.24147275955518177,
      "grad_norm": 1.5986328125,
      "learning_rate": 9.974646620645083e-06,
      "loss": 0.3822,
      "step": 2584
    },
    {
      "epoch": 0.2430613961312027,
      "grad_norm": 0.404052734375,
      "learning_rate": 9.973758332828504e-06,
      "loss": 0.5388,
      "step": 2601
    },
    {
      "epoch": 0.24465003270722363,
      "grad_norm": 1.015625,
      "learning_rate": 9.972854791567734e-06,
      "loss": 0.2384,
      "step": 2618
    },
    {
      "epoch": 0.24623866928324456,
      "grad_norm": 1.779296875,
      "learning_rate": 9.97193599963374e-06,
      "loss": 0.4567,
      "step": 2635
    },
    {
      "epoch": 0.2478273058592655,
      "grad_norm": 0.463134765625,
      "learning_rate": 9.971001959844257e-06,
      "loss": 0.5347,
      "step": 2652
    },
    {
      "epoch": 0.24941594243528642,
      "grad_norm": 1.205078125,
      "learning_rate": 9.970052675063787e-06,
      "loss": 0.2553,
      "step": 2669
    },
    {
      "epoch": 0.25100457901130735,
      "grad_norm": 1.7578125,
      "learning_rate": 9.969088148203579e-06,
      "loss": 0.4713,
      "step": 2686
    },
    {
      "epoch": 0.2525932155873283,
      "grad_norm": 0.403076171875,
      "learning_rate": 9.968108382221627e-06,
      "loss": 0.5314,
      "step": 2703
    },
    {
      "epoch": 0.2541818521633492,
      "grad_norm": 0.98291015625,
      "learning_rate": 9.967113380122666e-06,
      "loss": 0.2274,
      "step": 2720
    },
    {
      "epoch": 0.25577048873937014,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.966103144958152e-06,
      "loss": 0.4455,
      "step": 2737
    },
    {
      "epoch": 0.25735912531539107,
      "grad_norm": 0.466552734375,
      "learning_rate": 9.965077679826256e-06,
      "loss": 0.4896,
      "step": 2754
    },
    {
      "epoch": 0.258947761891412,
      "grad_norm": 1.0419921875,
      "learning_rate": 9.964036987871861e-06,
      "loss": 0.2658,
      "step": 2771
    },
    {
      "epoch": 0.26053639846743293,
      "grad_norm": 2.078125,
      "learning_rate": 9.962981072286545e-06,
      "loss": 0.4868,
      "step": 2788
    },
    {
      "epoch": 0.26212503504345386,
      "grad_norm": 1.203125,
      "learning_rate": 9.96190993630857e-06,
      "loss": 0.4055,
      "step": 2805
    },
    {
      "epoch": 0.26371367161947484,
      "grad_norm": 1.0390625,
      "learning_rate": 9.96082358322288e-06,
      "loss": 0.2543,
      "step": 2822
    },
    {
      "epoch": 0.2653023081954958,
      "grad_norm": 2.037109375,
      "learning_rate": 9.95972201636109e-06,
      "loss": 0.4767,
      "step": 2839
    },
    {
      "epoch": 0.2668909447715167,
      "grad_norm": 0.67431640625,
      "learning_rate": 9.958605239101463e-06,
      "loss": 0.4612,
      "step": 2856
    },
    {
      "epoch": 0.26847958134753763,
      "grad_norm": 1.0087890625,
      "learning_rate": 9.957473254868917e-06,
      "loss": 0.2772,
      "step": 2873
    },
    {
      "epoch": 0.27006821792355856,
      "grad_norm": 1.63671875,
      "learning_rate": 9.956326067135002e-06,
      "loss": 0.5177,
      "step": 2890
    },
    {
      "epoch": 0.2716568544995795,
      "grad_norm": 0.48583984375,
      "learning_rate": 9.955163679417896e-06,
      "loss": 0.4457,
      "step": 2907
    },
    {
      "epoch": 0.2732454910756004,
      "grad_norm": 1.255859375,
      "learning_rate": 9.95398609528239e-06,
      "loss": 0.3055,
      "step": 2924
    },
    {
      "epoch": 0.27483412765162135,
      "grad_norm": 1.7099609375,
      "learning_rate": 9.952793318339884e-06,
      "loss": 0.5562,
      "step": 2941
    },
    {
      "epoch": 0.2764227642276423,
      "grad_norm": 0.6337890625,
      "learning_rate": 9.951585352248365e-06,
      "loss": 0.3751,
      "step": 2958
    },
    {
      "epoch": 0.2780114008036632,
      "grad_norm": 1.15625,
      "learning_rate": 9.950362200712405e-06,
      "loss": 0.2979,
      "step": 2975
    },
    {
      "epoch": 0.27960003737968414,
      "grad_norm": 2.228515625,
      "learning_rate": 9.949123867483146e-06,
      "loss": 0.5297,
      "step": 2992
    },
    {
      "epoch": 0.28118867395570507,
      "grad_norm": 0.65283203125,
      "learning_rate": 9.947870356358287e-06,
      "loss": 0.3912,
      "step": 3009
    },
    {
      "epoch": 0.282777310531726,
      "grad_norm": 1.6064453125,
      "learning_rate": 9.94660167118208e-06,
      "loss": 0.3376,
      "step": 3026
    },
    {
      "epoch": 0.28436594710774693,
      "grad_norm": 2.18359375,
      "learning_rate": 9.945317815845307e-06,
      "loss": 0.5291,
      "step": 3043
    },
    {
      "epoch": 0.28595458368376786,
      "grad_norm": 0.93701171875,
      "learning_rate": 9.944018794285276e-06,
      "loss": 0.4249,
      "step": 3060
    },
    {
      "epoch": 0.2875432202597888,
      "grad_norm": 1.7197265625,
      "learning_rate": 9.942704610485803e-06,
      "loss": 0.3531,
      "step": 3077
    },
    {
      "epoch": 0.2891318568358097,
      "grad_norm": 2.181640625,
      "learning_rate": 9.94137526847721e-06,
      "loss": 0.5112,
      "step": 3094
    },
    {
      "epoch": 0.29072049341183065,
      "grad_norm": 0.533203125,
      "learning_rate": 9.940030772336303e-06,
      "loss": 0.3746,
      "step": 3111
    },
    {
      "epoch": 0.2923091299878516,
      "grad_norm": 1.5009765625,
      "learning_rate": 9.938671126186358e-06,
      "loss": 0.3515,
      "step": 3128
    },
    {
      "epoch": 0.2938977665638725,
      "grad_norm": 1.9814453125,
      "learning_rate": 9.93729633419712e-06,
      "loss": 0.4941,
      "step": 3145
    },
    {
      "epoch": 0.2954864031398935,
      "grad_norm": 0.79736328125,
      "learning_rate": 9.935906400584777e-06,
      "loss": 0.3307,
      "step": 3162
    },
    {
      "epoch": 0.2970750397159144,
      "grad_norm": 1.5244140625,
      "learning_rate": 9.934501329611957e-06,
      "loss": 0.3344,
      "step": 3179
    },
    {
      "epoch": 0.29866367629193535,
      "grad_norm": 2.0078125,
      "learning_rate": 9.933081125587706e-06,
      "loss": 0.5522,
      "step": 3196
    }
  ],
  "logging_steps": 17,
  "max_steps": 32103,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 3211,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.347515200665682e+17,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
