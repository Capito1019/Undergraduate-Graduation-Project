{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 6421,
  "global_step": 32103,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015886365760209326,
      "grad_norm": 0.30615234375,
      "learning_rate": 1.0585305105853052e-07,
      "loss": 0.3677,
      "step": 17
    },
    {
      "epoch": 0.003177273152041865,
      "grad_norm": 1.23828125,
      "learning_rate": 2.1170610211706104e-07,
      "loss": 0.5717,
      "step": 34
    },
    {
      "epoch": 0.004765909728062798,
      "grad_norm": 0.280029296875,
      "learning_rate": 3.1755915317559156e-07,
      "loss": 0.8085,
      "step": 51
    },
    {
      "epoch": 0.00635454630408373,
      "grad_norm": 0.34228515625,
      "learning_rate": 4.234122042341221e-07,
      "loss": 0.3141,
      "step": 68
    },
    {
      "epoch": 0.007943182880104663,
      "grad_norm": 0.6669921875,
      "learning_rate": 5.292652552926527e-07,
      "loss": 0.6057,
      "step": 85
    },
    {
      "epoch": 0.009531819456125596,
      "grad_norm": 0.106689453125,
      "learning_rate": 6.351183063511831e-07,
      "loss": 0.7759,
      "step": 102
    },
    {
      "epoch": 0.011120456032146528,
      "grad_norm": 0.41064453125,
      "learning_rate": 7.409713574097137e-07,
      "loss": 0.3873,
      "step": 119
    },
    {
      "epoch": 0.01270909260816746,
      "grad_norm": 0.52392578125,
      "learning_rate": 8.468244084682442e-07,
      "loss": 0.6285,
      "step": 136
    },
    {
      "epoch": 0.014297729184188394,
      "grad_norm": 0.1488037109375,
      "learning_rate": 9.526774595267747e-07,
      "loss": 0.7612,
      "step": 153
    },
    {
      "epoch": 0.015886365760209326,
      "grad_norm": 0.352294921875,
      "learning_rate": 1.0585305105853053e-06,
      "loss": 0.3533,
      "step": 170
    },
    {
      "epoch": 0.01747500233623026,
      "grad_norm": 0.74755859375,
      "learning_rate": 1.1643835616438357e-06,
      "loss": 0.6135,
      "step": 187
    },
    {
      "epoch": 0.019063638912251192,
      "grad_norm": 0.15283203125,
      "learning_rate": 1.2702366127023662e-06,
      "loss": 0.7373,
      "step": 204
    },
    {
      "epoch": 0.020652275488272125,
      "grad_norm": 0.59130859375,
      "learning_rate": 1.3760896637608966e-06,
      "loss": 0.4345,
      "step": 221
    },
    {
      "epoch": 0.022240912064293055,
      "grad_norm": 0.5458984375,
      "learning_rate": 1.4819427148194274e-06,
      "loss": 0.6566,
      "step": 238
    },
    {
      "epoch": 0.02382954864031399,
      "grad_norm": 0.29541015625,
      "learning_rate": 1.5877957658779578e-06,
      "loss": 0.7509,
      "step": 255
    },
    {
      "epoch": 0.02541818521633492,
      "grad_norm": 0.490478515625,
      "learning_rate": 1.6936488169364883e-06,
      "loss": 0.4075,
      "step": 272
    },
    {
      "epoch": 0.027006821792355855,
      "grad_norm": 0.796875,
      "learning_rate": 1.799501867995019e-06,
      "loss": 0.6673,
      "step": 289
    },
    {
      "epoch": 0.028595458368376788,
      "grad_norm": 0.1600341796875,
      "learning_rate": 1.9053549190535495e-06,
      "loss": 0.6821,
      "step": 306
    },
    {
      "epoch": 0.03018409494439772,
      "grad_norm": 0.4326171875,
      "learning_rate": 2.01120797011208e-06,
      "loss": 0.3543,
      "step": 323
    },
    {
      "epoch": 0.03177273152041865,
      "grad_norm": 0.75732421875,
      "learning_rate": 2.1170610211706106e-06,
      "loss": 0.6114,
      "step": 340
    },
    {
      "epoch": 0.03336136809643959,
      "grad_norm": 0.20703125,
      "learning_rate": 2.2229140722291408e-06,
      "loss": 0.5834,
      "step": 357
    },
    {
      "epoch": 0.03495000467246052,
      "grad_norm": 0.326416015625,
      "learning_rate": 2.3287671232876713e-06,
      "loss": 0.3978,
      "step": 374
    },
    {
      "epoch": 0.03653864124848145,
      "grad_norm": 0.62646484375,
      "learning_rate": 2.434620174346202e-06,
      "loss": 0.6366,
      "step": 391
    },
    {
      "epoch": 0.038127277824502384,
      "grad_norm": 0.259765625,
      "learning_rate": 2.5404732254047325e-06,
      "loss": 0.6095,
      "step": 408
    },
    {
      "epoch": 0.039715914400523314,
      "grad_norm": 0.82861328125,
      "learning_rate": 2.646326276463263e-06,
      "loss": 0.4376,
      "step": 425
    },
    {
      "epoch": 0.04130455097654425,
      "grad_norm": 0.97509765625,
      "learning_rate": 2.7521793275217932e-06,
      "loss": 0.7023,
      "step": 442
    },
    {
      "epoch": 0.04289318755256518,
      "grad_norm": 0.2115478515625,
      "learning_rate": 2.858032378580324e-06,
      "loss": 0.5356,
      "step": 459
    },
    {
      "epoch": 0.04448182412858611,
      "grad_norm": 0.83154296875,
      "learning_rate": 2.963885429638855e-06,
      "loss": 0.4777,
      "step": 476
    },
    {
      "epoch": 0.04607046070460705,
      "grad_norm": 0.7978515625,
      "learning_rate": 3.069738480697385e-06,
      "loss": 0.6041,
      "step": 493
    },
    {
      "epoch": 0.04765909728062798,
      "grad_norm": 0.41748046875,
      "learning_rate": 3.1755915317559155e-06,
      "loss": 0.4227,
      "step": 510
    },
    {
      "epoch": 0.04924773385664891,
      "grad_norm": 0.8466796875,
      "learning_rate": 3.281444582814446e-06,
      "loss": 0.443,
      "step": 527
    },
    {
      "epoch": 0.05083637043266984,
      "grad_norm": 0.9345703125,
      "learning_rate": 3.3872976338729767e-06,
      "loss": 0.6736,
      "step": 544
    },
    {
      "epoch": 0.05242500700869078,
      "grad_norm": 0.5810546875,
      "learning_rate": 3.4931506849315072e-06,
      "loss": 0.384,
      "step": 561
    },
    {
      "epoch": 0.05401364358471171,
      "grad_norm": 0.68017578125,
      "learning_rate": 3.599003735990038e-06,
      "loss": 0.3962,
      "step": 578
    },
    {
      "epoch": 0.05560228016073264,
      "grad_norm": 1.443359375,
      "learning_rate": 3.704856787048568e-06,
      "loss": 0.6065,
      "step": 595
    },
    {
      "epoch": 0.057190916736753576,
      "grad_norm": 0.67578125,
      "learning_rate": 3.810709838107099e-06,
      "loss": 0.4176,
      "step": 612
    },
    {
      "epoch": 0.058779553312774506,
      "grad_norm": 0.6826171875,
      "learning_rate": 3.916562889165629e-06,
      "loss": 0.4848,
      "step": 629
    },
    {
      "epoch": 0.06036818988879544,
      "grad_norm": 1.1982421875,
      "learning_rate": 4.02241594022416e-06,
      "loss": 0.6994,
      "step": 646
    },
    {
      "epoch": 0.06195682646481637,
      "grad_norm": 0.52587890625,
      "learning_rate": 4.12826899128269e-06,
      "loss": 0.3928,
      "step": 663
    },
    {
      "epoch": 0.0635454630408373,
      "grad_norm": 1.2802734375,
      "learning_rate": 4.234122042341221e-06,
      "loss": 0.4216,
      "step": 680
    },
    {
      "epoch": 0.06513409961685823,
      "grad_norm": 1.1298828125,
      "learning_rate": 4.339975093399751e-06,
      "loss": 0.618,
      "step": 697
    },
    {
      "epoch": 0.06672273619287918,
      "grad_norm": 0.7412109375,
      "learning_rate": 4.4458281444582815e-06,
      "loss": 0.3223,
      "step": 714
    },
    {
      "epoch": 0.0683113727689001,
      "grad_norm": 1.58984375,
      "learning_rate": 4.5516811955168125e-06,
      "loss": 0.5041,
      "step": 731
    },
    {
      "epoch": 0.06990000934492104,
      "grad_norm": 1.41796875,
      "learning_rate": 4.657534246575343e-06,
      "loss": 0.6834,
      "step": 748
    },
    {
      "epoch": 0.07148864592094197,
      "grad_norm": 0.86083984375,
      "learning_rate": 4.763387297633874e-06,
      "loss": 0.2818,
      "step": 765
    },
    {
      "epoch": 0.0730772824969629,
      "grad_norm": 0.94189453125,
      "learning_rate": 4.869240348692404e-06,
      "loss": 0.431,
      "step": 782
    },
    {
      "epoch": 0.07466591907298384,
      "grad_norm": 1.87109375,
      "learning_rate": 4.975093399750934e-06,
      "loss": 0.632,
      "step": 799
    },
    {
      "epoch": 0.07625455564900477,
      "grad_norm": 0.83203125,
      "learning_rate": 5.080946450809465e-06,
      "loss": 0.3002,
      "step": 816
    },
    {
      "epoch": 0.0778431922250257,
      "grad_norm": 1.318359375,
      "learning_rate": 5.186799501867995e-06,
      "loss": 0.4234,
      "step": 833
    },
    {
      "epoch": 0.07943182880104663,
      "grad_norm": 1.84375,
      "learning_rate": 5.292652552926526e-06,
      "loss": 0.6675,
      "step": 850
    },
    {
      "epoch": 0.08102046537706756,
      "grad_norm": 0.9638671875,
      "learning_rate": 5.398505603985057e-06,
      "loss": 0.2349,
      "step": 867
    },
    {
      "epoch": 0.0826091019530885,
      "grad_norm": 0.955078125,
      "learning_rate": 5.5043586550435864e-06,
      "loss": 0.4604,
      "step": 884
    },
    {
      "epoch": 0.08419773852910943,
      "grad_norm": 0.29052734375,
      "learning_rate": 5.6102117061021174e-06,
      "loss": 0.5977,
      "step": 901
    },
    {
      "epoch": 0.08578637510513036,
      "grad_norm": 0.7275390625,
      "learning_rate": 5.716064757160648e-06,
      "loss": 0.2387,
      "step": 918
    },
    {
      "epoch": 0.08737501168115129,
      "grad_norm": 1.1982421875,
      "learning_rate": 5.821917808219179e-06,
      "loss": 0.4467,
      "step": 935
    },
    {
      "epoch": 0.08896364825717222,
      "grad_norm": 0.444091796875,
      "learning_rate": 5.92777085927771e-06,
      "loss": 0.5707,
      "step": 952
    },
    {
      "epoch": 0.09055228483319316,
      "grad_norm": 0.982421875,
      "learning_rate": 6.033623910336239e-06,
      "loss": 0.3508,
      "step": 969
    },
    {
      "epoch": 0.0921409214092141,
      "grad_norm": 1.3583984375,
      "learning_rate": 6.13947696139477e-06,
      "loss": 0.4969,
      "step": 986
    },
    {
      "epoch": 0.09372955798523502,
      "grad_norm": 0.222412109375,
      "learning_rate": 6.245330012453301e-06,
      "loss": 0.5931,
      "step": 1003
    },
    {
      "epoch": 0.09531819456125595,
      "grad_norm": 0.84619140625,
      "learning_rate": 6.351183063511831e-06,
      "loss": 0.3055,
      "step": 1020
    },
    {
      "epoch": 0.09690683113727688,
      "grad_norm": 1.484375,
      "learning_rate": 6.457036114570362e-06,
      "loss": 0.5078,
      "step": 1037
    },
    {
      "epoch": 0.09849546771329783,
      "grad_norm": 0.6533203125,
      "learning_rate": 6.562889165628892e-06,
      "loss": 0.5422,
      "step": 1054
    },
    {
      "epoch": 0.10008410428931876,
      "grad_norm": 1.162109375,
      "learning_rate": 6.668742216687422e-06,
      "loss": 0.2925,
      "step": 1071
    },
    {
      "epoch": 0.10167274086533969,
      "grad_norm": 1.6494140625,
      "learning_rate": 6.774595267745953e-06,
      "loss": 0.4744,
      "step": 1088
    },
    {
      "epoch": 0.10326137744136062,
      "grad_norm": 0.85009765625,
      "learning_rate": 6.8804483188044835e-06,
      "loss": 0.5842,
      "step": 1105
    },
    {
      "epoch": 0.10485001401738156,
      "grad_norm": 0.99853515625,
      "learning_rate": 6.9863013698630145e-06,
      "loss": 0.361,
      "step": 1122
    },
    {
      "epoch": 0.10643865059340249,
      "grad_norm": 2.166015625,
      "learning_rate": 7.092154420921545e-06,
      "loss": 0.4835,
      "step": 1139
    },
    {
      "epoch": 0.10802728716942342,
      "grad_norm": 0.6533203125,
      "learning_rate": 7.198007471980076e-06,
      "loss": 0.4625,
      "step": 1156
    },
    {
      "epoch": 0.10961592374544435,
      "grad_norm": 0.9951171875,
      "learning_rate": 7.303860523038606e-06,
      "loss": 0.3469,
      "step": 1173
    },
    {
      "epoch": 0.11120456032146528,
      "grad_norm": 3.162109375,
      "learning_rate": 7.409713574097136e-06,
      "loss": 0.5231,
      "step": 1190
    },
    {
      "epoch": 0.11279319689748622,
      "grad_norm": 0.455078125,
      "learning_rate": 7.515566625155667e-06,
      "loss": 0.4403,
      "step": 1207
    },
    {
      "epoch": 0.11438183347350715,
      "grad_norm": 1.091796875,
      "learning_rate": 7.621419676214198e-06,
      "loss": 0.3341,
      "step": 1224
    },
    {
      "epoch": 0.11597047004952808,
      "grad_norm": 2.255859375,
      "learning_rate": 7.727272727272727e-06,
      "loss": 0.5361,
      "step": 1241
    },
    {
      "epoch": 0.11755910662554901,
      "grad_norm": 0.5732421875,
      "learning_rate": 7.833125778331258e-06,
      "loss": 0.4021,
      "step": 1258
    },
    {
      "epoch": 0.11914774320156994,
      "grad_norm": 0.9658203125,
      "learning_rate": 7.93897882938979e-06,
      "loss": 0.3574,
      "step": 1275
    },
    {
      "epoch": 0.12073637977759089,
      "grad_norm": 1.7958984375,
      "learning_rate": 8.04483188044832e-06,
      "loss": 0.5173,
      "step": 1292
    },
    {
      "epoch": 0.12232501635361182,
      "grad_norm": 0.71923828125,
      "learning_rate": 8.150684931506851e-06,
      "loss": 0.4297,
      "step": 1309
    },
    {
      "epoch": 0.12391365292963274,
      "grad_norm": 1.091796875,
      "learning_rate": 8.25653798256538e-06,
      "loss": 0.3493,
      "step": 1326
    },
    {
      "epoch": 0.12550228950565367,
      "grad_norm": 3.525390625,
      "learning_rate": 8.362391033623912e-06,
      "loss": 0.5447,
      "step": 1343
    },
    {
      "epoch": 0.1270909260816746,
      "grad_norm": 0.63623046875,
      "learning_rate": 8.468244084682442e-06,
      "loss": 0.3913,
      "step": 1360
    },
    {
      "epoch": 0.12867956265769553,
      "grad_norm": 1.380859375,
      "learning_rate": 8.574097135740972e-06,
      "loss": 0.3514,
      "step": 1377
    },
    {
      "epoch": 0.13026819923371646,
      "grad_norm": 1.703125,
      "learning_rate": 8.679950186799503e-06,
      "loss": 0.5447,
      "step": 1394
    },
    {
      "epoch": 0.13185683580973742,
      "grad_norm": 0.5234375,
      "learning_rate": 8.785803237858032e-06,
      "loss": 0.3191,
      "step": 1411
    },
    {
      "epoch": 0.13344547238575835,
      "grad_norm": 1.115234375,
      "learning_rate": 8.891656288916563e-06,
      "loss": 0.3458,
      "step": 1428
    },
    {
      "epoch": 0.13503410896177928,
      "grad_norm": 1.392578125,
      "learning_rate": 8.997509339975094e-06,
      "loss": 0.5391,
      "step": 1445
    },
    {
      "epoch": 0.1366227455378002,
      "grad_norm": 0.60888671875,
      "learning_rate": 9.103362391033625e-06,
      "loss": 0.2989,
      "step": 1462
    },
    {
      "epoch": 0.13821138211382114,
      "grad_norm": 1.1220703125,
      "learning_rate": 9.209215442092156e-06,
      "loss": 0.3724,
      "step": 1479
    },
    {
      "epoch": 0.13980001868984207,
      "grad_norm": 2.53125,
      "learning_rate": 9.315068493150685e-06,
      "loss": 0.5454,
      "step": 1496
    },
    {
      "epoch": 0.141388655265863,
      "grad_norm": 0.6748046875,
      "learning_rate": 9.420921544209216e-06,
      "loss": 0.3114,
      "step": 1513
    },
    {
      "epoch": 0.14297729184188393,
      "grad_norm": 1.4423828125,
      "learning_rate": 9.526774595267747e-06,
      "loss": 0.3943,
      "step": 1530
    },
    {
      "epoch": 0.14456592841790486,
      "grad_norm": 2.107421875,
      "learning_rate": 9.632627646326277e-06,
      "loss": 0.62,
      "step": 1547
    },
    {
      "epoch": 0.1461545649939258,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.738480697384808e-06,
      "loss": 0.2803,
      "step": 1564
    },
    {
      "epoch": 0.14774320156994675,
      "grad_norm": 1.455078125,
      "learning_rate": 9.844333748443339e-06,
      "loss": 0.3949,
      "step": 1581
    },
    {
      "epoch": 0.14933183814596768,
      "grad_norm": 2.21875,
      "learning_rate": 9.950186799501868e-06,
      "loss": 0.6392,
      "step": 1598
    },
    {
      "epoch": 0.1509204747219886,
      "grad_norm": 0.765625,
      "learning_rate": 9.999997851128222e-06,
      "loss": 0.2648,
      "step": 1615
    },
    {
      "epoch": 0.15250911129800954,
      "grad_norm": 1.33984375,
      "learning_rate": 9.999982066215332e-06,
      "loss": 0.3933,
      "step": 1632
    },
    {
      "epoch": 0.15409774787403047,
      "grad_norm": 2.046875,
      "learning_rate": 9.999950947435717e-06,
      "loss": 0.6,
      "step": 1649
    },
    {
      "epoch": 0.1556863844500514,
      "grad_norm": 0.65966796875,
      "learning_rate": 9.999904494884808e-06,
      "loss": 0.2117,
      "step": 1666
    },
    {
      "epoch": 0.15727502102607233,
      "grad_norm": 1.177734375,
      "learning_rate": 9.999842708705073e-06,
      "loss": 0.3763,
      "step": 1683
    },
    {
      "epoch": 0.15886365760209326,
      "grad_norm": 2.9765625,
      "learning_rate": 9.999765589085988e-06,
      "loss": 0.5906,
      "step": 1700
    },
    {
      "epoch": 0.16045229417811419,
      "grad_norm": 0.90185546875,
      "learning_rate": 9.999673136264067e-06,
      "loss": 0.265,
      "step": 1717
    },
    {
      "epoch": 0.16204093075413512,
      "grad_norm": 1.48046875,
      "learning_rate": 9.999565350522841e-06,
      "loss": 0.4085,
      "step": 1734
    },
    {
      "epoch": 0.16362956733015607,
      "grad_norm": 0.5478515625,
      "learning_rate": 9.999442232192867e-06,
      "loss": 0.5989,
      "step": 1751
    },
    {
      "epoch": 0.165218203906177,
      "grad_norm": 1.064453125,
      "learning_rate": 9.999303781651722e-06,
      "loss": 0.2099,
      "step": 1768
    },
    {
      "epoch": 0.16680684048219793,
      "grad_norm": 1.28125,
      "learning_rate": 9.999149999324002e-06,
      "loss": 0.4079,
      "step": 1785
    },
    {
      "epoch": 0.16839547705821886,
      "grad_norm": 0.37451171875,
      "learning_rate": 9.998980885681328e-06,
      "loss": 0.5364,
      "step": 1802
    },
    {
      "epoch": 0.1699841136342398,
      "grad_norm": 1.296875,
      "learning_rate": 9.998796441242333e-06,
      "loss": 0.2434,
      "step": 1819
    },
    {
      "epoch": 0.17157275021026072,
      "grad_norm": 1.68359375,
      "learning_rate": 9.998596666572668e-06,
      "loss": 0.4581,
      "step": 1836
    },
    {
      "epoch": 0.17316138678628165,
      "grad_norm": 0.09356689453125,
      "learning_rate": 9.998381562284999e-06,
      "loss": 0.5137,
      "step": 1853
    },
    {
      "epoch": 0.17475002336230258,
      "grad_norm": 1.197265625,
      "learning_rate": 9.998151129039005e-06,
      "loss": 0.2999,
      "step": 1870
    },
    {
      "epoch": 0.1763386599383235,
      "grad_norm": 1.2822265625,
      "learning_rate": 9.997905367541374e-06,
      "loss": 0.4893,
      "step": 1887
    },
    {
      "epoch": 0.17792729651434444,
      "grad_norm": 0.406005859375,
      "learning_rate": 9.997644278545805e-06,
      "loss": 0.4657,
      "step": 1904
    },
    {
      "epoch": 0.1795159330903654,
      "grad_norm": 1.0361328125,
      "learning_rate": 9.997367862853e-06,
      "loss": 0.2577,
      "step": 1921
    },
    {
      "epoch": 0.18110456966638633,
      "grad_norm": 1.94921875,
      "learning_rate": 9.997076121310668e-06,
      "loss": 0.4479,
      "step": 1938
    },
    {
      "epoch": 0.18269320624240726,
      "grad_norm": 0.51708984375,
      "learning_rate": 9.996769054813517e-06,
      "loss": 0.4454,
      "step": 1955
    },
    {
      "epoch": 0.1842818428184282,
      "grad_norm": 1.0224609375,
      "learning_rate": 9.996446664303252e-06,
      "loss": 0.2745,
      "step": 1972
    },
    {
      "epoch": 0.18587047939444912,
      "grad_norm": 1.5078125,
      "learning_rate": 9.996108950768579e-06,
      "loss": 0.5063,
      "step": 1989
    },
    {
      "epoch": 0.18745911597047005,
      "grad_norm": 0.59130859375,
      "learning_rate": 9.995755915245187e-06,
      "loss": 0.4971,
      "step": 2006
    },
    {
      "epoch": 0.18904775254649098,
      "grad_norm": 1.302734375,
      "learning_rate": 9.995387558815764e-06,
      "loss": 0.2852,
      "step": 2023
    },
    {
      "epoch": 0.1906363891225119,
      "grad_norm": 1.7626953125,
      "learning_rate": 9.99500388260998e-06,
      "loss": 0.4934,
      "step": 2040
    },
    {
      "epoch": 0.19222502569853284,
      "grad_norm": 0.47216796875,
      "learning_rate": 9.994604887804484e-06,
      "loss": 0.4508,
      "step": 2057
    },
    {
      "epoch": 0.19381366227455377,
      "grad_norm": 1.041015625,
      "learning_rate": 9.99419057562291e-06,
      "loss": 0.3276,
      "step": 2074
    },
    {
      "epoch": 0.19540229885057472,
      "grad_norm": 1.5029296875,
      "learning_rate": 9.993760947335863e-06,
      "loss": 0.5077,
      "step": 2091
    },
    {
      "epoch": 0.19699093542659565,
      "grad_norm": 0.638671875,
      "learning_rate": 9.99331600426092e-06,
      "loss": 0.4407,
      "step": 2108
    },
    {
      "epoch": 0.19857957200261658,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.992855747762625e-06,
      "loss": 0.3315,
      "step": 2125
    },
    {
      "epoch": 0.2001682085786375,
      "grad_norm": 1.5556640625,
      "learning_rate": 9.992380179252487e-06,
      "loss": 0.5101,
      "step": 2142
    },
    {
      "epoch": 0.20175684515465844,
      "grad_norm": 0.708984375,
      "learning_rate": 9.991889300188971e-06,
      "loss": 0.4032,
      "step": 2159
    },
    {
      "epoch": 0.20334548173067937,
      "grad_norm": 1.126953125,
      "learning_rate": 9.991383112077498e-06,
      "loss": 0.3304,
      "step": 2176
    },
    {
      "epoch": 0.2049341183067003,
      "grad_norm": 1.6201171875,
      "learning_rate": 9.990861616470434e-06,
      "loss": 0.5363,
      "step": 2193
    },
    {
      "epoch": 0.20652275488272123,
      "grad_norm": 0.74267578125,
      "learning_rate": 9.990324814967101e-06,
      "loss": 0.4124,
      "step": 2210
    },
    {
      "epoch": 0.20811139145874216,
      "grad_norm": 1.119140625,
      "learning_rate": 9.989772709213747e-06,
      "loss": 0.3725,
      "step": 2227
    },
    {
      "epoch": 0.20970002803476312,
      "grad_norm": 1.853515625,
      "learning_rate": 9.989205300903563e-06,
      "loss": 0.5147,
      "step": 2244
    },
    {
      "epoch": 0.21128866461078405,
      "grad_norm": 0.66015625,
      "learning_rate": 9.98862259177667e-06,
      "loss": 0.328,
      "step": 2261
    },
    {
      "epoch": 0.21287730118680498,
      "grad_norm": 1.2216796875,
      "learning_rate": 9.988024583620108e-06,
      "loss": 0.3662,
      "step": 2278
    },
    {
      "epoch": 0.2144659377628259,
      "grad_norm": 1.9306640625,
      "learning_rate": 9.987411278267842e-06,
      "loss": 0.5264,
      "step": 2295
    },
    {
      "epoch": 0.21605457433884684,
      "grad_norm": 0.82861328125,
      "learning_rate": 9.986782677600747e-06,
      "loss": 0.3458,
      "step": 2312
    },
    {
      "epoch": 0.21764321091486777,
      "grad_norm": 1.4697265625,
      "learning_rate": 9.986138783546603e-06,
      "loss": 0.4036,
      "step": 2329
    },
    {
      "epoch": 0.2192318474908887,
      "grad_norm": 2.091796875,
      "learning_rate": 9.985479598080095e-06,
      "loss": 0.561,
      "step": 2346
    },
    {
      "epoch": 0.22082048406690963,
      "grad_norm": 0.64453125,
      "learning_rate": 9.984805123222804e-06,
      "loss": 0.2843,
      "step": 2363
    },
    {
      "epoch": 0.22240912064293056,
      "grad_norm": 1.4150390625,
      "learning_rate": 9.9841153610432e-06,
      "loss": 0.3401,
      "step": 2380
    },
    {
      "epoch": 0.2239977572189515,
      "grad_norm": 1.7470703125,
      "learning_rate": 9.983410313656633e-06,
      "loss": 0.5495,
      "step": 2397
    },
    {
      "epoch": 0.22558639379497245,
      "grad_norm": 0.7314453125,
      "learning_rate": 9.98268998322533e-06,
      "loss": 0.2932,
      "step": 2414
    },
    {
      "epoch": 0.22717503037099337,
      "grad_norm": 1.6337890625,
      "learning_rate": 9.981954371958392e-06,
      "loss": 0.4074,
      "step": 2431
    },
    {
      "epoch": 0.2287636669470143,
      "grad_norm": 2.181640625,
      "learning_rate": 9.981203482111779e-06,
      "loss": 0.5556,
      "step": 2448
    },
    {
      "epoch": 0.23035230352303523,
      "grad_norm": 0.88818359375,
      "learning_rate": 9.980437315988307e-06,
      "loss": 0.2335,
      "step": 2465
    },
    {
      "epoch": 0.23194094009905616,
      "grad_norm": 1.58984375,
      "learning_rate": 9.979655875937644e-06,
      "loss": 0.4066,
      "step": 2482
    },
    {
      "epoch": 0.2335295766750771,
      "grad_norm": 3.404296875,
      "learning_rate": 9.978859164356298e-06,
      "loss": 0.5986,
      "step": 2499
    },
    {
      "epoch": 0.23511821325109802,
      "grad_norm": 0.970703125,
      "learning_rate": 9.97804718368761e-06,
      "loss": 0.2273,
      "step": 2516
    },
    {
      "epoch": 0.23670684982711895,
      "grad_norm": 1.6474609375,
      "learning_rate": 9.977219936421749e-06,
      "loss": 0.3798,
      "step": 2533
    },
    {
      "epoch": 0.23829548640313988,
      "grad_norm": 2.923828125,
      "learning_rate": 9.976377425095708e-06,
      "loss": 0.5819,
      "step": 2550
    },
    {
      "epoch": 0.2398841229791608,
      "grad_norm": 0.83837890625,
      "learning_rate": 9.975519652293284e-06,
      "loss": 0.2694,
      "step": 2567
    },
    {
      "epoch": 0.24147275955518177,
      "grad_norm": 1.5986328125,
      "learning_rate": 9.974646620645083e-06,
      "loss": 0.3822,
      "step": 2584
    },
    {
      "epoch": 0.2430613961312027,
      "grad_norm": 0.404052734375,
      "learning_rate": 9.973758332828504e-06,
      "loss": 0.5388,
      "step": 2601
    },
    {
      "epoch": 0.24465003270722363,
      "grad_norm": 1.015625,
      "learning_rate": 9.972854791567734e-06,
      "loss": 0.2384,
      "step": 2618
    },
    {
      "epoch": 0.24623866928324456,
      "grad_norm": 1.779296875,
      "learning_rate": 9.97193599963374e-06,
      "loss": 0.4567,
      "step": 2635
    },
    {
      "epoch": 0.2478273058592655,
      "grad_norm": 0.463134765625,
      "learning_rate": 9.971001959844257e-06,
      "loss": 0.5347,
      "step": 2652
    },
    {
      "epoch": 0.24941594243528642,
      "grad_norm": 1.205078125,
      "learning_rate": 9.970052675063787e-06,
      "loss": 0.2553,
      "step": 2669
    },
    {
      "epoch": 0.25100457901130735,
      "grad_norm": 1.7578125,
      "learning_rate": 9.969088148203579e-06,
      "loss": 0.4713,
      "step": 2686
    },
    {
      "epoch": 0.2525932155873283,
      "grad_norm": 0.403076171875,
      "learning_rate": 9.968108382221627e-06,
      "loss": 0.5314,
      "step": 2703
    },
    {
      "epoch": 0.2541818521633492,
      "grad_norm": 0.98291015625,
      "learning_rate": 9.967113380122666e-06,
      "loss": 0.2274,
      "step": 2720
    },
    {
      "epoch": 0.25577048873937014,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.966103144958152e-06,
      "loss": 0.4455,
      "step": 2737
    },
    {
      "epoch": 0.25735912531539107,
      "grad_norm": 0.466552734375,
      "learning_rate": 9.965077679826256e-06,
      "loss": 0.4896,
      "step": 2754
    },
    {
      "epoch": 0.258947761891412,
      "grad_norm": 1.0419921875,
      "learning_rate": 9.964036987871861e-06,
      "loss": 0.2658,
      "step": 2771
    },
    {
      "epoch": 0.26053639846743293,
      "grad_norm": 2.078125,
      "learning_rate": 9.962981072286545e-06,
      "loss": 0.4868,
      "step": 2788
    },
    {
      "epoch": 0.26212503504345386,
      "grad_norm": 1.203125,
      "learning_rate": 9.96190993630857e-06,
      "loss": 0.4055,
      "step": 2805
    },
    {
      "epoch": 0.26371367161947484,
      "grad_norm": 1.0390625,
      "learning_rate": 9.96082358322288e-06,
      "loss": 0.2543,
      "step": 2822
    },
    {
      "epoch": 0.2653023081954958,
      "grad_norm": 2.037109375,
      "learning_rate": 9.95972201636109e-06,
      "loss": 0.4767,
      "step": 2839
    },
    {
      "epoch": 0.2668909447715167,
      "grad_norm": 0.67431640625,
      "learning_rate": 9.958605239101463e-06,
      "loss": 0.4612,
      "step": 2856
    },
    {
      "epoch": 0.26847958134753763,
      "grad_norm": 1.0087890625,
      "learning_rate": 9.957473254868917e-06,
      "loss": 0.2772,
      "step": 2873
    },
    {
      "epoch": 0.27006821792355856,
      "grad_norm": 1.63671875,
      "learning_rate": 9.956326067135002e-06,
      "loss": 0.5177,
      "step": 2890
    },
    {
      "epoch": 0.2716568544995795,
      "grad_norm": 0.48583984375,
      "learning_rate": 9.955163679417896e-06,
      "loss": 0.4457,
      "step": 2907
    },
    {
      "epoch": 0.2732454910756004,
      "grad_norm": 1.255859375,
      "learning_rate": 9.95398609528239e-06,
      "loss": 0.3055,
      "step": 2924
    },
    {
      "epoch": 0.27483412765162135,
      "grad_norm": 1.7099609375,
      "learning_rate": 9.952793318339884e-06,
      "loss": 0.5562,
      "step": 2941
    },
    {
      "epoch": 0.2764227642276423,
      "grad_norm": 0.6337890625,
      "learning_rate": 9.951585352248365e-06,
      "loss": 0.3751,
      "step": 2958
    },
    {
      "epoch": 0.2780114008036632,
      "grad_norm": 1.15625,
      "learning_rate": 9.950362200712405e-06,
      "loss": 0.2979,
      "step": 2975
    },
    {
      "epoch": 0.27960003737968414,
      "grad_norm": 2.228515625,
      "learning_rate": 9.949123867483146e-06,
      "loss": 0.5297,
      "step": 2992
    },
    {
      "epoch": 0.28118867395570507,
      "grad_norm": 0.65283203125,
      "learning_rate": 9.947870356358287e-06,
      "loss": 0.3912,
      "step": 3009
    },
    {
      "epoch": 0.282777310531726,
      "grad_norm": 1.6064453125,
      "learning_rate": 9.94660167118208e-06,
      "loss": 0.3376,
      "step": 3026
    },
    {
      "epoch": 0.28436594710774693,
      "grad_norm": 2.18359375,
      "learning_rate": 9.945317815845307e-06,
      "loss": 0.5291,
      "step": 3043
    },
    {
      "epoch": 0.28595458368376786,
      "grad_norm": 0.93701171875,
      "learning_rate": 9.944018794285276e-06,
      "loss": 0.4249,
      "step": 3060
    },
    {
      "epoch": 0.2875432202597888,
      "grad_norm": 1.7197265625,
      "learning_rate": 9.942704610485803e-06,
      "loss": 0.3531,
      "step": 3077
    },
    {
      "epoch": 0.2891318568358097,
      "grad_norm": 2.181640625,
      "learning_rate": 9.94137526847721e-06,
      "loss": 0.5112,
      "step": 3094
    },
    {
      "epoch": 0.29072049341183065,
      "grad_norm": 0.533203125,
      "learning_rate": 9.940030772336303e-06,
      "loss": 0.3746,
      "step": 3111
    },
    {
      "epoch": 0.2923091299878516,
      "grad_norm": 1.5009765625,
      "learning_rate": 9.938671126186358e-06,
      "loss": 0.3515,
      "step": 3128
    },
    {
      "epoch": 0.2938977665638725,
      "grad_norm": 1.9814453125,
      "learning_rate": 9.93729633419712e-06,
      "loss": 0.4941,
      "step": 3145
    },
    {
      "epoch": 0.2954864031398935,
      "grad_norm": 0.79736328125,
      "learning_rate": 9.935906400584777e-06,
      "loss": 0.3307,
      "step": 3162
    },
    {
      "epoch": 0.2970750397159144,
      "grad_norm": 1.5244140625,
      "learning_rate": 9.934501329611957e-06,
      "loss": 0.3344,
      "step": 3179
    },
    {
      "epoch": 0.29866367629193535,
      "grad_norm": 2.0078125,
      "learning_rate": 9.933081125587706e-06,
      "loss": 0.5522,
      "step": 3196
    },
    {
      "epoch": 0.3002523128679563,
      "grad_norm": 0.96484375,
      "learning_rate": 9.93164579286749e-06,
      "loss": 0.3031,
      "step": 3213
    },
    {
      "epoch": 0.3018409494439772,
      "grad_norm": 1.4365234375,
      "learning_rate": 9.930195335853161e-06,
      "loss": 0.3945,
      "step": 3230
    },
    {
      "epoch": 0.30342958601999814,
      "grad_norm": 2.33984375,
      "learning_rate": 9.928729758992959e-06,
      "loss": 0.6077,
      "step": 3247
    },
    {
      "epoch": 0.3050182225960191,
      "grad_norm": 0.837890625,
      "learning_rate": 9.92724906678149e-06,
      "loss": 0.287,
      "step": 3264
    },
    {
      "epoch": 0.30660685917204,
      "grad_norm": 1.21875,
      "learning_rate": 9.92575326375972e-06,
      "loss": 0.3536,
      "step": 3281
    },
    {
      "epoch": 0.30819549574806093,
      "grad_norm": 2.48828125,
      "learning_rate": 9.924242354514953e-06,
      "loss": 0.5431,
      "step": 3298
    },
    {
      "epoch": 0.30978413232408186,
      "grad_norm": 0.775390625,
      "learning_rate": 9.922716343680823e-06,
      "loss": 0.2308,
      "step": 3315
    },
    {
      "epoch": 0.3113727689001028,
      "grad_norm": 1.4072265625,
      "learning_rate": 9.921175235937274e-06,
      "loss": 0.3154,
      "step": 3332
    },
    {
      "epoch": 0.3129614054761237,
      "grad_norm": 2.732421875,
      "learning_rate": 9.919619036010556e-06,
      "loss": 0.5608,
      "step": 3349
    },
    {
      "epoch": 0.31455004205214465,
      "grad_norm": 0.85400390625,
      "learning_rate": 9.918047748673194e-06,
      "loss": 0.206,
      "step": 3366
    },
    {
      "epoch": 0.3161386786281656,
      "grad_norm": 1.517578125,
      "learning_rate": 9.916461378743986e-06,
      "loss": 0.408,
      "step": 3383
    },
    {
      "epoch": 0.3177273152041865,
      "grad_norm": 3.0859375,
      "learning_rate": 9.914859931087992e-06,
      "loss": 0.6006,
      "step": 3400
    },
    {
      "epoch": 0.31931595178020744,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.913243410616502e-06,
      "loss": 0.2072,
      "step": 3417
    },
    {
      "epoch": 0.32090458835622837,
      "grad_norm": 1.5771484375,
      "learning_rate": 9.911611822287039e-06,
      "loss": 0.3664,
      "step": 3434
    },
    {
      "epoch": 0.3224932249322493,
      "grad_norm": 0.478271484375,
      "learning_rate": 9.909965171103331e-06,
      "loss": 0.5675,
      "step": 3451
    },
    {
      "epoch": 0.32408186150827023,
      "grad_norm": 1.4599609375,
      "learning_rate": 9.9083034621153e-06,
      "loss": 0.2956,
      "step": 3468
    },
    {
      "epoch": 0.32567049808429116,
      "grad_norm": 1.916015625,
      "learning_rate": 9.906626700419053e-06,
      "loss": 0.508,
      "step": 3485
    },
    {
      "epoch": 0.32725913466031215,
      "grad_norm": 0.2264404296875,
      "learning_rate": 9.904934891156852e-06,
      "loss": 0.5779,
      "step": 3502
    },
    {
      "epoch": 0.3288477712363331,
      "grad_norm": 0.9326171875,
      "learning_rate": 9.903228039517116e-06,
      "loss": 0.2653,
      "step": 3519
    },
    {
      "epoch": 0.330436407812354,
      "grad_norm": 1.8564453125,
      "learning_rate": 9.901506150734388e-06,
      "loss": 0.4316,
      "step": 3536
    },
    {
      "epoch": 0.33202504438837493,
      "grad_norm": 0.2393798828125,
      "learning_rate": 9.89976923008933e-06,
      "loss": 0.5253,
      "step": 3553
    },
    {
      "epoch": 0.33361368096439586,
      "grad_norm": 1.1494140625,
      "learning_rate": 9.898017282908703e-06,
      "loss": 0.2703,
      "step": 3570
    },
    {
      "epoch": 0.3352023175404168,
      "grad_norm": 1.39453125,
      "learning_rate": 9.896250314565353e-06,
      "loss": 0.4118,
      "step": 3587
    },
    {
      "epoch": 0.3367909541164377,
      "grad_norm": 0.1776123046875,
      "learning_rate": 9.894468330478189e-06,
      "loss": 0.4546,
      "step": 3604
    },
    {
      "epoch": 0.33837959069245865,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.892671336112172e-06,
      "loss": 0.2198,
      "step": 3621
    },
    {
      "epoch": 0.3399682272684796,
      "grad_norm": 1.54296875,
      "learning_rate": 9.890859336978295e-06,
      "loss": 0.4696,
      "step": 3638
    },
    {
      "epoch": 0.3415568638445005,
      "grad_norm": 0.5634765625,
      "learning_rate": 9.889032338633571e-06,
      "loss": 0.4633,
      "step": 3655
    },
    {
      "epoch": 0.34314550042052144,
      "grad_norm": 1.216796875,
      "learning_rate": 9.887190346681009e-06,
      "loss": 0.2919,
      "step": 3672
    },
    {
      "epoch": 0.3447341369965424,
      "grad_norm": 1.935546875,
      "learning_rate": 9.8853333667696e-06,
      "loss": 0.4891,
      "step": 3689
    },
    {
      "epoch": 0.3463227735725633,
      "grad_norm": 0.81494140625,
      "learning_rate": 9.883461404594303e-06,
      "loss": 0.4659,
      "step": 3706
    },
    {
      "epoch": 0.34791141014858423,
      "grad_norm": 1.5263671875,
      "learning_rate": 9.881574465896022e-06,
      "loss": 0.3132,
      "step": 3723
    },
    {
      "epoch": 0.34950004672460516,
      "grad_norm": 1.98046875,
      "learning_rate": 9.879672556461588e-06,
      "loss": 0.4814,
      "step": 3740
    },
    {
      "epoch": 0.3510886833006261,
      "grad_norm": 0.77783203125,
      "learning_rate": 9.877755682123751e-06,
      "loss": 0.4218,
      "step": 3757
    },
    {
      "epoch": 0.352677319876647,
      "grad_norm": 1.412109375,
      "learning_rate": 9.875823848761148e-06,
      "loss": 0.3357,
      "step": 3774
    },
    {
      "epoch": 0.35426595645266795,
      "grad_norm": 2.35546875,
      "learning_rate": 9.873877062298298e-06,
      "loss": 0.4997,
      "step": 3791
    },
    {
      "epoch": 0.3558545930286889,
      "grad_norm": 0.751953125,
      "learning_rate": 9.871915328705574e-06,
      "loss": 0.411,
      "step": 3808
    },
    {
      "epoch": 0.35744322960470987,
      "grad_norm": 1.3388671875,
      "learning_rate": 9.869938653999191e-06,
      "loss": 0.3062,
      "step": 3825
    },
    {
      "epoch": 0.3590318661807308,
      "grad_norm": 2.27734375,
      "learning_rate": 9.867947044241182e-06,
      "loss": 0.5262,
      "step": 3842
    },
    {
      "epoch": 0.3606205027567517,
      "grad_norm": 0.72705078125,
      "learning_rate": 9.865940505539386e-06,
      "loss": 0.5616,
      "step": 3859
    },
    {
      "epoch": 0.36220913933277266,
      "grad_norm": 1.3564453125,
      "learning_rate": 9.863919044047423e-06,
      "loss": 0.3186,
      "step": 3876
    },
    {
      "epoch": 0.3637977759087936,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.861882665964681e-06,
      "loss": 0.5198,
      "step": 3893
    },
    {
      "epoch": 0.3653864124848145,
      "grad_norm": 0.69873046875,
      "learning_rate": 9.859831377536293e-06,
      "loss": 0.3628,
      "step": 3910
    },
    {
      "epoch": 0.36697504906083545,
      "grad_norm": 1.1484375,
      "learning_rate": 9.857765185053116e-06,
      "loss": 0.3079,
      "step": 3927
    },
    {
      "epoch": 0.3685636856368564,
      "grad_norm": 2.169921875,
      "learning_rate": 9.85568409485172e-06,
      "loss": 0.545,
      "step": 3944
    },
    {
      "epoch": 0.3701523222128773,
      "grad_norm": 0.6591796875,
      "learning_rate": 9.853588113314354e-06,
      "loss": 0.3379,
      "step": 3961
    },
    {
      "epoch": 0.37174095878889823,
      "grad_norm": 1.201171875,
      "learning_rate": 9.851477246868948e-06,
      "loss": 0.352,
      "step": 3978
    },
    {
      "epoch": 0.37332959536491916,
      "grad_norm": 1.83203125,
      "learning_rate": 9.84935150198907e-06,
      "loss": 0.5088,
      "step": 3995
    },
    {
      "epoch": 0.3749182319409401,
      "grad_norm": 0.7421875,
      "learning_rate": 9.847210885193925e-06,
      "loss": 0.3166,
      "step": 4012
    },
    {
      "epoch": 0.376506868516961,
      "grad_norm": 1.2998046875,
      "learning_rate": 9.845055403048319e-06,
      "loss": 0.3658,
      "step": 4029
    },
    {
      "epoch": 0.37809550509298195,
      "grad_norm": 2.263671875,
      "learning_rate": 9.842885062162653e-06,
      "loss": 0.5306,
      "step": 4046
    },
    {
      "epoch": 0.3796841416690029,
      "grad_norm": 0.77783203125,
      "learning_rate": 9.840699869192894e-06,
      "loss": 0.2993,
      "step": 4063
    },
    {
      "epoch": 0.3812727782450238,
      "grad_norm": 1.36328125,
      "learning_rate": 9.838499830840555e-06,
      "loss": 0.3392,
      "step": 4080
    },
    {
      "epoch": 0.38286141482104474,
      "grad_norm": 2.095703125,
      "learning_rate": 9.836284953852684e-06,
      "loss": 0.5235,
      "step": 4097
    },
    {
      "epoch": 0.3844500513970657,
      "grad_norm": 0.984375,
      "learning_rate": 9.83405524502183e-06,
      "loss": 0.2942,
      "step": 4114
    },
    {
      "epoch": 0.3860386879730866,
      "grad_norm": 1.484375,
      "learning_rate": 9.831810711186025e-06,
      "loss": 0.3817,
      "step": 4131
    },
    {
      "epoch": 0.38762732454910753,
      "grad_norm": 2.125,
      "learning_rate": 9.829551359228774e-06,
      "loss": 0.5732,
      "step": 4148
    },
    {
      "epoch": 0.3892159611251285,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.827277196079024e-06,
      "loss": 0.2473,
      "step": 4165
    },
    {
      "epoch": 0.39080459770114945,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.824988228711138e-06,
      "loss": 0.4134,
      "step": 4182
    },
    {
      "epoch": 0.3923932342771704,
      "grad_norm": 2.427734375,
      "learning_rate": 9.822684464144888e-06,
      "loss": 0.5259,
      "step": 4199
    },
    {
      "epoch": 0.3939818708531913,
      "grad_norm": 0.86669921875,
      "learning_rate": 9.820365909445422e-06,
      "loss": 0.2343,
      "step": 4216
    },
    {
      "epoch": 0.39557050742921224,
      "grad_norm": 1.2109375,
      "learning_rate": 9.818032571723249e-06,
      "loss": 0.3131,
      "step": 4233
    },
    {
      "epoch": 0.39715914400523317,
      "grad_norm": 2.55859375,
      "learning_rate": 9.815684458134212e-06,
      "loss": 0.5624,
      "step": 4250
    },
    {
      "epoch": 0.3987477805812541,
      "grad_norm": 0.87548828125,
      "learning_rate": 9.813321575879466e-06,
      "loss": 0.1775,
      "step": 4267
    },
    {
      "epoch": 0.400336417157275,
      "grad_norm": 1.50390625,
      "learning_rate": 9.810943932205465e-06,
      "loss": 0.4143,
      "step": 4284
    },
    {
      "epoch": 0.40192505373329596,
      "grad_norm": 0.337158203125,
      "learning_rate": 9.808551534403929e-06,
      "loss": 0.5695,
      "step": 4301
    },
    {
      "epoch": 0.4035136903093169,
      "grad_norm": 0.8671875,
      "learning_rate": 9.806144389811824e-06,
      "loss": 0.2241,
      "step": 4318
    },
    {
      "epoch": 0.4051023268853378,
      "grad_norm": 1.6708984375,
      "learning_rate": 9.803722505811348e-06,
      "loss": 0.4214,
      "step": 4335
    },
    {
      "epoch": 0.40669096346135875,
      "grad_norm": 0.418701171875,
      "learning_rate": 9.80128588982989e-06,
      "loss": 0.5379,
      "step": 4352
    },
    {
      "epoch": 0.4082796000373797,
      "grad_norm": 1.02734375,
      "learning_rate": 9.798834549340031e-06,
      "loss": 0.2635,
      "step": 4369
    },
    {
      "epoch": 0.4098682366134006,
      "grad_norm": 1.45703125,
      "learning_rate": 9.796368491859502e-06,
      "loss": 0.4358,
      "step": 4386
    },
    {
      "epoch": 0.41145687318942153,
      "grad_norm": 0.37548828125,
      "learning_rate": 9.79388772495117e-06,
      "loss": 0.4854,
      "step": 4403
    },
    {
      "epoch": 0.41304550976544246,
      "grad_norm": 1.1064453125,
      "learning_rate": 9.791392256223012e-06,
      "loss": 0.2499,
      "step": 4420
    },
    {
      "epoch": 0.4146341463414634,
      "grad_norm": 1.810546875,
      "learning_rate": 9.788882093328089e-06,
      "loss": 0.4545,
      "step": 4437
    },
    {
      "epoch": 0.4162227829174843,
      "grad_norm": 0.265625,
      "learning_rate": 9.786357243964534e-06,
      "loss": 0.4673,
      "step": 4454
    },
    {
      "epoch": 0.41781141949350525,
      "grad_norm": 0.91455078125,
      "learning_rate": 9.783817715875517e-06,
      "loss": 0.2094,
      "step": 4471
    },
    {
      "epoch": 0.41940005606952624,
      "grad_norm": 1.876953125,
      "learning_rate": 9.781263516849216e-06,
      "loss": 0.402,
      "step": 4488
    },
    {
      "epoch": 0.42098869264554717,
      "grad_norm": 0.4345703125,
      "learning_rate": 9.778694654718813e-06,
      "loss": 0.4357,
      "step": 4505
    },
    {
      "epoch": 0.4225773292215681,
      "grad_norm": 0.8837890625,
      "learning_rate": 9.776111137362453e-06,
      "loss": 0.2856,
      "step": 4522
    },
    {
      "epoch": 0.42416596579758903,
      "grad_norm": 1.7802734375,
      "learning_rate": 9.77351297270323e-06,
      "loss": 0.4591,
      "step": 4539
    },
    {
      "epoch": 0.42575460237360996,
      "grad_norm": 0.72216796875,
      "learning_rate": 9.77090016870915e-06,
      "loss": 0.407,
      "step": 4556
    },
    {
      "epoch": 0.4273432389496309,
      "grad_norm": 1.265625,
      "learning_rate": 9.768272733393121e-06,
      "loss": 0.2999,
      "step": 4573
    },
    {
      "epoch": 0.4289318755256518,
      "grad_norm": 1.7109375,
      "learning_rate": 9.765630674812921e-06,
      "loss": 0.4681,
      "step": 4590
    },
    {
      "epoch": 0.43052051210167275,
      "grad_norm": 0.53076171875,
      "learning_rate": 9.762974001071175e-06,
      "loss": 0.363,
      "step": 4607
    },
    {
      "epoch": 0.4321091486776937,
      "grad_norm": 1.25390625,
      "learning_rate": 9.760302720315325e-06,
      "loss": 0.3099,
      "step": 4624
    },
    {
      "epoch": 0.4336977852537146,
      "grad_norm": 1.927734375,
      "learning_rate": 9.757616840737615e-06,
      "loss": 0.5074,
      "step": 4641
    },
    {
      "epoch": 0.43528642182973554,
      "grad_norm": 0.5927734375,
      "learning_rate": 9.75491637057506e-06,
      "loss": 0.4154,
      "step": 4658
    },
    {
      "epoch": 0.43687505840575647,
      "grad_norm": 1.4169921875,
      "learning_rate": 9.752201318109417e-06,
      "loss": 0.2808,
      "step": 4675
    },
    {
      "epoch": 0.4384636949817774,
      "grad_norm": 1.607421875,
      "learning_rate": 9.74947169166717e-06,
      "loss": 0.4569,
      "step": 4692
    },
    {
      "epoch": 0.4400523315577983,
      "grad_norm": 0.8046875,
      "learning_rate": 9.74672749961949e-06,
      "loss": 0.3568,
      "step": 4709
    },
    {
      "epoch": 0.44164096813381926,
      "grad_norm": 1.384765625,
      "learning_rate": 9.743968750382225e-06,
      "loss": 0.3673,
      "step": 4726
    },
    {
      "epoch": 0.4432296047098402,
      "grad_norm": 1.8779296875,
      "learning_rate": 9.741195452415864e-06,
      "loss": 0.4955,
      "step": 4743
    },
    {
      "epoch": 0.4448182412858611,
      "grad_norm": 0.59130859375,
      "learning_rate": 9.738407614225512e-06,
      "loss": 0.3545,
      "step": 4760
    },
    {
      "epoch": 0.44640687786188205,
      "grad_norm": 1.2578125,
      "learning_rate": 9.735605244360868e-06,
      "loss": 0.3063,
      "step": 4777
    },
    {
      "epoch": 0.447995514437903,
      "grad_norm": 2.44921875,
      "learning_rate": 9.732788351416197e-06,
      "loss": 0.5086,
      "step": 4794
    },
    {
      "epoch": 0.4495841510139239,
      "grad_norm": 0.75634765625,
      "learning_rate": 9.729956944030303e-06,
      "loss": 0.324,
      "step": 4811
    },
    {
      "epoch": 0.4511727875899449,
      "grad_norm": 1.388671875,
      "learning_rate": 9.7271110308865e-06,
      "loss": 0.3301,
      "step": 4828
    },
    {
      "epoch": 0.4527614241659658,
      "grad_norm": 2.08984375,
      "learning_rate": 9.724250620712592e-06,
      "loss": 0.5004,
      "step": 4845
    },
    {
      "epoch": 0.45435006074198675,
      "grad_norm": 0.806640625,
      "learning_rate": 9.721375722280837e-06,
      "loss": 0.3057,
      "step": 4862
    },
    {
      "epoch": 0.4559386973180077,
      "grad_norm": 1.91796875,
      "learning_rate": 9.718486344407932e-06,
      "loss": 0.4073,
      "step": 4879
    },
    {
      "epoch": 0.4575273338940286,
      "grad_norm": 2.13671875,
      "learning_rate": 9.715582495954972e-06,
      "loss": 0.5447,
      "step": 4896
    },
    {
      "epoch": 0.45911597047004954,
      "grad_norm": 0.75048828125,
      "learning_rate": 9.712664185827437e-06,
      "loss": 0.2754,
      "step": 4913
    },
    {
      "epoch": 0.46070460704607047,
      "grad_norm": 1.1904296875,
      "learning_rate": 9.709731422975155e-06,
      "loss": 0.3766,
      "step": 4930
    },
    {
      "epoch": 0.4622932436220914,
      "grad_norm": 1.98828125,
      "learning_rate": 9.706784216392274e-06,
      "loss": 0.4748,
      "step": 4947
    },
    {
      "epoch": 0.46388188019811233,
      "grad_norm": 0.8525390625,
      "learning_rate": 9.703822575117243e-06,
      "loss": 0.2786,
      "step": 4964
    },
    {
      "epoch": 0.46547051677413326,
      "grad_norm": 1.5380859375,
      "learning_rate": 9.700846508232778e-06,
      "loss": 0.3988,
      "step": 4981
    },
    {
      "epoch": 0.4670591533501542,
      "grad_norm": 2.5,
      "learning_rate": 9.697856024865835e-06,
      "loss": 0.5408,
      "step": 4998
    },
    {
      "epoch": 0.4686477899261751,
      "grad_norm": 1.01953125,
      "learning_rate": 9.694851134187578e-06,
      "loss": 0.263,
      "step": 5015
    },
    {
      "epoch": 0.47023642650219605,
      "grad_norm": 1.283203125,
      "learning_rate": 9.691831845413362e-06,
      "loss": 0.3988,
      "step": 5032
    },
    {
      "epoch": 0.471825063078217,
      "grad_norm": 2.224609375,
      "learning_rate": 9.688798167802693e-06,
      "loss": 0.616,
      "step": 5049
    },
    {
      "epoch": 0.4734136996542379,
      "grad_norm": 0.822265625,
      "learning_rate": 9.685750110659206e-06,
      "loss": 0.1851,
      "step": 5066
    },
    {
      "epoch": 0.47500233623025884,
      "grad_norm": 1.2666015625,
      "learning_rate": 9.682687683330636e-06,
      "loss": 0.3746,
      "step": 5083
    },
    {
      "epoch": 0.47659097280627977,
      "grad_norm": 2.953125,
      "learning_rate": 9.679610895208785e-06,
      "loss": 0.6085,
      "step": 5100
    },
    {
      "epoch": 0.4781796093823007,
      "grad_norm": 1.01171875,
      "learning_rate": 9.6765197557295e-06,
      "loss": 0.2046,
      "step": 5117
    },
    {
      "epoch": 0.4797682459583216,
      "grad_norm": 1.6572265625,
      "learning_rate": 9.673414274372641e-06,
      "loss": 0.4254,
      "step": 5134
    },
    {
      "epoch": 0.4813568825343426,
      "grad_norm": 0.4345703125,
      "learning_rate": 9.670294460662048e-06,
      "loss": 0.608,
      "step": 5151
    },
    {
      "epoch": 0.48294551911036354,
      "grad_norm": 0.98974609375,
      "learning_rate": 9.667160324165516e-06,
      "loss": 0.2329,
      "step": 5168
    },
    {
      "epoch": 0.48453415568638447,
      "grad_norm": 1.41015625,
      "learning_rate": 9.664011874494766e-06,
      "loss": 0.3831,
      "step": 5185
    },
    {
      "epoch": 0.4861227922624054,
      "grad_norm": 0.304931640625,
      "learning_rate": 9.660849121305414e-06,
      "loss": 0.5174,
      "step": 5202
    },
    {
      "epoch": 0.48771142883842633,
      "grad_norm": 0.875,
      "learning_rate": 9.657672074296944e-06,
      "loss": 0.2318,
      "step": 5219
    },
    {
      "epoch": 0.48930006541444726,
      "grad_norm": 1.623046875,
      "learning_rate": 9.654480743212672e-06,
      "loss": 0.4244,
      "step": 5236
    },
    {
      "epoch": 0.4908887019904682,
      "grad_norm": 0.19677734375,
      "learning_rate": 9.651275137839723e-06,
      "loss": 0.5229,
      "step": 5253
    },
    {
      "epoch": 0.4924773385664891,
      "grad_norm": 0.9189453125,
      "learning_rate": 9.648055268008997e-06,
      "loss": 0.2287,
      "step": 5270
    },
    {
      "epoch": 0.49406597514251005,
      "grad_norm": 1.62109375,
      "learning_rate": 9.64482114359514e-06,
      "loss": 0.4199,
      "step": 5287
    },
    {
      "epoch": 0.495654611718531,
      "grad_norm": 0.2281494140625,
      "learning_rate": 9.641572774516516e-06,
      "loss": 0.4793,
      "step": 5304
    },
    {
      "epoch": 0.4972432482945519,
      "grad_norm": 1.15625,
      "learning_rate": 9.63831017073517e-06,
      "loss": 0.2725,
      "step": 5321
    },
    {
      "epoch": 0.49883188487057284,
      "grad_norm": 1.7001953125,
      "learning_rate": 9.635033342256805e-06,
      "loss": 0.4374,
      "step": 5338
    },
    {
      "epoch": 0.5004205214465938,
      "grad_norm": 0.433349609375,
      "learning_rate": 9.63174229913075e-06,
      "loss": 0.4318,
      "step": 5355
    },
    {
      "epoch": 0.5020091580226147,
      "grad_norm": 1.046875,
      "learning_rate": 9.62843705144992e-06,
      "loss": 0.2716,
      "step": 5372
    },
    {
      "epoch": 0.5035977945986356,
      "grad_norm": 2.1875,
      "learning_rate": 9.6251176093508e-06,
      "loss": 0.4876,
      "step": 5389
    },
    {
      "epoch": 0.5051864311746566,
      "grad_norm": 0.3447265625,
      "learning_rate": 9.621783983013401e-06,
      "loss": 0.4381,
      "step": 5406
    },
    {
      "epoch": 0.5067750677506775,
      "grad_norm": 1.205078125,
      "learning_rate": 9.618436182661237e-06,
      "loss": 0.285,
      "step": 5423
    },
    {
      "epoch": 0.5083637043266984,
      "grad_norm": 2.310546875,
      "learning_rate": 9.615074218561291e-06,
      "loss": 0.4788,
      "step": 5440
    },
    {
      "epoch": 0.5099523409027193,
      "grad_norm": 0.271728515625,
      "learning_rate": 9.61169810102398e-06,
      "loss": 0.4248,
      "step": 5457
    },
    {
      "epoch": 0.5115409774787403,
      "grad_norm": 0.9267578125,
      "learning_rate": 9.60830784040313e-06,
      "loss": 0.2277,
      "step": 5474
    },
    {
      "epoch": 0.5131296140547612,
      "grad_norm": 1.6455078125,
      "learning_rate": 9.604903447095938e-06,
      "loss": 0.4025,
      "step": 5491
    },
    {
      "epoch": 0.5147182506307821,
      "grad_norm": 0.71240234375,
      "learning_rate": 9.601484931542943e-06,
      "loss": 0.4283,
      "step": 5508
    },
    {
      "epoch": 0.5163068872068031,
      "grad_norm": 1.0087890625,
      "learning_rate": 9.598052304227998e-06,
      "loss": 0.2746,
      "step": 5525
    },
    {
      "epoch": 0.517895523782824,
      "grad_norm": 1.572265625,
      "learning_rate": 9.594605575678228e-06,
      "loss": 0.4994,
      "step": 5542
    },
    {
      "epoch": 0.5194841603588449,
      "grad_norm": 0.568359375,
      "learning_rate": 9.591144756464008e-06,
      "loss": 0.3607,
      "step": 5559
    },
    {
      "epoch": 0.5210727969348659,
      "grad_norm": 1.150390625,
      "learning_rate": 9.587669857198925e-06,
      "loss": 0.3021,
      "step": 5576
    },
    {
      "epoch": 0.5226614335108868,
      "grad_norm": 1.5888671875,
      "learning_rate": 9.584180888539741e-06,
      "loss": 0.4276,
      "step": 5593
    },
    {
      "epoch": 0.5242500700869077,
      "grad_norm": 0.71142578125,
      "learning_rate": 9.580677861186377e-06,
      "loss": 0.3128,
      "step": 5610
    },
    {
      "epoch": 0.5258387066629286,
      "grad_norm": 1.201171875,
      "learning_rate": 9.577160785881855e-06,
      "loss": 0.3417,
      "step": 5627
    },
    {
      "epoch": 0.5274273432389497,
      "grad_norm": 2.05859375,
      "learning_rate": 9.573629673412293e-06,
      "loss": 0.5145,
      "step": 5644
    },
    {
      "epoch": 0.5290159798149706,
      "grad_norm": 0.64208984375,
      "learning_rate": 9.57008453460685e-06,
      "loss": 0.3125,
      "step": 5661
    },
    {
      "epoch": 0.5306046163909915,
      "grad_norm": 1.044921875,
      "learning_rate": 9.5665253803377e-06,
      "loss": 0.3029,
      "step": 5678
    },
    {
      "epoch": 0.5321932529670125,
      "grad_norm": 2.09375,
      "learning_rate": 9.56295222152e-06,
      "loss": 0.515,
      "step": 5695
    },
    {
      "epoch": 0.5337818895430334,
      "grad_norm": 1.0810546875,
      "learning_rate": 9.559365069111864e-06,
      "loss": 0.2806,
      "step": 5712
    },
    {
      "epoch": 0.5353705261190543,
      "grad_norm": 1.3232421875,
      "learning_rate": 9.555763934114309e-06,
      "loss": 0.3166,
      "step": 5729
    },
    {
      "epoch": 0.5369591626950753,
      "grad_norm": 2.236328125,
      "learning_rate": 9.552148827571241e-06,
      "loss": 0.512,
      "step": 5746
    },
    {
      "epoch": 0.5385477992710962,
      "grad_norm": 1.1650390625,
      "learning_rate": 9.548519760569415e-06,
      "loss": 0.3119,
      "step": 5763
    },
    {
      "epoch": 0.5401364358471171,
      "grad_norm": 1.5068359375,
      "learning_rate": 9.544876744238394e-06,
      "loss": 0.36,
      "step": 5780
    },
    {
      "epoch": 0.541725072423138,
      "grad_norm": 2.099609375,
      "learning_rate": 9.541219789750523e-06,
      "loss": 0.5053,
      "step": 5797
    },
    {
      "epoch": 0.543313708999159,
      "grad_norm": 0.79296875,
      "learning_rate": 9.537548908320895e-06,
      "loss": 0.2412,
      "step": 5814
    },
    {
      "epoch": 0.5449023455751799,
      "grad_norm": 1.7060546875,
      "learning_rate": 9.53386411120731e-06,
      "loss": 0.365,
      "step": 5831
    },
    {
      "epoch": 0.5464909821512008,
      "grad_norm": 2.990234375,
      "learning_rate": 9.530165409710246e-06,
      "loss": 0.5525,
      "step": 5848
    },
    {
      "epoch": 0.5480796187272218,
      "grad_norm": 0.857421875,
      "learning_rate": 9.526452815172824e-06,
      "loss": 0.3103,
      "step": 5865
    },
    {
      "epoch": 0.5496682553032427,
      "grad_norm": 1.458984375,
      "learning_rate": 9.52272633898077e-06,
      "loss": 0.4252,
      "step": 5882
    },
    {
      "epoch": 0.5512568918792636,
      "grad_norm": 2.52734375,
      "learning_rate": 9.518985992562383e-06,
      "loss": 0.5485,
      "step": 5899
    },
    {
      "epoch": 0.5528455284552846,
      "grad_norm": 1.2783203125,
      "learning_rate": 9.515231787388499e-06,
      "loss": 0.2215,
      "step": 5916
    },
    {
      "epoch": 0.5544341650313055,
      "grad_norm": 1.2705078125,
      "learning_rate": 9.511463734972456e-06,
      "loss": 0.404,
      "step": 5933
    },
    {
      "epoch": 0.5560228016073264,
      "grad_norm": 2.103515625,
      "learning_rate": 9.507681846870058e-06,
      "loss": 0.5888,
      "step": 5950
    },
    {
      "epoch": 0.5576114381833474,
      "grad_norm": 1.064453125,
      "learning_rate": 9.503886134679539e-06,
      "loss": 0.1894,
      "step": 5967
    },
    {
      "epoch": 0.5592000747593683,
      "grad_norm": 1.091796875,
      "learning_rate": 9.500076610041531e-06,
      "loss": 0.3988,
      "step": 5984
    },
    {
      "epoch": 0.5607887113353892,
      "grad_norm": 0.273681640625,
      "learning_rate": 9.496253284639024e-06,
      "loss": 0.5466,
      "step": 6001
    },
    {
      "epoch": 0.5623773479114101,
      "grad_norm": 1.224609375,
      "learning_rate": 9.492416170197333e-06,
      "loss": 0.2423,
      "step": 6018
    },
    {
      "epoch": 0.5639659844874311,
      "grad_norm": 1.2763671875,
      "learning_rate": 9.48856527848406e-06,
      "loss": 0.3584,
      "step": 6035
    },
    {
      "epoch": 0.565554621063452,
      "grad_norm": 0.37841796875,
      "learning_rate": 9.484700621309059e-06,
      "loss": 0.4996,
      "step": 6052
    },
    {
      "epoch": 0.5671432576394729,
      "grad_norm": 0.9658203125,
      "learning_rate": 9.480822210524402e-06,
      "loss": 0.2162,
      "step": 6069
    },
    {
      "epoch": 0.5687318942154939,
      "grad_norm": 1.4443359375,
      "learning_rate": 9.476930058024338e-06,
      "loss": 0.4194,
      "step": 6086
    },
    {
      "epoch": 0.5703205307915148,
      "grad_norm": 0.08843994140625,
      "learning_rate": 9.473024175745258e-06,
      "loss": 0.5071,
      "step": 6103
    },
    {
      "epoch": 0.5719091673675357,
      "grad_norm": 0.99072265625,
      "learning_rate": 9.46910457566566e-06,
      "loss": 0.1799,
      "step": 6120
    },
    {
      "epoch": 0.5734978039435566,
      "grad_norm": 1.7734375,
      "learning_rate": 9.465171269806114e-06,
      "loss": 0.4229,
      "step": 6137
    },
    {
      "epoch": 0.5750864405195776,
      "grad_norm": 0.373046875,
      "learning_rate": 9.46122427022922e-06,
      "loss": 0.4709,
      "step": 6154
    },
    {
      "epoch": 0.5766750770955985,
      "grad_norm": 1.40625,
      "learning_rate": 9.457263589039575e-06,
      "loss": 0.2852,
      "step": 6171
    },
    {
      "epoch": 0.5782637136716194,
      "grad_norm": 1.541015625,
      "learning_rate": 9.453289238383735e-06,
      "loss": 0.447,
      "step": 6188
    },
    {
      "epoch": 0.5798523502476404,
      "grad_norm": 0.724609375,
      "learning_rate": 9.449301230450173e-06,
      "loss": 0.4427,
      "step": 6205
    },
    {
      "epoch": 0.5814409868236613,
      "grad_norm": 1.2216796875,
      "learning_rate": 9.445299577469252e-06,
      "loss": 0.3075,
      "step": 6222
    },
    {
      "epoch": 0.5830296233996822,
      "grad_norm": 1.857421875,
      "learning_rate": 9.44128429171318e-06,
      "loss": 0.5006,
      "step": 6239
    },
    {
      "epoch": 0.5846182599757032,
      "grad_norm": 0.4912109375,
      "learning_rate": 9.437255385495969e-06,
      "loss": 0.4722,
      "step": 6256
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 1.08203125,
      "learning_rate": 9.433212871173407e-06,
      "loss": 0.319,
      "step": 6273
    },
    {
      "epoch": 0.587795533127745,
      "grad_norm": 1.6484375,
      "learning_rate": 9.429156761143014e-06,
      "loss": 0.4377,
      "step": 6290
    },
    {
      "epoch": 0.589384169703766,
      "grad_norm": 0.51416015625,
      "learning_rate": 9.425087067844005e-06,
      "loss": 0.4439,
      "step": 6307
    },
    {
      "epoch": 0.590972806279787,
      "grad_norm": 0.98046875,
      "learning_rate": 9.421003803757251e-06,
      "loss": 0.2866,
      "step": 6324
    },
    {
      "epoch": 0.5925614428558079,
      "grad_norm": 1.53515625,
      "learning_rate": 9.416906981405242e-06,
      "loss": 0.3949,
      "step": 6341
    },
    {
      "epoch": 0.5941500794318288,
      "grad_norm": 0.654296875,
      "learning_rate": 9.41279661335205e-06,
      "loss": 0.3554,
      "step": 6358
    },
    {
      "epoch": 0.5957387160078498,
      "grad_norm": 1.1337890625,
      "learning_rate": 9.408672712203287e-06,
      "loss": 0.3003,
      "step": 6375
    },
    {
      "epoch": 0.5973273525838707,
      "grad_norm": 2.009765625,
      "learning_rate": 9.404535290606068e-06,
      "loss": 0.5044,
      "step": 6392
    },
    {
      "epoch": 0.5989159891598916,
      "grad_norm": 0.494384765625,
      "learning_rate": 9.400384361248973e-06,
      "loss": 0.363,
      "step": 6409
    },
    {
      "epoch": 0.6000373796841416,
      "eval_loss": 0.38770315051078796,
      "eval_runtime": 1038.5043,
      "eval_samples_per_second": 7.727,
      "eval_steps_per_second": 2.576,
      "step": 6421
    },
    {
      "epoch": 0.6005046257359126,
      "grad_norm": 1.0927734375,
      "learning_rate": 9.396219936862008e-06,
      "loss": 0.2706,
      "step": 6426
    },
    {
      "epoch": 0.6020932623119335,
      "grad_norm": 1.9951171875,
      "learning_rate": 9.392042030216561e-06,
      "loss": 0.4537,
      "step": 6443
    },
    {
      "epoch": 0.6036818988879544,
      "grad_norm": 0.90869140625,
      "learning_rate": 9.387850654125375e-06,
      "loss": 0.3885,
      "step": 6460
    },
    {
      "epoch": 0.6052705354639754,
      "grad_norm": 1.44140625,
      "learning_rate": 9.383645821442495e-06,
      "loss": 0.3306,
      "step": 6477
    },
    {
      "epoch": 0.6068591720399963,
      "grad_norm": 1.9736328125,
      "learning_rate": 9.379427545063236e-06,
      "loss": 0.5751,
      "step": 6494
    },
    {
      "epoch": 0.6084478086160172,
      "grad_norm": 0.7861328125,
      "learning_rate": 9.375195837924142e-06,
      "loss": 0.3031,
      "step": 6511
    },
    {
      "epoch": 0.6100364451920381,
      "grad_norm": 1.482421875,
      "learning_rate": 9.370950713002947e-06,
      "loss": 0.3213,
      "step": 6528
    },
    {
      "epoch": 0.6116250817680591,
      "grad_norm": 2.265625,
      "learning_rate": 9.36669218331853e-06,
      "loss": 0.5077,
      "step": 6545
    },
    {
      "epoch": 0.61321371834408,
      "grad_norm": 0.66064453125,
      "learning_rate": 9.362420261930888e-06,
      "loss": 0.3154,
      "step": 6562
    },
    {
      "epoch": 0.6148023549201009,
      "grad_norm": 1.7568359375,
      "learning_rate": 9.358134961941082e-06,
      "loss": 0.3484,
      "step": 6579
    },
    {
      "epoch": 0.6163909914961219,
      "grad_norm": 2.14453125,
      "learning_rate": 9.353836296491198e-06,
      "loss": 0.5259,
      "step": 6596
    },
    {
      "epoch": 0.6179796280721428,
      "grad_norm": 0.82275390625,
      "learning_rate": 9.349524278764321e-06,
      "loss": 0.2758,
      "step": 6613
    },
    {
      "epoch": 0.6195682646481637,
      "grad_norm": 1.365234375,
      "learning_rate": 9.34519892198448e-06,
      "loss": 0.3363,
      "step": 6630
    },
    {
      "epoch": 0.6211569012241847,
      "grad_norm": 2.11328125,
      "learning_rate": 9.340860239416606e-06,
      "loss": 0.5382,
      "step": 6647
    },
    {
      "epoch": 0.6227455378002056,
      "grad_norm": 1.1103515625,
      "learning_rate": 9.336508244366508e-06,
      "loss": 0.3293,
      "step": 6664
    },
    {
      "epoch": 0.6243341743762265,
      "grad_norm": 1.4619140625,
      "learning_rate": 9.332142950180813e-06,
      "loss": 0.4003,
      "step": 6681
    },
    {
      "epoch": 0.6259228109522474,
      "grad_norm": 2.287109375,
      "learning_rate": 9.32776437024694e-06,
      "loss": 0.5724,
      "step": 6698
    },
    {
      "epoch": 0.6275114475282684,
      "grad_norm": 1.0908203125,
      "learning_rate": 9.323372517993048e-06,
      "loss": 0.2507,
      "step": 6715
    },
    {
      "epoch": 0.6291000841042893,
      "grad_norm": 1.697265625,
      "learning_rate": 9.318967406887997e-06,
      "loss": 0.4369,
      "step": 6732
    },
    {
      "epoch": 0.6306887206803102,
      "grad_norm": 2.794921875,
      "learning_rate": 9.31454905044132e-06,
      "loss": 0.5626,
      "step": 6749
    },
    {
      "epoch": 0.6322773572563312,
      "grad_norm": 0.98974609375,
      "learning_rate": 9.310117462203158e-06,
      "loss": 0.2286,
      "step": 6766
    },
    {
      "epoch": 0.6338659938323521,
      "grad_norm": 1.6181640625,
      "learning_rate": 9.305672655764237e-06,
      "loss": 0.417,
      "step": 6783
    },
    {
      "epoch": 0.635454630408373,
      "grad_norm": 2.64453125,
      "learning_rate": 9.301214644755823e-06,
      "loss": 0.5178,
      "step": 6800
    },
    {
      "epoch": 0.637043266984394,
      "grad_norm": 0.8515625,
      "learning_rate": 9.29674344284967e-06,
      "loss": 0.1778,
      "step": 6817
    },
    {
      "epoch": 0.6386319035604149,
      "grad_norm": 1.44140625,
      "learning_rate": 9.292259063757993e-06,
      "loss": 0.4437,
      "step": 6834
    },
    {
      "epoch": 0.6402205401364358,
      "grad_norm": 0.91552734375,
      "learning_rate": 9.287761521233416e-06,
      "loss": 0.5764,
      "step": 6851
    },
    {
      "epoch": 0.6418091767124567,
      "grad_norm": 1.1669921875,
      "learning_rate": 9.28325082906893e-06,
      "loss": 0.2388,
      "step": 6868
    },
    {
      "epoch": 0.6433978132884777,
      "grad_norm": 1.5703125,
      "learning_rate": 9.278727001097855e-06,
      "loss": 0.4473,
      "step": 6885
    },
    {
      "epoch": 0.6449864498644986,
      "grad_norm": 0.226806640625,
      "learning_rate": 9.274190051193797e-06,
      "loss": 0.5338,
      "step": 6902
    },
    {
      "epoch": 0.6465750864405195,
      "grad_norm": 1.0966796875,
      "learning_rate": 9.269639993270602e-06,
      "loss": 0.2211,
      "step": 6919
    },
    {
      "epoch": 0.6481637230165405,
      "grad_norm": 1.3427734375,
      "learning_rate": 9.265076841282318e-06,
      "loss": 0.4037,
      "step": 6936
    },
    {
      "epoch": 0.6497523595925614,
      "grad_norm": 0.267822265625,
      "learning_rate": 9.260500609223149e-06,
      "loss": 0.4799,
      "step": 6953
    },
    {
      "epoch": 0.6513409961685823,
      "grad_norm": 0.85009765625,
      "learning_rate": 9.255911311127406e-06,
      "loss": 0.2615,
      "step": 6970
    },
    {
      "epoch": 0.6529296327446034,
      "grad_norm": 1.35546875,
      "learning_rate": 9.251308961069483e-06,
      "loss": 0.3903,
      "step": 6987
    },
    {
      "epoch": 0.6545182693206243,
      "grad_norm": 0.348388671875,
      "learning_rate": 9.246693573163792e-06,
      "loss": 0.4429,
      "step": 7004
    },
    {
      "epoch": 0.6561069058966452,
      "grad_norm": 1.3681640625,
      "learning_rate": 9.242065161564733e-06,
      "loss": 0.2546,
      "step": 7021
    },
    {
      "epoch": 0.6576955424726662,
      "grad_norm": 1.6494140625,
      "learning_rate": 9.237423740466647e-06,
      "loss": 0.484,
      "step": 7038
    },
    {
      "epoch": 0.6592841790486871,
      "grad_norm": 0.43603515625,
      "learning_rate": 9.23276932410377e-06,
      "loss": 0.4673,
      "step": 7055
    },
    {
      "epoch": 0.660872815624708,
      "grad_norm": 1.17578125,
      "learning_rate": 9.228101926750194e-06,
      "loss": 0.2579,
      "step": 7072
    },
    {
      "epoch": 0.6624614522007289,
      "grad_norm": 2.033203125,
      "learning_rate": 9.223421562719821e-06,
      "loss": 0.4563,
      "step": 7089
    },
    {
      "epoch": 0.6640500887767499,
      "grad_norm": 0.87646484375,
      "learning_rate": 9.218728246366316e-06,
      "loss": 0.4641,
      "step": 7106
    },
    {
      "epoch": 0.6656387253527708,
      "grad_norm": 0.84814453125,
      "learning_rate": 9.214021992083071e-06,
      "loss": 0.2785,
      "step": 7123
    },
    {
      "epoch": 0.6672273619287917,
      "grad_norm": 2.595703125,
      "learning_rate": 9.20930281430315e-06,
      "loss": 0.5061,
      "step": 7140
    },
    {
      "epoch": 0.6688159985048127,
      "grad_norm": 0.55859375,
      "learning_rate": 9.204570727499256e-06,
      "loss": 0.4073,
      "step": 7157
    },
    {
      "epoch": 0.6704046350808336,
      "grad_norm": 1.083984375,
      "learning_rate": 9.199825746183678e-06,
      "loss": 0.291,
      "step": 7174
    },
    {
      "epoch": 0.6719932716568545,
      "grad_norm": 2.955078125,
      "learning_rate": 9.195067884908248e-06,
      "loss": 0.4732,
      "step": 7191
    },
    {
      "epoch": 0.6735819082328754,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.190297158264302e-06,
      "loss": 0.4065,
      "step": 7208
    },
    {
      "epoch": 0.6751705448088964,
      "grad_norm": 1.3232421875,
      "learning_rate": 9.185513580882633e-06,
      "loss": 0.2948,
      "step": 7225
    },
    {
      "epoch": 0.6767591813849173,
      "grad_norm": 2.03515625,
      "learning_rate": 9.180717167433438e-06,
      "loss": 0.4618,
      "step": 7242
    },
    {
      "epoch": 0.6783478179609382,
      "grad_norm": 0.6484375,
      "learning_rate": 9.175907932626283e-06,
      "loss": 0.3842,
      "step": 7259
    },
    {
      "epoch": 0.6799364545369592,
      "grad_norm": 1.416015625,
      "learning_rate": 9.171085891210054e-06,
      "loss": 0.2983,
      "step": 7276
    },
    {
      "epoch": 0.6815250911129801,
      "grad_norm": 2.076171875,
      "learning_rate": 9.166251057972912e-06,
      "loss": 0.4953,
      "step": 7293
    },
    {
      "epoch": 0.683113727689001,
      "grad_norm": 0.7958984375,
      "learning_rate": 9.161403447742248e-06,
      "loss": 0.3542,
      "step": 7310
    },
    {
      "epoch": 0.684702364265022,
      "grad_norm": 1.345703125,
      "learning_rate": 9.156543075384637e-06,
      "loss": 0.333,
      "step": 7327
    },
    {
      "epoch": 0.6862910008410429,
      "grad_norm": 2.484375,
      "learning_rate": 9.151669955805796e-06,
      "loss": 0.5339,
      "step": 7344
    },
    {
      "epoch": 0.6878796374170638,
      "grad_norm": 0.81591796875,
      "learning_rate": 9.146784103950526e-06,
      "loss": 0.3254,
      "step": 7361
    },
    {
      "epoch": 0.6894682739930847,
      "grad_norm": 1.66796875,
      "learning_rate": 9.141885534802686e-06,
      "loss": 0.3474,
      "step": 7378
    },
    {
      "epoch": 0.6910569105691057,
      "grad_norm": 1.9287109375,
      "learning_rate": 9.136974263385128e-06,
      "loss": 0.4733,
      "step": 7395
    },
    {
      "epoch": 0.6926455471451266,
      "grad_norm": 0.783203125,
      "learning_rate": 9.132050304759666e-06,
      "loss": 0.3208,
      "step": 7412
    },
    {
      "epoch": 0.6942341837211475,
      "grad_norm": 1.4931640625,
      "learning_rate": 9.127113674027013e-06,
      "loss": 0.3582,
      "step": 7429
    },
    {
      "epoch": 0.6958228202971685,
      "grad_norm": 2.431640625,
      "learning_rate": 9.122164386326757e-06,
      "loss": 0.5215,
      "step": 7446
    },
    {
      "epoch": 0.6974114568731894,
      "grad_norm": 1.005859375,
      "learning_rate": 9.117202456837293e-06,
      "loss": 0.2535,
      "step": 7463
    },
    {
      "epoch": 0.6990000934492103,
      "grad_norm": 1.603515625,
      "learning_rate": 9.11222790077579e-06,
      "loss": 0.3575,
      "step": 7480
    },
    {
      "epoch": 0.7005887300252313,
      "grad_norm": 2.328125,
      "learning_rate": 9.107240733398139e-06,
      "loss": 0.4937,
      "step": 7497
    },
    {
      "epoch": 0.7021773666012522,
      "grad_norm": 0.84033203125,
      "learning_rate": 9.102240969998904e-06,
      "loss": 0.2808,
      "step": 7514
    },
    {
      "epoch": 0.7037660031772731,
      "grad_norm": 1.3154296875,
      "learning_rate": 9.097228625911283e-06,
      "loss": 0.3629,
      "step": 7531
    },
    {
      "epoch": 0.705354639753294,
      "grad_norm": 2.49609375,
      "learning_rate": 9.092203716507055e-06,
      "loss": 0.5001,
      "step": 7548
    },
    {
      "epoch": 0.706943276329315,
      "grad_norm": 0.7802734375,
      "learning_rate": 9.087166257196534e-06,
      "loss": 0.2256,
      "step": 7565
    },
    {
      "epoch": 0.7085319129053359,
      "grad_norm": 1.2744140625,
      "learning_rate": 9.082116263428518e-06,
      "loss": 0.3411,
      "step": 7582
    },
    {
      "epoch": 0.7101205494813568,
      "grad_norm": 2.5859375,
      "learning_rate": 9.077053750690252e-06,
      "loss": 0.5795,
      "step": 7599
    },
    {
      "epoch": 0.7117091860573778,
      "grad_norm": 1.17578125,
      "learning_rate": 9.07197873450737e-06,
      "loss": 0.2563,
      "step": 7616
    },
    {
      "epoch": 0.7132978226333987,
      "grad_norm": 1.41796875,
      "learning_rate": 9.066891230443851e-06,
      "loss": 0.3713,
      "step": 7633
    },
    {
      "epoch": 0.7148864592094197,
      "grad_norm": 2.435546875,
      "learning_rate": 9.061791254101975e-06,
      "loss": 0.5464,
      "step": 7650
    },
    {
      "epoch": 0.7164750957854407,
      "grad_norm": 1.1220703125,
      "learning_rate": 9.056678821122268e-06,
      "loss": 0.2008,
      "step": 7667
    },
    {
      "epoch": 0.7180637323614616,
      "grad_norm": 1.8505859375,
      "learning_rate": 9.05155394718346e-06,
      "loss": 0.4434,
      "step": 7684
    },
    {
      "epoch": 0.7196523689374825,
      "grad_norm": 0.2333984375,
      "learning_rate": 9.046416648002433e-06,
      "loss": 0.5842,
      "step": 7701
    },
    {
      "epoch": 0.7212410055135035,
      "grad_norm": 1.228515625,
      "learning_rate": 9.04126693933418e-06,
      "loss": 0.1999,
      "step": 7718
    },
    {
      "epoch": 0.7228296420895244,
      "grad_norm": 1.5693359375,
      "learning_rate": 9.03610483697174e-06,
      "loss": 0.4003,
      "step": 7735
    },
    {
      "epoch": 0.7244182786655453,
      "grad_norm": 0.03564453125,
      "learning_rate": 9.030930356746173e-06,
      "loss": 0.5111,
      "step": 7752
    },
    {
      "epoch": 0.7260069152415662,
      "grad_norm": 1.189453125,
      "learning_rate": 9.025743514526493e-06,
      "loss": 0.2424,
      "step": 7769
    },
    {
      "epoch": 0.7275955518175872,
      "grad_norm": 1.7080078125,
      "learning_rate": 9.020544326219625e-06,
      "loss": 0.462,
      "step": 7786
    },
    {
      "epoch": 0.7291841883936081,
      "grad_norm": 0.5263671875,
      "learning_rate": 9.015332807770359e-06,
      "loss": 0.5362,
      "step": 7803
    },
    {
      "epoch": 0.730772824969629,
      "grad_norm": 1.427734375,
      "learning_rate": 9.010108975161297e-06,
      "loss": 0.3223,
      "step": 7820
    },
    {
      "epoch": 0.73236146154565,
      "grad_norm": 1.6904296875,
      "learning_rate": 9.004872844412811e-06,
      "loss": 0.4806,
      "step": 7837
    },
    {
      "epoch": 0.7339500981216709,
      "grad_norm": 0.5634765625,
      "learning_rate": 8.99962443158298e-06,
      "loss": 0.4956,
      "step": 7854
    },
    {
      "epoch": 0.7355387346976918,
      "grad_norm": 1.0185546875,
      "learning_rate": 8.994363752767557e-06,
      "loss": 0.2681,
      "step": 7871
    },
    {
      "epoch": 0.7371273712737128,
      "grad_norm": 1.8310546875,
      "learning_rate": 8.98909082409991e-06,
      "loss": 0.4442,
      "step": 7888
    },
    {
      "epoch": 0.7387160078497337,
      "grad_norm": 0.533203125,
      "learning_rate": 8.983805661750972e-06,
      "loss": 0.4797,
      "step": 7905
    },
    {
      "epoch": 0.7403046444257546,
      "grad_norm": 1.263671875,
      "learning_rate": 8.9785082819292e-06,
      "loss": 0.3004,
      "step": 7922
    },
    {
      "epoch": 0.7418932810017755,
      "grad_norm": 1.8154296875,
      "learning_rate": 8.97319870088051e-06,
      "loss": 0.4745,
      "step": 7939
    },
    {
      "epoch": 0.7434819175777965,
      "grad_norm": 0.6728515625,
      "learning_rate": 8.967876934888245e-06,
      "loss": 0.4404,
      "step": 7956
    },
    {
      "epoch": 0.7450705541538174,
      "grad_norm": 1.1865234375,
      "learning_rate": 8.962543000273113e-06,
      "loss": 0.2779,
      "step": 7973
    },
    {
      "epoch": 0.7466591907298383,
      "grad_norm": 1.8984375,
      "learning_rate": 8.957196913393142e-06,
      "loss": 0.4083,
      "step": 7990
    },
    {
      "epoch": 0.7482478273058593,
      "grad_norm": 0.61328125,
      "learning_rate": 8.951838690643626e-06,
      "loss": 0.4231,
      "step": 8007
    },
    {
      "epoch": 0.7498364638818802,
      "grad_norm": 1.0966796875,
      "learning_rate": 8.946468348457082e-06,
      "loss": 0.2788,
      "step": 8024
    },
    {
      "epoch": 0.7514251004579011,
      "grad_norm": 1.98046875,
      "learning_rate": 8.941085903303188e-06,
      "loss": 0.4474,
      "step": 8041
    },
    {
      "epoch": 0.753013737033922,
      "grad_norm": 0.87255859375,
      "learning_rate": 8.935691371688744e-06,
      "loss": 0.4911,
      "step": 8058
    },
    {
      "epoch": 0.754602373609943,
      "grad_norm": 1.4599609375,
      "learning_rate": 8.930284770157614e-06,
      "loss": 0.299,
      "step": 8075
    },
    {
      "epoch": 0.7561910101859639,
      "grad_norm": 2.228515625,
      "learning_rate": 8.92486611529068e-06,
      "loss": 0.5236,
      "step": 8092
    },
    {
      "epoch": 0.7577796467619848,
      "grad_norm": 0.828125,
      "learning_rate": 8.919435423705786e-06,
      "loss": 0.3771,
      "step": 8109
    },
    {
      "epoch": 0.7593682833380058,
      "grad_norm": 1.833984375,
      "learning_rate": 8.913992712057696e-06,
      "loss": 0.2973,
      "step": 8126
    },
    {
      "epoch": 0.7609569199140267,
      "grad_norm": 1.763671875,
      "learning_rate": 8.908537997038031e-06,
      "loss": 0.4774,
      "step": 8143
    },
    {
      "epoch": 0.7625455564900476,
      "grad_norm": 0.71337890625,
      "learning_rate": 8.903071295375222e-06,
      "loss": 0.3373,
      "step": 8160
    },
    {
      "epoch": 0.7641341930660686,
      "grad_norm": 1.2646484375,
      "learning_rate": 8.897592623834469e-06,
      "loss": 0.3729,
      "step": 8177
    },
    {
      "epoch": 0.7657228296420895,
      "grad_norm": 1.931640625,
      "learning_rate": 8.892101999217673e-06,
      "loss": 0.5125,
      "step": 8194
    },
    {
      "epoch": 0.7673114662181104,
      "grad_norm": 0.646484375,
      "learning_rate": 8.886599438363399e-06,
      "loss": 0.3436,
      "step": 8211
    },
    {
      "epoch": 0.7689001027941313,
      "grad_norm": 1.4443359375,
      "learning_rate": 8.88108495814681e-06,
      "loss": 0.3521,
      "step": 8228
    },
    {
      "epoch": 0.7704887393701523,
      "grad_norm": 2.6796875,
      "learning_rate": 8.875558575479631e-06,
      "loss": 0.4941,
      "step": 8245
    },
    {
      "epoch": 0.7720773759461732,
      "grad_norm": 0.63818359375,
      "learning_rate": 8.870020307310085e-06,
      "loss": 0.2562,
      "step": 8262
    },
    {
      "epoch": 0.7736660125221941,
      "grad_norm": 1.484375,
      "learning_rate": 8.864470170622845e-06,
      "loss": 0.3227,
      "step": 8279
    },
    {
      "epoch": 0.7752546490982151,
      "grad_norm": 1.9404296875,
      "learning_rate": 8.858908182438985e-06,
      "loss": 0.534,
      "step": 8296
    },
    {
      "epoch": 0.7768432856742361,
      "grad_norm": 0.923828125,
      "learning_rate": 8.853334359815922e-06,
      "loss": 0.2681,
      "step": 8313
    },
    {
      "epoch": 0.778431922250257,
      "grad_norm": 1.3388671875,
      "learning_rate": 8.847748719847369e-06,
      "loss": 0.3564,
      "step": 8330
    },
    {
      "epoch": 0.780020558826278,
      "grad_norm": 2.123046875,
      "learning_rate": 8.842151279663278e-06,
      "loss": 0.498,
      "step": 8347
    },
    {
      "epoch": 0.7816091954022989,
      "grad_norm": 0.7080078125,
      "learning_rate": 8.836542056429791e-06,
      "loss": 0.2557,
      "step": 8364
    },
    {
      "epoch": 0.7831978319783198,
      "grad_norm": 1.326171875,
      "learning_rate": 8.830921067349187e-06,
      "loss": 0.3606,
      "step": 8381
    },
    {
      "epoch": 0.7847864685543408,
      "grad_norm": 1.7919921875,
      "learning_rate": 8.82528832965983e-06,
      "loss": 0.5401,
      "step": 8398
    },
    {
      "epoch": 0.7863751051303617,
      "grad_norm": 0.6240234375,
      "learning_rate": 8.819643860636105e-06,
      "loss": 0.2178,
      "step": 8415
    },
    {
      "epoch": 0.7879637417063826,
      "grad_norm": 1.3876953125,
      "learning_rate": 8.813987677588385e-06,
      "loss": 0.358,
      "step": 8432
    },
    {
      "epoch": 0.7895523782824035,
      "grad_norm": 2.900390625,
      "learning_rate": 8.808319797862965e-06,
      "loss": 0.5406,
      "step": 8449
    },
    {
      "epoch": 0.7911410148584245,
      "grad_norm": 1.1181640625,
      "learning_rate": 8.802640238842007e-06,
      "loss": 0.253,
      "step": 8466
    },
    {
      "epoch": 0.7927296514344454,
      "grad_norm": 1.7685546875,
      "learning_rate": 8.796949017943496e-06,
      "loss": 0.4065,
      "step": 8483
    },
    {
      "epoch": 0.7943182880104663,
      "grad_norm": 2.509765625,
      "learning_rate": 8.791246152621177e-06,
      "loss": 0.5664,
      "step": 8500
    },
    {
      "epoch": 0.7959069245864873,
      "grad_norm": 0.93505859375,
      "learning_rate": 8.78553166036451e-06,
      "loss": 0.2357,
      "step": 8517
    },
    {
      "epoch": 0.7974955611625082,
      "grad_norm": 1.353515625,
      "learning_rate": 8.779805558698611e-06,
      "loss": 0.3866,
      "step": 8534
    },
    {
      "epoch": 0.7990841977385291,
      "grad_norm": 0.60888671875,
      "learning_rate": 8.774067865184195e-06,
      "loss": 0.5187,
      "step": 8551
    },
    {
      "epoch": 0.80067283431455,
      "grad_norm": 0.97998046875,
      "learning_rate": 8.768318597417535e-06,
      "loss": 0.2549,
      "step": 8568
    },
    {
      "epoch": 0.802261470890571,
      "grad_norm": 1.6162109375,
      "learning_rate": 8.762557773030393e-06,
      "loss": 0.4058,
      "step": 8585
    },
    {
      "epoch": 0.8038501074665919,
      "grad_norm": 0.2958984375,
      "learning_rate": 8.756785409689977e-06,
      "loss": 0.484,
      "step": 8602
    },
    {
      "epoch": 0.8054387440426128,
      "grad_norm": 1.0068359375,
      "learning_rate": 8.751001525098878e-06,
      "loss": 0.2756,
      "step": 8619
    },
    {
      "epoch": 0.8070273806186338,
      "grad_norm": 1.6484375,
      "learning_rate": 8.745206136995023e-06,
      "loss": 0.4378,
      "step": 8636
    },
    {
      "epoch": 0.8086160171946547,
      "grad_norm": 0.48681640625,
      "learning_rate": 8.73939926315162e-06,
      "loss": 0.4921,
      "step": 8653
    },
    {
      "epoch": 0.8102046537706756,
      "grad_norm": 0.9609375,
      "learning_rate": 8.733580921377098e-06,
      "loss": 0.1957,
      "step": 8670
    },
    {
      "epoch": 0.8117932903466966,
      "grad_norm": 1.970703125,
      "learning_rate": 8.727751129515053e-06,
      "loss": 0.426,
      "step": 8687
    },
    {
      "epoch": 0.8133819269227175,
      "grad_norm": 0.12548828125,
      "learning_rate": 8.721909905444204e-06,
      "loss": 0.4706,
      "step": 8704
    },
    {
      "epoch": 0.8149705634987384,
      "grad_norm": 1.041015625,
      "learning_rate": 8.716057267078323e-06,
      "loss": 0.2678,
      "step": 8721
    },
    {
      "epoch": 0.8165592000747594,
      "grad_norm": 1.8095703125,
      "learning_rate": 8.71019323236619e-06,
      "loss": 0.4182,
      "step": 8738
    },
    {
      "epoch": 0.8181478366507803,
      "grad_norm": 0.356201171875,
      "learning_rate": 8.704317819291536e-06,
      "loss": 0.4573,
      "step": 8755
    },
    {
      "epoch": 0.8197364732268012,
      "grad_norm": 1.056640625,
      "learning_rate": 8.698431045872985e-06,
      "loss": 0.2602,
      "step": 8772
    },
    {
      "epoch": 0.8213251098028221,
      "grad_norm": 1.673828125,
      "learning_rate": 8.692532930164e-06,
      "loss": 0.4398,
      "step": 8789
    },
    {
      "epoch": 0.8229137463788431,
      "grad_norm": 0.67822265625,
      "learning_rate": 8.686623490252835e-06,
      "loss": 0.4097,
      "step": 8806
    },
    {
      "epoch": 0.824502382954864,
      "grad_norm": 1.259765625,
      "learning_rate": 8.680702744262462e-06,
      "loss": 0.2765,
      "step": 8823
    },
    {
      "epoch": 0.8260910195308849,
      "grad_norm": 2.0234375,
      "learning_rate": 8.674770710350535e-06,
      "loss": 0.4465,
      "step": 8840
    },
    {
      "epoch": 0.8276796561069059,
      "grad_norm": 0.72265625,
      "learning_rate": 8.668827406709322e-06,
      "loss": 0.4133,
      "step": 8857
    },
    {
      "epoch": 0.8292682926829268,
      "grad_norm": 1.2802734375,
      "learning_rate": 8.662872851565652e-06,
      "loss": 0.3178,
      "step": 8874
    },
    {
      "epoch": 0.8308569292589477,
      "grad_norm": 1.90234375,
      "learning_rate": 8.656907063180866e-06,
      "loss": 0.4974,
      "step": 8891
    },
    {
      "epoch": 0.8324455658349686,
      "grad_norm": 0.787109375,
      "learning_rate": 8.650930059850746e-06,
      "loss": 0.4093,
      "step": 8908
    },
    {
      "epoch": 0.8340342024109896,
      "grad_norm": 1.111328125,
      "learning_rate": 8.644941859905474e-06,
      "loss": 0.3003,
      "step": 8925
    },
    {
      "epoch": 0.8356228389870105,
      "grad_norm": 1.78515625,
      "learning_rate": 8.63894248170957e-06,
      "loss": 0.504,
      "step": 8942
    },
    {
      "epoch": 0.8372114755630314,
      "grad_norm": 0.77783203125,
      "learning_rate": 8.632931943661829e-06,
      "loss": 0.3659,
      "step": 8959
    },
    {
      "epoch": 0.8388001121390525,
      "grad_norm": 1.4267578125,
      "learning_rate": 8.626910264195276e-06,
      "loss": 0.3546,
      "step": 8976
    },
    {
      "epoch": 0.8403887487150734,
      "grad_norm": 1.94921875,
      "learning_rate": 8.620877461777106e-06,
      "loss": 0.4955,
      "step": 8993
    },
    {
      "epoch": 0.8419773852910943,
      "grad_norm": 0.81103515625,
      "learning_rate": 8.61483355490862e-06,
      "loss": 0.3391,
      "step": 9010
    },
    {
      "epoch": 0.8435660218671153,
      "grad_norm": 1.068359375,
      "learning_rate": 8.60877856212518e-06,
      "loss": 0.34,
      "step": 9027
    },
    {
      "epoch": 0.8451546584431362,
      "grad_norm": 2.029296875,
      "learning_rate": 8.602712501996139e-06,
      "loss": 0.4959,
      "step": 9044
    },
    {
      "epoch": 0.8467432950191571,
      "grad_norm": 0.720703125,
      "learning_rate": 8.596635393124798e-06,
      "loss": 0.325,
      "step": 9061
    },
    {
      "epoch": 0.8483319315951781,
      "grad_norm": 1.3662109375,
      "learning_rate": 8.59054725414834e-06,
      "loss": 0.3572,
      "step": 9078
    },
    {
      "epoch": 0.849920568171199,
      "grad_norm": 2.041015625,
      "learning_rate": 8.584448103737772e-06,
      "loss": 0.5228,
      "step": 9095
    },
    {
      "epoch": 0.8515092047472199,
      "grad_norm": 0.947265625,
      "learning_rate": 8.578337960597875e-06,
      "loss": 0.3448,
      "step": 9112
    },
    {
      "epoch": 0.8530978413232408,
      "grad_norm": 1.5908203125,
      "learning_rate": 8.572216843467138e-06,
      "loss": 0.351,
      "step": 9129
    },
    {
      "epoch": 0.8546864778992618,
      "grad_norm": 2.015625,
      "learning_rate": 8.566084771117711e-06,
      "loss": 0.5239,
      "step": 9146
    },
    {
      "epoch": 0.8562751144752827,
      "grad_norm": 0.9619140625,
      "learning_rate": 8.559941762355333e-06,
      "loss": 0.2353,
      "step": 9163
    },
    {
      "epoch": 0.8578637510513036,
      "grad_norm": 1.5380859375,
      "learning_rate": 8.55378783601929e-06,
      "loss": 0.3201,
      "step": 9180
    },
    {
      "epoch": 0.8594523876273246,
      "grad_norm": 2.658203125,
      "learning_rate": 8.547623010982347e-06,
      "loss": 0.5311,
      "step": 9197
    },
    {
      "epoch": 0.8610410242033455,
      "grad_norm": 0.9345703125,
      "learning_rate": 8.541447306150692e-06,
      "loss": 0.2686,
      "step": 9214
    },
    {
      "epoch": 0.8626296607793664,
      "grad_norm": 1.787109375,
      "learning_rate": 8.535260740463878e-06,
      "loss": 0.3888,
      "step": 9231
    },
    {
      "epoch": 0.8642182973553874,
      "grad_norm": 2.48828125,
      "learning_rate": 8.529063332894771e-06,
      "loss": 0.5565,
      "step": 9248
    },
    {
      "epoch": 0.8658069339314083,
      "grad_norm": 0.84912109375,
      "learning_rate": 8.522855102449483e-06,
      "loss": 0.2693,
      "step": 9265
    },
    {
      "epoch": 0.8673955705074292,
      "grad_norm": 1.65625,
      "learning_rate": 8.516636068167319e-06,
      "loss": 0.358,
      "step": 9282
    },
    {
      "epoch": 0.8689842070834501,
      "grad_norm": 2.63671875,
      "learning_rate": 8.510406249120711e-06,
      "loss": 0.5695,
      "step": 9299
    },
    {
      "epoch": 0.8705728436594711,
      "grad_norm": 0.83642578125,
      "learning_rate": 8.504165664415173e-06,
      "loss": 0.2027,
      "step": 9316
    },
    {
      "epoch": 0.872161480235492,
      "grad_norm": 1.5439453125,
      "learning_rate": 8.497914333189236e-06,
      "loss": 0.3381,
      "step": 9333
    },
    {
      "epoch": 0.8737501168115129,
      "grad_norm": 2.779296875,
      "learning_rate": 8.49165227461438e-06,
      "loss": 0.5968,
      "step": 9350
    },
    {
      "epoch": 0.8753387533875339,
      "grad_norm": 0.9287109375,
      "learning_rate": 8.485379507894993e-06,
      "loss": 0.182,
      "step": 9367
    },
    {
      "epoch": 0.8769273899635548,
      "grad_norm": 1.62890625,
      "learning_rate": 8.479096052268291e-06,
      "loss": 0.3524,
      "step": 9384
    },
    {
      "epoch": 0.8785160265395757,
      "grad_norm": 0.6494140625,
      "learning_rate": 8.472801927004286e-06,
      "loss": 0.5009,
      "step": 9401
    },
    {
      "epoch": 0.8801046631155967,
      "grad_norm": 1.197265625,
      "learning_rate": 8.466497151405695e-06,
      "loss": 0.2639,
      "step": 9418
    },
    {
      "epoch": 0.8816932996916176,
      "grad_norm": 1.53515625,
      "learning_rate": 8.460181744807909e-06,
      "loss": 0.4123,
      "step": 9435
    },
    {
      "epoch": 0.8832819362676385,
      "grad_norm": 0.389892578125,
      "learning_rate": 8.453855726578917e-06,
      "loss": 0.5044,
      "step": 9452
    },
    {
      "epoch": 0.8848705728436594,
      "grad_norm": 1.015625,
      "learning_rate": 8.447519116119252e-06,
      "loss": 0.2229,
      "step": 9469
    },
    {
      "epoch": 0.8864592094196804,
      "grad_norm": 1.7353515625,
      "learning_rate": 8.441171932861934e-06,
      "loss": 0.3896,
      "step": 9486
    },
    {
      "epoch": 0.8880478459957013,
      "grad_norm": 0.2471923828125,
      "learning_rate": 8.434814196272405e-06,
      "loss": 0.451,
      "step": 9503
    },
    {
      "epoch": 0.8896364825717222,
      "grad_norm": 1.1064453125,
      "learning_rate": 8.42844592584847e-06,
      "loss": 0.2668,
      "step": 9520
    },
    {
      "epoch": 0.8912251191477432,
      "grad_norm": 2.224609375,
      "learning_rate": 8.422067141120241e-06,
      "loss": 0.4365,
      "step": 9537
    },
    {
      "epoch": 0.8928137557237641,
      "grad_norm": 0.2099609375,
      "learning_rate": 8.415677861650078e-06,
      "loss": 0.4743,
      "step": 9554
    },
    {
      "epoch": 0.894402392299785,
      "grad_norm": 1.0654296875,
      "learning_rate": 8.40927810703252e-06,
      "loss": 0.2987,
      "step": 9571
    },
    {
      "epoch": 0.895991028875806,
      "grad_norm": 1.984375,
      "learning_rate": 8.402867896894238e-06,
      "loss": 0.4532,
      "step": 9588
    },
    {
      "epoch": 0.8975796654518269,
      "grad_norm": 0.5126953125,
      "learning_rate": 8.39644725089396e-06,
      "loss": 0.4199,
      "step": 9605
    },
    {
      "epoch": 0.8991683020278478,
      "grad_norm": 1.2001953125,
      "learning_rate": 8.390016188722425e-06,
      "loss": 0.3214,
      "step": 9622
    },
    {
      "epoch": 0.9007569386038689,
      "grad_norm": 1.8583984375,
      "learning_rate": 8.383574730102313e-06,
      "loss": 0.4627,
      "step": 9639
    },
    {
      "epoch": 0.9023455751798898,
      "grad_norm": 0.6298828125,
      "learning_rate": 8.377122894788187e-06,
      "loss": 0.4102,
      "step": 9656
    },
    {
      "epoch": 0.9039342117559107,
      "grad_norm": 1.732421875,
      "learning_rate": 8.37066070256644e-06,
      "loss": 0.2948,
      "step": 9673
    },
    {
      "epoch": 0.9055228483319316,
      "grad_norm": 1.96875,
      "learning_rate": 8.364188173255215e-06,
      "loss": 0.4904,
      "step": 9690
    },
    {
      "epoch": 0.9071114849079526,
      "grad_norm": 0.55126953125,
      "learning_rate": 8.357705326704369e-06,
      "loss": 0.4154,
      "step": 9707
    },
    {
      "epoch": 0.9087001214839735,
      "grad_norm": 1.177734375,
      "learning_rate": 8.35121218279539e-06,
      "loss": 0.2688,
      "step": 9724
    },
    {
      "epoch": 0.9102887580599944,
      "grad_norm": 1.98046875,
      "learning_rate": 8.344708761441354e-06,
      "loss": 0.5225,
      "step": 9741
    },
    {
      "epoch": 0.9118773946360154,
      "grad_norm": 0.7529296875,
      "learning_rate": 8.33819508258685e-06,
      "loss": 0.403,
      "step": 9758
    },
    {
      "epoch": 0.9134660312120363,
      "grad_norm": 1.22265625,
      "learning_rate": 8.331671166207925e-06,
      "loss": 0.3208,
      "step": 9775
    },
    {
      "epoch": 0.9150546677880572,
      "grad_norm": 1.673828125,
      "learning_rate": 8.325137032312026e-06,
      "loss": 0.4742,
      "step": 9792
    },
    {
      "epoch": 0.9166433043640781,
      "grad_norm": 0.765625,
      "learning_rate": 8.318592700937931e-06,
      "loss": 0.3824,
      "step": 9809
    },
    {
      "epoch": 0.9182319409400991,
      "grad_norm": 1.1904296875,
      "learning_rate": 8.312038192155694e-06,
      "loss": 0.3472,
      "step": 9826
    },
    {
      "epoch": 0.91982057751612,
      "grad_norm": 1.916015625,
      "learning_rate": 8.305473526066578e-06,
      "loss": 0.5098,
      "step": 9843
    },
    {
      "epoch": 0.9214092140921409,
      "grad_norm": 0.7109375,
      "learning_rate": 8.298898722803001e-06,
      "loss": 0.3959,
      "step": 9860
    },
    {
      "epoch": 0.9229978506681619,
      "grad_norm": 1.41015625,
      "learning_rate": 8.292313802528465e-06,
      "loss": 0.3406,
      "step": 9877
    },
    {
      "epoch": 0.9245864872441828,
      "grad_norm": 2.078125,
      "learning_rate": 8.2857187854375e-06,
      "loss": 0.4848,
      "step": 9894
    },
    {
      "epoch": 0.9261751238202037,
      "grad_norm": 0.71923828125,
      "learning_rate": 8.279113691755603e-06,
      "loss": 0.3017,
      "step": 9911
    },
    {
      "epoch": 0.9277637603962247,
      "grad_norm": 1.3134765625,
      "learning_rate": 8.27249854173917e-06,
      "loss": 0.3627,
      "step": 9928
    },
    {
      "epoch": 0.9293523969722456,
      "grad_norm": 2.4609375,
      "learning_rate": 8.26587335567544e-06,
      "loss": 0.5503,
      "step": 9945
    },
    {
      "epoch": 0.9309410335482665,
      "grad_norm": 1.017578125,
      "learning_rate": 8.259238153882432e-06,
      "loss": 0.3352,
      "step": 9962
    },
    {
      "epoch": 0.9325296701242874,
      "grad_norm": 1.4345703125,
      "learning_rate": 8.252592956708875e-06,
      "loss": 0.336,
      "step": 9979
    },
    {
      "epoch": 0.9341183067003084,
      "grad_norm": 2.05859375,
      "learning_rate": 8.245937784534157e-06,
      "loss": 0.5158,
      "step": 9996
    },
    {
      "epoch": 0.9357069432763293,
      "grad_norm": 0.8251953125,
      "learning_rate": 8.239272657768261e-06,
      "loss": 0.3373,
      "step": 10013
    },
    {
      "epoch": 0.9372955798523502,
      "grad_norm": 1.5078125,
      "learning_rate": 8.232597596851686e-06,
      "loss": 0.3714,
      "step": 10030
    },
    {
      "epoch": 0.9388842164283712,
      "grad_norm": 2.259765625,
      "learning_rate": 8.225912622255407e-06,
      "loss": 0.4965,
      "step": 10047
    },
    {
      "epoch": 0.9404728530043921,
      "grad_norm": 0.91455078125,
      "learning_rate": 8.219217754480802e-06,
      "loss": 0.2676,
      "step": 10064
    },
    {
      "epoch": 0.942061489580413,
      "grad_norm": 1.7705078125,
      "learning_rate": 8.212513014059582e-06,
      "loss": 0.3456,
      "step": 10081
    },
    {
      "epoch": 0.943650126156434,
      "grad_norm": 2.388671875,
      "learning_rate": 8.205798421553744e-06,
      "loss": 0.5135,
      "step": 10098
    },
    {
      "epoch": 0.9452387627324549,
      "grad_norm": 0.970703125,
      "learning_rate": 8.199073997555495e-06,
      "loss": 0.2468,
      "step": 10115
    },
    {
      "epoch": 0.9468273993084758,
      "grad_norm": 1.337890625,
      "learning_rate": 8.19233976268719e-06,
      "loss": 0.3404,
      "step": 10132
    },
    {
      "epoch": 0.9484160358844967,
      "grad_norm": 2.314453125,
      "learning_rate": 8.185595737601277e-06,
      "loss": 0.5087,
      "step": 10149
    },
    {
      "epoch": 0.9500046724605177,
      "grad_norm": 0.77978515625,
      "learning_rate": 8.178841942980227e-06,
      "loss": 0.2138,
      "step": 10166
    },
    {
      "epoch": 0.9515933090365386,
      "grad_norm": 1.6552734375,
      "learning_rate": 8.172078399536472e-06,
      "loss": 0.4236,
      "step": 10183
    },
    {
      "epoch": 0.9531819456125595,
      "grad_norm": 2.796875,
      "learning_rate": 8.16530512801234e-06,
      "loss": 0.6091,
      "step": 10200
    },
    {
      "epoch": 0.9547705821885805,
      "grad_norm": 1.0302734375,
      "learning_rate": 8.158522149179993e-06,
      "loss": 0.2437,
      "step": 10217
    },
    {
      "epoch": 0.9563592187646014,
      "grad_norm": 1.7001953125,
      "learning_rate": 8.151729483841367e-06,
      "loss": 0.4341,
      "step": 10234
    },
    {
      "epoch": 0.9579478553406223,
      "grad_norm": 0.30712890625,
      "learning_rate": 8.1449271528281e-06,
      "loss": 0.5646,
      "step": 10251
    },
    {
      "epoch": 0.9595364919166433,
      "grad_norm": 0.9833984375,
      "learning_rate": 8.138115177001475e-06,
      "loss": 0.2454,
      "step": 10268
    },
    {
      "epoch": 0.9611251284926642,
      "grad_norm": 1.8056640625,
      "learning_rate": 8.131293577252353e-06,
      "loss": 0.4145,
      "step": 10285
    },
    {
      "epoch": 0.9627137650686852,
      "grad_norm": 0.402099609375,
      "learning_rate": 8.124462374501107e-06,
      "loss": 0.4938,
      "step": 10302
    },
    {
      "epoch": 0.9643024016447062,
      "grad_norm": 1.1181640625,
      "learning_rate": 8.117621589697566e-06,
      "loss": 0.245,
      "step": 10319
    },
    {
      "epoch": 0.9658910382207271,
      "grad_norm": 1.85546875,
      "learning_rate": 8.11077124382094e-06,
      "loss": 0.463,
      "step": 10336
    },
    {
      "epoch": 0.967479674796748,
      "grad_norm": 0.238525390625,
      "learning_rate": 8.103911357879762e-06,
      "loss": 0.5053,
      "step": 10353
    },
    {
      "epoch": 0.9690683113727689,
      "grad_norm": 1.0244140625,
      "learning_rate": 8.097041952911824e-06,
      "loss": 0.2083,
      "step": 10370
    },
    {
      "epoch": 0.9706569479487899,
      "grad_norm": 1.65625,
      "learning_rate": 8.09016304998411e-06,
      "loss": 0.3777,
      "step": 10387
    },
    {
      "epoch": 0.9722455845248108,
      "grad_norm": 0.56298828125,
      "learning_rate": 8.083274670192729e-06,
      "loss": 0.4496,
      "step": 10404
    },
    {
      "epoch": 0.9738342211008317,
      "grad_norm": 1.1865234375,
      "learning_rate": 8.07637683466286e-06,
      "loss": 0.2883,
      "step": 10421
    },
    {
      "epoch": 0.9754228576768527,
      "grad_norm": 1.6396484375,
      "learning_rate": 8.069469564548675e-06,
      "loss": 0.4145,
      "step": 10438
    },
    {
      "epoch": 0.9770114942528736,
      "grad_norm": 0.46923828125,
      "learning_rate": 8.06255288103328e-06,
      "loss": 0.4098,
      "step": 10455
    },
    {
      "epoch": 0.9786001308288945,
      "grad_norm": 1.12109375,
      "learning_rate": 8.055626805328657e-06,
      "loss": 0.2896,
      "step": 10472
    },
    {
      "epoch": 0.9801887674049155,
      "grad_norm": 1.8798828125,
      "learning_rate": 8.048691358675582e-06,
      "loss": 0.4423,
      "step": 10489
    },
    {
      "epoch": 0.9817774039809364,
      "grad_norm": 0.6298828125,
      "learning_rate": 8.041746562343575e-06,
      "loss": 0.4246,
      "step": 10506
    },
    {
      "epoch": 0.9833660405569573,
      "grad_norm": 1.1259765625,
      "learning_rate": 8.034792437630829e-06,
      "loss": 0.2856,
      "step": 10523
    },
    {
      "epoch": 0.9849546771329782,
      "grad_norm": 1.9150390625,
      "learning_rate": 8.027829005864147e-06,
      "loss": 0.4293,
      "step": 10540
    },
    {
      "epoch": 0.9865433137089992,
      "grad_norm": 0.669921875,
      "learning_rate": 8.02085628839887e-06,
      "loss": 0.3968,
      "step": 10557
    },
    {
      "epoch": 0.9881319502850201,
      "grad_norm": 1.2373046875,
      "learning_rate": 8.013874306618819e-06,
      "loss": 0.2945,
      "step": 10574
    },
    {
      "epoch": 0.989720586861041,
      "grad_norm": 1.9794921875,
      "learning_rate": 8.006883081936228e-06,
      "loss": 0.4689,
      "step": 10591
    },
    {
      "epoch": 0.991309223437062,
      "grad_norm": 0.76171875,
      "learning_rate": 7.999882635791672e-06,
      "loss": 0.4204,
      "step": 10608
    },
    {
      "epoch": 0.9928978600130829,
      "grad_norm": 1.2578125,
      "learning_rate": 7.992872989654013e-06,
      "loss": 0.3296,
      "step": 10625
    },
    {
      "epoch": 0.9944864965891038,
      "grad_norm": 1.9404296875,
      "learning_rate": 7.985854165020324e-06,
      "loss": 0.4805,
      "step": 10642
    },
    {
      "epoch": 0.9960751331651247,
      "grad_norm": 0.625,
      "learning_rate": 7.978826183415822e-06,
      "loss": 0.396,
      "step": 10659
    },
    {
      "epoch": 0.9976637697411457,
      "grad_norm": 1.4072265625,
      "learning_rate": 7.971789066393817e-06,
      "loss": 0.3129,
      "step": 10676
    },
    {
      "epoch": 0.9992524063171666,
      "grad_norm": 2.091796875,
      "learning_rate": 7.964742835535625e-06,
      "loss": 0.4779,
      "step": 10693
    },
    {
      "epoch": 1.0008410428931875,
      "grad_norm": 0.69482421875,
      "learning_rate": 7.957687512450521e-06,
      "loss": 0.307,
      "step": 10710
    },
    {
      "epoch": 1.0024296794692085,
      "grad_norm": 1.1591796875,
      "learning_rate": 7.950623118775655e-06,
      "loss": 0.3115,
      "step": 10727
    },
    {
      "epoch": 1.0040183160452294,
      "grad_norm": 2.220703125,
      "learning_rate": 7.943549676175999e-06,
      "loss": 0.4948,
      "step": 10744
    },
    {
      "epoch": 1.0056069526212503,
      "grad_norm": 0.71533203125,
      "learning_rate": 7.936467206344279e-06,
      "loss": 0.3006,
      "step": 10761
    },
    {
      "epoch": 1.0071955891972713,
      "grad_norm": 1.39453125,
      "learning_rate": 7.929375731000901e-06,
      "loss": 0.3034,
      "step": 10778
    },
    {
      "epoch": 1.0087842257732922,
      "grad_norm": 2.28125,
      "learning_rate": 7.922275271893892e-06,
      "loss": 0.4842,
      "step": 10795
    },
    {
      "epoch": 1.0103728623493131,
      "grad_norm": 0.83203125,
      "learning_rate": 7.915165850798825e-06,
      "loss": 0.3426,
      "step": 10812
    },
    {
      "epoch": 1.011961498925334,
      "grad_norm": 1.5791015625,
      "learning_rate": 7.908047489518765e-06,
      "loss": 0.3368,
      "step": 10829
    },
    {
      "epoch": 1.013550135501355,
      "grad_norm": 2.2890625,
      "learning_rate": 7.90092020988419e-06,
      "loss": 0.5083,
      "step": 10846
    },
    {
      "epoch": 1.015138772077376,
      "grad_norm": 0.8310546875,
      "learning_rate": 7.893784033752928e-06,
      "loss": 0.2786,
      "step": 10863
    },
    {
      "epoch": 1.0167274086533968,
      "grad_norm": 1.833984375,
      "learning_rate": 7.886638983010095e-06,
      "loss": 0.3228,
      "step": 10880
    },
    {
      "epoch": 1.0183160452294178,
      "grad_norm": 2.255859375,
      "learning_rate": 7.879485079568019e-06,
      "loss": 0.5258,
      "step": 10897
    },
    {
      "epoch": 1.0199046818054387,
      "grad_norm": 0.939453125,
      "learning_rate": 7.87232234536618e-06,
      "loss": 0.2831,
      "step": 10914
    },
    {
      "epoch": 1.0214933183814596,
      "grad_norm": 1.515625,
      "learning_rate": 7.865150802371138e-06,
      "loss": 0.3507,
      "step": 10931
    },
    {
      "epoch": 1.0230819549574806,
      "grad_norm": 1.970703125,
      "learning_rate": 7.857970472576469e-06,
      "loss": 0.5338,
      "step": 10948
    },
    {
      "epoch": 1.0246705915335015,
      "grad_norm": 0.931640625,
      "learning_rate": 7.850781378002697e-06,
      "loss": 0.3034,
      "step": 10965
    },
    {
      "epoch": 1.0262592281095224,
      "grad_norm": 1.67578125,
      "learning_rate": 7.843583540697223e-06,
      "loss": 0.3575,
      "step": 10982
    },
    {
      "epoch": 1.0278478646855433,
      "grad_norm": 2.203125,
      "learning_rate": 7.836376982734264e-06,
      "loss": 0.5187,
      "step": 10999
    },
    {
      "epoch": 1.0294365012615643,
      "grad_norm": 1.0185546875,
      "learning_rate": 7.829161726214778e-06,
      "loss": 0.2878,
      "step": 11016
    },
    {
      "epoch": 1.0310251378375852,
      "grad_norm": 1.517578125,
      "learning_rate": 7.8219377932664e-06,
      "loss": 0.3427,
      "step": 11033
    },
    {
      "epoch": 1.0326137744136061,
      "grad_norm": 2.595703125,
      "learning_rate": 7.814705206043375e-06,
      "loss": 0.6171,
      "step": 11050
    },
    {
      "epoch": 1.034202410989627,
      "grad_norm": 1.052734375,
      "learning_rate": 7.80746398672649e-06,
      "loss": 0.1955,
      "step": 11067
    },
    {
      "epoch": 1.035791047565648,
      "grad_norm": 1.4130859375,
      "learning_rate": 7.800214157522999e-06,
      "loss": 0.3548,
      "step": 11084
    },
    {
      "epoch": 1.037379684141669,
      "grad_norm": 4.0859375,
      "learning_rate": 7.79295574066657e-06,
      "loss": 0.5652,
      "step": 11101
    },
    {
      "epoch": 1.0389683207176899,
      "grad_norm": 1.1025390625,
      "learning_rate": 7.785688758417197e-06,
      "loss": 0.2248,
      "step": 11118
    },
    {
      "epoch": 1.0405569572937108,
      "grad_norm": 1.591796875,
      "learning_rate": 7.77841323306115e-06,
      "loss": 0.4066,
      "step": 11135
    },
    {
      "epoch": 1.0421455938697317,
      "grad_norm": 0.416015625,
      "learning_rate": 7.771129186910898e-06,
      "loss": 0.5519,
      "step": 11152
    },
    {
      "epoch": 1.0437342304457526,
      "grad_norm": 1.1171875,
      "learning_rate": 7.763836642305037e-06,
      "loss": 0.2155,
      "step": 11169
    },
    {
      "epoch": 1.0453228670217736,
      "grad_norm": 1.73828125,
      "learning_rate": 7.756535621608227e-06,
      "loss": 0.4098,
      "step": 11186
    },
    {
      "epoch": 1.0469115035977945,
      "grad_norm": 0.447265625,
      "learning_rate": 7.749226147211128e-06,
      "loss": 0.496,
      "step": 11203
    },
    {
      "epoch": 1.0485001401738154,
      "grad_norm": 1.041015625,
      "learning_rate": 7.74190824153032e-06,
      "loss": 0.2178,
      "step": 11220
    },
    {
      "epoch": 1.0500887767498364,
      "grad_norm": 1.5703125,
      "learning_rate": 7.734581927008243e-06,
      "loss": 0.3809,
      "step": 11237
    },
    {
      "epoch": 1.0516774133258573,
      "grad_norm": 0.30712890625,
      "learning_rate": 7.727247226113119e-06,
      "loss": 0.4879,
      "step": 11254
    },
    {
      "epoch": 1.0532660499018784,
      "grad_norm": 0.98583984375,
      "learning_rate": 7.719904161338898e-06,
      "loss": 0.2356,
      "step": 11271
    },
    {
      "epoch": 1.0548546864778992,
      "grad_norm": 1.54296875,
      "learning_rate": 7.712552755205179e-06,
      "loss": 0.3932,
      "step": 11288
    },
    {
      "epoch": 1.0564433230539203,
      "grad_norm": 0.2117919921875,
      "learning_rate": 7.705193030257133e-06,
      "loss": 0.473,
      "step": 11305
    },
    {
      "epoch": 1.0580319596299412,
      "grad_norm": 1.1455078125,
      "learning_rate": 7.697825009065451e-06,
      "loss": 0.2548,
      "step": 11322
    },
    {
      "epoch": 1.0596205962059622,
      "grad_norm": 2.00390625,
      "learning_rate": 7.690448714226265e-06,
      "loss": 0.4138,
      "step": 11339
    },
    {
      "epoch": 1.061209232781983,
      "grad_norm": 0.493896484375,
      "learning_rate": 7.683064168361082e-06,
      "loss": 0.4121,
      "step": 11356
    },
    {
      "epoch": 1.062797869358004,
      "grad_norm": 1.1748046875,
      "learning_rate": 7.675671394116711e-06,
      "loss": 0.2854,
      "step": 11373
    },
    {
      "epoch": 1.064386505934025,
      "grad_norm": 2.24609375,
      "learning_rate": 7.668270414165198e-06,
      "loss": 0.4399,
      "step": 11390
    },
    {
      "epoch": 1.0659751425100459,
      "grad_norm": 0.55078125,
      "learning_rate": 7.660861251203748e-06,
      "loss": 0.3967,
      "step": 11407
    },
    {
      "epoch": 1.0675637790860668,
      "grad_norm": 1.4990234375,
      "learning_rate": 7.653443927954671e-06,
      "loss": 0.2596,
      "step": 11424
    },
    {
      "epoch": 1.0691524156620877,
      "grad_norm": 2.189453125,
      "learning_rate": 7.646018467165295e-06,
      "loss": 0.4387,
      "step": 11441
    },
    {
      "epoch": 1.0707410522381087,
      "grad_norm": 0.6025390625,
      "learning_rate": 7.638584891607908e-06,
      "loss": 0.3772,
      "step": 11458
    },
    {
      "epoch": 1.0723296888141296,
      "grad_norm": 1.330078125,
      "learning_rate": 7.631143224079681e-06,
      "loss": 0.2985,
      "step": 11475
    },
    {
      "epoch": 1.0739183253901505,
      "grad_norm": 1.9697265625,
      "learning_rate": 7.623693487402606e-06,
      "loss": 0.5358,
      "step": 11492
    },
    {
      "epoch": 1.0755069619661715,
      "grad_norm": 0.69970703125,
      "learning_rate": 7.616235704423418e-06,
      "loss": 0.4083,
      "step": 11509
    },
    {
      "epoch": 1.0770955985421924,
      "grad_norm": 1.22265625,
      "learning_rate": 7.6087698980135286e-06,
      "loss": 0.327,
      "step": 11526
    },
    {
      "epoch": 1.0786842351182133,
      "grad_norm": 1.9443359375,
      "learning_rate": 7.601296091068955e-06,
      "loss": 0.4458,
      "step": 11543
    },
    {
      "epoch": 1.0802728716942342,
      "grad_norm": 0.69482421875,
      "learning_rate": 7.593814306510254e-06,
      "loss": 0.3461,
      "step": 11560
    },
    {
      "epoch": 1.0818615082702552,
      "grad_norm": 1.693359375,
      "learning_rate": 7.586324567282445e-06,
      "loss": 0.2826,
      "step": 11577
    },
    {
      "epoch": 1.083450144846276,
      "grad_norm": 2.220703125,
      "learning_rate": 7.578826896354942e-06,
      "loss": 0.4753,
      "step": 11594
    },
    {
      "epoch": 1.085038781422297,
      "grad_norm": 0.9189453125,
      "learning_rate": 7.571321316721483e-06,
      "loss": 0.3364,
      "step": 11611
    },
    {
      "epoch": 1.086627417998318,
      "grad_norm": 1.1572265625,
      "learning_rate": 7.563807851400066e-06,
      "loss": 0.3201,
      "step": 11628
    },
    {
      "epoch": 1.088216054574339,
      "grad_norm": 2.248046875,
      "learning_rate": 7.5562865234328655e-06,
      "loss": 0.494,
      "step": 11645
    },
    {
      "epoch": 1.0898046911503598,
      "grad_norm": 0.82763671875,
      "learning_rate": 7.5487573558861735e-06,
      "loss": 0.3451,
      "step": 11662
    },
    {
      "epoch": 1.0913933277263808,
      "grad_norm": 1.599609375,
      "learning_rate": 7.541220371850324e-06,
      "loss": 0.3644,
      "step": 11679
    },
    {
      "epoch": 1.0929819643024017,
      "grad_norm": 1.8330078125,
      "learning_rate": 7.5336755944396225e-06,
      "loss": 0.5386,
      "step": 11696
    },
    {
      "epoch": 1.0945706008784226,
      "grad_norm": 0.83642578125,
      "learning_rate": 7.526123046792271e-06,
      "loss": 0.2857,
      "step": 11713
    },
    {
      "epoch": 1.0961592374544435,
      "grad_norm": 1.77734375,
      "learning_rate": 7.518562752070306e-06,
      "loss": 0.3344,
      "step": 11730
    },
    {
      "epoch": 1.0977478740304645,
      "grad_norm": 2.169921875,
      "learning_rate": 7.510994733459522e-06,
      "loss": 0.4948,
      "step": 11747
    },
    {
      "epoch": 1.0993365106064854,
      "grad_norm": 0.8671875,
      "learning_rate": 7.503419014169399e-06,
      "loss": 0.265,
      "step": 11764
    },
    {
      "epoch": 1.1009251471825063,
      "grad_norm": 1.4345703125,
      "learning_rate": 7.495835617433034e-06,
      "loss": 0.3476,
      "step": 11781
    },
    {
      "epoch": 1.1025137837585273,
      "grad_norm": 2.822265625,
      "learning_rate": 7.48824456650707e-06,
      "loss": 0.4714,
      "step": 11798
    },
    {
      "epoch": 1.1041024203345482,
      "grad_norm": 1.0888671875,
      "learning_rate": 7.4806458846716234e-06,
      "loss": 0.2834,
      "step": 11815
    },
    {
      "epoch": 1.1056910569105691,
      "grad_norm": 1.802734375,
      "learning_rate": 7.473039595230212e-06,
      "loss": 0.3939,
      "step": 11832
    },
    {
      "epoch": 1.10727969348659,
      "grad_norm": 2.61328125,
      "learning_rate": 7.465425721509686e-06,
      "loss": 0.5345,
      "step": 11849
    },
    {
      "epoch": 1.108868330062611,
      "grad_norm": 0.7802734375,
      "learning_rate": 7.457804286860153e-06,
      "loss": 0.2006,
      "step": 11866
    },
    {
      "epoch": 1.110456966638632,
      "grad_norm": 1.6953125,
      "learning_rate": 7.450175314654912e-06,
      "loss": 0.3586,
      "step": 11883
    },
    {
      "epoch": 1.1120456032146528,
      "grad_norm": 2.197265625,
      "learning_rate": 7.442538828290371e-06,
      "loss": 0.4907,
      "step": 11900
    },
    {
      "epoch": 1.1136342397906738,
      "grad_norm": 1.2666015625,
      "learning_rate": 7.43489485118599e-06,
      "loss": 0.2453,
      "step": 11917
    },
    {
      "epoch": 1.1152228763666947,
      "grad_norm": 1.318359375,
      "learning_rate": 7.427243406784198e-06,
      "loss": 0.3638,
      "step": 11934
    },
    {
      "epoch": 1.1168115129427156,
      "grad_norm": 2.912109375,
      "learning_rate": 7.419584518550325e-06,
      "loss": 0.535,
      "step": 11951
    },
    {
      "epoch": 1.1184001495187366,
      "grad_norm": 0.91845703125,
      "learning_rate": 7.411918209972528e-06,
      "loss": 0.2143,
      "step": 11968
    },
    {
      "epoch": 1.1199887860947575,
      "grad_norm": 1.634765625,
      "learning_rate": 7.404244504561725e-06,
      "loss": 0.3509,
      "step": 11985
    },
    {
      "epoch": 1.1215774226707784,
      "grad_norm": 0.1953125,
      "learning_rate": 7.396563425851514e-06,
      "loss": 0.5083,
      "step": 12002
    },
    {
      "epoch": 1.1231660592467994,
      "grad_norm": 1.025390625,
      "learning_rate": 7.388874997398107e-06,
      "loss": 0.2424,
      "step": 12019
    },
    {
      "epoch": 1.1247546958228203,
      "grad_norm": 1.56640625,
      "learning_rate": 7.381179242780255e-06,
      "loss": 0.4055,
      "step": 12036
    },
    {
      "epoch": 1.1263433323988412,
      "grad_norm": 0.27587890625,
      "learning_rate": 7.3734761855991785e-06,
      "loss": 0.4897,
      "step": 12053
    },
    {
      "epoch": 1.1279319689748621,
      "grad_norm": 0.85302734375,
      "learning_rate": 7.365765849478492e-06,
      "loss": 0.1958,
      "step": 12070
    },
    {
      "epoch": 1.129520605550883,
      "grad_norm": 1.5869140625,
      "learning_rate": 7.3580482580641365e-06,
      "loss": 0.4108,
      "step": 12087
    },
    {
      "epoch": 1.131109242126904,
      "grad_norm": 0.32666015625,
      "learning_rate": 7.350323435024298e-06,
      "loss": 0.4951,
      "step": 12104
    },
    {
      "epoch": 1.132697878702925,
      "grad_norm": 1.1943359375,
      "learning_rate": 7.342591404049343e-06,
      "loss": 0.24,
      "step": 12121
    },
    {
      "epoch": 1.1342865152789459,
      "grad_norm": 2.279296875,
      "learning_rate": 7.334852188851743e-06,
      "loss": 0.4216,
      "step": 12138
    },
    {
      "epoch": 1.1358751518549668,
      "grad_norm": 0.26171875,
      "learning_rate": 7.3271058131660036e-06,
      "loss": 0.4272,
      "step": 12155
    },
    {
      "epoch": 1.1374637884309877,
      "grad_norm": 1.5859375,
      "learning_rate": 7.319352300748588e-06,
      "loss": 0.2654,
      "step": 12172
    },
    {
      "epoch": 1.1390524250070087,
      "grad_norm": 2.1171875,
      "learning_rate": 7.3115916753778444e-06,
      "loss": 0.4304,
      "step": 12189
    },
    {
      "epoch": 1.1406410615830296,
      "grad_norm": 0.751953125,
      "learning_rate": 7.303823960853939e-06,
      "loss": 0.4446,
      "step": 12206
    },
    {
      "epoch": 1.1422296981590505,
      "grad_norm": 1.18359375,
      "learning_rate": 7.296049180998777e-06,
      "loss": 0.2652,
      "step": 12223
    },
    {
      "epoch": 1.1438183347350714,
      "grad_norm": 1.7744140625,
      "learning_rate": 7.288267359655931e-06,
      "loss": 0.3833,
      "step": 12240
    },
    {
      "epoch": 1.1454069713110924,
      "grad_norm": 0.556640625,
      "learning_rate": 7.280478520690571e-06,
      "loss": 0.3797,
      "step": 12257
    },
    {
      "epoch": 1.1469956078871133,
      "grad_norm": 1.154296875,
      "learning_rate": 7.272682687989383e-06,
      "loss": 0.2619,
      "step": 12274
    },
    {
      "epoch": 1.1485842444631342,
      "grad_norm": 1.6923828125,
      "learning_rate": 7.264879885460506e-06,
      "loss": 0.4565,
      "step": 12291
    },
    {
      "epoch": 1.1501728810391552,
      "grad_norm": 0.6904296875,
      "learning_rate": 7.257070137033455e-06,
      "loss": 0.4118,
      "step": 12308
    },
    {
      "epoch": 1.151761517615176,
      "grad_norm": 1.541015625,
      "learning_rate": 7.249253466659042e-06,
      "loss": 0.3148,
      "step": 12325
    },
    {
      "epoch": 1.153350154191197,
      "grad_norm": 1.6904296875,
      "learning_rate": 7.241429898309309e-06,
      "loss": 0.4355,
      "step": 12342
    },
    {
      "epoch": 1.154938790767218,
      "grad_norm": 0.765625,
      "learning_rate": 7.233599455977454e-06,
      "loss": 0.3971,
      "step": 12359
    },
    {
      "epoch": 1.1565274273432389,
      "grad_norm": 1.4931640625,
      "learning_rate": 7.225762163677754e-06,
      "loss": 0.2935,
      "step": 12376
    },
    {
      "epoch": 1.1581160639192598,
      "grad_norm": 1.8916015625,
      "learning_rate": 7.2179180454454945e-06,
      "loss": 0.4941,
      "step": 12393
    },
    {
      "epoch": 1.1597047004952807,
      "grad_norm": 0.82373046875,
      "learning_rate": 7.2100671253368945e-06,
      "loss": 0.3138,
      "step": 12410
    },
    {
      "epoch": 1.1612933370713017,
      "grad_norm": 1.486328125,
      "learning_rate": 7.202209427429035e-06,
      "loss": 0.298,
      "step": 12427
    },
    {
      "epoch": 1.1628819736473226,
      "grad_norm": 1.7890625,
      "learning_rate": 7.194344975819777e-06,
      "loss": 0.4171,
      "step": 12444
    },
    {
      "epoch": 1.1644706102233435,
      "grad_norm": 0.763671875,
      "learning_rate": 7.1864737946277015e-06,
      "loss": 0.3061,
      "step": 12461
    },
    {
      "epoch": 1.1660592467993645,
      "grad_norm": 1.4736328125,
      "learning_rate": 7.178595907992021e-06,
      "loss": 0.3356,
      "step": 12478
    },
    {
      "epoch": 1.1676478833753854,
      "grad_norm": 2.349609375,
      "learning_rate": 7.170711340072517e-06,
      "loss": 0.4678,
      "step": 12495
    },
    {
      "epoch": 1.1692365199514063,
      "grad_norm": 1.0888671875,
      "learning_rate": 7.162820115049457e-06,
      "loss": 0.3107,
      "step": 12512
    },
    {
      "epoch": 1.1708251565274272,
      "grad_norm": 1.474609375,
      "learning_rate": 7.1549222571235275e-06,
      "loss": 0.3037,
      "step": 12529
    },
    {
      "epoch": 1.1724137931034484,
      "grad_norm": 2.255859375,
      "learning_rate": 7.147017790515755e-06,
      "loss": 0.486,
      "step": 12546
    },
    {
      "epoch": 1.174002429679469,
      "grad_norm": 0.86474609375,
      "learning_rate": 7.139106739467434e-06,
      "loss": 0.2866,
      "step": 12563
    },
    {
      "epoch": 1.1755910662554903,
      "grad_norm": 1.68359375,
      "learning_rate": 7.131189128240052e-06,
      "loss": 0.3379,
      "step": 12580
    },
    {
      "epoch": 1.177179702831511,
      "grad_norm": 2.1953125,
      "learning_rate": 7.123264981115217e-06,
      "loss": 0.4976,
      "step": 12597
    },
    {
      "epoch": 1.1787683394075321,
      "grad_norm": 0.87255859375,
      "learning_rate": 7.115334322394576e-06,
      "loss": 0.2788,
      "step": 12614
    },
    {
      "epoch": 1.1803569759835528,
      "grad_norm": 1.265625,
      "learning_rate": 7.107397176399751e-06,
      "loss": 0.3375,
      "step": 12631
    },
    {
      "epoch": 1.181945612559574,
      "grad_norm": 2.478515625,
      "learning_rate": 7.0994535674722575e-06,
      "loss": 0.5168,
      "step": 12648
    },
    {
      "epoch": 1.1835342491355947,
      "grad_norm": 0.9921875,
      "learning_rate": 7.091503519973428e-06,
      "loss": 0.2396,
      "step": 12665
    },
    {
      "epoch": 1.1851228857116158,
      "grad_norm": 1.578125,
      "learning_rate": 7.083547058284349e-06,
      "loss": 0.4086,
      "step": 12682
    },
    {
      "epoch": 1.1867115222876368,
      "grad_norm": 2.16796875,
      "learning_rate": 7.075584206805768e-06,
      "loss": 0.5858,
      "step": 12699
    },
    {
      "epoch": 1.1883001588636577,
      "grad_norm": 0.96044921875,
      "learning_rate": 7.067614989958036e-06,
      "loss": 0.2382,
      "step": 12716
    },
    {
      "epoch": 1.1898887954396786,
      "grad_norm": 1.8857421875,
      "learning_rate": 7.05963943218102e-06,
      "loss": 0.3839,
      "step": 12733
    },
    {
      "epoch": 1.1914774320156996,
      "grad_norm": 3.056640625,
      "learning_rate": 7.05165755793404e-06,
      "loss": 0.5271,
      "step": 12750
    },
    {
      "epoch": 1.1930660685917205,
      "grad_norm": 0.78369140625,
      "learning_rate": 7.043669391695778e-06,
      "loss": 0.1857,
      "step": 12767
    },
    {
      "epoch": 1.1946547051677414,
      "grad_norm": 1.91796875,
      "learning_rate": 7.035674957964218e-06,
      "loss": 0.379,
      "step": 12784
    },
    {
      "epoch": 1.1962433417437623,
      "grad_norm": 3.716796875,
      "learning_rate": 7.027674281256568e-06,
      "loss": 0.5485,
      "step": 12801
    },
    {
      "epoch": 1.1978319783197833,
      "grad_norm": 1.1279296875,
      "learning_rate": 7.019667386109173e-06,
      "loss": 0.188,
      "step": 12818
    },
    {
      "epoch": 1.1994206148958042,
      "grad_norm": 1.658203125,
      "learning_rate": 7.011654297077459e-06,
      "loss": 0.3974,
      "step": 12835
    },
    {
      "epoch": 1.2000747593682832,
      "eval_loss": 0.3795914947986603,
      "eval_runtime": 1038.76,
      "eval_samples_per_second": 7.726,
      "eval_steps_per_second": 2.575,
      "step": 12842
    },
    {
      "epoch": 1.2010092514718251,
      "grad_norm": 0.3876953125,
      "learning_rate": 7.0036350387358374e-06,
      "loss": 0.5274,
      "step": 12852
    },
    {
      "epoch": 1.202597888047846,
      "grad_norm": 0.99462890625,
      "learning_rate": 6.9956096356776474e-06,
      "loss": 0.2221,
      "step": 12869
    },
    {
      "epoch": 1.204186524623867,
      "grad_norm": 1.5673828125,
      "learning_rate": 6.987578112515066e-06,
      "loss": 0.3991,
      "step": 12886
    },
    {
      "epoch": 1.205775161199888,
      "grad_norm": 0.56005859375,
      "learning_rate": 6.979540493879047e-06,
      "loss": 0.5019,
      "step": 12903
    },
    {
      "epoch": 1.2073637977759089,
      "grad_norm": 1.181640625,
      "learning_rate": 6.971496804419231e-06,
      "loss": 0.2578,
      "step": 12920
    },
    {
      "epoch": 1.2089524343519298,
      "grad_norm": 2.013671875,
      "learning_rate": 6.963447068803877e-06,
      "loss": 0.4037,
      "step": 12937
    },
    {
      "epoch": 1.2105410709279507,
      "grad_norm": 0.371826171875,
      "learning_rate": 6.955391311719792e-06,
      "loss": 0.5013,
      "step": 12954
    },
    {
      "epoch": 1.2121297075039716,
      "grad_norm": 1.1318359375,
      "learning_rate": 6.947329557872243e-06,
      "loss": 0.2541,
      "step": 12971
    },
    {
      "epoch": 1.2137183440799926,
      "grad_norm": 1.8056640625,
      "learning_rate": 6.9392618319848926e-06,
      "loss": 0.4242,
      "step": 12988
    },
    {
      "epoch": 1.2153069806560135,
      "grad_norm": 0.68408203125,
      "learning_rate": 6.9311881587997146e-06,
      "loss": 0.4894,
      "step": 13005
    },
    {
      "epoch": 1.2168956172320344,
      "grad_norm": 1.271484375,
      "learning_rate": 6.923108563076924e-06,
      "loss": 0.2698,
      "step": 13022
    },
    {
      "epoch": 1.2184842538080554,
      "grad_norm": 1.626953125,
      "learning_rate": 6.915023069594897e-06,
      "loss": 0.455,
      "step": 13039
    },
    {
      "epoch": 1.2200728903840763,
      "grad_norm": 0.7734375,
      "learning_rate": 6.906931703150101e-06,
      "loss": 0.4212,
      "step": 13056
    },
    {
      "epoch": 1.2216615269600972,
      "grad_norm": 1.4501953125,
      "learning_rate": 6.898834488557013e-06,
      "loss": 0.2509,
      "step": 13073
    },
    {
      "epoch": 1.2232501635361182,
      "grad_norm": 1.734375,
      "learning_rate": 6.890731450648041e-06,
      "loss": 0.3582,
      "step": 13090
    },
    {
      "epoch": 1.224838800112139,
      "grad_norm": 0.6435546875,
      "learning_rate": 6.882622614273453e-06,
      "loss": 0.381,
      "step": 13107
    },
    {
      "epoch": 1.22642743668816,
      "grad_norm": 1.1279296875,
      "learning_rate": 6.8745080043013055e-06,
      "loss": 0.2658,
      "step": 13124
    },
    {
      "epoch": 1.228016073264181,
      "grad_norm": 1.7255859375,
      "learning_rate": 6.8663876456173566e-06,
      "loss": 0.4445,
      "step": 13141
    },
    {
      "epoch": 1.2296047098402019,
      "grad_norm": 0.673828125,
      "learning_rate": 6.858261563124993e-06,
      "loss": 0.4028,
      "step": 13158
    },
    {
      "epoch": 1.2311933464162228,
      "grad_norm": 1.2802734375,
      "learning_rate": 6.8501297817451605e-06,
      "loss": 0.2751,
      "step": 13175
    },
    {
      "epoch": 1.2327819829922437,
      "grad_norm": 2.01953125,
      "learning_rate": 6.841992326416275e-06,
      "loss": 0.4528,
      "step": 13192
    },
    {
      "epoch": 1.2343706195682647,
      "grad_norm": 1.359375,
      "learning_rate": 6.833849222094162e-06,
      "loss": 0.378,
      "step": 13209
    },
    {
      "epoch": 1.2359592561442856,
      "grad_norm": 1.4921875,
      "learning_rate": 6.825700493751963e-06,
      "loss": 0.2893,
      "step": 13226
    },
    {
      "epoch": 1.2375478927203065,
      "grad_norm": 2.029296875,
      "learning_rate": 6.817546166380072e-06,
      "loss": 0.4539,
      "step": 13243
    },
    {
      "epoch": 1.2391365292963274,
      "grad_norm": 0.77197265625,
      "learning_rate": 6.8093862649860485e-06,
      "loss": 0.3487,
      "step": 13260
    },
    {
      "epoch": 1.2407251658723484,
      "grad_norm": 1.5341796875,
      "learning_rate": 6.801220814594556e-06,
      "loss": 0.3286,
      "step": 13277
    },
    {
      "epoch": 1.2423138024483693,
      "grad_norm": 2.20703125,
      "learning_rate": 6.793049840247266e-06,
      "loss": 0.4547,
      "step": 13294
    },
    {
      "epoch": 1.2439024390243902,
      "grad_norm": 0.740234375,
      "learning_rate": 6.784873367002797e-06,
      "loss": 0.3541,
      "step": 13311
    },
    {
      "epoch": 1.2454910756004112,
      "grad_norm": 1.4375,
      "learning_rate": 6.77669141993663e-06,
      "loss": 0.2878,
      "step": 13328
    },
    {
      "epoch": 1.247079712176432,
      "grad_norm": 2.083984375,
      "learning_rate": 6.768504024141028e-06,
      "loss": 0.5297,
      "step": 13345
    },
    {
      "epoch": 1.248668348752453,
      "grad_norm": 0.73388671875,
      "learning_rate": 6.760311204724972e-06,
      "loss": 0.3146,
      "step": 13362
    },
    {
      "epoch": 1.250256985328474,
      "grad_norm": 1.25,
      "learning_rate": 6.752112986814071e-06,
      "loss": 0.2836,
      "step": 13379
    },
    {
      "epoch": 1.2518456219044949,
      "grad_norm": 2.337890625,
      "learning_rate": 6.743909395550492e-06,
      "loss": 0.4845,
      "step": 13396
    },
    {
      "epoch": 1.2534342584805158,
      "grad_norm": 0.7998046875,
      "learning_rate": 6.7357004560928785e-06,
      "loss": 0.3223,
      "step": 13413
    },
    {
      "epoch": 1.2550228950565367,
      "grad_norm": 1.37109375,
      "learning_rate": 6.72748619361628e-06,
      "loss": 0.3468,
      "step": 13430
    },
    {
      "epoch": 1.2566115316325577,
      "grad_norm": 2.458984375,
      "learning_rate": 6.7192666333120645e-06,
      "loss": 0.4935,
      "step": 13447
    },
    {
      "epoch": 1.2582001682085786,
      "grad_norm": 0.85400390625,
      "learning_rate": 6.711041800387855e-06,
      "loss": 0.2711,
      "step": 13464
    },
    {
      "epoch": 1.2597888047845995,
      "grad_norm": 1.5322265625,
      "learning_rate": 6.702811720067439e-06,
      "loss": 0.344,
      "step": 13481
    },
    {
      "epoch": 1.2613774413606205,
      "grad_norm": 2.20703125,
      "learning_rate": 6.694576417590696e-06,
      "loss": 0.5246,
      "step": 13498
    },
    {
      "epoch": 1.2629660779366414,
      "grad_norm": 0.98779296875,
      "learning_rate": 6.686335918213524e-06,
      "loss": 0.2756,
      "step": 13515
    },
    {
      "epoch": 1.2645547145126623,
      "grad_norm": 1.9072265625,
      "learning_rate": 6.678090247207761e-06,
      "loss": 0.383,
      "step": 13532
    },
    {
      "epoch": 1.2661433510886833,
      "grad_norm": 2.6015625,
      "learning_rate": 6.669839429861096e-06,
      "loss": 0.5081,
      "step": 13549
    },
    {
      "epoch": 1.2677319876647042,
      "grad_norm": 1.142578125,
      "learning_rate": 6.6615834914770085e-06,
      "loss": 0.2559,
      "step": 13566
    },
    {
      "epoch": 1.2693206242407251,
      "grad_norm": 1.6943359375,
      "learning_rate": 6.653322457374682e-06,
      "loss": 0.3575,
      "step": 13583
    },
    {
      "epoch": 1.270909260816746,
      "grad_norm": 3.048828125,
      "learning_rate": 6.645056352888926e-06,
      "loss": 0.5099,
      "step": 13600
    },
    {
      "epoch": 1.272497897392767,
      "grad_norm": 0.96728515625,
      "learning_rate": 6.6367852033700995e-06,
      "loss": 0.2207,
      "step": 13617
    },
    {
      "epoch": 1.274086533968788,
      "grad_norm": 1.6015625,
      "learning_rate": 6.628509034184036e-06,
      "loss": 0.41,
      "step": 13634
    },
    {
      "epoch": 1.2756751705448088,
      "grad_norm": 2.892578125,
      "learning_rate": 6.620227870711962e-06,
      "loss": 0.5572,
      "step": 13651
    },
    {
      "epoch": 1.2772638071208298,
      "grad_norm": 1.1025390625,
      "learning_rate": 6.611941738350417e-06,
      "loss": 0.2306,
      "step": 13668
    },
    {
      "epoch": 1.2788524436968507,
      "grad_norm": 1.99609375,
      "learning_rate": 6.603650662511185e-06,
      "loss": 0.3919,
      "step": 13685
    },
    {
      "epoch": 1.2804410802728716,
      "grad_norm": 0.301025390625,
      "learning_rate": 6.595354668621207e-06,
      "loss": 0.4825,
      "step": 13702
    },
    {
      "epoch": 1.2820297168488926,
      "grad_norm": 1.1357421875,
      "learning_rate": 6.587053782122504e-06,
      "loss": 0.2365,
      "step": 13719
    },
    {
      "epoch": 1.2836183534249135,
      "grad_norm": 1.6669921875,
      "learning_rate": 6.57874802847211e-06,
      "loss": 0.3961,
      "step": 13736
    },
    {
      "epoch": 1.2852069900009344,
      "grad_norm": 0.37646484375,
      "learning_rate": 6.570437433141977e-06,
      "loss": 0.4984,
      "step": 13753
    },
    {
      "epoch": 1.2867956265769553,
      "grad_norm": 1.2783203125,
      "learning_rate": 6.562122021618909e-06,
      "loss": 0.2459,
      "step": 13770
    },
    {
      "epoch": 1.2883842631529765,
      "grad_norm": 2.029296875,
      "learning_rate": 6.553801819404479e-06,
      "loss": 0.4271,
      "step": 13787
    },
    {
      "epoch": 1.2899728997289972,
      "grad_norm": 0.75048828125,
      "learning_rate": 6.545476852014956e-06,
      "loss": 0.4857,
      "step": 13804
    },
    {
      "epoch": 1.2915615363050184,
      "grad_norm": 1.345703125,
      "learning_rate": 6.537147144981218e-06,
      "loss": 0.2486,
      "step": 13821
    },
    {
      "epoch": 1.293150172881039,
      "grad_norm": 2.294921875,
      "learning_rate": 6.528812723848678e-06,
      "loss": 0.4263,
      "step": 13838
    },
    {
      "epoch": 1.2947388094570602,
      "grad_norm": 0.54931640625,
      "learning_rate": 6.520473614177212e-06,
      "loss": 0.4839,
      "step": 13855
    },
    {
      "epoch": 1.296327446033081,
      "grad_norm": 1.333984375,
      "learning_rate": 6.512129841541067e-06,
      "loss": 0.3074,
      "step": 13872
    },
    {
      "epoch": 1.297916082609102,
      "grad_norm": 1.908203125,
      "learning_rate": 6.503781431528798e-06,
      "loss": 0.4178,
      "step": 13889
    },
    {
      "epoch": 1.2995047191851228,
      "grad_norm": 0.693359375,
      "learning_rate": 6.495428409743176e-06,
      "loss": 0.4279,
      "step": 13906
    },
    {
      "epoch": 1.301093355761144,
      "grad_norm": 0.99365234375,
      "learning_rate": 6.487070801801118e-06,
      "loss": 0.2228,
      "step": 13923
    },
    {
      "epoch": 1.3026819923371646,
      "grad_norm": 1.9697265625,
      "learning_rate": 6.478708633333605e-06,
      "loss": 0.4495,
      "step": 13940
    },
    {
      "epoch": 1.3042706289131858,
      "grad_norm": 0.5693359375,
      "learning_rate": 6.4703419299856055e-06,
      "loss": 0.3705,
      "step": 13957
    },
    {
      "epoch": 1.3058592654892065,
      "grad_norm": 1.10546875,
      "learning_rate": 6.461970717415993e-06,
      "loss": 0.2536,
      "step": 13974
    },
    {
      "epoch": 1.3074479020652277,
      "grad_norm": 2.14453125,
      "learning_rate": 6.45359502129747e-06,
      "loss": 0.4457,
      "step": 13991
    },
    {
      "epoch": 1.3090365386412484,
      "grad_norm": 0.705078125,
      "learning_rate": 6.445214867316495e-06,
      "loss": 0.4011,
      "step": 14008
    },
    {
      "epoch": 1.3106251752172695,
      "grad_norm": 2.06640625,
      "learning_rate": 6.436830281173188e-06,
      "loss": 0.2763,
      "step": 14025
    },
    {
      "epoch": 1.3122138117932902,
      "grad_norm": 2.109375,
      "learning_rate": 6.428441288581268e-06,
      "loss": 0.4674,
      "step": 14042
    },
    {
      "epoch": 1.3138024483693114,
      "grad_norm": 0.7265625,
      "learning_rate": 6.420047915267966e-06,
      "loss": 0.3664,
      "step": 14059
    },
    {
      "epoch": 1.315391084945332,
      "grad_norm": 1.033203125,
      "learning_rate": 6.411650186973949e-06,
      "loss": 0.276,
      "step": 14076
    },
    {
      "epoch": 1.3169797215213532,
      "grad_norm": 2.201171875,
      "learning_rate": 6.4032481294532375e-06,
      "loss": 0.4681,
      "step": 14093
    },
    {
      "epoch": 1.3185683580973742,
      "grad_norm": 0.69580078125,
      "learning_rate": 6.394841768473132e-06,
      "loss": 0.3287,
      "step": 14110
    },
    {
      "epoch": 1.320156994673395,
      "grad_norm": 1.529296875,
      "learning_rate": 6.386431129814127e-06,
      "loss": 0.2696,
      "step": 14127
    },
    {
      "epoch": 1.321745631249416,
      "grad_norm": 2.462890625,
      "learning_rate": 6.378016239269837e-06,
      "loss": 0.4664,
      "step": 14144
    },
    {
      "epoch": 1.323334267825437,
      "grad_norm": 0.74951171875,
      "learning_rate": 6.3695971226469175e-06,
      "loss": 0.3279,
      "step": 14161
    },
    {
      "epoch": 1.3249229044014579,
      "grad_norm": 1.46875,
      "learning_rate": 6.361173805764982e-06,
      "loss": 0.2847,
      "step": 14178
    },
    {
      "epoch": 1.3265115409774788,
      "grad_norm": 1.794921875,
      "learning_rate": 6.352746314456531e-06,
      "loss": 0.4675,
      "step": 14195
    },
    {
      "epoch": 1.3281001775534997,
      "grad_norm": 0.84326171875,
      "learning_rate": 6.344314674566858e-06,
      "loss": 0.3128,
      "step": 14212
    },
    {
      "epoch": 1.3296888141295207,
      "grad_norm": 1.91015625,
      "learning_rate": 6.335878911953988e-06,
      "loss": 0.3677,
      "step": 14229
    },
    {
      "epoch": 1.3312774507055416,
      "grad_norm": 2.060546875,
      "learning_rate": 6.327439052488582e-06,
      "loss": 0.4926,
      "step": 14246
    },
    {
      "epoch": 1.3328660872815625,
      "grad_norm": 0.9580078125,
      "learning_rate": 6.318995122053873e-06,
      "loss": 0.289,
      "step": 14263
    },
    {
      "epoch": 1.3344547238575835,
      "grad_norm": 1.7783203125,
      "learning_rate": 6.310547146545571e-06,
      "loss": 0.3204,
      "step": 14280
    },
    {
      "epoch": 1.3360433604336044,
      "grad_norm": 2.275390625,
      "learning_rate": 6.302095151871798e-06,
      "loss": 0.5622,
      "step": 14297
    },
    {
      "epoch": 1.3376319970096253,
      "grad_norm": 1.029296875,
      "learning_rate": 6.293639163952996e-06,
      "loss": 0.2684,
      "step": 14314
    },
    {
      "epoch": 1.3392206335856462,
      "grad_norm": 1.7470703125,
      "learning_rate": 6.285179208721859e-06,
      "loss": 0.3178,
      "step": 14331
    },
    {
      "epoch": 1.3408092701616672,
      "grad_norm": 2.453125,
      "learning_rate": 6.276715312123244e-06,
      "loss": 0.5155,
      "step": 14348
    },
    {
      "epoch": 1.342397906737688,
      "grad_norm": 0.71435546875,
      "learning_rate": 6.2682475001140965e-06,
      "loss": 0.2613,
      "step": 14365
    },
    {
      "epoch": 1.343986543313709,
      "grad_norm": 1.611328125,
      "learning_rate": 6.25977579866337e-06,
      "loss": 0.3473,
      "step": 14382
    },
    {
      "epoch": 1.34557517988973,
      "grad_norm": 3.1796875,
      "learning_rate": 6.251300233751947e-06,
      "loss": 0.48,
      "step": 14399
    },
    {
      "epoch": 1.347163816465751,
      "grad_norm": 1.0654296875,
      "learning_rate": 6.242820831372556e-06,
      "loss": 0.2246,
      "step": 14416
    },
    {
      "epoch": 1.3487524530417718,
      "grad_norm": 1.462890625,
      "learning_rate": 6.234337617529696e-06,
      "loss": 0.3645,
      "step": 14433
    },
    {
      "epoch": 1.3503410896177928,
      "grad_norm": 2.978515625,
      "learning_rate": 6.225850618239554e-06,
      "loss": 0.528,
      "step": 14450
    },
    {
      "epoch": 1.3519297261938137,
      "grad_norm": 1.1171875,
      "learning_rate": 6.217359859529926e-06,
      "loss": 0.2103,
      "step": 14467
    },
    {
      "epoch": 1.3535183627698346,
      "grad_norm": 1.2607421875,
      "learning_rate": 6.208865367440139e-06,
      "loss": 0.4161,
      "step": 14484
    },
    {
      "epoch": 1.3551069993458555,
      "grad_norm": 2.921875,
      "learning_rate": 6.200367168020968e-06,
      "loss": 0.5296,
      "step": 14501
    },
    {
      "epoch": 1.3566956359218765,
      "grad_norm": 0.90673828125,
      "learning_rate": 6.191865287334558e-06,
      "loss": 0.1648,
      "step": 14518
    },
    {
      "epoch": 1.3582842724978974,
      "grad_norm": 2.060546875,
      "learning_rate": 6.183359751454343e-06,
      "loss": 0.3659,
      "step": 14535
    },
    {
      "epoch": 1.3598729090739183,
      "grad_norm": 0.457763671875,
      "learning_rate": 6.174850586464968e-06,
      "loss": 0.5812,
      "step": 14552
    },
    {
      "epoch": 1.3614615456499393,
      "grad_norm": 0.904296875,
      "learning_rate": 6.166337818462207e-06,
      "loss": 0.1595,
      "step": 14569
    },
    {
      "epoch": 1.3630501822259602,
      "grad_norm": 1.802734375,
      "learning_rate": 6.157821473552884e-06,
      "loss": 0.3823,
      "step": 14586
    },
    {
      "epoch": 1.3646388188019811,
      "grad_norm": 0.1177978515625,
      "learning_rate": 6.149301577854792e-06,
      "loss": 0.4866,
      "step": 14603
    },
    {
      "epoch": 1.366227455378002,
      "grad_norm": 1.244140625,
      "learning_rate": 6.140778157496612e-06,
      "loss": 0.2177,
      "step": 14620
    },
    {
      "epoch": 1.367816091954023,
      "grad_norm": 2.396484375,
      "learning_rate": 6.132251238617838e-06,
      "loss": 0.4241,
      "step": 14637
    },
    {
      "epoch": 1.369404728530044,
      "grad_norm": 0.229248046875,
      "learning_rate": 6.123720847368691e-06,
      "loss": 0.506,
      "step": 14654
    },
    {
      "epoch": 1.3709933651060648,
      "grad_norm": 1.3544921875,
      "learning_rate": 6.11518700991004e-06,
      "loss": 0.2616,
      "step": 14671
    },
    {
      "epoch": 1.3725820016820858,
      "grad_norm": 1.791015625,
      "learning_rate": 6.106649752413326e-06,
      "loss": 0.3821,
      "step": 14688
    },
    {
      "epoch": 1.3741706382581067,
      "grad_norm": 0.6923828125,
      "learning_rate": 6.0981091010604764e-06,
      "loss": 0.481,
      "step": 14705
    },
    {
      "epoch": 1.3757592748341276,
      "grad_norm": 1.2138671875,
      "learning_rate": 6.089565082043827e-06,
      "loss": 0.2808,
      "step": 14722
    },
    {
      "epoch": 1.3773479114101486,
      "grad_norm": 1.8466796875,
      "learning_rate": 6.08101772156604e-06,
      "loss": 0.4308,
      "step": 14739
    },
    {
      "epoch": 1.3789365479861695,
      "grad_norm": 0.470703125,
      "learning_rate": 6.072467045840029e-06,
      "loss": 0.4504,
      "step": 14756
    },
    {
      "epoch": 1.3805251845621904,
      "grad_norm": 1.4443359375,
      "learning_rate": 6.0639130810888715e-06,
      "loss": 0.2486,
      "step": 14773
    },
    {
      "epoch": 1.3821138211382114,
      "grad_norm": 2.193359375,
      "learning_rate": 6.055355853545733e-06,
      "loss": 0.4612,
      "step": 14790
    },
    {
      "epoch": 1.3837024577142323,
      "grad_norm": 0.625,
      "learning_rate": 6.046795389453781e-06,
      "loss": 0.441,
      "step": 14807
    },
    {
      "epoch": 1.3852910942902532,
      "grad_norm": 1.5810546875,
      "learning_rate": 6.038231715066119e-06,
      "loss": 0.2764,
      "step": 14824
    },
    {
      "epoch": 1.3868797308662741,
      "grad_norm": 2.041015625,
      "learning_rate": 6.029664856645687e-06,
      "loss": 0.4507,
      "step": 14841
    },
    {
      "epoch": 1.388468367442295,
      "grad_norm": 0.8662109375,
      "learning_rate": 6.021094840465191e-06,
      "loss": 0.4188,
      "step": 14858
    },
    {
      "epoch": 1.390057004018316,
      "grad_norm": 1.3876953125,
      "learning_rate": 6.012521692807025e-06,
      "loss": 0.3199,
      "step": 14875
    },
    {
      "epoch": 1.391645640594337,
      "grad_norm": 2.04296875,
      "learning_rate": 6.003945439963181e-06,
      "loss": 0.4747,
      "step": 14892
    },
    {
      "epoch": 1.3932342771703579,
      "grad_norm": 0.826171875,
      "learning_rate": 5.99536610823518e-06,
      "loss": 0.353,
      "step": 14909
    },
    {
      "epoch": 1.3948229137463788,
      "grad_norm": 1.2724609375,
      "learning_rate": 5.9867837239339795e-06,
      "loss": 0.3237,
      "step": 14926
    },
    {
      "epoch": 1.3964115503223997,
      "grad_norm": 2.369140625,
      "learning_rate": 5.9781983133799035e-06,
      "loss": 0.4762,
      "step": 14943
    },
    {
      "epoch": 1.3980001868984206,
      "grad_norm": 0.6103515625,
      "learning_rate": 5.969609902902553e-06,
      "loss": 0.3515,
      "step": 14960
    },
    {
      "epoch": 1.3995888234744416,
      "grad_norm": 1.5712890625,
      "learning_rate": 5.9610185188407325e-06,
      "loss": 0.338,
      "step": 14977
    },
    {
      "epoch": 1.4011774600504625,
      "grad_norm": 2.37109375,
      "learning_rate": 5.952424187542362e-06,
      "loss": 0.4391,
      "step": 14994
    },
    {
      "epoch": 1.4027660966264834,
      "grad_norm": 0.72265625,
      "learning_rate": 5.943826935364404e-06,
      "loss": 0.3283,
      "step": 15011
    },
    {
      "epoch": 1.4043547332025044,
      "grad_norm": 2.115234375,
      "learning_rate": 5.935226788672777e-06,
      "loss": 0.3072,
      "step": 15028
    },
    {
      "epoch": 1.4059433697785253,
      "grad_norm": 2.341796875,
      "learning_rate": 5.926623773842274e-06,
      "loss": 0.5041,
      "step": 15045
    },
    {
      "epoch": 1.4075320063545462,
      "grad_norm": 0.8828125,
      "learning_rate": 5.918017917256489e-06,
      "loss": 0.2725,
      "step": 15062
    },
    {
      "epoch": 1.4091206429305672,
      "grad_norm": 1.5478515625,
      "learning_rate": 5.9094092453077255e-06,
      "loss": 0.3567,
      "step": 15079
    },
    {
      "epoch": 1.410709279506588,
      "grad_norm": 2.296875,
      "learning_rate": 5.900797784396926e-06,
      "loss": 0.5107,
      "step": 15096
    },
    {
      "epoch": 1.412297916082609,
      "grad_norm": 0.77392578125,
      "learning_rate": 5.892183560933583e-06,
      "loss": 0.2742,
      "step": 15113
    },
    {
      "epoch": 1.4138865526586302,
      "grad_norm": 1.3857421875,
      "learning_rate": 5.883566601335664e-06,
      "loss": 0.3273,
      "step": 15130
    },
    {
      "epoch": 1.4154751892346509,
      "grad_norm": 2.349609375,
      "learning_rate": 5.874946932029522e-06,
      "loss": 0.5161,
      "step": 15147
    },
    {
      "epoch": 1.417063825810672,
      "grad_norm": 0.85205078125,
      "learning_rate": 5.866324579449829e-06,
      "loss": 0.2592,
      "step": 15164
    },
    {
      "epoch": 1.4186524623866927,
      "grad_norm": 1.5478515625,
      "learning_rate": 5.857699570039477e-06,
      "loss": 0.3146,
      "step": 15181
    },
    {
      "epoch": 1.4202410989627139,
      "grad_norm": 2.353515625,
      "learning_rate": 5.8490719302495106e-06,
      "loss": 0.4906,
      "step": 15198
    },
    {
      "epoch": 1.4218297355387346,
      "grad_norm": 0.880859375,
      "learning_rate": 5.8404416865390414e-06,
      "loss": 0.3252,
      "step": 15215
    },
    {
      "epoch": 1.4234183721147557,
      "grad_norm": 1.880859375,
      "learning_rate": 5.831808865375164e-06,
      "loss": 0.4085,
      "step": 15232
    },
    {
      "epoch": 1.4250070086907765,
      "grad_norm": 2.556640625,
      "learning_rate": 5.8231734932328806e-06,
      "loss": 0.5274,
      "step": 15249
    },
    {
      "epoch": 1.4265956452667976,
      "grad_norm": 1.1748046875,
      "learning_rate": 5.814535596595014e-06,
      "loss": 0.2379,
      "step": 15266
    },
    {
      "epoch": 1.4281842818428183,
      "grad_norm": 1.7275390625,
      "learning_rate": 5.805895201952133e-06,
      "loss": 0.3429,
      "step": 15283
    },
    {
      "epoch": 1.4297729184188395,
      "grad_norm": 2.76953125,
      "learning_rate": 5.797252335802462e-06,
      "loss": 0.5217,
      "step": 15300
    },
    {
      "epoch": 1.4313615549948602,
      "grad_norm": 0.87841796875,
      "learning_rate": 5.788607024651809e-06,
      "loss": 0.2199,
      "step": 15317
    },
    {
      "epoch": 1.4329501915708813,
      "grad_norm": 2.58984375,
      "learning_rate": 5.77995929501348e-06,
      "loss": 0.3381,
      "step": 15334
    },
    {
      "epoch": 1.434538828146902,
      "grad_norm": 2.736328125,
      "learning_rate": 5.771309173408194e-06,
      "loss": 0.5164,
      "step": 15351
    },
    {
      "epoch": 1.4361274647229232,
      "grad_norm": 1.0869140625,
      "learning_rate": 5.762656686364009e-06,
      "loss": 0.1842,
      "step": 15368
    },
    {
      "epoch": 1.437716101298944,
      "grad_norm": 2.005859375,
      "learning_rate": 5.754001860416237e-06,
      "loss": 0.3505,
      "step": 15385
    },
    {
      "epoch": 1.439304737874965,
      "grad_norm": 0.58642578125,
      "learning_rate": 5.745344722107366e-06,
      "loss": 0.5094,
      "step": 15402
    },
    {
      "epoch": 1.4408933744509858,
      "grad_norm": 0.9833984375,
      "learning_rate": 5.736685297986968e-06,
      "loss": 0.1658,
      "step": 15419
    },
    {
      "epoch": 1.442482011027007,
      "grad_norm": 1.51171875,
      "learning_rate": 5.728023614611632e-06,
      "loss": 0.3594,
      "step": 15436
    },
    {
      "epoch": 1.4440706476030278,
      "grad_norm": 0.35302734375,
      "learning_rate": 5.719359698544871e-06,
      "loss": 0.478,
      "step": 15453
    },
    {
      "epoch": 1.4456592841790488,
      "grad_norm": 0.9892578125,
      "learning_rate": 5.710693576357048e-06,
      "loss": 0.2286,
      "step": 15470
    },
    {
      "epoch": 1.4472479207550697,
      "grad_norm": 2.291015625,
      "learning_rate": 5.702025274625292e-06,
      "loss": 0.4044,
      "step": 15487
    },
    {
      "epoch": 1.4488365573310906,
      "grad_norm": 0.56884765625,
      "learning_rate": 5.693354819933414e-06,
      "loss": 0.4948,
      "step": 15504
    },
    {
      "epoch": 1.4504251939071116,
      "grad_norm": 1.134765625,
      "learning_rate": 5.684682238871828e-06,
      "loss": 0.2392,
      "step": 15521
    },
    {
      "epoch": 1.4520138304831325,
      "grad_norm": 1.896484375,
      "learning_rate": 5.676007558037469e-06,
      "loss": 0.3929,
      "step": 15538
    },
    {
      "epoch": 1.4536024670591534,
      "grad_norm": 0.58984375,
      "learning_rate": 5.667330804033717e-06,
      "loss": 0.4856,
      "step": 15555
    },
    {
      "epoch": 1.4551911036351743,
      "grad_norm": 1.1396484375,
      "learning_rate": 5.658652003470301e-06,
      "loss": 0.2563,
      "step": 15572
    },
    {
      "epoch": 1.4567797402111953,
      "grad_norm": 1.947265625,
      "learning_rate": 5.649971182963232e-06,
      "loss": 0.4019,
      "step": 15589
    },
    {
      "epoch": 1.4583683767872162,
      "grad_norm": 0.83544921875,
      "learning_rate": 5.641288369134713e-06,
      "loss": 0.4449,
      "step": 15606
    },
    {
      "epoch": 1.4599570133632371,
      "grad_norm": 1.373046875,
      "learning_rate": 5.632603588613065e-06,
      "loss": 0.2957,
      "step": 15623
    },
    {
      "epoch": 1.461545649939258,
      "grad_norm": 1.6875,
      "learning_rate": 5.623916868032635e-06,
      "loss": 0.4386,
      "step": 15640
    },
    {
      "epoch": 1.463134286515279,
      "grad_norm": 0.59130859375,
      "learning_rate": 5.61522823403372e-06,
      "loss": 0.4349,
      "step": 15657
    },
    {
      "epoch": 1.4647229230913,
      "grad_norm": 1.2783203125,
      "learning_rate": 5.60653771326249e-06,
      "loss": 0.2711,
      "step": 15674
    },
    {
      "epoch": 1.4663115596673209,
      "grad_norm": 1.875,
      "learning_rate": 5.597845332370895e-06,
      "loss": 0.4419,
      "step": 15691
    },
    {
      "epoch": 1.4679001962433418,
      "grad_norm": 0.6357421875,
      "learning_rate": 5.589151118016594e-06,
      "loss": 0.3355,
      "step": 15708
    },
    {
      "epoch": 1.4694888328193627,
      "grad_norm": 1.3251953125,
      "learning_rate": 5.5804550968628665e-06,
      "loss": 0.2883,
      "step": 15725
    },
    {
      "epoch": 1.4710774693953836,
      "grad_norm": 1.6796875,
      "learning_rate": 5.5717572955785374e-06,
      "loss": 0.4214,
      "step": 15742
    },
    {
      "epoch": 1.4726661059714046,
      "grad_norm": 0.63037109375,
      "learning_rate": 5.563057740837884e-06,
      "loss": 0.3976,
      "step": 15759
    },
    {
      "epoch": 1.4742547425474255,
      "grad_norm": 1.1328125,
      "learning_rate": 5.554356459320566e-06,
      "loss": 0.2648,
      "step": 15776
    },
    {
      "epoch": 1.4758433791234464,
      "grad_norm": 2.443359375,
      "learning_rate": 5.545653477711537e-06,
      "loss": 0.4546,
      "step": 15793
    },
    {
      "epoch": 1.4774320156994674,
      "grad_norm": 0.78076171875,
      "learning_rate": 5.536948822700965e-06,
      "loss": 0.3532,
      "step": 15810
    },
    {
      "epoch": 1.4790206522754883,
      "grad_norm": 1.1982421875,
      "learning_rate": 5.528242520984148e-06,
      "loss": 0.2723,
      "step": 15827
    },
    {
      "epoch": 1.4806092888515092,
      "grad_norm": 2.349609375,
      "learning_rate": 5.519534599261439e-06,
      "loss": 0.4543,
      "step": 15844
    },
    {
      "epoch": 1.4821979254275301,
      "grad_norm": 0.77587890625,
      "learning_rate": 5.510825084238152e-06,
      "loss": 0.3221,
      "step": 15861
    },
    {
      "epoch": 1.483786562003551,
      "grad_norm": 1.455078125,
      "learning_rate": 5.502114002624495e-06,
      "loss": 0.3739,
      "step": 15878
    },
    {
      "epoch": 1.485375198579572,
      "grad_norm": 2.17578125,
      "learning_rate": 5.493401381135477e-06,
      "loss": 0.5235,
      "step": 15895
    },
    {
      "epoch": 1.486963835155593,
      "grad_norm": 0.884765625,
      "learning_rate": 5.484687246490827e-06,
      "loss": 0.333,
      "step": 15912
    },
    {
      "epoch": 1.4885524717316139,
      "grad_norm": 1.771484375,
      "learning_rate": 5.475971625414916e-06,
      "loss": 0.3447,
      "step": 15929
    },
    {
      "epoch": 1.4901411083076348,
      "grad_norm": 2.666015625,
      "learning_rate": 5.467254544636675e-06,
      "loss": 0.4616,
      "step": 15946
    },
    {
      "epoch": 1.4917297448836557,
      "grad_norm": 0.8388671875,
      "learning_rate": 5.458536030889514e-06,
      "loss": 0.3294,
      "step": 15963
    },
    {
      "epoch": 1.4933183814596767,
      "grad_norm": 1.65625,
      "learning_rate": 5.449816110911229e-06,
      "loss": 0.341,
      "step": 15980
    },
    {
      "epoch": 1.4949070180356976,
      "grad_norm": 2.658203125,
      "learning_rate": 5.441094811443939e-06,
      "loss": 0.4877,
      "step": 15997
    },
    {
      "epoch": 1.4964956546117185,
      "grad_norm": 0.828125,
      "learning_rate": 5.432372159233985e-06,
      "loss": 0.2805,
      "step": 16014
    },
    {
      "epoch": 1.4980842911877394,
      "grad_norm": 1.4853515625,
      "learning_rate": 5.423648181031863e-06,
      "loss": 0.3095,
      "step": 16031
    },
    {
      "epoch": 1.4996729277637604,
      "grad_norm": 2.6328125,
      "learning_rate": 5.414922903592131e-06,
      "loss": 0.5203,
      "step": 16048
    },
    {
      "epoch": 1.5012615643397813,
      "grad_norm": 0.95556640625,
      "learning_rate": 5.406196353673334e-06,
      "loss": 0.2503,
      "step": 16065
    },
    {
      "epoch": 1.5028502009158022,
      "grad_norm": 1.53125,
      "learning_rate": 5.397468558037919e-06,
      "loss": 0.3618,
      "step": 16082
    },
    {
      "epoch": 1.5044388374918232,
      "grad_norm": 2.681640625,
      "learning_rate": 5.388739543452153e-06,
      "loss": 0.5703,
      "step": 16099
    },
    {
      "epoch": 1.506027474067844,
      "grad_norm": 1.1328125,
      "learning_rate": 5.380009336686041e-06,
      "loss": 0.2635,
      "step": 16116
    },
    {
      "epoch": 1.507616110643865,
      "grad_norm": 1.61328125,
      "learning_rate": 5.3712779645132425e-06,
      "loss": 0.3584,
      "step": 16133
    },
    {
      "epoch": 1.509204747219886,
      "grad_norm": 2.728515625,
      "learning_rate": 5.362545453710996e-06,
      "loss": 0.5587,
      "step": 16150
    },
    {
      "epoch": 1.5107933837959069,
      "grad_norm": 1.3642578125,
      "learning_rate": 5.353811831060027e-06,
      "loss": 0.2635,
      "step": 16167
    },
    {
      "epoch": 1.5123820203719278,
      "grad_norm": 1.8896484375,
      "learning_rate": 5.345077123344476e-06,
      "loss": 0.4036,
      "step": 16184
    },
    {
      "epoch": 1.5139706569479487,
      "grad_norm": 3.486328125,
      "learning_rate": 5.336341357351802e-06,
      "loss": 0.5284,
      "step": 16201
    },
    {
      "epoch": 1.5155592935239697,
      "grad_norm": 0.90625,
      "learning_rate": 5.32760455987272e-06,
      "loss": 0.2062,
      "step": 16218
    },
    {
      "epoch": 1.5171479300999906,
      "grad_norm": 1.9580078125,
      "learning_rate": 5.318866757701103e-06,
      "loss": 0.3607,
      "step": 16235
    },
    {
      "epoch": 1.5187365666760115,
      "grad_norm": 0.298095703125,
      "learning_rate": 5.3101279776339046e-06,
      "loss": 0.4917,
      "step": 16252
    },
    {
      "epoch": 1.5203252032520327,
      "grad_norm": 1.0908203125,
      "learning_rate": 5.30138824647108e-06,
      "loss": 0.1962,
      "step": 16269
    },
    {
      "epoch": 1.5219138398280534,
      "grad_norm": 1.78125,
      "learning_rate": 5.2926475910154985e-06,
      "loss": 0.4381,
      "step": 16286
    },
    {
      "epoch": 1.5235024764040745,
      "grad_norm": 0.2034912109375,
      "learning_rate": 5.283906038072868e-06,
      "loss": 0.5217,
      "step": 16303
    },
    {
      "epoch": 1.5250911129800953,
      "grad_norm": 1.11328125,
      "learning_rate": 5.2751636144516425e-06,
      "loss": 0.2035,
      "step": 16320
    },
    {
      "epoch": 1.5266797495561164,
      "grad_norm": 1.568359375,
      "learning_rate": 5.266420346962953e-06,
      "loss": 0.402,
      "step": 16337
    },
    {
      "epoch": 1.5282683861321371,
      "grad_norm": 0.5283203125,
      "learning_rate": 5.257676262420514e-06,
      "loss": 0.4975,
      "step": 16354
    },
    {
      "epoch": 1.5298570227081583,
      "grad_norm": 1.37109375,
      "learning_rate": 5.248931387640548e-06,
      "loss": 0.2909,
      "step": 16371
    },
    {
      "epoch": 1.531445659284179,
      "grad_norm": 2.748046875,
      "learning_rate": 5.240185749441698e-06,
      "loss": 0.4285,
      "step": 16388
    },
    {
      "epoch": 1.5330342958602001,
      "grad_norm": 0.40771484375,
      "learning_rate": 5.231439374644953e-06,
      "loss": 0.4394,
      "step": 16405
    },
    {
      "epoch": 1.5346229324362208,
      "grad_norm": 1.3828125,
      "learning_rate": 5.222692290073557e-06,
      "loss": 0.2013,
      "step": 16422
    },
    {
      "epoch": 1.536211569012242,
      "grad_norm": 2.3125,
      "learning_rate": 5.213944522552931e-06,
      "loss": 0.3947,
      "step": 16439
    },
    {
      "epoch": 1.5378002055882627,
      "grad_norm": 0.446533203125,
      "learning_rate": 5.205196098910593e-06,
      "loss": 0.4405,
      "step": 16456
    },
    {
      "epoch": 1.5393888421642838,
      "grad_norm": 1.306640625,
      "learning_rate": 5.196447045976072e-06,
      "loss": 0.2431,
      "step": 16473
    },
    {
      "epoch": 1.5409774787403046,
      "grad_norm": 2.232421875,
      "learning_rate": 5.1876973905808244e-06,
      "loss": 0.4323,
      "step": 16490
    },
    {
      "epoch": 1.5425661153163257,
      "grad_norm": 0.48095703125,
      "learning_rate": 5.1789471595581584e-06,
      "loss": 0.4386,
      "step": 16507
    },
    {
      "epoch": 1.5441547518923464,
      "grad_norm": 0.953125,
      "learning_rate": 5.170196379743145e-06,
      "loss": 0.2616,
      "step": 16524
    },
    {
      "epoch": 1.5457433884683676,
      "grad_norm": 2.0625,
      "learning_rate": 5.16144507797254e-06,
      "loss": 0.4225,
      "step": 16541
    },
    {
      "epoch": 1.5473320250443883,
      "grad_norm": 0.69287109375,
      "learning_rate": 5.152693281084696e-06,
      "loss": 0.3347,
      "step": 16558
    },
    {
      "epoch": 1.5489206616204094,
      "grad_norm": 1.248046875,
      "learning_rate": 5.143941015919488e-06,
      "loss": 0.3083,
      "step": 16575
    },
    {
      "epoch": 1.5505092981964301,
      "grad_norm": 2.228515625,
      "learning_rate": 5.1351883093182254e-06,
      "loss": 0.4747,
      "step": 16592
    },
    {
      "epoch": 1.5520979347724513,
      "grad_norm": 0.8671875,
      "learning_rate": 5.126435188123573e-06,
      "loss": 0.3693,
      "step": 16609
    },
    {
      "epoch": 1.553686571348472,
      "grad_norm": 1.4013671875,
      "learning_rate": 5.117681679179464e-06,
      "loss": 0.3204,
      "step": 16626
    },
    {
      "epoch": 1.5552752079244931,
      "grad_norm": 1.9423828125,
      "learning_rate": 5.108927809331025e-06,
      "loss": 0.4683,
      "step": 16643
    },
    {
      "epoch": 1.5568638445005138,
      "grad_norm": 0.8505859375,
      "learning_rate": 5.1001736054244835e-06,
      "loss": 0.3558,
      "step": 16660
    },
    {
      "epoch": 1.558452481076535,
      "grad_norm": 1.73046875,
      "learning_rate": 5.091419094307099e-06,
      "loss": 0.3213,
      "step": 16677
    },
    {
      "epoch": 1.5600411176525557,
      "grad_norm": 2.412109375,
      "learning_rate": 5.0826643028270675e-06,
      "loss": 0.5085,
      "step": 16694
    },
    {
      "epoch": 1.5616297542285769,
      "grad_norm": 0.81640625,
      "learning_rate": 5.073909257833445e-06,
      "loss": 0.3424,
      "step": 16711
    },
    {
      "epoch": 1.5632183908045976,
      "grad_norm": 1.6572265625,
      "learning_rate": 5.065153986176068e-06,
      "loss": 0.296,
      "step": 16728
    },
    {
      "epoch": 1.5648070273806187,
      "grad_norm": 2.177734375,
      "learning_rate": 5.056398514705465e-06,
      "loss": 0.4882,
      "step": 16745
    },
    {
      "epoch": 1.5663956639566394,
      "grad_norm": 1.0361328125,
      "learning_rate": 5.047642870272782e-06,
      "loss": 0.3124,
      "step": 16762
    },
    {
      "epoch": 1.5679843005326606,
      "grad_norm": 1.3955078125,
      "learning_rate": 5.038887079729689e-06,
      "loss": 0.3115,
      "step": 16779
    },
    {
      "epoch": 1.5695729371086813,
      "grad_norm": 2.6171875,
      "learning_rate": 5.030131169928309e-06,
      "loss": 0.5079,
      "step": 16796
    },
    {
      "epoch": 1.5711615736847024,
      "grad_norm": 0.93701171875,
      "learning_rate": 5.021375167721128e-06,
      "loss": 0.3369,
      "step": 16813
    },
    {
      "epoch": 1.5727502102607231,
      "grad_norm": 1.466796875,
      "learning_rate": 5.012619099960919e-06,
      "loss": 0.3847,
      "step": 16830
    },
    {
      "epoch": 1.5743388468367443,
      "grad_norm": 2.5390625,
      "learning_rate": 5.003862993500651e-06,
      "loss": 0.5206,
      "step": 16847
    },
    {
      "epoch": 1.575927483412765,
      "grad_norm": 0.96142578125,
      "learning_rate": 4.995106875193416e-06,
      "loss": 0.2724,
      "step": 16864
    },
    {
      "epoch": 1.5775161199887862,
      "grad_norm": 2.029296875,
      "learning_rate": 4.986350771892339e-06,
      "loss": 0.3639,
      "step": 16881
    },
    {
      "epoch": 1.5791047565648069,
      "grad_norm": 2.576171875,
      "learning_rate": 4.977594710450499e-06,
      "loss": 0.5595,
      "step": 16898
    },
    {
      "epoch": 1.580693393140828,
      "grad_norm": 1.181640625,
      "learning_rate": 4.968838717720852e-06,
      "loss": 0.2371,
      "step": 16915
    },
    {
      "epoch": 1.582282029716849,
      "grad_norm": 1.7236328125,
      "learning_rate": 4.960082820556138e-06,
      "loss": 0.3789,
      "step": 16932
    },
    {
      "epoch": 1.5838706662928699,
      "grad_norm": 2.580078125,
      "learning_rate": 4.951327045808804e-06,
      "loss": 0.5512,
      "step": 16949
    },
    {
      "epoch": 1.5854593028688908,
      "grad_norm": 1.04296875,
      "learning_rate": 4.942571420330925e-06,
      "loss": 0.2278,
      "step": 16966
    },
    {
      "epoch": 1.5870479394449117,
      "grad_norm": 1.96484375,
      "learning_rate": 4.933815970974114e-06,
      "loss": 0.3609,
      "step": 16983
    },
    {
      "epoch": 1.5886365760209327,
      "grad_norm": 2.828125,
      "learning_rate": 4.9250607245894484e-06,
      "loss": 0.5036,
      "step": 17000
    },
    {
      "epoch": 1.5902252125969536,
      "grad_norm": 0.92626953125,
      "learning_rate": 4.916305708027378e-06,
      "loss": 0.2242,
      "step": 17017
    },
    {
      "epoch": 1.5918138491729745,
      "grad_norm": 1.42578125,
      "learning_rate": 4.907550948137653e-06,
      "loss": 0.3554,
      "step": 17034
    },
    {
      "epoch": 1.5934024857489955,
      "grad_norm": 3.298828125,
      "learning_rate": 4.898796471769233e-06,
      "loss": 0.5669,
      "step": 17051
    },
    {
      "epoch": 1.5949911223250164,
      "grad_norm": 0.83642578125,
      "learning_rate": 4.890042305770209e-06,
      "loss": 0.1582,
      "step": 17068
    },
    {
      "epoch": 1.5965797589010373,
      "grad_norm": 1.6162109375,
      "learning_rate": 4.881288476987718e-06,
      "loss": 0.3528,
      "step": 17085
    },
    {
      "epoch": 1.5981683954770582,
      "grad_norm": 0.3330078125,
      "learning_rate": 4.87253501226787e-06,
      "loss": 0.5019,
      "step": 17102
    },
    {
      "epoch": 1.5997570320530792,
      "grad_norm": 0.98291015625,
      "learning_rate": 4.863781938455651e-06,
      "loss": 0.2364,
      "step": 17119
    },
    {
      "epoch": 1.6013456686291,
      "grad_norm": 1.9404296875,
      "learning_rate": 4.855029282394849e-06,
      "loss": 0.3943,
      "step": 17136
    },
    {
      "epoch": 1.602934305205121,
      "grad_norm": 1.0625,
      "learning_rate": 4.846277070927975e-06,
      "loss": 0.4679,
      "step": 17153
    },
    {
      "epoch": 1.604522941781142,
      "grad_norm": 1.259765625,
      "learning_rate": 4.837525330896174e-06,
      "loss": 0.226,
      "step": 17170
    },
    {
      "epoch": 1.606111578357163,
      "grad_norm": 2.095703125,
      "learning_rate": 4.828774089139144e-06,
      "loss": 0.4095,
      "step": 17187
    },
    {
      "epoch": 1.6077002149331838,
      "grad_norm": 0.315185546875,
      "learning_rate": 4.820023372495055e-06,
      "loss": 0.444,
      "step": 17204
    },
    {
      "epoch": 1.6092888515092048,
      "grad_norm": 1.251953125,
      "learning_rate": 4.811273207800472e-06,
      "loss": 0.2766,
      "step": 17221
    },
    {
      "epoch": 1.6108774880852257,
      "grad_norm": 1.576171875,
      "learning_rate": 4.8025236218902615e-06,
      "loss": 0.4249,
      "step": 17238
    },
    {
      "epoch": 1.6124661246612466,
      "grad_norm": 0.75146484375,
      "learning_rate": 4.793774641597515e-06,
      "loss": 0.4755,
      "step": 17255
    },
    {
      "epoch": 1.6140547612372675,
      "grad_norm": 1.3798828125,
      "learning_rate": 4.785026293753468e-06,
      "loss": 0.274,
      "step": 17272
    },
    {
      "epoch": 1.6156433978132885,
      "grad_norm": 3.283203125,
      "learning_rate": 4.77627860518742e-06,
      "loss": 0.4221,
      "step": 17289
    },
    {
      "epoch": 1.6172320343893094,
      "grad_norm": 0.79931640625,
      "learning_rate": 4.767531602726643e-06,
      "loss": 0.4743,
      "step": 17306
    },
    {
      "epoch": 1.6188206709653303,
      "grad_norm": 1.4140625,
      "learning_rate": 4.758785313196305e-06,
      "loss": 0.3245,
      "step": 17323
    },
    {
      "epoch": 1.6204093075413513,
      "grad_norm": 2.224609375,
      "learning_rate": 4.750039763419394e-06,
      "loss": 0.4545,
      "step": 17340
    },
    {
      "epoch": 1.6219979441173722,
      "grad_norm": 0.736328125,
      "learning_rate": 4.741294980216623e-06,
      "loss": 0.3768,
      "step": 17357
    },
    {
      "epoch": 1.6235865806933931,
      "grad_norm": 1.2490234375,
      "learning_rate": 4.732550990406359e-06,
      "loss": 0.3033,
      "step": 17374
    },
    {
      "epoch": 1.625175217269414,
      "grad_norm": 2.51171875,
      "learning_rate": 4.723807820804526e-06,
      "loss": 0.5007,
      "step": 17391
    },
    {
      "epoch": 1.626763853845435,
      "grad_norm": 0.6728515625,
      "learning_rate": 4.715065498224547e-06,
      "loss": 0.4145,
      "step": 17408
    },
    {
      "epoch": 1.628352490421456,
      "grad_norm": 1.2744140625,
      "learning_rate": 4.7063240494772375e-06,
      "loss": 0.3099,
      "step": 17425
    },
    {
      "epoch": 1.6299411269974768,
      "grad_norm": 2.46484375,
      "learning_rate": 4.697583501370735e-06,
      "loss": 0.4696,
      "step": 17442
    },
    {
      "epoch": 1.6315297635734978,
      "grad_norm": 0.7119140625,
      "learning_rate": 4.688843880710417e-06,
      "loss": 0.3615,
      "step": 17459
    },
    {
      "epoch": 1.6331184001495187,
      "grad_norm": 1.509765625,
      "learning_rate": 4.6801052142988145e-06,
      "loss": 0.3573,
      "step": 17476
    },
    {
      "epoch": 1.6347070367255396,
      "grad_norm": 1.9345703125,
      "learning_rate": 4.671367528935533e-06,
      "loss": 0.4747,
      "step": 17493
    },
    {
      "epoch": 1.6362956733015606,
      "grad_norm": 0.86279296875,
      "learning_rate": 4.6626308514171665e-06,
      "loss": 0.3427,
      "step": 17510
    },
    {
      "epoch": 1.6378843098775815,
      "grad_norm": 1.388671875,
      "learning_rate": 4.6538952085372256e-06,
      "loss": 0.2839,
      "step": 17527
    },
    {
      "epoch": 1.6394729464536024,
      "grad_norm": 1.8642578125,
      "learning_rate": 4.645160627086041e-06,
      "loss": 0.4094,
      "step": 17544
    },
    {
      "epoch": 1.6410615830296233,
      "grad_norm": 0.74609375,
      "learning_rate": 4.63642713385069e-06,
      "loss": 0.3273,
      "step": 17561
    },
    {
      "epoch": 1.6426502196056443,
      "grad_norm": 1.498046875,
      "learning_rate": 4.627694755614912e-06,
      "loss": 0.307,
      "step": 17578
    },
    {
      "epoch": 1.6442388561816652,
      "grad_norm": 2.33984375,
      "learning_rate": 4.61896351915903e-06,
      "loss": 0.4779,
      "step": 17595
    },
    {
      "epoch": 1.6458274927576864,
      "grad_norm": 0.83984375,
      "learning_rate": 4.610233451259864e-06,
      "loss": 0.273,
      "step": 17612
    },
    {
      "epoch": 1.647416129333707,
      "grad_norm": 1.3642578125,
      "learning_rate": 4.601504578690644e-06,
      "loss": 0.3002,
      "step": 17629
    },
    {
      "epoch": 1.6490047659097282,
      "grad_norm": 2.482421875,
      "learning_rate": 4.592776928220946e-06,
      "loss": 0.478,
      "step": 17646
    },
    {
      "epoch": 1.650593402485749,
      "grad_norm": 0.84375,
      "learning_rate": 4.584050526616589e-06,
      "loss": 0.257,
      "step": 17663
    },
    {
      "epoch": 1.65218203906177,
      "grad_norm": 1.3955078125,
      "learning_rate": 4.575325400639566e-06,
      "loss": 0.3331,
      "step": 17680
    },
    {
      "epoch": 1.6537706756377908,
      "grad_norm": 3.080078125,
      "learning_rate": 4.566601577047954e-06,
      "loss": 0.5352,
      "step": 17697
    },
    {
      "epoch": 1.655359312213812,
      "grad_norm": 0.69091796875,
      "learning_rate": 4.557879082595842e-06,
      "loss": 0.2319,
      "step": 17714
    },
    {
      "epoch": 1.6569479487898326,
      "grad_norm": 1.4423828125,
      "learning_rate": 4.549157944033239e-06,
      "loss": 0.3432,
      "step": 17731
    },
    {
      "epoch": 1.6585365853658538,
      "grad_norm": 2.296875,
      "learning_rate": 4.540438188105994e-06,
      "loss": 0.4595,
      "step": 17748
    },
    {
      "epoch": 1.6601252219418745,
      "grad_norm": 1.029296875,
      "learning_rate": 4.531719841555719e-06,
      "loss": 0.2731,
      "step": 17765
    },
    {
      "epoch": 1.6617138585178957,
      "grad_norm": 1.486328125,
      "learning_rate": 4.523002931119705e-06,
      "loss": 0.3928,
      "step": 17782
    },
    {
      "epoch": 1.6633024950939164,
      "grad_norm": 2.388671875,
      "learning_rate": 4.514287483530833e-06,
      "loss": 0.5295,
      "step": 17799
    },
    {
      "epoch": 1.6648911316699375,
      "grad_norm": 0.994140625,
      "learning_rate": 4.5055735255175e-06,
      "loss": 0.1826,
      "step": 17816
    },
    {
      "epoch": 1.6664797682459582,
      "grad_norm": 1.240234375,
      "learning_rate": 4.4968610838035425e-06,
      "loss": 0.3421,
      "step": 17833
    },
    {
      "epoch": 1.6680684048219794,
      "grad_norm": 2.34765625,
      "learning_rate": 4.488150185108135e-06,
      "loss": 0.5292,
      "step": 17850
    },
    {
      "epoch": 1.669657041398,
      "grad_norm": 1.224609375,
      "learning_rate": 4.4794408561457284e-06,
      "loss": 0.2351,
      "step": 17867
    },
    {
      "epoch": 1.6712456779740212,
      "grad_norm": 2.1640625,
      "learning_rate": 4.4707331236259525e-06,
      "loss": 0.4172,
      "step": 17884
    },
    {
      "epoch": 1.672834314550042,
      "grad_norm": 3.0859375,
      "learning_rate": 4.46202701425355e-06,
      "loss": 0.5688,
      "step": 17901
    },
    {
      "epoch": 1.674422951126063,
      "grad_norm": 1.08984375,
      "learning_rate": 4.453322554728277e-06,
      "loss": 0.1846,
      "step": 17918
    },
    {
      "epoch": 1.6760115877020838,
      "grad_norm": 1.8125,
      "learning_rate": 4.444619771744834e-06,
      "loss": 0.3756,
      "step": 17935
    },
    {
      "epoch": 1.677600224278105,
      "grad_norm": 0.342529296875,
      "learning_rate": 4.43591869199278e-06,
      "loss": 0.5025,
      "step": 17952
    },
    {
      "epoch": 1.6791888608541257,
      "grad_norm": 1.234375,
      "learning_rate": 4.427219342156452e-06,
      "loss": 0.2225,
      "step": 17969
    },
    {
      "epoch": 1.6807774974301468,
      "grad_norm": 2.455078125,
      "learning_rate": 4.418521748914878e-06,
      "loss": 0.4101,
      "step": 17986
    },
    {
      "epoch": 1.6823661340061675,
      "grad_norm": 0.464111328125,
      "learning_rate": 4.409825938941701e-06,
      "loss": 0.4983,
      "step": 18003
    },
    {
      "epoch": 1.6839547705821887,
      "grad_norm": 1.154296875,
      "learning_rate": 4.401131938905097e-06,
      "loss": 0.2291,
      "step": 18020
    },
    {
      "epoch": 1.6855434071582094,
      "grad_norm": 2.087890625,
      "learning_rate": 4.392439775467686e-06,
      "loss": 0.4443,
      "step": 18037
    },
    {
      "epoch": 1.6871320437342305,
      "grad_norm": 0.2105712890625,
      "learning_rate": 4.3837494752864615e-06,
      "loss": 0.4796,
      "step": 18054
    },
    {
      "epoch": 1.6887206803102512,
      "grad_norm": 1.0615234375,
      "learning_rate": 4.3750610650126965e-06,
      "loss": 0.2439,
      "step": 18071
    },
    {
      "epoch": 1.6903093168862724,
      "grad_norm": 2.080078125,
      "learning_rate": 4.366374571291875e-06,
      "loss": 0.3926,
      "step": 18088
    },
    {
      "epoch": 1.691897953462293,
      "grad_norm": 0.351806640625,
      "learning_rate": 4.3576900207636e-06,
      "loss": 0.4314,
      "step": 18105
    },
    {
      "epoch": 1.6934865900383143,
      "grad_norm": 1.2978515625,
      "learning_rate": 4.349007440061513e-06,
      "loss": 0.2174,
      "step": 18122
    },
    {
      "epoch": 1.695075226614335,
      "grad_norm": 2.322265625,
      "learning_rate": 4.340326855813216e-06,
      "loss": 0.499,
      "step": 18139
    },
    {
      "epoch": 1.6966638631903561,
      "grad_norm": 0.312255859375,
      "learning_rate": 4.331648294640192e-06,
      "loss": 0.4278,
      "step": 18156
    },
    {
      "epoch": 1.6982524997663768,
      "grad_norm": 1.5,
      "learning_rate": 4.322971783157716e-06,
      "loss": 0.2806,
      "step": 18173
    },
    {
      "epoch": 1.699841136342398,
      "grad_norm": 1.92578125,
      "learning_rate": 4.314297347974774e-06,
      "loss": 0.4334,
      "step": 18190
    },
    {
      "epoch": 1.7014297729184187,
      "grad_norm": 0.501953125,
      "learning_rate": 4.3056250156939924e-06,
      "loss": 0.4082,
      "step": 18207
    },
    {
      "epoch": 1.7030184094944398,
      "grad_norm": 1.310546875,
      "learning_rate": 4.296954812911542e-06,
      "loss": 0.2716,
      "step": 18224
    },
    {
      "epoch": 1.7046070460704605,
      "grad_norm": 2.34375,
      "learning_rate": 4.2882867662170655e-06,
      "loss": 0.4807,
      "step": 18241
    },
    {
      "epoch": 1.7061956826464817,
      "grad_norm": 0.8447265625,
      "learning_rate": 4.27962090219359e-06,
      "loss": 0.3743,
      "step": 18258
    },
    {
      "epoch": 1.7077843192225026,
      "grad_norm": 1.541015625,
      "learning_rate": 4.270957247417456e-06,
      "loss": 0.2792,
      "step": 18275
    },
    {
      "epoch": 1.7093729557985236,
      "grad_norm": 2.67578125,
      "learning_rate": 4.262295828458223e-06,
      "loss": 0.4596,
      "step": 18292
    },
    {
      "epoch": 1.7109615923745445,
      "grad_norm": 0.8125,
      "learning_rate": 4.2536366718785925e-06,
      "loss": 0.4049,
      "step": 18309
    },
    {
      "epoch": 1.7125502289505654,
      "grad_norm": 1.6220703125,
      "learning_rate": 4.244979804234333e-06,
      "loss": 0.2971,
      "step": 18326
    },
    {
      "epoch": 1.7141388655265863,
      "grad_norm": 2.083984375,
      "learning_rate": 4.236325252074192e-06,
      "loss": 0.4808,
      "step": 18343
    },
    {
      "epoch": 1.7157275021026073,
      "grad_norm": 1.0,
      "learning_rate": 4.227673041939811e-06,
      "loss": 0.3686,
      "step": 18360
    },
    {
      "epoch": 1.7173161386786282,
      "grad_norm": 1.40625,
      "learning_rate": 4.219023200365653e-06,
      "loss": 0.3087,
      "step": 18377
    },
    {
      "epoch": 1.7189047752546491,
      "grad_norm": 2.06640625,
      "learning_rate": 4.2103757538789195e-06,
      "loss": 0.4861,
      "step": 18394
    },
    {
      "epoch": 1.72049341183067,
      "grad_norm": 1.0732421875,
      "learning_rate": 4.201730728999463e-06,
      "loss": 0.3667,
      "step": 18411
    },
    {
      "epoch": 1.722082048406691,
      "grad_norm": 1.33203125,
      "learning_rate": 4.193088152239709e-06,
      "loss": 0.313,
      "step": 18428
    },
    {
      "epoch": 1.723670684982712,
      "grad_norm": 2.5859375,
      "learning_rate": 4.184448050104576e-06,
      "loss": 0.5256,
      "step": 18445
    },
    {
      "epoch": 1.7252593215587329,
      "grad_norm": 0.83740234375,
      "learning_rate": 4.175810449091397e-06,
      "loss": 0.2924,
      "step": 18462
    },
    {
      "epoch": 1.7268479581347538,
      "grad_norm": 1.4482421875,
      "learning_rate": 4.16717537568983e-06,
      "loss": 0.3087,
      "step": 18479
    },
    {
      "epoch": 1.7284365947107747,
      "grad_norm": 2.22265625,
      "learning_rate": 4.158542856381783e-06,
      "loss": 0.5215,
      "step": 18496
    },
    {
      "epoch": 1.7300252312867956,
      "grad_norm": 0.93408203125,
      "learning_rate": 4.149912917641331e-06,
      "loss": 0.2695,
      "step": 18513
    },
    {
      "epoch": 1.7316138678628166,
      "grad_norm": 1.275390625,
      "learning_rate": 4.141285585934635e-06,
      "loss": 0.307,
      "step": 18530
    },
    {
      "epoch": 1.7332025044388375,
      "grad_norm": 2.1875,
      "learning_rate": 4.1326608877198615e-06,
      "loss": 0.5367,
      "step": 18547
    },
    {
      "epoch": 1.7347911410148584,
      "grad_norm": 0.833984375,
      "learning_rate": 4.124038849447097e-06,
      "loss": 0.2833,
      "step": 18564
    },
    {
      "epoch": 1.7363797775908794,
      "grad_norm": 1.990234375,
      "learning_rate": 4.115419497558277e-06,
      "loss": 0.3832,
      "step": 18581
    },
    {
      "epoch": 1.7379684141669003,
      "grad_norm": 2.4296875,
      "learning_rate": 4.106802858487095e-06,
      "loss": 0.5257,
      "step": 18598
    },
    {
      "epoch": 1.7395570507429212,
      "grad_norm": 0.9306640625,
      "learning_rate": 4.098188958658923e-06,
      "loss": 0.3223,
      "step": 18615
    },
    {
      "epoch": 1.7411456873189421,
      "grad_norm": 1.548828125,
      "learning_rate": 4.089577824490733e-06,
      "loss": 0.3767,
      "step": 18632
    },
    {
      "epoch": 1.742734323894963,
      "grad_norm": 2.6015625,
      "learning_rate": 4.0809694823910205e-06,
      "loss": 0.4954,
      "step": 18649
    },
    {
      "epoch": 1.744322960470984,
      "grad_norm": 1.20703125,
      "learning_rate": 4.0723639587597116e-06,
      "loss": 0.2428,
      "step": 18666
    },
    {
      "epoch": 1.745911597047005,
      "grad_norm": 1.5224609375,
      "learning_rate": 4.063761279988089e-06,
      "loss": 0.3748,
      "step": 18683
    },
    {
      "epoch": 1.7475002336230259,
      "grad_norm": 2.841796875,
      "learning_rate": 4.055161472458719e-06,
      "loss": 0.5908,
      "step": 18700
    },
    {
      "epoch": 1.7490888701990468,
      "grad_norm": 1.0576171875,
      "learning_rate": 4.046564562545353e-06,
      "loss": 0.1854,
      "step": 18717
    },
    {
      "epoch": 1.7506775067750677,
      "grad_norm": 2.01953125,
      "learning_rate": 4.037970576612861e-06,
      "loss": 0.3492,
      "step": 18734
    },
    {
      "epoch": 1.7522661433510887,
      "grad_norm": 3.720703125,
      "learning_rate": 4.0293795410171415e-06,
      "loss": 0.5344,
      "step": 18751
    },
    {
      "epoch": 1.7538547799271096,
      "grad_norm": 0.9775390625,
      "learning_rate": 4.020791482105053e-06,
      "loss": 0.185,
      "step": 18768
    },
    {
      "epoch": 1.7554434165031305,
      "grad_norm": 1.8955078125,
      "learning_rate": 4.012206426214318e-06,
      "loss": 0.3872,
      "step": 18785
    },
    {
      "epoch": 1.7570320530791514,
      "grad_norm": 0.8720703125,
      "learning_rate": 4.003624399673451e-06,
      "loss": 0.563,
      "step": 18802
    },
    {
      "epoch": 1.7586206896551724,
      "grad_norm": 1.013671875,
      "learning_rate": 3.995045428801674e-06,
      "loss": 0.2086,
      "step": 18819
    },
    {
      "epoch": 1.7602093262311933,
      "grad_norm": 1.9150390625,
      "learning_rate": 3.986469539908846e-06,
      "loss": 0.3939,
      "step": 18836
    },
    {
      "epoch": 1.7617979628072142,
      "grad_norm": 0.373779296875,
      "learning_rate": 3.977896759295366e-06,
      "loss": 0.4711,
      "step": 18853
    },
    {
      "epoch": 1.7633865993832352,
      "grad_norm": 1.328125,
      "learning_rate": 3.969327113252101e-06,
      "loss": 0.2401,
      "step": 18870
    },
    {
      "epoch": 1.764975235959256,
      "grad_norm": 1.96484375,
      "learning_rate": 3.960760628060313e-06,
      "loss": 0.4163,
      "step": 18887
    },
    {
      "epoch": 1.766563872535277,
      "grad_norm": 0.53955078125,
      "learning_rate": 3.9521973299915605e-06,
      "loss": 0.4618,
      "step": 18904
    },
    {
      "epoch": 1.768152509111298,
      "grad_norm": 1.23046875,
      "learning_rate": 3.943637245307633e-06,
      "loss": 0.3054,
      "step": 18921
    },
    {
      "epoch": 1.7697411456873189,
      "grad_norm": 2.435546875,
      "learning_rate": 3.935080400260463e-06,
      "loss": 0.3827,
      "step": 18938
    },
    {
      "epoch": 1.77132978226334,
      "grad_norm": 0.258056640625,
      "learning_rate": 3.926526821092052e-06,
      "loss": 0.4477,
      "step": 18955
    },
    {
      "epoch": 1.7729184188393607,
      "grad_norm": 1.1328125,
      "learning_rate": 3.9179765340343804e-06,
      "loss": 0.2761,
      "step": 18972
    },
    {
      "epoch": 1.774507055415382,
      "grad_norm": 1.8388671875,
      "learning_rate": 3.909429565309334e-06,
      "loss": 0.4409,
      "step": 18989
    },
    {
      "epoch": 1.7760956919914026,
      "grad_norm": 0.7119140625,
      "learning_rate": 3.900885941128624e-06,
      "loss": 0.4154,
      "step": 19006
    },
    {
      "epoch": 1.7776843285674238,
      "grad_norm": 1.1357421875,
      "learning_rate": 3.892345687693704e-06,
      "loss": 0.2408,
      "step": 19023
    },
    {
      "epoch": 1.7792729651434445,
      "grad_norm": 1.908203125,
      "learning_rate": 3.883808831195689e-06,
      "loss": 0.4266,
      "step": 19040
    },
    {
      "epoch": 1.7808616017194656,
      "grad_norm": 0.54638671875,
      "learning_rate": 3.875275397815275e-06,
      "loss": 0.3744,
      "step": 19057
    },
    {
      "epoch": 1.7824502382954863,
      "grad_norm": 1.2109375,
      "learning_rate": 3.866745413722664e-06,
      "loss": 0.2631,
      "step": 19074
    },
    {
      "epoch": 1.7840388748715075,
      "grad_norm": 2.06640625,
      "learning_rate": 3.858218905077477e-06,
      "loss": 0.4382,
      "step": 19091
    },
    {
      "epoch": 1.7856275114475282,
      "grad_norm": 0.85595703125,
      "learning_rate": 3.849695898028678e-06,
      "loss": 0.4065,
      "step": 19108
    },
    {
      "epoch": 1.7872161480235493,
      "grad_norm": 1.3037109375,
      "learning_rate": 3.841176418714489e-06,
      "loss": 0.2912,
      "step": 19125
    },
    {
      "epoch": 1.78880478459957,
      "grad_norm": 2.5859375,
      "learning_rate": 3.832660493262319e-06,
      "loss": 0.5211,
      "step": 19142
    },
    {
      "epoch": 1.7903934211755912,
      "grad_norm": 0.7783203125,
      "learning_rate": 3.824148147788674e-06,
      "loss": 0.3868,
      "step": 19159
    },
    {
      "epoch": 1.791982057751612,
      "grad_norm": 1.783203125,
      "learning_rate": 3.815639408399079e-06,
      "loss": 0.3025,
      "step": 19176
    },
    {
      "epoch": 1.793570694327633,
      "grad_norm": 2.193359375,
      "learning_rate": 3.8071343011880068e-06,
      "loss": 0.4971,
      "step": 19193
    },
    {
      "epoch": 1.7951593309036538,
      "grad_norm": 0.80078125,
      "learning_rate": 3.798632852238786e-06,
      "loss": 0.346,
      "step": 19210
    },
    {
      "epoch": 1.796747967479675,
      "grad_norm": 1.5341796875,
      "learning_rate": 3.790135087623526e-06,
      "loss": 0.3101,
      "step": 19227
    },
    {
      "epoch": 1.7983366040556956,
      "grad_norm": 2.00390625,
      "learning_rate": 3.7816410334030378e-06,
      "loss": 0.4789,
      "step": 19244
    },
    {
      "epoch": 1.7999252406317168,
      "grad_norm": 0.90966796875,
      "learning_rate": 3.7731507156267567e-06,
      "loss": 0.3528,
      "step": 19261
    },
    {
      "epoch": 1.800112139052425,
      "eval_loss": 0.37429991364479065,
      "eval_runtime": 1039.9788,
      "eval_samples_per_second": 7.717,
      "eval_steps_per_second": 2.572,
      "step": 19263
    },
    {
      "epoch": 1.8015138772077375,
      "grad_norm": 1.587890625,
      "learning_rate": 3.7646641603326537e-06,
      "loss": 0.333,
      "step": 19278
    },
    {
      "epoch": 1.8031025137837586,
      "grad_norm": 2.40234375,
      "learning_rate": 3.7561813935471645e-06,
      "loss": 0.4941,
      "step": 19295
    },
    {
      "epoch": 1.8046911503597793,
      "grad_norm": 0.939453125,
      "learning_rate": 3.7477024412851037e-06,
      "loss": 0.3034,
      "step": 19312
    },
    {
      "epoch": 1.8062797869358005,
      "grad_norm": 1.4482421875,
      "learning_rate": 3.739227329549594e-06,
      "loss": 0.3045,
      "step": 19329
    },
    {
      "epoch": 1.8078684235118212,
      "grad_norm": 1.9892578125,
      "learning_rate": 3.730756084331971e-06,
      "loss": 0.5039,
      "step": 19346
    },
    {
      "epoch": 1.8094570600878424,
      "grad_norm": 0.96044921875,
      "learning_rate": 3.722288731611719e-06,
      "loss": 0.2761,
      "step": 19363
    },
    {
      "epoch": 1.811045696663863,
      "grad_norm": 1.439453125,
      "learning_rate": 3.7138252973563824e-06,
      "loss": 0.2929,
      "step": 19380
    },
    {
      "epoch": 1.8126343332398842,
      "grad_norm": 9.09375,
      "learning_rate": 3.7053658075214893e-06,
      "loss": 0.5057,
      "step": 19397
    },
    {
      "epoch": 1.814222969815905,
      "grad_norm": 1.1328125,
      "learning_rate": 3.6969102880504702e-06,
      "loss": 0.2876,
      "step": 19414
    },
    {
      "epoch": 1.815811606391926,
      "grad_norm": 1.701171875,
      "learning_rate": 3.6884587648745775e-06,
      "loss": 0.3638,
      "step": 19431
    },
    {
      "epoch": 1.8174002429679468,
      "grad_norm": 2.66015625,
      "learning_rate": 3.6800112639128137e-06,
      "loss": 0.4813,
      "step": 19448
    },
    {
      "epoch": 1.818988879543968,
      "grad_norm": 1.0888671875,
      "learning_rate": 3.6715678110718423e-06,
      "loss": 0.2686,
      "step": 19465
    },
    {
      "epoch": 1.8205775161199886,
      "grad_norm": 2.193359375,
      "learning_rate": 3.663128432245911e-06,
      "loss": 0.3805,
      "step": 19482
    },
    {
      "epoch": 1.8221661526960098,
      "grad_norm": 3.09765625,
      "learning_rate": 3.654693153316773e-06,
      "loss": 0.5282,
      "step": 19499
    },
    {
      "epoch": 1.8237547892720305,
      "grad_norm": 1.0546875,
      "learning_rate": 3.646262000153613e-06,
      "loss": 0.2231,
      "step": 19516
    },
    {
      "epoch": 1.8253434258480516,
      "grad_norm": 1.6806640625,
      "learning_rate": 3.6378349986129586e-06,
      "loss": 0.3461,
      "step": 19533
    },
    {
      "epoch": 1.8269320624240724,
      "grad_norm": 2.48828125,
      "learning_rate": 3.629412174538605e-06,
      "loss": 0.5438,
      "step": 19550
    },
    {
      "epoch": 1.8285206990000935,
      "grad_norm": 1.154296875,
      "learning_rate": 3.620993553761538e-06,
      "loss": 0.2015,
      "step": 19567
    },
    {
      "epoch": 1.8301093355761142,
      "grad_norm": 1.8447265625,
      "learning_rate": 3.6125791620998524e-06,
      "loss": 0.364,
      "step": 19584
    },
    {
      "epoch": 1.8316979721521354,
      "grad_norm": 3.361328125,
      "learning_rate": 3.6041690253586726e-06,
      "loss": 0.5603,
      "step": 19601
    },
    {
      "epoch": 1.8332866087281563,
      "grad_norm": 1.1455078125,
      "learning_rate": 3.5957631693300714e-06,
      "loss": 0.251,
      "step": 19618
    },
    {
      "epoch": 1.8348752453041772,
      "grad_norm": 1.900390625,
      "learning_rate": 3.5873616197930015e-06,
      "loss": 0.3926,
      "step": 19635
    },
    {
      "epoch": 1.8364638818801982,
      "grad_norm": 0.47802734375,
      "learning_rate": 3.578964402513201e-06,
      "loss": 0.5178,
      "step": 19652
    },
    {
      "epoch": 1.838052518456219,
      "grad_norm": 1.12109375,
      "learning_rate": 3.5705715432431247e-06,
      "loss": 0.2378,
      "step": 19669
    },
    {
      "epoch": 1.83964115503224,
      "grad_norm": 2.0625,
      "learning_rate": 3.5621830677218606e-06,
      "loss": 0.4011,
      "step": 19686
    },
    {
      "epoch": 1.841229791608261,
      "grad_norm": 0.313720703125,
      "learning_rate": 3.5537990016750567e-06,
      "loss": 0.4929,
      "step": 19703
    },
    {
      "epoch": 1.8428184281842819,
      "grad_norm": 1.1650390625,
      "learning_rate": 3.545419370814834e-06,
      "loss": 0.2215,
      "step": 19720
    },
    {
      "epoch": 1.8444070647603028,
      "grad_norm": 1.9794921875,
      "learning_rate": 3.537044200839711e-06,
      "loss": 0.4045,
      "step": 19737
    },
    {
      "epoch": 1.8459957013363237,
      "grad_norm": 0.1917724609375,
      "learning_rate": 3.5286735174345323e-06,
      "loss": 0.4798,
      "step": 19754
    },
    {
      "epoch": 1.8475843379123447,
      "grad_norm": 1.1025390625,
      "learning_rate": 3.520307346270377e-06,
      "loss": 0.2828,
      "step": 19771
    },
    {
      "epoch": 1.8491729744883656,
      "grad_norm": 1.587890625,
      "learning_rate": 3.5119457130044875e-06,
      "loss": 0.4037,
      "step": 19788
    },
    {
      "epoch": 1.8507616110643865,
      "grad_norm": 0.79150390625,
      "learning_rate": 3.503588643280187e-06,
      "loss": 0.4554,
      "step": 19805
    },
    {
      "epoch": 1.8523502476404075,
      "grad_norm": 1.4365234375,
      "learning_rate": 3.4952361627268116e-06,
      "loss": 0.2869,
      "step": 19822
    },
    {
      "epoch": 1.8539388842164284,
      "grad_norm": 2.134765625,
      "learning_rate": 3.486888296959615e-06,
      "loss": 0.421,
      "step": 19839
    },
    {
      "epoch": 1.8555275207924493,
      "grad_norm": 0.489990234375,
      "learning_rate": 3.478545071579701e-06,
      "loss": 0.4196,
      "step": 19856
    },
    {
      "epoch": 1.8571161573684702,
      "grad_norm": 1.46875,
      "learning_rate": 3.4702065121739435e-06,
      "loss": 0.2586,
      "step": 19873
    },
    {
      "epoch": 1.8587047939444912,
      "grad_norm": 2.279296875,
      "learning_rate": 3.4618726443149054e-06,
      "loss": 0.4349,
      "step": 19890
    },
    {
      "epoch": 1.860293430520512,
      "grad_norm": 0.810546875,
      "learning_rate": 3.4535434935607627e-06,
      "loss": 0.4075,
      "step": 19907
    },
    {
      "epoch": 1.861882067096533,
      "grad_norm": 1.8857421875,
      "learning_rate": 3.4452190854552215e-06,
      "loss": 0.2922,
      "step": 19924
    },
    {
      "epoch": 1.863470703672554,
      "grad_norm": 2.515625,
      "learning_rate": 3.4368994455274517e-06,
      "loss": 0.5177,
      "step": 19941
    },
    {
      "epoch": 1.865059340248575,
      "grad_norm": 0.72998046875,
      "learning_rate": 3.4285845992919915e-06,
      "loss": 0.4062,
      "step": 19958
    },
    {
      "epoch": 1.8666479768245958,
      "grad_norm": 1.4541015625,
      "learning_rate": 3.4202745722486814e-06,
      "loss": 0.3209,
      "step": 19975
    },
    {
      "epoch": 1.8682366134006168,
      "grad_norm": 1.79296875,
      "learning_rate": 3.411969389882581e-06,
      "loss": 0.4509,
      "step": 19992
    },
    {
      "epoch": 1.8698252499766377,
      "grad_norm": 3.017578125,
      "learning_rate": 3.403669077663897e-06,
      "loss": 0.3688,
      "step": 20009
    },
    {
      "epoch": 1.8714138865526586,
      "grad_norm": 1.388671875,
      "learning_rate": 3.395373661047895e-06,
      "loss": 0.2926,
      "step": 20026
    },
    {
      "epoch": 1.8730025231286795,
      "grad_norm": 1.970703125,
      "learning_rate": 3.387083165474826e-06,
      "loss": 0.5161,
      "step": 20043
    },
    {
      "epoch": 1.8745911597047005,
      "grad_norm": 0.77783203125,
      "learning_rate": 3.3787976163698578e-06,
      "loss": 0.3756,
      "step": 20060
    },
    {
      "epoch": 1.8761797962807214,
      "grad_norm": 1.50390625,
      "learning_rate": 3.3705170391429786e-06,
      "loss": 0.3377,
      "step": 20077
    },
    {
      "epoch": 1.8777684328567423,
      "grad_norm": 2.345703125,
      "learning_rate": 3.3622414591889353e-06,
      "loss": 0.4665,
      "step": 20094
    },
    {
      "epoch": 1.8793570694327633,
      "grad_norm": 0.7783203125,
      "learning_rate": 3.353970901887144e-06,
      "loss": 0.306,
      "step": 20111
    },
    {
      "epoch": 1.8809457060087842,
      "grad_norm": 1.6962890625,
      "learning_rate": 3.3457053926016234e-06,
      "loss": 0.3191,
      "step": 20128
    },
    {
      "epoch": 1.8825343425848051,
      "grad_norm": 2.00390625,
      "learning_rate": 3.3374449566809065e-06,
      "loss": 0.4798,
      "step": 20145
    },
    {
      "epoch": 1.884122979160826,
      "grad_norm": 0.71044921875,
      "learning_rate": 3.3291896194579687e-06,
      "loss": 0.3275,
      "step": 20162
    },
    {
      "epoch": 1.885711615736847,
      "grad_norm": 1.3046875,
      "learning_rate": 3.3209394062501486e-06,
      "loss": 0.3426,
      "step": 20179
    },
    {
      "epoch": 1.887300252312868,
      "grad_norm": 2.396484375,
      "learning_rate": 3.312694342359073e-06,
      "loss": 0.4318,
      "step": 20196
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.91162109375,
      "learning_rate": 3.3044544530705737e-06,
      "loss": 0.2803,
      "step": 20213
    },
    {
      "epoch": 1.8904775254649098,
      "grad_norm": 1.4873046875,
      "learning_rate": 3.2962197636546113e-06,
      "loss": 0.3381,
      "step": 20230
    },
    {
      "epoch": 1.8920661620409307,
      "grad_norm": 2.8203125,
      "learning_rate": 3.287990299365207e-06,
      "loss": 0.5041,
      "step": 20247
    },
    {
      "epoch": 1.8936547986169519,
      "grad_norm": 0.7890625,
      "learning_rate": 3.2797660854403513e-06,
      "loss": 0.2698,
      "step": 20264
    },
    {
      "epoch": 1.8952434351929726,
      "grad_norm": 1.66015625,
      "learning_rate": 3.2715471471019344e-06,
      "loss": 0.3011,
      "step": 20281
    },
    {
      "epoch": 1.8968320717689937,
      "grad_norm": 2.802734375,
      "learning_rate": 3.2633335095556664e-06,
      "loss": 0.5037,
      "step": 20298
    },
    {
      "epoch": 1.8984207083450144,
      "grad_norm": 1.0478515625,
      "learning_rate": 3.2551251979910055e-06,
      "loss": 0.2824,
      "step": 20315
    },
    {
      "epoch": 1.9000093449210356,
      "grad_norm": 1.8662109375,
      "learning_rate": 3.2469222375810704e-06,
      "loss": 0.3773,
      "step": 20332
    },
    {
      "epoch": 1.9015979814970563,
      "grad_norm": 2.953125,
      "learning_rate": 3.2387246534825733e-06,
      "loss": 0.5696,
      "step": 20349
    },
    {
      "epoch": 1.9031866180730774,
      "grad_norm": 0.9990234375,
      "learning_rate": 3.230532470835733e-06,
      "loss": 0.2172,
      "step": 20366
    },
    {
      "epoch": 1.9047752546490981,
      "grad_norm": 1.544921875,
      "learning_rate": 3.2223457147642135e-06,
      "loss": 0.3706,
      "step": 20383
    },
    {
      "epoch": 1.9063638912251193,
      "grad_norm": 2.798828125,
      "learning_rate": 3.214164410375026e-06,
      "loss": 0.5156,
      "step": 20400
    },
    {
      "epoch": 1.90795252780114,
      "grad_norm": 1.0380859375,
      "learning_rate": 3.2059885827584665e-06,
      "loss": 0.2185,
      "step": 20417
    },
    {
      "epoch": 1.9095411643771611,
      "grad_norm": 1.458984375,
      "learning_rate": 3.1978182569880367e-06,
      "loss": 0.344,
      "step": 20434
    },
    {
      "epoch": 1.9111298009531819,
      "grad_norm": 3.17578125,
      "learning_rate": 3.1896534581203635e-06,
      "loss": 0.5358,
      "step": 20451
    },
    {
      "epoch": 1.912718437529203,
      "grad_norm": 1.02734375,
      "learning_rate": 3.181494211195124e-06,
      "loss": 0.1307,
      "step": 20468
    },
    {
      "epoch": 1.9143070741052237,
      "grad_norm": 1.8466796875,
      "learning_rate": 3.1733405412349667e-06,
      "loss": 0.3748,
      "step": 20485
    },
    {
      "epoch": 1.9158957106812449,
      "grad_norm": 0.17529296875,
      "learning_rate": 3.165192473245443e-06,
      "loss": 0.4831,
      "step": 20502
    },
    {
      "epoch": 1.9174843472572656,
      "grad_norm": 1.1162109375,
      "learning_rate": 3.1570500322149183e-06,
      "loss": 0.2008,
      "step": 20519
    },
    {
      "epoch": 1.9190729838332867,
      "grad_norm": 2.119140625,
      "learning_rate": 3.1489132431145035e-06,
      "loss": 0.3784,
      "step": 20536
    },
    {
      "epoch": 1.9206616204093074,
      "grad_norm": 0.307861328125,
      "learning_rate": 3.1407821308979738e-06,
      "loss": 0.5027,
      "step": 20553
    },
    {
      "epoch": 1.9222502569853286,
      "grad_norm": 1.296875,
      "learning_rate": 3.1326567205017012e-06,
      "loss": 0.217,
      "step": 20570
    },
    {
      "epoch": 1.9238388935613493,
      "grad_norm": 1.9716796875,
      "learning_rate": 3.1245370368445643e-06,
      "loss": 0.396,
      "step": 20587
    },
    {
      "epoch": 1.9254275301373704,
      "grad_norm": 1.0966796875,
      "learning_rate": 3.1164231048278814e-06,
      "loss": 0.4672,
      "step": 20604
    },
    {
      "epoch": 1.9270161667133912,
      "grad_norm": 1.16796875,
      "learning_rate": 3.1083149493353347e-06,
      "loss": 0.252,
      "step": 20621
    },
    {
      "epoch": 1.9286048032894123,
      "grad_norm": 2.052734375,
      "learning_rate": 3.1002125952328867e-06,
      "loss": 0.4443,
      "step": 20638
    },
    {
      "epoch": 1.930193439865433,
      "grad_norm": 0.429931640625,
      "learning_rate": 3.09211606736871e-06,
      "loss": 0.4343,
      "step": 20655
    },
    {
      "epoch": 1.9317820764414542,
      "grad_norm": 1.1650390625,
      "learning_rate": 3.084025390573109e-06,
      "loss": 0.2566,
      "step": 20672
    },
    {
      "epoch": 1.9333707130174749,
      "grad_norm": 2.236328125,
      "learning_rate": 3.075940589658446e-06,
      "loss": 0.4348,
      "step": 20689
    },
    {
      "epoch": 1.934959349593496,
      "grad_norm": 0.32666015625,
      "learning_rate": 3.067861689419063e-06,
      "loss": 0.4072,
      "step": 20706
    },
    {
      "epoch": 1.9365479861695167,
      "grad_norm": 1.2841796875,
      "learning_rate": 3.0597887146312003e-06,
      "loss": 0.2749,
      "step": 20723
    },
    {
      "epoch": 1.9381366227455379,
      "grad_norm": 1.830078125,
      "learning_rate": 3.051721690052936e-06,
      "loss": 0.4398,
      "step": 20740
    },
    {
      "epoch": 1.9397252593215586,
      "grad_norm": 0.6005859375,
      "learning_rate": 3.0436606404240913e-06,
      "loss": 0.3631,
      "step": 20757
    },
    {
      "epoch": 1.9413138958975797,
      "grad_norm": 1.236328125,
      "learning_rate": 3.0356055904661683e-06,
      "loss": 0.2513,
      "step": 20774
    },
    {
      "epoch": 1.9429025324736005,
      "grad_norm": 2.080078125,
      "learning_rate": 3.027556564882266e-06,
      "loss": 0.4065,
      "step": 20791
    },
    {
      "epoch": 1.9444911690496216,
      "grad_norm": 0.79052734375,
      "learning_rate": 3.0195135883570136e-06,
      "loss": 0.3954,
      "step": 20808
    },
    {
      "epoch": 1.9460798056256423,
      "grad_norm": 1.30859375,
      "learning_rate": 3.011476685556485e-06,
      "loss": 0.2331,
      "step": 20825
    },
    {
      "epoch": 1.9476684422016635,
      "grad_norm": 2.005859375,
      "learning_rate": 3.0034458811281254e-06,
      "loss": 0.4428,
      "step": 20842
    },
    {
      "epoch": 1.9492570787776842,
      "grad_norm": 0.6005859375,
      "learning_rate": 2.9954211997006793e-06,
      "loss": 0.373,
      "step": 20859
    },
    {
      "epoch": 1.9508457153537053,
      "grad_norm": 1.7177734375,
      "learning_rate": 2.9874026658841184e-06,
      "loss": 0.3246,
      "step": 20876
    },
    {
      "epoch": 1.952434351929726,
      "grad_norm": 2.6328125,
      "learning_rate": 2.979390304269555e-06,
      "loss": 0.4884,
      "step": 20893
    },
    {
      "epoch": 1.9540229885057472,
      "grad_norm": 0.82861328125,
      "learning_rate": 2.971384139429172e-06,
      "loss": 0.3824,
      "step": 20910
    },
    {
      "epoch": 1.9556116250817681,
      "grad_norm": 1.634765625,
      "learning_rate": 2.9633841959161536e-06,
      "loss": 0.3475,
      "step": 20927
    },
    {
      "epoch": 1.957200261657789,
      "grad_norm": 2.25,
      "learning_rate": 2.9553904982645997e-06,
      "loss": 0.4635,
      "step": 20944
    },
    {
      "epoch": 1.95878889823381,
      "grad_norm": 0.82373046875,
      "learning_rate": 2.9474030709894576e-06,
      "loss": 0.3447,
      "step": 20961
    },
    {
      "epoch": 1.960377534809831,
      "grad_norm": 1.2607421875,
      "learning_rate": 2.9394219385864415e-06,
      "loss": 0.3035,
      "step": 20978
    },
    {
      "epoch": 1.9619661713858518,
      "grad_norm": 2.509765625,
      "learning_rate": 2.9314471255319678e-06,
      "loss": 0.4959,
      "step": 20995
    },
    {
      "epoch": 1.9635548079618728,
      "grad_norm": 0.7626953125,
      "learning_rate": 2.9234786562830663e-06,
      "loss": 0.312,
      "step": 21012
    },
    {
      "epoch": 1.9651434445378937,
      "grad_norm": 1.6376953125,
      "learning_rate": 2.9155165552773147e-06,
      "loss": 0.2913,
      "step": 21029
    },
    {
      "epoch": 1.9667320811139146,
      "grad_norm": 2.314453125,
      "learning_rate": 2.9075608469327556e-06,
      "loss": 0.4854,
      "step": 21046
    },
    {
      "epoch": 1.9683207176899356,
      "grad_norm": 0.84130859375,
      "learning_rate": 2.899611555647836e-06,
      "loss": 0.3227,
      "step": 21063
    },
    {
      "epoch": 1.9699093542659565,
      "grad_norm": 1.56640625,
      "learning_rate": 2.891668705801316e-06,
      "loss": 0.3369,
      "step": 21080
    },
    {
      "epoch": 1.9714979908419774,
      "grad_norm": 2.521484375,
      "learning_rate": 2.8837323217522007e-06,
      "loss": 0.5033,
      "step": 21097
    },
    {
      "epoch": 1.9730866274179983,
      "grad_norm": 0.93798828125,
      "learning_rate": 2.8758024278396727e-06,
      "loss": 0.2484,
      "step": 21114
    },
    {
      "epoch": 1.9746752639940193,
      "grad_norm": 1.607421875,
      "learning_rate": 2.867879048383005e-06,
      "loss": 0.3344,
      "step": 21131
    },
    {
      "epoch": 1.9762639005700402,
      "grad_norm": 2.634765625,
      "learning_rate": 2.859962207681493e-06,
      "loss": 0.5299,
      "step": 21148
    },
    {
      "epoch": 1.9778525371460611,
      "grad_norm": 1.0615234375,
      "learning_rate": 2.852051930014378e-06,
      "loss": 0.2601,
      "step": 21165
    },
    {
      "epoch": 1.979441173722082,
      "grad_norm": 1.8056640625,
      "learning_rate": 2.8441482396407806e-06,
      "loss": 0.3891,
      "step": 21182
    },
    {
      "epoch": 1.981029810298103,
      "grad_norm": 2.87109375,
      "learning_rate": 2.836251160799611e-06,
      "loss": 0.508,
      "step": 21199
    },
    {
      "epoch": 1.982618446874124,
      "grad_norm": 0.98046875,
      "learning_rate": 2.8283607177095087e-06,
      "loss": 0.2612,
      "step": 21216
    },
    {
      "epoch": 1.9842070834501448,
      "grad_norm": 2.0625,
      "learning_rate": 2.820476934568757e-06,
      "loss": 0.3912,
      "step": 21233
    },
    {
      "epoch": 1.9857957200261658,
      "grad_norm": 3.025390625,
      "learning_rate": 2.812599835555225e-06,
      "loss": 0.5054,
      "step": 21250
    },
    {
      "epoch": 1.9873843566021867,
      "grad_norm": 0.98583984375,
      "learning_rate": 2.804729444826273e-06,
      "loss": 0.2161,
      "step": 21267
    },
    {
      "epoch": 1.9889729931782076,
      "grad_norm": 1.369140625,
      "learning_rate": 2.796865786518692e-06,
      "loss": 0.3697,
      "step": 21284
    },
    {
      "epoch": 1.9905616297542286,
      "grad_norm": 2.99609375,
      "learning_rate": 2.7890088847486276e-06,
      "loss": 0.5161,
      "step": 21301
    },
    {
      "epoch": 1.9921502663302495,
      "grad_norm": 1.123046875,
      "learning_rate": 2.7811587636115025e-06,
      "loss": 0.2745,
      "step": 21318
    },
    {
      "epoch": 1.9937389029062704,
      "grad_norm": 1.693359375,
      "learning_rate": 2.7733154471819444e-06,
      "loss": 0.3912,
      "step": 21335
    },
    {
      "epoch": 1.9953275394822914,
      "grad_norm": 0.405517578125,
      "learning_rate": 2.765478959513712e-06,
      "loss": 0.5299,
      "step": 21352
    },
    {
      "epoch": 1.9969161760583123,
      "grad_norm": 1.3427734375,
      "learning_rate": 2.7576493246396275e-06,
      "loss": 0.2531,
      "step": 21369
    },
    {
      "epoch": 1.9985048126343332,
      "grad_norm": 2.12109375,
      "learning_rate": 2.7498265665714897e-06,
      "loss": 0.3764,
      "step": 21386
    },
    {
      "epoch": 2.0000934492103544,
      "grad_norm": 1.1396484375,
      "learning_rate": 2.7420107093000114e-06,
      "loss": 0.5435,
      "step": 21403
    },
    {
      "epoch": 2.001682085786375,
      "grad_norm": 1.1015625,
      "learning_rate": 2.734201776794738e-06,
      "loss": 0.2168,
      "step": 21420
    },
    {
      "epoch": 2.0032707223623962,
      "grad_norm": 1.9658203125,
      "learning_rate": 2.7263997930039877e-06,
      "loss": 0.4024,
      "step": 21437
    },
    {
      "epoch": 2.004859358938417,
      "grad_norm": 0.11212158203125,
      "learning_rate": 2.718604781854758e-06,
      "loss": 0.4749,
      "step": 21454
    },
    {
      "epoch": 2.006447995514438,
      "grad_norm": 1.193359375,
      "learning_rate": 2.7108167672526664e-06,
      "loss": 0.2166,
      "step": 21471
    },
    {
      "epoch": 2.008036632090459,
      "grad_norm": 2.244140625,
      "learning_rate": 2.7030357730818774e-06,
      "loss": 0.4216,
      "step": 21488
    },
    {
      "epoch": 2.00962526866648,
      "grad_norm": 0.370849609375,
      "learning_rate": 2.6952618232050205e-06,
      "loss": 0.4412,
      "step": 21505
    },
    {
      "epoch": 2.0112139052425007,
      "grad_norm": 1.552734375,
      "learning_rate": 2.6874949414631236e-06,
      "loss": 0.2456,
      "step": 21522
    },
    {
      "epoch": 2.012802541818522,
      "grad_norm": 2.380859375,
      "learning_rate": 2.6797351516755355e-06,
      "loss": 0.4176,
      "step": 21539
    },
    {
      "epoch": 2.0143911783945425,
      "grad_norm": 0.50146484375,
      "learning_rate": 2.671982477639863e-06,
      "loss": 0.4595,
      "step": 21556
    },
    {
      "epoch": 2.0159798149705637,
      "grad_norm": 1.546875,
      "learning_rate": 2.664236943131882e-06,
      "loss": 0.2647,
      "step": 21573
    },
    {
      "epoch": 2.0175684515465844,
      "grad_norm": 2.279296875,
      "learning_rate": 2.656498571905478e-06,
      "loss": 0.4272,
      "step": 21590
    },
    {
      "epoch": 2.0191570881226055,
      "grad_norm": 0.77099609375,
      "learning_rate": 2.648767387692566e-06,
      "loss": 0.4009,
      "step": 21607
    },
    {
      "epoch": 2.0207457246986262,
      "grad_norm": 1.173828125,
      "learning_rate": 2.6410434142030206e-06,
      "loss": 0.2616,
      "step": 21624
    },
    {
      "epoch": 2.0223343612746474,
      "grad_norm": 2.001953125,
      "learning_rate": 2.633326675124603e-06,
      "loss": 0.4309,
      "step": 21641
    },
    {
      "epoch": 2.023922997850668,
      "grad_norm": 0.55810546875,
      "learning_rate": 2.6256171941228856e-06,
      "loss": 0.3699,
      "step": 21658
    },
    {
      "epoch": 2.0255116344266892,
      "grad_norm": 1.1826171875,
      "learning_rate": 2.6179149948411888e-06,
      "loss": 0.2502,
      "step": 21675
    },
    {
      "epoch": 2.02710027100271,
      "grad_norm": 2.26171875,
      "learning_rate": 2.6102201009004935e-06,
      "loss": 0.4101,
      "step": 21692
    },
    {
      "epoch": 2.028688907578731,
      "grad_norm": 0.80419921875,
      "learning_rate": 2.6025325358993805e-06,
      "loss": 0.3953,
      "step": 21709
    },
    {
      "epoch": 2.030277544154752,
      "grad_norm": 1.7705078125,
      "learning_rate": 2.594852323413952e-06,
      "loss": 0.2879,
      "step": 21726
    },
    {
      "epoch": 2.031866180730773,
      "grad_norm": 2.197265625,
      "learning_rate": 2.5871794869977683e-06,
      "loss": 0.4661,
      "step": 21743
    },
    {
      "epoch": 2.0334548173067937,
      "grad_norm": 0.7353515625,
      "learning_rate": 2.5795140501817605e-06,
      "loss": 0.3576,
      "step": 21760
    },
    {
      "epoch": 2.035043453882815,
      "grad_norm": 1.18359375,
      "learning_rate": 2.5718560364741683e-06,
      "loss": 0.2737,
      "step": 21777
    },
    {
      "epoch": 2.0366320904588355,
      "grad_norm": 1.8310546875,
      "learning_rate": 2.5642054693604733e-06,
      "loss": 0.4055,
      "step": 21794
    },
    {
      "epoch": 2.0382207270348567,
      "grad_norm": 0.83056640625,
      "learning_rate": 2.5565623723033124e-06,
      "loss": 0.3574,
      "step": 21811
    },
    {
      "epoch": 2.0398093636108774,
      "grad_norm": 1.98828125,
      "learning_rate": 2.548926768742416e-06,
      "loss": 0.3261,
      "step": 21828
    },
    {
      "epoch": 2.0413980001868985,
      "grad_norm": 2.59375,
      "learning_rate": 2.541298682094533e-06,
      "loss": 0.4745,
      "step": 21845
    },
    {
      "epoch": 2.0429866367629193,
      "grad_norm": 0.71826171875,
      "learning_rate": 2.5336781357533612e-06,
      "loss": 0.2926,
      "step": 21862
    },
    {
      "epoch": 2.0445752733389404,
      "grad_norm": 1.357421875,
      "learning_rate": 2.526065153089472e-06,
      "loss": 0.2979,
      "step": 21879
    },
    {
      "epoch": 2.046163909914961,
      "grad_norm": 2.63671875,
      "learning_rate": 2.518459757450242e-06,
      "loss": 0.4425,
      "step": 21896
    },
    {
      "epoch": 2.0477525464909823,
      "grad_norm": 0.91650390625,
      "learning_rate": 2.510861972159777e-06,
      "loss": 0.3057,
      "step": 21913
    },
    {
      "epoch": 2.049341183067003,
      "grad_norm": 1.599609375,
      "learning_rate": 2.503271820518851e-06,
      "loss": 0.2798,
      "step": 21930
    },
    {
      "epoch": 2.050929819643024,
      "grad_norm": 2.212890625,
      "learning_rate": 2.4956893258048187e-06,
      "loss": 0.4084,
      "step": 21947
    },
    {
      "epoch": 2.052518456219045,
      "grad_norm": 1.021484375,
      "learning_rate": 2.4881145112715547e-06,
      "loss": 0.2629,
      "step": 21964
    },
    {
      "epoch": 2.054107092795066,
      "grad_norm": 1.6630859375,
      "learning_rate": 2.4805474001493868e-06,
      "loss": 0.3219,
      "step": 21981
    },
    {
      "epoch": 2.0556957293710867,
      "grad_norm": 2.736328125,
      "learning_rate": 2.4729880156450094e-06,
      "loss": 0.4698,
      "step": 21998
    },
    {
      "epoch": 2.057284365947108,
      "grad_norm": 0.83154296875,
      "learning_rate": 2.465436380941425e-06,
      "loss": 0.253,
      "step": 22015
    },
    {
      "epoch": 2.0588730025231285,
      "grad_norm": 1.7373046875,
      "learning_rate": 2.457892519197867e-06,
      "loss": 0.3671,
      "step": 22032
    },
    {
      "epoch": 2.0604616390991497,
      "grad_norm": 2.896484375,
      "learning_rate": 2.4503564535497364e-06,
      "loss": 0.5135,
      "step": 22049
    },
    {
      "epoch": 2.0620502756751704,
      "grad_norm": 0.994140625,
      "learning_rate": 2.442828207108519e-06,
      "loss": 0.266,
      "step": 22066
    },
    {
      "epoch": 2.0636389122511916,
      "grad_norm": 1.794921875,
      "learning_rate": 2.4353078029617233e-06,
      "loss": 0.347,
      "step": 22083
    },
    {
      "epoch": 2.0652275488272123,
      "grad_norm": 2.9453125,
      "learning_rate": 2.4277952641728058e-06,
      "loss": 0.5696,
      "step": 22100
    },
    {
      "epoch": 2.0668161854032334,
      "grad_norm": 1.1025390625,
      "learning_rate": 2.4202906137811055e-06,
      "loss": 0.2111,
      "step": 22117
    },
    {
      "epoch": 2.068404821979254,
      "grad_norm": 2.0390625,
      "learning_rate": 2.412793874801766e-06,
      "loss": 0.3534,
      "step": 22134
    },
    {
      "epoch": 2.0699934585552753,
      "grad_norm": 3.201171875,
      "learning_rate": 2.4053050702256683e-06,
      "loss": 0.5404,
      "step": 22151
    },
    {
      "epoch": 2.071582095131296,
      "grad_norm": 1.099609375,
      "learning_rate": 2.3978242230193607e-06,
      "loss": 0.1764,
      "step": 22168
    },
    {
      "epoch": 2.073170731707317,
      "grad_norm": 2.3515625,
      "learning_rate": 2.3903513561249888e-06,
      "loss": 0.4028,
      "step": 22185
    },
    {
      "epoch": 2.074759368283338,
      "grad_norm": 3.08984375,
      "learning_rate": 2.382886492460224e-06,
      "loss": 0.5295,
      "step": 22202
    },
    {
      "epoch": 2.076348004859359,
      "grad_norm": 1.3056640625,
      "learning_rate": 2.375429654918191e-06,
      "loss": 0.2051,
      "step": 22219
    },
    {
      "epoch": 2.0779366414353797,
      "grad_norm": 1.8955078125,
      "learning_rate": 2.3679808663674063e-06,
      "loss": 0.4437,
      "step": 22236
    },
    {
      "epoch": 2.079525278011401,
      "grad_norm": 0.32421875,
      "learning_rate": 2.3605401496516965e-06,
      "loss": 0.4647,
      "step": 22253
    },
    {
      "epoch": 2.0811139145874216,
      "grad_norm": 1.1708984375,
      "learning_rate": 2.353107527590135e-06,
      "loss": 0.2178,
      "step": 22270
    },
    {
      "epoch": 2.0827025511634427,
      "grad_norm": 2.548828125,
      "learning_rate": 2.345683022976969e-06,
      "loss": 0.416,
      "step": 22287
    },
    {
      "epoch": 2.0842911877394634,
      "grad_norm": 0.284423828125,
      "learning_rate": 2.338266658581556e-06,
      "loss": 0.4893,
      "step": 22304
    },
    {
      "epoch": 2.0858798243154846,
      "grad_norm": 1.3876953125,
      "learning_rate": 2.3308584571482858e-06,
      "loss": 0.2342,
      "step": 22321
    },
    {
      "epoch": 2.0874684608915053,
      "grad_norm": 2.263671875,
      "learning_rate": 2.3234584413965107e-06,
      "loss": 0.3921,
      "step": 22338
    },
    {
      "epoch": 2.0890570974675264,
      "grad_norm": 0.6181640625,
      "learning_rate": 2.3160666340204885e-06,
      "loss": 0.475,
      "step": 22355
    },
    {
      "epoch": 2.090645734043547,
      "grad_norm": 1.3466796875,
      "learning_rate": 2.3086830576892962e-06,
      "loss": 0.2479,
      "step": 22372
    },
    {
      "epoch": 2.0922343706195683,
      "grad_norm": 2.775390625,
      "learning_rate": 2.3013077350467694e-06,
      "loss": 0.4048,
      "step": 22389
    },
    {
      "epoch": 2.093823007195589,
      "grad_norm": 0.7255859375,
      "learning_rate": 2.2939406887114314e-06,
      "loss": 0.4329,
      "step": 22406
    },
    {
      "epoch": 2.09541164377161,
      "grad_norm": 1.28515625,
      "learning_rate": 2.2865819412764274e-06,
      "loss": 0.2707,
      "step": 22423
    },
    {
      "epoch": 2.097000280347631,
      "grad_norm": 1.8623046875,
      "learning_rate": 2.2792315153094468e-06,
      "loss": 0.3855,
      "step": 22440
    },
    {
      "epoch": 2.098588916923652,
      "grad_norm": 0.496826171875,
      "learning_rate": 2.271889433352662e-06,
      "loss": 0.4077,
      "step": 22457
    },
    {
      "epoch": 2.1001775534996727,
      "grad_norm": 1.4814453125,
      "learning_rate": 2.2645557179226536e-06,
      "loss": 0.2408,
      "step": 22474
    },
    {
      "epoch": 2.101766190075694,
      "grad_norm": 2.326171875,
      "learning_rate": 2.2572303915103462e-06,
      "loss": 0.4473,
      "step": 22491
    },
    {
      "epoch": 2.1033548266517146,
      "grad_norm": 0.6416015625,
      "learning_rate": 2.249913476580936e-06,
      "loss": 0.4071,
      "step": 22508
    },
    {
      "epoch": 2.1049434632277357,
      "grad_norm": 1.5791015625,
      "learning_rate": 2.2426049955738216e-06,
      "loss": 0.2895,
      "step": 22525
    },
    {
      "epoch": 2.106532099803757,
      "grad_norm": 2.2890625,
      "learning_rate": 2.2353049709025408e-06,
      "loss": 0.4532,
      "step": 22542
    },
    {
      "epoch": 2.1081207363797776,
      "grad_norm": 0.84521484375,
      "learning_rate": 2.2280134249546943e-06,
      "loss": 0.3633,
      "step": 22559
    },
    {
      "epoch": 2.1097093729557983,
      "grad_norm": 1.599609375,
      "learning_rate": 2.2207303800918805e-06,
      "loss": 0.2837,
      "step": 22576
    },
    {
      "epoch": 2.1112980095318195,
      "grad_norm": 2.583984375,
      "learning_rate": 2.213455858649626e-06,
      "loss": 0.4704,
      "step": 22593
    },
    {
      "epoch": 2.1128866461078406,
      "grad_norm": 0.80126953125,
      "learning_rate": 2.2061898829373217e-06,
      "loss": 0.3519,
      "step": 22610
    },
    {
      "epoch": 2.1144752826838613,
      "grad_norm": 1.2919921875,
      "learning_rate": 2.1989324752381475e-06,
      "loss": 0.2826,
      "step": 22627
    },
    {
      "epoch": 2.1160639192598825,
      "grad_norm": 1.99609375,
      "learning_rate": 2.1916836578090054e-06,
      "loss": 0.4687,
      "step": 22644
    },
    {
      "epoch": 2.117652555835903,
      "grad_norm": 1.0517578125,
      "learning_rate": 2.1844434528804597e-06,
      "loss": 0.3809,
      "step": 22661
    },
    {
      "epoch": 2.1192411924119243,
      "grad_norm": 1.71484375,
      "learning_rate": 2.1772118826566545e-06,
      "loss": 0.3342,
      "step": 22678
    },
    {
      "epoch": 2.120829828987945,
      "grad_norm": 2.677734375,
      "learning_rate": 2.169988969315257e-06,
      "loss": 0.4784,
      "step": 22695
    },
    {
      "epoch": 2.122418465563966,
      "grad_norm": 0.96533203125,
      "learning_rate": 2.1627747350073825e-06,
      "loss": 0.3281,
      "step": 22712
    },
    {
      "epoch": 2.124007102139987,
      "grad_norm": 1.7021484375,
      "learning_rate": 2.155569201857536e-06,
      "loss": 0.3343,
      "step": 22729
    },
    {
      "epoch": 2.125595738716008,
      "grad_norm": 3.1875,
      "learning_rate": 2.148372391963531e-06,
      "loss": 0.5363,
      "step": 22746
    },
    {
      "epoch": 2.1271843752920288,
      "grad_norm": 0.9208984375,
      "learning_rate": 2.141184327396432e-06,
      "loss": 0.3197,
      "step": 22763
    },
    {
      "epoch": 2.12877301186805,
      "grad_norm": 1.822265625,
      "learning_rate": 2.1340050302004834e-06,
      "loss": 0.3559,
      "step": 22780
    },
    {
      "epoch": 2.1303616484440706,
      "grad_norm": 2.677734375,
      "learning_rate": 2.1268345223930404e-06,
      "loss": 0.4977,
      "step": 22797
    },
    {
      "epoch": 2.1319502850200918,
      "grad_norm": 1.037109375,
      "learning_rate": 2.1196728259645044e-06,
      "loss": 0.3177,
      "step": 22814
    },
    {
      "epoch": 2.1335389215961125,
      "grad_norm": 1.7421875,
      "learning_rate": 2.1125199628782528e-06,
      "loss": 0.3341,
      "step": 22831
    },
    {
      "epoch": 2.1351275581721336,
      "grad_norm": 2.373046875,
      "learning_rate": 2.1053759550705772e-06,
      "loss": 0.4731,
      "step": 22848
    },
    {
      "epoch": 2.1367161947481543,
      "grad_norm": 1.076171875,
      "learning_rate": 2.098240824450607e-06,
      "loss": 0.267,
      "step": 22865
    },
    {
      "epoch": 2.1383048313241755,
      "grad_norm": 1.6806640625,
      "learning_rate": 2.0911145929002492e-06,
      "loss": 0.3516,
      "step": 22882
    },
    {
      "epoch": 2.139893467900196,
      "grad_norm": 2.708984375,
      "learning_rate": 2.0839972822741168e-06,
      "loss": 0.4964,
      "step": 22899
    },
    {
      "epoch": 2.1414821044762173,
      "grad_norm": 1.115234375,
      "learning_rate": 2.0768889143994715e-06,
      "loss": 0.3071,
      "step": 22916
    },
    {
      "epoch": 2.143070741052238,
      "grad_norm": 1.9609375,
      "learning_rate": 2.0697895110761417e-06,
      "loss": 0.3669,
      "step": 22933
    },
    {
      "epoch": 2.144659377628259,
      "grad_norm": 2.3828125,
      "learning_rate": 2.062699094076467e-06,
      "loss": 0.5321,
      "step": 22950
    },
    {
      "epoch": 2.14624801420428,
      "grad_norm": 1.1240234375,
      "learning_rate": 2.0556176851452254e-06,
      "loss": 0.2513,
      "step": 22967
    },
    {
      "epoch": 2.147836650780301,
      "grad_norm": 1.796875,
      "learning_rate": 2.048545305999574e-06,
      "loss": 0.3712,
      "step": 22984
    },
    {
      "epoch": 2.1494252873563218,
      "grad_norm": 2.708984375,
      "learning_rate": 2.041481978328973e-06,
      "loss": 0.5099,
      "step": 23001
    },
    {
      "epoch": 2.151013923932343,
      "grad_norm": 1.1640625,
      "learning_rate": 2.034427723795123e-06,
      "loss": 0.2434,
      "step": 23018
    },
    {
      "epoch": 2.1526025605083636,
      "grad_norm": 2.01171875,
      "learning_rate": 2.027382564031906e-06,
      "loss": 0.3775,
      "step": 23035
    },
    {
      "epoch": 2.154191197084385,
      "grad_norm": 3.26171875,
      "learning_rate": 2.020346520645305e-06,
      "loss": 0.5056,
      "step": 23052
    },
    {
      "epoch": 2.1557798336604055,
      "grad_norm": 1.166015625,
      "learning_rate": 2.0133196152133477e-06,
      "loss": 0.1976,
      "step": 23069
    },
    {
      "epoch": 2.1573684702364266,
      "grad_norm": 2.111328125,
      "learning_rate": 2.006301869286038e-06,
      "loss": 0.3743,
      "step": 23086
    },
    {
      "epoch": 2.1589571068124473,
      "grad_norm": 0.46044921875,
      "learning_rate": 1.999293304385289e-06,
      "loss": 0.4756,
      "step": 23103
    },
    {
      "epoch": 2.1605457433884685,
      "grad_norm": 1.4287109375,
      "learning_rate": 1.992293942004858e-06,
      "loss": 0.1979,
      "step": 23120
    },
    {
      "epoch": 2.162134379964489,
      "grad_norm": 2.134765625,
      "learning_rate": 1.9853038036102803e-06,
      "loss": 0.4117,
      "step": 23137
    },
    {
      "epoch": 2.1637230165405104,
      "grad_norm": 0.266845703125,
      "learning_rate": 1.9783229106388e-06,
      "loss": 0.4978,
      "step": 23154
    },
    {
      "epoch": 2.165311653116531,
      "grad_norm": 1.0888671875,
      "learning_rate": 1.971351284499315e-06,
      "loss": 0.2215,
      "step": 23171
    },
    {
      "epoch": 2.166900289692552,
      "grad_norm": 2.130859375,
      "learning_rate": 1.964388946572297e-06,
      "loss": 0.3713,
      "step": 23188
    },
    {
      "epoch": 2.168488926268573,
      "grad_norm": 0.4560546875,
      "learning_rate": 1.957435918209733e-06,
      "loss": 0.4428,
      "step": 23205
    },
    {
      "epoch": 2.170077562844594,
      "grad_norm": 1.341796875,
      "learning_rate": 1.9504922207350657e-06,
      "loss": 0.233,
      "step": 23222
    },
    {
      "epoch": 2.171666199420615,
      "grad_norm": 1.86328125,
      "learning_rate": 1.9435578754431156e-06,
      "loss": 0.4125,
      "step": 23239
    },
    {
      "epoch": 2.173254835996636,
      "grad_norm": 0.338134765625,
      "learning_rate": 1.936632903600024e-06,
      "loss": 0.4344,
      "step": 23256
    },
    {
      "epoch": 2.1748434725726566,
      "grad_norm": 1.1103515625,
      "learning_rate": 1.9297173264431853e-06,
      "loss": 0.2826,
      "step": 23273
    },
    {
      "epoch": 2.176432109148678,
      "grad_norm": 2.380859375,
      "learning_rate": 1.922811165181186e-06,
      "loss": 0.4137,
      "step": 23290
    },
    {
      "epoch": 2.1780207457246985,
      "grad_norm": 0.46826171875,
      "learning_rate": 1.9159144409937315e-06,
      "loss": 0.4645,
      "step": 23307
    },
    {
      "epoch": 2.1796093823007197,
      "grad_norm": 1.3662109375,
      "learning_rate": 1.9090271750315866e-06,
      "loss": 0.2336,
      "step": 23324
    },
    {
      "epoch": 2.1811980188767404,
      "grad_norm": 1.9306640625,
      "learning_rate": 1.9021493884165132e-06,
      "loss": 0.4185,
      "step": 23341
    },
    {
      "epoch": 2.1827866554527615,
      "grad_norm": 0.54638671875,
      "learning_rate": 1.8952811022411987e-06,
      "loss": 0.3815,
      "step": 23358
    },
    {
      "epoch": 2.1843752920287822,
      "grad_norm": 1.5615234375,
      "learning_rate": 1.8884223375691958e-06,
      "loss": 0.2564,
      "step": 23375
    },
    {
      "epoch": 2.1859639286048034,
      "grad_norm": 2.380859375,
      "learning_rate": 1.8815731154348554e-06,
      "loss": 0.4386,
      "step": 23392
    },
    {
      "epoch": 2.187552565180824,
      "grad_norm": 0.71044921875,
      "learning_rate": 1.8747334568432656e-06,
      "loss": 0.3977,
      "step": 23409
    },
    {
      "epoch": 2.1891412017568452,
      "grad_norm": 1.537109375,
      "learning_rate": 1.8679033827701847e-06,
      "loss": 0.2557,
      "step": 23426
    },
    {
      "epoch": 2.190729838332866,
      "grad_norm": 2.060546875,
      "learning_rate": 1.8610829141619757e-06,
      "loss": 0.4731,
      "step": 23443
    },
    {
      "epoch": 2.192318474908887,
      "grad_norm": 0.87255859375,
      "learning_rate": 1.8542720719355445e-06,
      "loss": 0.3948,
      "step": 23460
    },
    {
      "epoch": 2.193907111484908,
      "grad_norm": 1.701171875,
      "learning_rate": 1.8474708769782779e-06,
      "loss": 0.3069,
      "step": 23477
    },
    {
      "epoch": 2.195495748060929,
      "grad_norm": 2.158203125,
      "learning_rate": 1.8406793501479731e-06,
      "loss": 0.4562,
      "step": 23494
    },
    {
      "epoch": 2.1970843846369497,
      "grad_norm": 0.97705078125,
      "learning_rate": 1.8338975122727764e-06,
      "loss": 0.3456,
      "step": 23511
    },
    {
      "epoch": 2.198673021212971,
      "grad_norm": 1.58203125,
      "learning_rate": 1.8271253841511249e-06,
      "loss": 0.3099,
      "step": 23528
    },
    {
      "epoch": 2.2002616577889915,
      "grad_norm": 2.228515625,
      "learning_rate": 1.8203629865516742e-06,
      "loss": 0.5621,
      "step": 23545
    },
    {
      "epoch": 2.2018502943650127,
      "grad_norm": 0.85107421875,
      "learning_rate": 1.8136103402132388e-06,
      "loss": 0.3083,
      "step": 23562
    },
    {
      "epoch": 2.2034389309410334,
      "grad_norm": 1.814453125,
      "learning_rate": 1.8068674658447272e-06,
      "loss": 0.2962,
      "step": 23579
    },
    {
      "epoch": 2.2050275675170545,
      "grad_norm": 2.236328125,
      "learning_rate": 1.800134384125084e-06,
      "loss": 0.4869,
      "step": 23596
    },
    {
      "epoch": 2.2066162040930752,
      "grad_norm": 0.8046875,
      "learning_rate": 1.793411115703218e-06,
      "loss": 0.3107,
      "step": 23613
    },
    {
      "epoch": 2.2082048406690964,
      "grad_norm": 1.87109375,
      "learning_rate": 1.786697681197943e-06,
      "loss": 0.3497,
      "step": 23630
    },
    {
      "epoch": 2.209793477245117,
      "grad_norm": 2.904296875,
      "learning_rate": 1.7799941011979133e-06,
      "loss": 0.512,
      "step": 23647
    },
    {
      "epoch": 2.2113821138211383,
      "grad_norm": 0.8427734375,
      "learning_rate": 1.7733003962615663e-06,
      "loss": 0.299,
      "step": 23664
    },
    {
      "epoch": 2.212970750397159,
      "grad_norm": 1.669921875,
      "learning_rate": 1.76661658691705e-06,
      "loss": 0.2912,
      "step": 23681
    },
    {
      "epoch": 2.21455938697318,
      "grad_norm": 2.365234375,
      "learning_rate": 1.7599426936621662e-06,
      "loss": 0.4456,
      "step": 23698
    },
    {
      "epoch": 2.216148023549201,
      "grad_norm": 0.8232421875,
      "learning_rate": 1.753278736964306e-06,
      "loss": 0.2637,
      "step": 23715
    },
    {
      "epoch": 2.217736660125222,
      "grad_norm": 1.5537109375,
      "learning_rate": 1.7466247372603883e-06,
      "loss": 0.3311,
      "step": 23732
    },
    {
      "epoch": 2.2193252967012427,
      "grad_norm": 2.708984375,
      "learning_rate": 1.7399807149567944e-06,
      "loss": 0.5171,
      "step": 23749
    },
    {
      "epoch": 2.220913933277264,
      "grad_norm": 1.1796875,
      "learning_rate": 1.7333466904293061e-06,
      "loss": 0.305,
      "step": 23766
    },
    {
      "epoch": 2.2225025698532845,
      "grad_norm": 2.068359375,
      "learning_rate": 1.72672268402305e-06,
      "loss": 0.3492,
      "step": 23783
    },
    {
      "epoch": 2.2240912064293057,
      "grad_norm": 2.888671875,
      "learning_rate": 1.7201087160524228e-06,
      "loss": 0.5213,
      "step": 23800
    },
    {
      "epoch": 2.2256798430053264,
      "grad_norm": 1.1416015625,
      "learning_rate": 1.7135048068010385e-06,
      "loss": 0.2094,
      "step": 23817
    },
    {
      "epoch": 2.2272684795813475,
      "grad_norm": 1.650390625,
      "learning_rate": 1.7069109765216613e-06,
      "loss": 0.3429,
      "step": 23834
    },
    {
      "epoch": 2.2288571161573687,
      "grad_norm": 2.91015625,
      "learning_rate": 1.7003272454361492e-06,
      "loss": 0.507,
      "step": 23851
    },
    {
      "epoch": 2.2304457527333894,
      "grad_norm": 1.1689453125,
      "learning_rate": 1.6937536337353843e-06,
      "loss": 0.2181,
      "step": 23868
    },
    {
      "epoch": 2.23203438930941,
      "grad_norm": 1.822265625,
      "learning_rate": 1.6871901615792142e-06,
      "loss": 0.3557,
      "step": 23885
    },
    {
      "epoch": 2.2336230258854313,
      "grad_norm": 3.193359375,
      "learning_rate": 1.6806368490963964e-06,
      "loss": 0.5575,
      "step": 23902
    },
    {
      "epoch": 2.2352116624614524,
      "grad_norm": 1.1455078125,
      "learning_rate": 1.6740937163845244e-06,
      "loss": 0.2196,
      "step": 23919
    },
    {
      "epoch": 2.236800299037473,
      "grad_norm": 1.9814453125,
      "learning_rate": 1.6675607835099766e-06,
      "loss": 0.4103,
      "step": 23936
    },
    {
      "epoch": 2.238388935613494,
      "grad_norm": 0.259521484375,
      "learning_rate": 1.6610380705078478e-06,
      "loss": 0.5132,
      "step": 23953
    },
    {
      "epoch": 2.239977572189515,
      "grad_norm": 1.3046875,
      "learning_rate": 1.654525597381893e-06,
      "loss": 0.2049,
      "step": 23970
    },
    {
      "epoch": 2.241566208765536,
      "grad_norm": 1.9892578125,
      "learning_rate": 1.6480233841044623e-06,
      "loss": 0.3743,
      "step": 23987
    },
    {
      "epoch": 2.243154845341557,
      "grad_norm": 0.50341796875,
      "learning_rate": 1.6415314506164427e-06,
      "loss": 0.4914,
      "step": 24004
    },
    {
      "epoch": 2.244743481917578,
      "grad_norm": 1.142578125,
      "learning_rate": 1.635049816827191e-06,
      "loss": 0.21,
      "step": 24021
    },
    {
      "epoch": 2.2463321184935987,
      "grad_norm": 2.154296875,
      "learning_rate": 1.6285785026144846e-06,
      "loss": 0.4111,
      "step": 24038
    },
    {
      "epoch": 2.24792075506962,
      "grad_norm": 0.46533203125,
      "learning_rate": 1.6221175278244467e-06,
      "loss": 0.459,
      "step": 24055
    },
    {
      "epoch": 2.2495093916456406,
      "grad_norm": 1.154296875,
      "learning_rate": 1.6156669122714913e-06,
      "loss": 0.1916,
      "step": 24072
    },
    {
      "epoch": 2.2510980282216617,
      "grad_norm": 1.5595703125,
      "learning_rate": 1.6092266757382695e-06,
      "loss": 0.3824,
      "step": 24089
    },
    {
      "epoch": 2.2526866647976824,
      "grad_norm": 0.26904296875,
      "learning_rate": 1.602796837975596e-06,
      "loss": 0.4091,
      "step": 24106
    },
    {
      "epoch": 2.2542753013737036,
      "grad_norm": 1.533203125,
      "learning_rate": 1.5963774187023967e-06,
      "loss": 0.2147,
      "step": 24123
    },
    {
      "epoch": 2.2558639379497243,
      "grad_norm": 2.265625,
      "learning_rate": 1.5899684376056434e-06,
      "loss": 0.4019,
      "step": 24140
    },
    {
      "epoch": 2.2574525745257454,
      "grad_norm": 0.309326171875,
      "learning_rate": 1.5835699143403038e-06,
      "loss": 0.3735,
      "step": 24157
    },
    {
      "epoch": 2.259041211101766,
      "grad_norm": 1.2314453125,
      "learning_rate": 1.5771818685292662e-06,
      "loss": 0.2537,
      "step": 24174
    },
    {
      "epoch": 2.2606298476777873,
      "grad_norm": 1.890625,
      "learning_rate": 1.5708043197632882e-06,
      "loss": 0.4169,
      "step": 24191
    },
    {
      "epoch": 2.262218484253808,
      "grad_norm": 0.64599609375,
      "learning_rate": 1.56443728760094e-06,
      "loss": 0.3825,
      "step": 24208
    },
    {
      "epoch": 2.263807120829829,
      "grad_norm": 1.078125,
      "learning_rate": 1.5580807915685343e-06,
      "loss": 0.2344,
      "step": 24225
    },
    {
      "epoch": 2.26539575740585,
      "grad_norm": 1.9833984375,
      "learning_rate": 1.5517348511600734e-06,
      "loss": 0.3999,
      "step": 24242
    },
    {
      "epoch": 2.266984393981871,
      "grad_norm": 0.89697265625,
      "learning_rate": 1.5453994858371885e-06,
      "loss": 0.3659,
      "step": 24259
    },
    {
      "epoch": 2.2685730305578917,
      "grad_norm": 1.2900390625,
      "learning_rate": 1.539074715029078e-06,
      "loss": 0.2487,
      "step": 24276
    },
    {
      "epoch": 2.270161667133913,
      "grad_norm": 2.375,
      "learning_rate": 1.5327605581324506e-06,
      "loss": 0.4891,
      "step": 24293
    },
    {
      "epoch": 2.2717503037099336,
      "grad_norm": 1.0078125,
      "learning_rate": 1.5264570345114642e-06,
      "loss": 0.4288,
      "step": 24310
    },
    {
      "epoch": 2.2733389402859547,
      "grad_norm": 1.7470703125,
      "learning_rate": 1.5201641634976638e-06,
      "loss": 0.3486,
      "step": 24327
    },
    {
      "epoch": 2.2749275768619754,
      "grad_norm": 2.38671875,
      "learning_rate": 1.5138819643899323e-06,
      "loss": 0.464,
      "step": 24344
    },
    {
      "epoch": 2.2765162134379966,
      "grad_norm": 0.724609375,
      "learning_rate": 1.5076104564544158e-06,
      "loss": 0.3386,
      "step": 24361
    },
    {
      "epoch": 2.2781048500140173,
      "grad_norm": 1.7314453125,
      "learning_rate": 1.5013496589244774e-06,
      "loss": 0.3278,
      "step": 24378
    },
    {
      "epoch": 2.2796934865900385,
      "grad_norm": 2.2734375,
      "learning_rate": 1.4950995910006344e-06,
      "loss": 0.5168,
      "step": 24395
    },
    {
      "epoch": 2.281282123166059,
      "grad_norm": 1.09375,
      "learning_rate": 1.488860271850497e-06,
      "loss": 0.3586,
      "step": 24412
    },
    {
      "epoch": 2.2828707597420803,
      "grad_norm": 1.49609375,
      "learning_rate": 1.48263172060871e-06,
      "loss": 0.3031,
      "step": 24429
    },
    {
      "epoch": 2.284459396318101,
      "grad_norm": 2.712890625,
      "learning_rate": 1.4764139563768964e-06,
      "loss": 0.4844,
      "step": 24446
    },
    {
      "epoch": 2.286048032894122,
      "grad_norm": 0.94873046875,
      "learning_rate": 1.4702069982236018e-06,
      "loss": 0.2999,
      "step": 24463
    },
    {
      "epoch": 2.287636669470143,
      "grad_norm": 1.70703125,
      "learning_rate": 1.464010865184225e-06,
      "loss": 0.3324,
      "step": 24480
    },
    {
      "epoch": 2.289225306046164,
      "grad_norm": 2.3046875,
      "learning_rate": 1.4578255762609711e-06,
      "loss": 0.4929,
      "step": 24497
    },
    {
      "epoch": 2.2908139426221847,
      "grad_norm": 0.86181640625,
      "learning_rate": 1.451651150422786e-06,
      "loss": 0.2946,
      "step": 24514
    },
    {
      "epoch": 2.292402579198206,
      "grad_norm": 1.62109375,
      "learning_rate": 1.4454876066053043e-06,
      "loss": 0.3216,
      "step": 24531
    },
    {
      "epoch": 2.2939912157742266,
      "grad_norm": 2.9453125,
      "learning_rate": 1.4393349637107845e-06,
      "loss": 0.5391,
      "step": 24548
    },
    {
      "epoch": 2.2955798523502478,
      "grad_norm": 1.08984375,
      "learning_rate": 1.4331932406080557e-06,
      "loss": 0.2877,
      "step": 24565
    },
    {
      "epoch": 2.2971684889262685,
      "grad_norm": 1.392578125,
      "learning_rate": 1.427062456132458e-06,
      "loss": 0.354,
      "step": 24582
    },
    {
      "epoch": 2.2987571255022896,
      "grad_norm": 2.52734375,
      "learning_rate": 1.4209426290857858e-06,
      "loss": 0.4732,
      "step": 24599
    },
    {
      "epoch": 2.3003457620783103,
      "grad_norm": 0.7890625,
      "learning_rate": 1.414833778236228e-06,
      "loss": 0.2606,
      "step": 24616
    },
    {
      "epoch": 2.3019343986543315,
      "grad_norm": 1.787109375,
      "learning_rate": 1.4087359223183116e-06,
      "loss": 0.3511,
      "step": 24633
    },
    {
      "epoch": 2.303523035230352,
      "grad_norm": 2.455078125,
      "learning_rate": 1.402649080032849e-06,
      "loss": 0.5147,
      "step": 24650
    },
    {
      "epoch": 2.3051116718063733,
      "grad_norm": 1.203125,
      "learning_rate": 1.396573270046871e-06,
      "loss": 0.2209,
      "step": 24667
    },
    {
      "epoch": 2.306700308382394,
      "grad_norm": 1.8564453125,
      "learning_rate": 1.3905085109935767e-06,
      "loss": 0.3717,
      "step": 24684
    },
    {
      "epoch": 2.308288944958415,
      "grad_norm": 2.7578125,
      "learning_rate": 1.3844548214722725e-06,
      "loss": 0.4888,
      "step": 24701
    },
    {
      "epoch": 2.309877581534436,
      "grad_norm": 1.310546875,
      "learning_rate": 1.3784122200483218e-06,
      "loss": 0.2728,
      "step": 24718
    },
    {
      "epoch": 2.311466218110457,
      "grad_norm": 2.005859375,
      "learning_rate": 1.3723807252530785e-06,
      "loss": 0.4035,
      "step": 24735
    },
    {
      "epoch": 2.3130548546864778,
      "grad_norm": 3.478515625,
      "learning_rate": 1.366360355583835e-06,
      "loss": 0.5416,
      "step": 24752
    },
    {
      "epoch": 2.314643491262499,
      "grad_norm": 1.0966796875,
      "learning_rate": 1.3603511295037697e-06,
      "loss": 0.2277,
      "step": 24769
    },
    {
      "epoch": 2.3162321278385196,
      "grad_norm": 1.732421875,
      "learning_rate": 1.3543530654418818e-06,
      "loss": 0.3535,
      "step": 24786
    },
    {
      "epoch": 2.3178207644145408,
      "grad_norm": 0.328125,
      "learning_rate": 1.34836618179294e-06,
      "loss": 0.5328,
      "step": 24803
    },
    {
      "epoch": 2.3194094009905615,
      "grad_norm": 0.857421875,
      "learning_rate": 1.3423904969174234e-06,
      "loss": 0.1609,
      "step": 24820
    },
    {
      "epoch": 2.3209980375665826,
      "grad_norm": 1.9580078125,
      "learning_rate": 1.3364260291414726e-06,
      "loss": 0.3759,
      "step": 24837
    },
    {
      "epoch": 2.3225866741426033,
      "grad_norm": 0.5048828125,
      "learning_rate": 1.3304727967568227e-06,
      "loss": 0.4999,
      "step": 24854
    },
    {
      "epoch": 2.3241753107186245,
      "grad_norm": 1.34765625,
      "learning_rate": 1.3245308180207527e-06,
      "loss": 0.2139,
      "step": 24871
    },
    {
      "epoch": 2.325763947294645,
      "grad_norm": 1.73828125,
      "learning_rate": 1.3186001111560303e-06,
      "loss": 0.3929,
      "step": 24888
    },
    {
      "epoch": 2.3273525838706663,
      "grad_norm": 1.0234375,
      "learning_rate": 1.3126806943508546e-06,
      "loss": 0.4683,
      "step": 24905
    },
    {
      "epoch": 2.328941220446687,
      "grad_norm": 1.73046875,
      "learning_rate": 1.3067725857588004e-06,
      "loss": 0.2215,
      "step": 24922
    },
    {
      "epoch": 2.330529857022708,
      "grad_norm": 2.005859375,
      "learning_rate": 1.3008758034987606e-06,
      "loss": 0.403,
      "step": 24939
    },
    {
      "epoch": 2.332118493598729,
      "grad_norm": 0.1868896484375,
      "learning_rate": 1.294990365654899e-06,
      "loss": 0.4652,
      "step": 24956
    },
    {
      "epoch": 2.33370713017475,
      "grad_norm": 1.3193359375,
      "learning_rate": 1.2891162902765813e-06,
      "loss": 0.2471,
      "step": 24973
    },
    {
      "epoch": 2.3352957667507708,
      "grad_norm": 1.8740234375,
      "learning_rate": 1.2832535953783304e-06,
      "loss": 0.3781,
      "step": 24990
    },
    {
      "epoch": 2.336884403326792,
      "grad_norm": 0.576171875,
      "learning_rate": 1.2774022989397667e-06,
      "loss": 0.4123,
      "step": 25007
    },
    {
      "epoch": 2.3384730399028126,
      "grad_norm": 1.298828125,
      "learning_rate": 1.2715624189055558e-06,
      "loss": 0.2833,
      "step": 25024
    },
    {
      "epoch": 2.340061676478834,
      "grad_norm": 2.072265625,
      "learning_rate": 1.2657339731853502e-06,
      "loss": 0.3912,
      "step": 25041
    },
    {
      "epoch": 2.3416503130548545,
      "grad_norm": 0.7421875,
      "learning_rate": 1.2599169796537342e-06,
      "loss": 0.4017,
      "step": 25058
    },
    {
      "epoch": 2.3432389496308756,
      "grad_norm": 1.3740234375,
      "learning_rate": 1.254111456150175e-06,
      "loss": 0.2708,
      "step": 25075
    },
    {
      "epoch": 2.344827586206897,
      "grad_norm": 2.4453125,
      "learning_rate": 1.24831742047896e-06,
      "loss": 0.4912,
      "step": 25092
    },
    {
      "epoch": 2.3464162227829175,
      "grad_norm": 0.84033203125,
      "learning_rate": 1.2425348904091473e-06,
      "loss": 0.3916,
      "step": 25109
    },
    {
      "epoch": 2.348004859358938,
      "grad_norm": 1.6962890625,
      "learning_rate": 1.2367638836745077e-06,
      "loss": 0.2786,
      "step": 25126
    },
    {
      "epoch": 2.3495934959349594,
      "grad_norm": 2.85546875,
      "learning_rate": 1.2310044179734776e-06,
      "loss": 0.4657,
      "step": 25143
    },
    {
      "epoch": 2.3511821325109805,
      "grad_norm": 0.84765625,
      "learning_rate": 1.2252565109690946e-06,
      "loss": 0.3678,
      "step": 25160
    },
    {
      "epoch": 2.3527707690870012,
      "grad_norm": 1.5625,
      "learning_rate": 1.2195201802889501e-06,
      "loss": 0.2962,
      "step": 25177
    },
    {
      "epoch": 2.354359405663022,
      "grad_norm": 2.7421875,
      "learning_rate": 1.2137954435251331e-06,
      "loss": 0.4725,
      "step": 25194
    },
    {
      "epoch": 2.355948042239043,
      "grad_norm": 1.0595703125,
      "learning_rate": 1.2080823182341766e-06,
      "loss": 0.3618,
      "step": 25211
    },
    {
      "epoch": 2.3575366788150642,
      "grad_norm": 2.029296875,
      "learning_rate": 1.2023808219370043e-06,
      "loss": 0.3465,
      "step": 25228
    },
    {
      "epoch": 2.359125315391085,
      "grad_norm": 2.619140625,
      "learning_rate": 1.1966909721188734e-06,
      "loss": 0.514,
      "step": 25245
    },
    {
      "epoch": 2.3607139519671057,
      "grad_norm": 1.0732421875,
      "learning_rate": 1.1910127862293303e-06,
      "loss": 0.355,
      "step": 25262
    },
    {
      "epoch": 2.362302588543127,
      "grad_norm": 1.3955078125,
      "learning_rate": 1.1853462816821442e-06,
      "loss": 0.3111,
      "step": 25279
    },
    {
      "epoch": 2.363891225119148,
      "grad_norm": 2.68359375,
      "learning_rate": 1.1796914758552625e-06,
      "loss": 0.4742,
      "step": 25296
    },
    {
      "epoch": 2.3654798616951687,
      "grad_norm": 0.9111328125,
      "learning_rate": 1.1740483860907548e-06,
      "loss": 0.3287,
      "step": 25313
    },
    {
      "epoch": 2.3670684982711894,
      "grad_norm": 1.4267578125,
      "learning_rate": 1.1684170296947622e-06,
      "loss": 0.2438,
      "step": 25330
    },
    {
      "epoch": 2.3686571348472105,
      "grad_norm": 2.50390625,
      "learning_rate": 1.1627974239374395e-06,
      "loss": 0.4336,
      "step": 25347
    },
    {
      "epoch": 2.3702457714232317,
      "grad_norm": 1.1201171875,
      "learning_rate": 1.1571895860529053e-06,
      "loss": 0.3123,
      "step": 25364
    },
    {
      "epoch": 2.3718344079992524,
      "grad_norm": 1.8837890625,
      "learning_rate": 1.1515935332391882e-06,
      "loss": 0.3027,
      "step": 25381
    },
    {
      "epoch": 2.3734230445752735,
      "grad_norm": 2.4765625,
      "learning_rate": 1.146009282658177e-06,
      "loss": 0.5146,
      "step": 25398
    },
    {
      "epoch": 2.3750116811512942,
      "grad_norm": 1.0986328125,
      "learning_rate": 1.1404368514355641e-06,
      "loss": 0.2726,
      "step": 25415
    },
    {
      "epoch": 2.3766003177273154,
      "grad_norm": 1.6064453125,
      "learning_rate": 1.1348762566607918e-06,
      "loss": 0.3552,
      "step": 25432
    },
    {
      "epoch": 2.378188954303336,
      "grad_norm": 2.85546875,
      "learning_rate": 1.1293275153870086e-06,
      "loss": 0.5443,
      "step": 25449
    },
    {
      "epoch": 2.3797775908793573,
      "grad_norm": 0.970703125,
      "learning_rate": 1.1237906446310053e-06,
      "loss": 0.2319,
      "step": 25466
    },
    {
      "epoch": 2.381366227455378,
      "grad_norm": 1.73828125,
      "learning_rate": 1.1182656613731712e-06,
      "loss": 0.3379,
      "step": 25483
    },
    {
      "epoch": 2.382954864031399,
      "grad_norm": 3.130859375,
      "learning_rate": 1.1127525825574382e-06,
      "loss": 0.4706,
      "step": 25500
    },
    {
      "epoch": 2.38454350060742,
      "grad_norm": 1.20703125,
      "learning_rate": 1.1072514250912297e-06,
      "loss": 0.2172,
      "step": 25517
    },
    {
      "epoch": 2.386132137183441,
      "grad_norm": 1.8994140625,
      "learning_rate": 1.1017622058454092e-06,
      "loss": 0.3183,
      "step": 25534
    },
    {
      "epoch": 2.3877207737594617,
      "grad_norm": 2.796875,
      "learning_rate": 1.0962849416542293e-06,
      "loss": 0.5481,
      "step": 25551
    },
    {
      "epoch": 2.389309410335483,
      "grad_norm": 1.0546875,
      "learning_rate": 1.0908196493152763e-06,
      "loss": 0.211,
      "step": 25568
    },
    {
      "epoch": 2.3908980469115035,
      "grad_norm": 2.13671875,
      "learning_rate": 1.0853663455894248e-06,
      "loss": 0.364,
      "step": 25585
    },
    {
      "epoch": 2.3924866834875247,
      "grad_norm": 3.435546875,
      "learning_rate": 1.0799250472007817e-06,
      "loss": 0.5499,
      "step": 25602
    },
    {
      "epoch": 2.3940753200635454,
      "grad_norm": 0.85400390625,
      "learning_rate": 1.0744957708366332e-06,
      "loss": 0.1719,
      "step": 25619
    },
    {
      "epoch": 2.3956639566395665,
      "grad_norm": 1.62890625,
      "learning_rate": 1.0690785331474024e-06,
      "loss": 0.34,
      "step": 25636
    },
    {
      "epoch": 2.3972525932155873,
      "grad_norm": 0.5185546875,
      "learning_rate": 1.0636733507465873e-06,
      "loss": 0.5067,
      "step": 25653
    },
    {
      "epoch": 2.3988412297916084,
      "grad_norm": 1.220703125,
      "learning_rate": 1.0582802402107168e-06,
      "loss": 0.245,
      "step": 25670
    },
    {
      "epoch": 2.4001495187365665,
      "eval_loss": 0.37205854058265686,
      "eval_runtime": 1038.4633,
      "eval_samples_per_second": 7.728,
      "eval_steps_per_second": 2.576,
      "step": 25684
    },
    {
      "epoch": 2.400429866367629,
      "grad_norm": 2.328125,
      "learning_rate": 1.0528992180792963e-06,
      "loss": 0.3937,
      "step": 25687
    },
    {
      "epoch": 2.4020185029436503,
      "grad_norm": 0.4306640625,
      "learning_rate": 1.0475303008547633e-06,
      "loss": 0.4498,
      "step": 25704
    },
    {
      "epoch": 2.403607139519671,
      "grad_norm": 1.0849609375,
      "learning_rate": 1.0421735050024273e-06,
      "loss": 0.2211,
      "step": 25721
    },
    {
      "epoch": 2.405195776095692,
      "grad_norm": 1.76171875,
      "learning_rate": 1.0368288469504262e-06,
      "loss": 0.387,
      "step": 25738
    },
    {
      "epoch": 2.406784412671713,
      "grad_norm": 0.3984375,
      "learning_rate": 1.0314963430896724e-06,
      "loss": 0.4416,
      "step": 25755
    },
    {
      "epoch": 2.408373049247734,
      "grad_norm": 1.3046875,
      "learning_rate": 1.0261760097738083e-06,
      "loss": 0.2103,
      "step": 25772
    },
    {
      "epoch": 2.4099616858237547,
      "grad_norm": 2.134765625,
      "learning_rate": 1.0208678633191466e-06,
      "loss": 0.42,
      "step": 25789
    },
    {
      "epoch": 2.411550322399776,
      "grad_norm": 0.3193359375,
      "learning_rate": 1.0155719200046283e-06,
      "loss": 0.3982,
      "step": 25806
    },
    {
      "epoch": 2.4131389589757966,
      "grad_norm": 1.353515625,
      "learning_rate": 1.0102881960717692e-06,
      "loss": 0.2417,
      "step": 25823
    },
    {
      "epoch": 2.4147275955518177,
      "grad_norm": 2.033203125,
      "learning_rate": 1.0050167077246115e-06,
      "loss": 0.4712,
      "step": 25840
    },
    {
      "epoch": 2.4163162321278384,
      "grad_norm": 0.615234375,
      "learning_rate": 9.997574711296726e-07,
      "loss": 0.4201,
      "step": 25857
    },
    {
      "epoch": 2.4179048687038596,
      "grad_norm": 1.376953125,
      "learning_rate": 9.945105024158963e-07,
      "loss": 0.2801,
      "step": 25874
    },
    {
      "epoch": 2.4194935052798803,
      "grad_norm": 2.388671875,
      "learning_rate": 9.892758176746059e-07,
      "loss": 0.437,
      "step": 25891
    },
    {
      "epoch": 2.4210821418559014,
      "grad_norm": 0.611328125,
      "learning_rate": 9.840534329594504e-07,
      "loss": 0.3468,
      "step": 25908
    },
    {
      "epoch": 2.422670778431922,
      "grad_norm": 1.8095703125,
      "learning_rate": 9.788433642863548e-07,
      "loss": 0.278,
      "step": 25925
    },
    {
      "epoch": 2.4242594150079433,
      "grad_norm": 2.0,
      "learning_rate": 9.736456276334804e-07,
      "loss": 0.4099,
      "step": 25942
    },
    {
      "epoch": 2.425848051583964,
      "grad_norm": 0.70458984375,
      "learning_rate": 9.68460238941162e-07,
      "loss": 0.3603,
      "step": 25959
    },
    {
      "epoch": 2.427436688159985,
      "grad_norm": 1.6630859375,
      "learning_rate": 9.632872141118689e-07,
      "loss": 0.3364,
      "step": 25976
    },
    {
      "epoch": 2.429025324736006,
      "grad_norm": 2.146484375,
      "learning_rate": 9.581265690101516e-07,
      "loss": 0.4925,
      "step": 25993
    },
    {
      "epoch": 2.430613961312027,
      "grad_norm": 0.7421875,
      "learning_rate": 9.529783194625975e-07,
      "loss": 0.3648,
      "step": 26010
    },
    {
      "epoch": 2.4322025978880477,
      "grad_norm": 1.5185546875,
      "learning_rate": 9.478424812577774e-07,
      "loss": 0.289,
      "step": 26027
    },
    {
      "epoch": 2.433791234464069,
      "grad_norm": 2.103515625,
      "learning_rate": 9.427190701461991e-07,
      "loss": 0.4628,
      "step": 26044
    },
    {
      "epoch": 2.4353798710400896,
      "grad_norm": 0.822265625,
      "learning_rate": 9.376081018402594e-07,
      "loss": 0.3905,
      "step": 26061
    },
    {
      "epoch": 2.4369685076161107,
      "grad_norm": 1.6953125,
      "learning_rate": 9.325095920141958e-07,
      "loss": 0.2883,
      "step": 26078
    },
    {
      "epoch": 2.4385571441921314,
      "grad_norm": 2.38671875,
      "learning_rate": 9.27423556304039e-07,
      "loss": 0.4591,
      "step": 26095
    },
    {
      "epoch": 2.4401457807681526,
      "grad_norm": 0.97021484375,
      "learning_rate": 9.223500103075622e-07,
      "loss": 0.3283,
      "step": 26112
    },
    {
      "epoch": 2.4417344173441733,
      "grad_norm": 1.5224609375,
      "learning_rate": 9.172889695842391e-07,
      "loss": 0.3022,
      "step": 26129
    },
    {
      "epoch": 2.4433230539201944,
      "grad_norm": 2.26171875,
      "learning_rate": 9.12240449655189e-07,
      "loss": 0.428,
      "step": 26146
    },
    {
      "epoch": 2.444911690496215,
      "grad_norm": 1.1318359375,
      "learning_rate": 9.072044660031337e-07,
      "loss": 0.3106,
      "step": 26163
    },
    {
      "epoch": 2.4465003270722363,
      "grad_norm": 1.95703125,
      "learning_rate": 9.021810340723486e-07,
      "loss": 0.2871,
      "step": 26180
    },
    {
      "epoch": 2.448088963648257,
      "grad_norm": 2.46875,
      "learning_rate": 8.971701692686174e-07,
      "loss": 0.4699,
      "step": 26197
    },
    {
      "epoch": 2.449677600224278,
      "grad_norm": 0.7841796875,
      "learning_rate": 8.921718869591812e-07,
      "loss": 0.2823,
      "step": 26214
    },
    {
      "epoch": 2.451266236800299,
      "grad_norm": 1.650390625,
      "learning_rate": 8.871862024726935e-07,
      "loss": 0.3088,
      "step": 26231
    },
    {
      "epoch": 2.45285487337632,
      "grad_norm": 2.435546875,
      "learning_rate": 8.822131310991727e-07,
      "loss": 0.4889,
      "step": 26248
    },
    {
      "epoch": 2.4544435099523407,
      "grad_norm": 0.953125,
      "learning_rate": 8.77252688089959e-07,
      "loss": 0.248,
      "step": 26265
    },
    {
      "epoch": 2.456032146528362,
      "grad_norm": 1.6240234375,
      "learning_rate": 8.723048886576591e-07,
      "loss": 0.3314,
      "step": 26282
    },
    {
      "epoch": 2.4576207831043826,
      "grad_norm": 2.7265625,
      "learning_rate": 8.673697479761067e-07,
      "loss": 0.543,
      "step": 26299
    },
    {
      "epoch": 2.4592094196804037,
      "grad_norm": 1.072265625,
      "learning_rate": 8.624472811803158e-07,
      "loss": 0.2399,
      "step": 26316
    },
    {
      "epoch": 2.4607980562564244,
      "grad_norm": 1.705078125,
      "learning_rate": 8.57537503366429e-07,
      "loss": 0.3484,
      "step": 26333
    },
    {
      "epoch": 2.4623866928324456,
      "grad_norm": 3.4921875,
      "learning_rate": 8.526404295916768e-07,
      "loss": 0.5199,
      "step": 26350
    },
    {
      "epoch": 2.4639753294084663,
      "grad_norm": 1.2724609375,
      "learning_rate": 8.47756074874328e-07,
      "loss": 0.2423,
      "step": 26367
    },
    {
      "epoch": 2.4655639659844875,
      "grad_norm": 2.154296875,
      "learning_rate": 8.428844541936454e-07,
      "loss": 0.3612,
      "step": 26384
    },
    {
      "epoch": 2.4671526025605086,
      "grad_norm": 3.4453125,
      "learning_rate": 8.380255824898386e-07,
      "loss": 0.4926,
      "step": 26401
    },
    {
      "epoch": 2.4687412391365293,
      "grad_norm": 1.32421875,
      "learning_rate": 8.331794746640193e-07,
      "loss": 0.2056,
      "step": 26418
    },
    {
      "epoch": 2.47032987571255,
      "grad_norm": 1.748046875,
      "learning_rate": 8.283461455781544e-07,
      "loss": 0.3704,
      "step": 26435
    },
    {
      "epoch": 2.471918512288571,
      "grad_norm": 3.302734375,
      "learning_rate": 8.235256100550243e-07,
      "loss": 0.5237,
      "step": 26452
    },
    {
      "epoch": 2.4735071488645923,
      "grad_norm": 1.35546875,
      "learning_rate": 8.1871788287817e-07,
      "loss": 0.1733,
      "step": 26469
    },
    {
      "epoch": 2.475095785440613,
      "grad_norm": 1.599609375,
      "learning_rate": 8.139229787918535e-07,
      "loss": 0.3517,
      "step": 26486
    },
    {
      "epoch": 2.4766844220166337,
      "grad_norm": 0.763671875,
      "learning_rate": 8.09140912501013e-07,
      "loss": 0.4688,
      "step": 26503
    },
    {
      "epoch": 2.478273058592655,
      "grad_norm": 1.3134765625,
      "learning_rate": 8.043716986712147e-07,
      "loss": 0.2167,
      "step": 26520
    },
    {
      "epoch": 2.479861695168676,
      "grad_norm": 1.7451171875,
      "learning_rate": 7.996153519286077e-07,
      "loss": 0.3953,
      "step": 26537
    },
    {
      "epoch": 2.4814503317446968,
      "grad_norm": 0.442626953125,
      "learning_rate": 7.948718868598809e-07,
      "loss": 0.5129,
      "step": 26554
    },
    {
      "epoch": 2.4830389683207175,
      "grad_norm": 1.39453125,
      "learning_rate": 7.901413180122213e-07,
      "loss": 0.2105,
      "step": 26571
    },
    {
      "epoch": 2.4846276048967386,
      "grad_norm": 2.060546875,
      "learning_rate": 7.854236598932624e-07,
      "loss": 0.3435,
      "step": 26588
    },
    {
      "epoch": 2.4862162414727598,
      "grad_norm": 0.09320068359375,
      "learning_rate": 7.807189269710424e-07,
      "loss": 0.4297,
      "step": 26605
    },
    {
      "epoch": 2.4878048780487805,
      "grad_norm": 1.3720703125,
      "learning_rate": 7.760271336739655e-07,
      "loss": 0.2476,
      "step": 26622
    },
    {
      "epoch": 2.489393514624801,
      "grad_norm": 2.0,
      "learning_rate": 7.713482943907491e-07,
      "loss": 0.323,
      "step": 26639
    },
    {
      "epoch": 2.4909821512008223,
      "grad_norm": 0.273193359375,
      "learning_rate": 7.666824234703829e-07,
      "loss": 0.4596,
      "step": 26656
    },
    {
      "epoch": 2.4925707877768435,
      "grad_norm": 1.2314453125,
      "learning_rate": 7.62029535222088e-07,
      "loss": 0.2448,
      "step": 26673
    },
    {
      "epoch": 2.494159424352864,
      "grad_norm": 2.48828125,
      "learning_rate": 7.573896439152689e-07,
      "loss": 0.422,
      "step": 26690
    },
    {
      "epoch": 2.495748060928885,
      "grad_norm": 0.3837890625,
      "learning_rate": 7.527627637794715e-07,
      "loss": 0.3904,
      "step": 26707
    },
    {
      "epoch": 2.497336697504906,
      "grad_norm": 1.3037109375,
      "learning_rate": 7.481489090043392e-07,
      "loss": 0.2586,
      "step": 26724
    },
    {
      "epoch": 2.498925334080927,
      "grad_norm": 2.13671875,
      "learning_rate": 7.43548093739569e-07,
      "loss": 0.4122,
      "step": 26741
    },
    {
      "epoch": 2.500513970656948,
      "grad_norm": 0.84423828125,
      "learning_rate": 7.389603320948713e-07,
      "loss": 0.4359,
      "step": 26758
    },
    {
      "epoch": 2.5021026072329686,
      "grad_norm": 1.5791015625,
      "learning_rate": 7.3438563813992e-07,
      "loss": 0.2243,
      "step": 26775
    },
    {
      "epoch": 2.5036912438089898,
      "grad_norm": 2.09765625,
      "learning_rate": 7.298240259043143e-07,
      "loss": 0.4051,
      "step": 26792
    },
    {
      "epoch": 2.505279880385011,
      "grad_norm": 0.69287109375,
      "learning_rate": 7.252755093775377e-07,
      "loss": 0.3584,
      "step": 26809
    },
    {
      "epoch": 2.5068685169610316,
      "grad_norm": 1.3369140625,
      "learning_rate": 7.207401025089073e-07,
      "loss": 0.272,
      "step": 26826
    },
    {
      "epoch": 2.5084571535370523,
      "grad_norm": 2.330078125,
      "learning_rate": 7.162178192075386e-07,
      "loss": 0.4957,
      "step": 26843
    },
    {
      "epoch": 2.5100457901130735,
      "grad_norm": 0.68994140625,
      "learning_rate": 7.117086733422984e-07,
      "loss": 0.3953,
      "step": 26860
    },
    {
      "epoch": 2.5116344266890946,
      "grad_norm": 1.9287109375,
      "learning_rate": 7.07212678741766e-07,
      "loss": 0.3241,
      "step": 26877
    },
    {
      "epoch": 2.5132230632651154,
      "grad_norm": 2.607421875,
      "learning_rate": 7.027298491941875e-07,
      "loss": 0.5153,
      "step": 26894
    },
    {
      "epoch": 2.5148116998411365,
      "grad_norm": 0.96484375,
      "learning_rate": 6.98260198447433e-07,
      "loss": 0.3487,
      "step": 26911
    },
    {
      "epoch": 2.516400336417157,
      "grad_norm": 1.564453125,
      "learning_rate": 6.938037402089565e-07,
      "loss": 0.3077,
      "step": 26928
    },
    {
      "epoch": 2.5179889729931784,
      "grad_norm": 2.181640625,
      "learning_rate": 6.893604881457577e-07,
      "loss": 0.4749,
      "step": 26945
    },
    {
      "epoch": 2.519577609569199,
      "grad_norm": 1.0615234375,
      "learning_rate": 6.849304558843301e-07,
      "loss": 0.292,
      "step": 26962
    },
    {
      "epoch": 2.5211662461452202,
      "grad_norm": 1.7216796875,
      "learning_rate": 6.80513657010628e-07,
      "loss": 0.3386,
      "step": 26979
    },
    {
      "epoch": 2.522754882721241,
      "grad_norm": 2.203125,
      "learning_rate": 6.761101050700208e-07,
      "loss": 0.4337,
      "step": 26996
    },
    {
      "epoch": 2.524343519297262,
      "grad_norm": 0.85986328125,
      "learning_rate": 6.717198135672526e-07,
      "loss": 0.3257,
      "step": 27013
    },
    {
      "epoch": 2.525932155873283,
      "grad_norm": 1.517578125,
      "learning_rate": 6.673427959664008e-07,
      "loss": 0.3119,
      "step": 27030
    },
    {
      "epoch": 2.527520792449304,
      "grad_norm": 2.765625,
      "learning_rate": 6.62979065690833e-07,
      "loss": 0.4684,
      "step": 27047
    },
    {
      "epoch": 2.5291094290253247,
      "grad_norm": 1.005859375,
      "learning_rate": 6.58628636123172e-07,
      "loss": 0.2586,
      "step": 27064
    },
    {
      "epoch": 2.530698065601346,
      "grad_norm": 1.5869140625,
      "learning_rate": 6.542915206052452e-07,
      "loss": 0.3029,
      "step": 27081
    },
    {
      "epoch": 2.5322867021773665,
      "grad_norm": 2.5234375,
      "learning_rate": 6.499677324380505e-07,
      "loss": 0.4766,
      "step": 27098
    },
    {
      "epoch": 2.5338753387533877,
      "grad_norm": 1.2197265625,
      "learning_rate": 6.456572848817128e-07,
      "loss": 0.2785,
      "step": 27115
    },
    {
      "epoch": 2.5354639753294084,
      "grad_norm": 1.8056640625,
      "learning_rate": 6.413601911554479e-07,
      "loss": 0.3685,
      "step": 27132
    },
    {
      "epoch": 2.5370526119054295,
      "grad_norm": 2.361328125,
      "learning_rate": 6.370764644375138e-07,
      "loss": 0.4899,
      "step": 27149
    },
    {
      "epoch": 2.5386412484814502,
      "grad_norm": 0.970703125,
      "learning_rate": 6.328061178651756e-07,
      "loss": 0.2612,
      "step": 27166
    },
    {
      "epoch": 2.5402298850574714,
      "grad_norm": 1.744140625,
      "learning_rate": 6.285491645346681e-07,
      "loss": 0.3439,
      "step": 27183
    },
    {
      "epoch": 2.541818521633492,
      "grad_norm": 2.79296875,
      "learning_rate": 6.243056175011475e-07,
      "loss": 0.5622,
      "step": 27200
    },
    {
      "epoch": 2.5434071582095132,
      "grad_norm": 0.9140625,
      "learning_rate": 6.200754897786571e-07,
      "loss": 0.2465,
      "step": 27217
    },
    {
      "epoch": 2.544995794785534,
      "grad_norm": 2.08203125,
      "learning_rate": 6.158587943400857e-07,
      "loss": 0.3734,
      "step": 27234
    },
    {
      "epoch": 2.546584431361555,
      "grad_norm": 2.748046875,
      "learning_rate": 6.116555441171312e-07,
      "loss": 0.519,
      "step": 27251
    },
    {
      "epoch": 2.548173067937576,
      "grad_norm": 0.94873046875,
      "learning_rate": 6.074657520002542e-07,
      "loss": 0.2094,
      "step": 27268
    },
    {
      "epoch": 2.549761704513597,
      "grad_norm": 1.6298828125,
      "learning_rate": 6.032894308386433e-07,
      "loss": 0.3632,
      "step": 27285
    },
    {
      "epoch": 2.5513503410896177,
      "grad_norm": 2.9296875,
      "learning_rate": 5.991265934401757e-07,
      "loss": 0.4705,
      "step": 27302
    },
    {
      "epoch": 2.552938977665639,
      "grad_norm": 1.0400390625,
      "learning_rate": 5.949772525713748e-07,
      "loss": 0.2137,
      "step": 27319
    },
    {
      "epoch": 2.5545276142416595,
      "grad_norm": 1.8779296875,
      "learning_rate": 5.908414209573754e-07,
      "loss": 0.3737,
      "step": 27336
    },
    {
      "epoch": 2.5561162508176807,
      "grad_norm": 0.1578369140625,
      "learning_rate": 5.867191112818799e-07,
      "loss": 0.5781,
      "step": 27353
    },
    {
      "epoch": 2.5577048873937014,
      "grad_norm": 1.0830078125,
      "learning_rate": 5.826103361871243e-07,
      "loss": 0.1951,
      "step": 27370
    },
    {
      "epoch": 2.5592935239697225,
      "grad_norm": 1.634765625,
      "learning_rate": 5.785151082738355e-07,
      "loss": 0.3649,
      "step": 27387
    },
    {
      "epoch": 2.5608821605457432,
      "grad_norm": 0.3681640625,
      "learning_rate": 5.744334401011942e-07,
      "loss": 0.4963,
      "step": 27404
    },
    {
      "epoch": 2.5624707971217644,
      "grad_norm": 1.2373046875,
      "learning_rate": 5.703653441867952e-07,
      "loss": 0.2138,
      "step": 27421
    },
    {
      "epoch": 2.564059433697785,
      "grad_norm": 1.744140625,
      "learning_rate": 5.663108330066136e-07,
      "loss": 0.3795,
      "step": 27438
    },
    {
      "epoch": 2.5656480702738063,
      "grad_norm": 0.71728515625,
      "learning_rate": 5.622699189949593e-07,
      "loss": 0.4955,
      "step": 27455
    },
    {
      "epoch": 2.567236706849827,
      "grad_norm": 1.369140625,
      "learning_rate": 5.582426145444442e-07,
      "loss": 0.2688,
      "step": 27472
    },
    {
      "epoch": 2.568825343425848,
      "grad_norm": 2.17578125,
      "learning_rate": 5.542289320059435e-07,
      "loss": 0.4153,
      "step": 27489
    },
    {
      "epoch": 2.570413980001869,
      "grad_norm": 0.2181396484375,
      "learning_rate": 5.502288836885555e-07,
      "loss": 0.448,
      "step": 27506
    },
    {
      "epoch": 2.57200261657789,
      "grad_norm": 1.2568359375,
      "learning_rate": 5.462424818595658e-07,
      "loss": 0.2161,
      "step": 27523
    },
    {
      "epoch": 2.5735912531539107,
      "grad_norm": 2.220703125,
      "learning_rate": 5.422697387444076e-07,
      "loss": 0.4005,
      "step": 27540
    },
    {
      "epoch": 2.575179889729932,
      "grad_norm": 1.0107421875,
      "learning_rate": 5.383106665266302e-07,
      "loss": 0.4431,
      "step": 27557
    },
    {
      "epoch": 2.576768526305953,
      "grad_norm": 1.7705078125,
      "learning_rate": 5.343652773478525e-07,
      "loss": 0.2761,
      "step": 27574
    },
    {
      "epoch": 2.5783571628819737,
      "grad_norm": 2.77734375,
      "learning_rate": 5.304335833077324e-07,
      "loss": 0.3934,
      "step": 27591
    },
    {
      "epoch": 2.5799457994579944,
      "grad_norm": 0.6728515625,
      "learning_rate": 5.265155964639279e-07,
      "loss": 0.3847,
      "step": 27608
    },
    {
      "epoch": 2.5815344360340156,
      "grad_norm": 1.181640625,
      "learning_rate": 5.226113288320594e-07,
      "loss": 0.2277,
      "step": 27625
    },
    {
      "epoch": 2.5831230726100367,
      "grad_norm": 2.22265625,
      "learning_rate": 5.18720792385674e-07,
      "loss": 0.4079,
      "step": 27642
    },
    {
      "epoch": 2.5847117091860574,
      "grad_norm": 0.66552734375,
      "learning_rate": 5.148439990562071e-07,
      "loss": 0.3537,
      "step": 27659
    },
    {
      "epoch": 2.586300345762078,
      "grad_norm": 1.2529296875,
      "learning_rate": 5.109809607329491e-07,
      "loss": 0.2596,
      "step": 27676
    },
    {
      "epoch": 2.5878889823380993,
      "grad_norm": 2.623046875,
      "learning_rate": 5.071316892630057e-07,
      "loss": 0.4441,
      "step": 27693
    },
    {
      "epoch": 2.5894776189141204,
      "grad_norm": 0.8583984375,
      "learning_rate": 5.032961964512611e-07,
      "loss": 0.365,
      "step": 27710
    },
    {
      "epoch": 2.591066255490141,
      "grad_norm": 1.5712890625,
      "learning_rate": 4.994744940603441e-07,
      "loss": 0.3337,
      "step": 27727
    },
    {
      "epoch": 2.592654892066162,
      "grad_norm": 2.615234375,
      "learning_rate": 4.956665938105937e-07,
      "loss": 0.4812,
      "step": 27744
    },
    {
      "epoch": 2.594243528642183,
      "grad_norm": 0.86474609375,
      "learning_rate": 4.91872507380018e-07,
      "loss": 0.3683,
      "step": 27761
    },
    {
      "epoch": 2.595832165218204,
      "grad_norm": 1.88671875,
      "learning_rate": 4.88092246404262e-07,
      "loss": 0.2841,
      "step": 27778
    },
    {
      "epoch": 2.597420801794225,
      "grad_norm": 3.220703125,
      "learning_rate": 4.843258224765696e-07,
      "loss": 0.4264,
      "step": 27795
    },
    {
      "epoch": 2.5990094383702456,
      "grad_norm": 0.70654296875,
      "learning_rate": 4.80573247147752e-07,
      "loss": 0.3358,
      "step": 27812
    },
    {
      "epoch": 2.6005980749462667,
      "grad_norm": 1.505859375,
      "learning_rate": 4.7683453192614915e-07,
      "loss": 0.2913,
      "step": 27829
    },
    {
      "epoch": 2.602186711522288,
      "grad_norm": 2.109375,
      "learning_rate": 4.731096882775921e-07,
      "loss": 0.4875,
      "step": 27846
    },
    {
      "epoch": 2.6037753480983086,
      "grad_norm": 0.76416015625,
      "learning_rate": 4.693987276253753e-07,
      "loss": 0.2789,
      "step": 27863
    },
    {
      "epoch": 2.6053639846743293,
      "grad_norm": 1.5078125,
      "learning_rate": 4.6570166135021354e-07,
      "loss": 0.2678,
      "step": 27880
    },
    {
      "epoch": 2.6069526212503504,
      "grad_norm": 2.955078125,
      "learning_rate": 4.6201850079021283e-07,
      "loss": 0.4295,
      "step": 27897
    },
    {
      "epoch": 2.6085412578263716,
      "grad_norm": 0.9091796875,
      "learning_rate": 4.5834925724083103e-07,
      "loss": 0.2788,
      "step": 27914
    },
    {
      "epoch": 2.6101298944023923,
      "grad_norm": 1.6201171875,
      "learning_rate": 4.546939419548474e-07,
      "loss": 0.31,
      "step": 27931
    },
    {
      "epoch": 2.611718530978413,
      "grad_norm": 2.3984375,
      "learning_rate": 4.5105256614232594e-07,
      "loss": 0.4687,
      "step": 27948
    },
    {
      "epoch": 2.613307167554434,
      "grad_norm": 1.107421875,
      "learning_rate": 4.474251409705804e-07,
      "loss": 0.2975,
      "step": 27965
    },
    {
      "epoch": 2.6148958041304553,
      "grad_norm": 1.6796875,
      "learning_rate": 4.43811677564141e-07,
      "loss": 0.3396,
      "step": 27982
    },
    {
      "epoch": 2.616484440706476,
      "grad_norm": 2.740234375,
      "learning_rate": 4.4021218700472267e-07,
      "loss": 0.5308,
      "step": 27999
    },
    {
      "epoch": 2.6180730772824967,
      "grad_norm": 1.0234375,
      "learning_rate": 4.3662668033118526e-07,
      "loss": 0.2492,
      "step": 28016
    },
    {
      "epoch": 2.619661713858518,
      "grad_norm": 1.4990234375,
      "learning_rate": 4.33055168539504e-07,
      "loss": 0.3133,
      "step": 28033
    },
    {
      "epoch": 2.621250350434539,
      "grad_norm": 2.939453125,
      "learning_rate": 4.294976625827368e-07,
      "loss": 0.4933,
      "step": 28050
    },
    {
      "epoch": 2.6228389870105597,
      "grad_norm": 1.1943359375,
      "learning_rate": 4.2595417337098653e-07,
      "loss": 0.2574,
      "step": 28067
    },
    {
      "epoch": 2.6244276235865804,
      "grad_norm": 1.814453125,
      "learning_rate": 4.224247117713709e-07,
      "loss": 0.3662,
      "step": 28084
    },
    {
      "epoch": 2.6260162601626016,
      "grad_norm": 2.607421875,
      "learning_rate": 4.1890928860798595e-07,
      "loss": 0.4798,
      "step": 28101
    },
    {
      "epoch": 2.6276048967386227,
      "grad_norm": 1.240234375,
      "learning_rate": 4.1540791466187836e-07,
      "loss": 0.2252,
      "step": 28118
    },
    {
      "epoch": 2.6291935333146434,
      "grad_norm": 1.76953125,
      "learning_rate": 4.119206006710064e-07,
      "loss": 0.3351,
      "step": 28135
    },
    {
      "epoch": 2.630782169890664,
      "grad_norm": 3.05078125,
      "learning_rate": 4.0844735733020947e-07,
      "loss": 0.5164,
      "step": 28152
    },
    {
      "epoch": 2.6323708064666853,
      "grad_norm": 1.0087890625,
      "learning_rate": 4.0498819529117604e-07,
      "loss": 0.1738,
      "step": 28169
    },
    {
      "epoch": 2.6339594430427065,
      "grad_norm": 1.7392578125,
      "learning_rate": 4.0154312516241024e-07,
      "loss": 0.3751,
      "step": 28186
    },
    {
      "epoch": 2.635548079618727,
      "grad_norm": 0.41259765625,
      "learning_rate": 3.981121575091995e-07,
      "loss": 0.5438,
      "step": 28203
    },
    {
      "epoch": 2.6371367161947483,
      "grad_norm": 1.064453125,
      "learning_rate": 3.9469530285357994e-07,
      "loss": 0.1758,
      "step": 28220
    },
    {
      "epoch": 2.638725352770769,
      "grad_norm": 1.845703125,
      "learning_rate": 3.9129257167431045e-07,
      "loss": 0.3561,
      "step": 28237
    },
    {
      "epoch": 2.64031398934679,
      "grad_norm": 0.2137451171875,
      "learning_rate": 3.8790397440683245e-07,
      "loss": 0.5005,
      "step": 28254
    },
    {
      "epoch": 2.641902625922811,
      "grad_norm": 1.427734375,
      "learning_rate": 3.8452952144324374e-07,
      "loss": 0.2155,
      "step": 28271
    },
    {
      "epoch": 2.643491262498832,
      "grad_norm": 2.033203125,
      "learning_rate": 3.8116922313226166e-07,
      "loss": 0.4182,
      "step": 28288
    },
    {
      "epoch": 2.6450798990748527,
      "grad_norm": 0.260498046875,
      "learning_rate": 3.7782308977919954e-07,
      "loss": 0.4651,
      "step": 28305
    },
    {
      "epoch": 2.646668535650874,
      "grad_norm": 1.2119140625,
      "learning_rate": 3.7449113164592487e-07,
      "loss": 0.2896,
      "step": 28322
    },
    {
      "epoch": 2.6482571722268946,
      "grad_norm": 2.09765625,
      "learning_rate": 3.7117335895083484e-07,
      "loss": 0.416,
      "step": 28339
    },
    {
      "epoch": 2.6498458088029158,
      "grad_norm": 0.269287109375,
      "learning_rate": 3.6786978186882316e-07,
      "loss": 0.4423,
      "step": 28356
    },
    {
      "epoch": 2.6514344453789365,
      "grad_norm": 1.2568359375,
      "learning_rate": 3.645804105312489e-07,
      "loss": 0.2206,
      "step": 28373
    },
    {
      "epoch": 2.6530230819549576,
      "grad_norm": 2.08203125,
      "learning_rate": 3.6130525502590385e-07,
      "loss": 0.3913,
      "step": 28390
    },
    {
      "epoch": 2.6546117185309783,
      "grad_norm": 0.69970703125,
      "learning_rate": 3.580443253969823e-07,
      "loss": 0.4605,
      "step": 28407
    },
    {
      "epoch": 2.6562003551069995,
      "grad_norm": 1.49609375,
      "learning_rate": 3.547976316450552e-07,
      "loss": 0.3015,
      "step": 28424
    },
    {
      "epoch": 2.65778899168302,
      "grad_norm": 2.0625,
      "learning_rate": 3.515651837270301e-07,
      "loss": 0.4345,
      "step": 28441
    },
    {
      "epoch": 2.6593776282590413,
      "grad_norm": 0.71337890625,
      "learning_rate": 3.483469915561283e-07,
      "loss": 0.3877,
      "step": 28458
    },
    {
      "epoch": 2.660966264835062,
      "grad_norm": 1.6103515625,
      "learning_rate": 3.451430650018506e-07,
      "loss": 0.2591,
      "step": 28475
    },
    {
      "epoch": 2.662554901411083,
      "grad_norm": 2.111328125,
      "learning_rate": 3.419534138899494e-07,
      "loss": 0.4142,
      "step": 28492
    },
    {
      "epoch": 2.664143537987104,
      "grad_norm": 0.810546875,
      "learning_rate": 3.3877804800239666e-07,
      "loss": 0.3787,
      "step": 28509
    },
    {
      "epoch": 2.665732174563125,
      "grad_norm": 1.3720703125,
      "learning_rate": 3.356169770773537e-07,
      "loss": 0.2617,
      "step": 28526
    },
    {
      "epoch": 2.6673208111391458,
      "grad_norm": 2.875,
      "learning_rate": 3.324702108091454e-07,
      "loss": 0.4686,
      "step": 28543
    },
    {
      "epoch": 2.668909447715167,
      "grad_norm": 0.6884765625,
      "learning_rate": 3.2933775884822385e-07,
      "loss": 0.3864,
      "step": 28560
    },
    {
      "epoch": 2.6704980842911876,
      "grad_norm": 1.322265625,
      "learning_rate": 3.262196308011445e-07,
      "loss": 0.2905,
      "step": 28577
    },
    {
      "epoch": 2.6720867208672088,
      "grad_norm": 3.173828125,
      "learning_rate": 3.23115836230532e-07,
      "loss": 0.4564,
      "step": 28594
    },
    {
      "epoch": 2.6736753574432295,
      "grad_norm": 1.009765625,
      "learning_rate": 3.2002638465505664e-07,
      "loss": 0.3679,
      "step": 28611
    },
    {
      "epoch": 2.6752639940192506,
      "grad_norm": 1.2705078125,
      "learning_rate": 3.169512855494e-07,
      "loss": 0.2496,
      "step": 28628
    },
    {
      "epoch": 2.6768526305952713,
      "grad_norm": 2.759765625,
      "learning_rate": 3.1389054834422783e-07,
      "loss": 0.4359,
      "step": 28645
    },
    {
      "epoch": 2.6784412671712925,
      "grad_norm": 0.79052734375,
      "learning_rate": 3.1084418242615935e-07,
      "loss": 0.342,
      "step": 28662
    },
    {
      "epoch": 2.680029903747313,
      "grad_norm": 1.7314453125,
      "learning_rate": 3.078121971377446e-07,
      "loss": 0.3144,
      "step": 28679
    },
    {
      "epoch": 2.6816185403233344,
      "grad_norm": 2.517578125,
      "learning_rate": 3.047946017774267e-07,
      "loss": 0.4595,
      "step": 28696
    },
    {
      "epoch": 2.683207176899355,
      "grad_norm": 0.79443359375,
      "learning_rate": 3.0179140559952025e-07,
      "loss": 0.3398,
      "step": 28713
    },
    {
      "epoch": 2.684795813475376,
      "grad_norm": 1.4482421875,
      "learning_rate": 2.9880261781418063e-07,
      "loss": 0.2898,
      "step": 28730
    },
    {
      "epoch": 2.686384450051397,
      "grad_norm": 2.533203125,
      "learning_rate": 2.958282475873758e-07,
      "loss": 0.5012,
      "step": 28747
    },
    {
      "epoch": 2.687973086627418,
      "grad_norm": 1.0185546875,
      "learning_rate": 2.92868304040857e-07,
      "loss": 0.2721,
      "step": 28764
    },
    {
      "epoch": 2.689561723203439,
      "grad_norm": 2.185546875,
      "learning_rate": 2.899227962521328e-07,
      "loss": 0.3442,
      "step": 28781
    },
    {
      "epoch": 2.69115035977946,
      "grad_norm": 2.26171875,
      "learning_rate": 2.8699173325444085e-07,
      "loss": 0.4724,
      "step": 28798
    },
    {
      "epoch": 2.6927389963554806,
      "grad_norm": 1.025390625,
      "learning_rate": 2.84075124036719e-07,
      "loss": 0.2448,
      "step": 28815
    },
    {
      "epoch": 2.694327632931502,
      "grad_norm": 1.6650390625,
      "learning_rate": 2.8117297754357844e-07,
      "loss": 0.3482,
      "step": 28832
    },
    {
      "epoch": 2.6959162695075225,
      "grad_norm": 2.720703125,
      "learning_rate": 2.782853026752769e-07,
      "loss": 0.5024,
      "step": 28849
    },
    {
      "epoch": 2.6975049060835437,
      "grad_norm": 0.97607421875,
      "learning_rate": 2.7541210828769037e-07,
      "loss": 0.2562,
      "step": 28866
    },
    {
      "epoch": 2.699093542659565,
      "grad_norm": 1.8798828125,
      "learning_rate": 2.7255340319228664e-07,
      "loss": 0.3614,
      "step": 28883
    },
    {
      "epoch": 2.7006821792355855,
      "grad_norm": 2.9765625,
      "learning_rate": 2.6970919615609715e-07,
      "loss": 0.5601,
      "step": 28900
    },
    {
      "epoch": 2.702270815811606,
      "grad_norm": 1.00390625,
      "learning_rate": 2.668794959016929e-07,
      "loss": 0.1943,
      "step": 28917
    },
    {
      "epoch": 2.7038594523876274,
      "grad_norm": 2.087890625,
      "learning_rate": 2.6406431110715334e-07,
      "loss": 0.3106,
      "step": 28934
    },
    {
      "epoch": 2.7054480889636485,
      "grad_norm": 2.826171875,
      "learning_rate": 2.612636504060428e-07,
      "loss": 0.5121,
      "step": 28951
    },
    {
      "epoch": 2.7070367255396692,
      "grad_norm": 1.109375,
      "learning_rate": 2.5847752238738367e-07,
      "loss": 0.2161,
      "step": 28968
    },
    {
      "epoch": 2.70862536211569,
      "grad_norm": 1.4794921875,
      "learning_rate": 2.5570593559563095e-07,
      "loss": 0.3549,
      "step": 28985
    },
    {
      "epoch": 2.710213998691711,
      "grad_norm": 3.0703125,
      "learning_rate": 2.529488985306422e-07,
      "loss": 0.5103,
      "step": 29002
    },
    {
      "epoch": 2.7118026352677322,
      "grad_norm": 1.14453125,
      "learning_rate": 2.502064196476567e-07,
      "loss": 0.1977,
      "step": 29019
    },
    {
      "epoch": 2.713391271843753,
      "grad_norm": 2.13671875,
      "learning_rate": 2.4747850735726444e-07,
      "loss": 0.3898,
      "step": 29036
    },
    {
      "epoch": 2.7149799084197737,
      "grad_norm": 0.426025390625,
      "learning_rate": 2.4476517002538557e-07,
      "loss": 0.5196,
      "step": 29053
    },
    {
      "epoch": 2.716568544995795,
      "grad_norm": 1.14453125,
      "learning_rate": 2.4206641597323997e-07,
      "loss": 0.2476,
      "step": 29070
    },
    {
      "epoch": 2.718157181571816,
      "grad_norm": 2.21484375,
      "learning_rate": 2.393822534773238e-07,
      "loss": 0.3907,
      "step": 29087
    },
    {
      "epoch": 2.7197458181478367,
      "grad_norm": 0.484375,
      "learning_rate": 2.367126907693851e-07,
      "loss": 0.4998,
      "step": 29104
    },
    {
      "epoch": 2.7213344547238574,
      "grad_norm": 1.1025390625,
      "learning_rate": 2.3405773603639715e-07,
      "loss": 0.2086,
      "step": 29121
    },
    {
      "epoch": 2.7229230912998785,
      "grad_norm": 2.490234375,
      "learning_rate": 2.3141739742053304e-07,
      "loss": 0.4109,
      "step": 29138
    },
    {
      "epoch": 2.7245117278758997,
      "grad_norm": 0.48974609375,
      "learning_rate": 2.2879168301914166e-07,
      "loss": 0.4553,
      "step": 29155
    },
    {
      "epoch": 2.7261003644519204,
      "grad_norm": 1.31640625,
      "learning_rate": 2.2618060088472394e-07,
      "loss": 0.2273,
      "step": 29172
    },
    {
      "epoch": 2.727689001027941,
      "grad_norm": 1.7763671875,
      "learning_rate": 2.2358415902490493e-07,
      "loss": 0.3943,
      "step": 29189
    },
    {
      "epoch": 2.7292776376039622,
      "grad_norm": 0.2467041015625,
      "learning_rate": 2.210023654024118e-07,
      "loss": 0.4074,
      "step": 29206
    },
    {
      "epoch": 2.7308662741799834,
      "grad_norm": 1.50390625,
      "learning_rate": 2.1843522793504934e-07,
      "loss": 0.2512,
      "step": 29223
    },
    {
      "epoch": 2.732454910756004,
      "grad_norm": 2.4375,
      "learning_rate": 2.1588275449567432e-07,
      "loss": 0.4187,
      "step": 29240
    },
    {
      "epoch": 2.734043547332025,
      "grad_norm": 0.81787109375,
      "learning_rate": 2.133449529121723e-07,
      "loss": 0.4034,
      "step": 29257
    },
    {
      "epoch": 2.735632183908046,
      "grad_norm": 1.87890625,
      "learning_rate": 2.108218309674326e-07,
      "loss": 0.2668,
      "step": 29274
    },
    {
      "epoch": 2.737220820484067,
      "grad_norm": 2.203125,
      "learning_rate": 2.0831339639932725e-07,
      "loss": 0.4002,
      "step": 29291
    },
    {
      "epoch": 2.738809457060088,
      "grad_norm": 0.896484375,
      "learning_rate": 2.0581965690068427e-07,
      "loss": 0.3874,
      "step": 29308
    },
    {
      "epoch": 2.7403980936361085,
      "grad_norm": 1.341796875,
      "learning_rate": 2.0334062011926448e-07,
      "loss": 0.2968,
      "step": 29325
    },
    {
      "epoch": 2.7419867302121297,
      "grad_norm": 2.2734375,
      "learning_rate": 2.0087629365773798e-07,
      "loss": 0.4471,
      "step": 29342
    },
    {
      "epoch": 2.743575366788151,
      "grad_norm": 0.9404296875,
      "learning_rate": 1.9842668507366437e-07,
      "loss": 0.4018,
      "step": 29359
    },
    {
      "epoch": 2.7451640033641715,
      "grad_norm": 1.591796875,
      "learning_rate": 1.9599180187946432e-07,
      "loss": 0.2594,
      "step": 29376
    },
    {
      "epoch": 2.7467526399401923,
      "grad_norm": 2.328125,
      "learning_rate": 1.935716515423991e-07,
      "loss": 0.4304,
      "step": 29393
    },
    {
      "epoch": 2.7483412765162134,
      "grad_norm": 0.80517578125,
      "learning_rate": 1.9116624148454777e-07,
      "loss": 0.3991,
      "step": 29410
    },
    {
      "epoch": 2.7499299130922346,
      "grad_norm": 1.455078125,
      "learning_rate": 1.8877557908278498e-07,
      "loss": 0.2857,
      "step": 29427
    },
    {
      "epoch": 2.7515185496682553,
      "grad_norm": 2.7734375,
      "learning_rate": 1.8639967166875604e-07,
      "loss": 0.4397,
      "step": 29444
    },
    {
      "epoch": 2.753107186244276,
      "grad_norm": 1.064453125,
      "learning_rate": 1.840385265288569e-07,
      "loss": 0.3964,
      "step": 29461
    },
    {
      "epoch": 2.754695822820297,
      "grad_norm": 2.013671875,
      "learning_rate": 1.8169215090421077e-07,
      "loss": 0.2919,
      "step": 29478
    },
    {
      "epoch": 2.7562844593963183,
      "grad_norm": 2.6484375,
      "learning_rate": 1.7936055199064495e-07,
      "loss": 0.467,
      "step": 29495
    },
    {
      "epoch": 2.757873095972339,
      "grad_norm": 0.8232421875,
      "learning_rate": 1.7704373693867183e-07,
      "loss": 0.3393,
      "step": 29512
    },
    {
      "epoch": 2.7594617325483597,
      "grad_norm": 1.751953125,
      "learning_rate": 1.747417128534612e-07,
      "loss": 0.3307,
      "step": 29529
    },
    {
      "epoch": 2.761050369124381,
      "grad_norm": 2.453125,
      "learning_rate": 1.7245448679482745e-07,
      "loss": 0.481,
      "step": 29546
    },
    {
      "epoch": 2.762639005700402,
      "grad_norm": 0.7470703125,
      "learning_rate": 1.7018206577719742e-07,
      "loss": 0.264,
      "step": 29563
    },
    {
      "epoch": 2.7642276422764227,
      "grad_norm": 1.65625,
      "learning_rate": 1.67924456769597e-07,
      "loss": 0.2815,
      "step": 29580
    },
    {
      "epoch": 2.765816278852444,
      "grad_norm": 1.9912109375,
      "learning_rate": 1.6568166669562625e-07,
      "loss": 0.4522,
      "step": 29597
    },
    {
      "epoch": 2.7674049154284646,
      "grad_norm": 0.91259765625,
      "learning_rate": 1.6345370243343929e-07,
      "loss": 0.2801,
      "step": 29614
    },
    {
      "epoch": 2.7689935520044857,
      "grad_norm": 1.7724609375,
      "learning_rate": 1.6124057081572053e-07,
      "loss": 0.3132,
      "step": 29631
    },
    {
      "epoch": 2.7705821885805064,
      "grad_norm": 2.72265625,
      "learning_rate": 1.590422786296686e-07,
      "loss": 0.4687,
      "step": 29648
    },
    {
      "epoch": 2.7721708251565276,
      "grad_norm": 0.8330078125,
      "learning_rate": 1.5685883261697122e-07,
      "loss": 0.3278,
      "step": 29665
    },
    {
      "epoch": 2.7737594617325483,
      "grad_norm": 2.126953125,
      "learning_rate": 1.5469023947378593e-07,
      "loss": 0.3536,
      "step": 29682
    },
    {
      "epoch": 2.7753480983085694,
      "grad_norm": 2.81640625,
      "learning_rate": 1.525365058507211e-07,
      "loss": 0.5566,
      "step": 29699
    },
    {
      "epoch": 2.77693673488459,
      "grad_norm": 1.01953125,
      "learning_rate": 1.503976383528133e-07,
      "loss": 0.2301,
      "step": 29716
    },
    {
      "epoch": 2.7785253714606113,
      "grad_norm": 1.8349609375,
      "learning_rate": 1.4827364353950712e-07,
      "loss": 0.3271,
      "step": 29733
    },
    {
      "epoch": 2.780114008036632,
      "grad_norm": 2.880859375,
      "learning_rate": 1.4616452792463653e-07,
      "loss": 0.5523,
      "step": 29750
    },
    {
      "epoch": 2.781702644612653,
      "grad_norm": 0.9326171875,
      "learning_rate": 1.440702979764047e-07,
      "loss": 0.2205,
      "step": 29767
    },
    {
      "epoch": 2.783291281188674,
      "grad_norm": 1.890625,
      "learning_rate": 1.4199096011736357e-07,
      "loss": 0.3927,
      "step": 29784
    },
    {
      "epoch": 2.784879917764695,
      "grad_norm": 3.19921875,
      "learning_rate": 1.3992652072439384e-07,
      "loss": 0.4978,
      "step": 29801
    },
    {
      "epoch": 2.7864685543407157,
      "grad_norm": 0.98046875,
      "learning_rate": 1.378769861286855e-07,
      "loss": 0.2203,
      "step": 29818
    },
    {
      "epoch": 2.788057190916737,
      "grad_norm": 1.826171875,
      "learning_rate": 1.358423626157185e-07,
      "loss": 0.3419,
      "step": 29835
    },
    {
      "epoch": 2.7896458274927576,
      "grad_norm": 3.349609375,
      "learning_rate": 1.338226564252465e-07,
      "loss": 0.546,
      "step": 29852
    },
    {
      "epoch": 2.7912344640687787,
      "grad_norm": 0.84521484375,
      "learning_rate": 1.31817873751271e-07,
      "loss": 0.1818,
      "step": 29869
    },
    {
      "epoch": 2.7928231006447994,
      "grad_norm": 1.7294921875,
      "learning_rate": 1.2982802074202882e-07,
      "loss": 0.316,
      "step": 29886
    },
    {
      "epoch": 2.7944117372208206,
      "grad_norm": 0.646484375,
      "learning_rate": 1.2785310349996917e-07,
      "loss": 0.5308,
      "step": 29903
    },
    {
      "epoch": 2.7960003737968413,
      "grad_norm": 1.10546875,
      "learning_rate": 1.258931280817388e-07,
      "loss": 0.2141,
      "step": 29920
    },
    {
      "epoch": 2.7975890103728625,
      "grad_norm": 2.4140625,
      "learning_rate": 1.2394810049815854e-07,
      "loss": 0.3532,
      "step": 29937
    },
    {
      "epoch": 2.799177646948883,
      "grad_norm": 0.51318359375,
      "learning_rate": 1.2201802671420904e-07,
      "loss": 0.4787,
      "step": 29954
    },
    {
      "epoch": 2.8007662835249043,
      "grad_norm": 1.0703125,
      "learning_rate": 1.2010291264900998e-07,
      "loss": 0.2003,
      "step": 29971
    },
    {
      "epoch": 2.802354920100925,
      "grad_norm": 1.888671875,
      "learning_rate": 1.1820276417580379e-07,
      "loss": 0.3808,
      "step": 29988
    },
    {
      "epoch": 2.803943556676946,
      "grad_norm": 0.08917236328125,
      "learning_rate": 1.1631758712193575e-07,
      "loss": 0.4387,
      "step": 30005
    },
    {
      "epoch": 2.805532193252967,
      "grad_norm": 1.26953125,
      "learning_rate": 1.1444738726883675e-07,
      "loss": 0.2602,
      "step": 30022
    },
    {
      "epoch": 2.807120829828988,
      "grad_norm": 1.826171875,
      "learning_rate": 1.1259217035200776e-07,
      "loss": 0.4276,
      "step": 30039
    },
    {
      "epoch": 2.8087094664050087,
      "grad_norm": 0.457763671875,
      "learning_rate": 1.107519420609976e-07,
      "loss": 0.4196,
      "step": 30056
    },
    {
      "epoch": 2.81029810298103,
      "grad_norm": 1.23828125,
      "learning_rate": 1.0892670803938965e-07,
      "loss": 0.2337,
      "step": 30073
    },
    {
      "epoch": 2.8118867395570506,
      "grad_norm": 2.12109375,
      "learning_rate": 1.0711647388478408e-07,
      "loss": 0.4228,
      "step": 30090
    },
    {
      "epoch": 2.8134753761330717,
      "grad_norm": 0.278564453125,
      "learning_rate": 1.0532124514877784e-07,
      "loss": 0.3903,
      "step": 30107
    },
    {
      "epoch": 2.8150640127090925,
      "grad_norm": 1.3798828125,
      "learning_rate": 1.0354102733695081e-07,
      "loss": 0.2406,
      "step": 30124
    },
    {
      "epoch": 2.8166526492851136,
      "grad_norm": 2.376953125,
      "learning_rate": 1.0177582590884638e-07,
      "loss": 0.4232,
      "step": 30141
    },
    {
      "epoch": 2.8182412858611343,
      "grad_norm": 0.689453125,
      "learning_rate": 1.0002564627795808e-07,
      "loss": 0.3368,
      "step": 30158
    },
    {
      "epoch": 2.8198299224371555,
      "grad_norm": 1.7265625,
      "learning_rate": 9.829049381170797e-08,
      "loss": 0.2658,
      "step": 30175
    },
    {
      "epoch": 2.821418559013176,
      "grad_norm": 2.44140625,
      "learning_rate": 9.657037383143497e-08,
      "loss": 0.4746,
      "step": 30192
    },
    {
      "epoch": 2.8230071955891973,
      "grad_norm": 0.6357421875,
      "learning_rate": 9.486529161237546e-08,
      "loss": 0.3304,
      "step": 30209
    },
    {
      "epoch": 2.824595832165218,
      "grad_norm": 1.28515625,
      "learning_rate": 9.317525238365044e-08,
      "loss": 0.2416,
      "step": 30226
    },
    {
      "epoch": 2.826184468741239,
      "grad_norm": 2.716796875,
      "learning_rate": 9.150026132824452e-08,
      "loss": 0.4633,
      "step": 30243
    },
    {
      "epoch": 2.8277731053172603,
      "grad_norm": 0.67236328125,
      "learning_rate": 8.984032358299422e-08,
      "loss": 0.3597,
      "step": 30260
    },
    {
      "epoch": 2.829361741893281,
      "grad_norm": 1.7919921875,
      "learning_rate": 8.819544423857129e-08,
      "loss": 0.3111,
      "step": 30277
    },
    {
      "epoch": 2.8309503784693018,
      "grad_norm": 2.419921875,
      "learning_rate": 8.656562833946502e-08,
      "loss": 0.4742,
      "step": 30294
    },
    {
      "epoch": 2.832539015045323,
      "grad_norm": 0.822265625,
      "learning_rate": 8.495088088396941e-08,
      "loss": 0.3393,
      "step": 30311
    },
    {
      "epoch": 2.834127651621344,
      "grad_norm": 1.5263671875,
      "learning_rate": 8.335120682416765e-08,
      "loss": 0.272,
      "step": 30328
    },
    {
      "epoch": 2.8357162881973648,
      "grad_norm": 2.44921875,
      "learning_rate": 8.176661106591433e-08,
      "loss": 0.4937,
      "step": 30345
    },
    {
      "epoch": 2.8373049247733855,
      "grad_norm": 0.81787109375,
      "learning_rate": 8.019709846882328e-08,
      "loss": 0.3097,
      "step": 30362
    },
    {
      "epoch": 2.8388935613494066,
      "grad_norm": 1.46484375,
      "learning_rate": 7.864267384625034e-08,
      "loss": 0.3408,
      "step": 30379
    },
    {
      "epoch": 2.8404821979254278,
      "grad_norm": 2.21484375,
      "learning_rate": 7.710334196528113e-08,
      "loss": 0.449,
      "step": 30396
    },
    {
      "epoch": 2.8420708345014485,
      "grad_norm": 1.0380859375,
      "learning_rate": 7.557910754671494e-08,
      "loss": 0.3342,
      "step": 30413
    },
    {
      "epoch": 2.843659471077469,
      "grad_norm": 1.6630859375,
      "learning_rate": 7.406997526504978e-08,
      "loss": 0.305,
      "step": 30430
    },
    {
      "epoch": 2.8452481076534903,
      "grad_norm": 2.337890625,
      "learning_rate": 7.257594974846849e-08,
      "loss": 0.4688,
      "step": 30447
    },
    {
      "epoch": 2.8468367442295115,
      "grad_norm": 0.93701171875,
      "learning_rate": 7.109703557882597e-08,
      "loss": 0.3154,
      "step": 30464
    },
    {
      "epoch": 2.848425380805532,
      "grad_norm": 1.4755859375,
      "learning_rate": 6.963323729163196e-08,
      "loss": 0.3413,
      "step": 30481
    },
    {
      "epoch": 2.850014017381553,
      "grad_norm": 2.529296875,
      "learning_rate": 6.818455937604163e-08,
      "loss": 0.4772,
      "step": 30498
    },
    {
      "epoch": 2.851602653957574,
      "grad_norm": 0.9677734375,
      "learning_rate": 6.675100627483554e-08,
      "loss": 0.262,
      "step": 30515
    },
    {
      "epoch": 2.853191290533595,
      "grad_norm": 1.478515625,
      "learning_rate": 6.53325823844142e-08,
      "loss": 0.3408,
      "step": 30532
    },
    {
      "epoch": 2.854779927109616,
      "grad_norm": 2.98046875,
      "learning_rate": 6.392929205477627e-08,
      "loss": 0.5294,
      "step": 30549
    },
    {
      "epoch": 2.8563685636856366,
      "grad_norm": 1.0341796875,
      "learning_rate": 6.254113958951147e-08,
      "loss": 0.2488,
      "step": 30566
    },
    {
      "epoch": 2.857957200261658,
      "grad_norm": 1.7392578125,
      "learning_rate": 6.11681292457833e-08,
      "loss": 0.3422,
      "step": 30583
    },
    {
      "epoch": 2.859545836837679,
      "grad_norm": 2.642578125,
      "learning_rate": 5.98102652343191e-08,
      "loss": 0.5261,
      "step": 30600
    },
    {
      "epoch": 2.8611344734136996,
      "grad_norm": 0.90869140625,
      "learning_rate": 5.846755171939444e-08,
      "loss": 0.2459,
      "step": 30617
    },
    {
      "epoch": 2.8627231099897203,
      "grad_norm": 2.201171875,
      "learning_rate": 5.713999281882154e-08,
      "loss": 0.3297,
      "step": 30634
    },
    {
      "epoch": 2.8643117465657415,
      "grad_norm": 3.369140625,
      "learning_rate": 5.5827592603938665e-08,
      "loss": 0.5089,
      "step": 30651
    },
    {
      "epoch": 2.8659003831417627,
      "grad_norm": 1.0693359375,
      "learning_rate": 5.453035509959348e-08,
      "loss": 0.2096,
      "step": 30668
    },
    {
      "epoch": 2.8674890197177834,
      "grad_norm": 1.76953125,
      "learning_rate": 5.32482842841342e-08,
      "loss": 0.3488,
      "step": 30685
    },
    {
      "epoch": 2.869077656293804,
      "grad_norm": 3.201171875,
      "learning_rate": 5.1981384089394015e-08,
      "loss": 0.535,
      "step": 30702
    },
    {
      "epoch": 2.870666292869825,
      "grad_norm": 1.0791015625,
      "learning_rate": 5.0729658400684444e-08,
      "loss": 0.225,
      "step": 30719
    },
    {
      "epoch": 2.8722549294458464,
      "grad_norm": 1.7158203125,
      "learning_rate": 4.949311105677701e-08,
      "loss": 0.3442,
      "step": 30736
    },
    {
      "epoch": 2.873843566021867,
      "grad_norm": 0.3623046875,
      "learning_rate": 4.827174584989658e-08,
      "loss": 0.5127,
      "step": 30753
    },
    {
      "epoch": 2.875432202597888,
      "grad_norm": 1.2900390625,
      "learning_rate": 4.706556652570637e-08,
      "loss": 0.1996,
      "step": 30770
    },
    {
      "epoch": 2.877020839173909,
      "grad_norm": 2.177734375,
      "learning_rate": 4.587457678329799e-08,
      "loss": 0.4447,
      "step": 30787
    },
    {
      "epoch": 2.87860947574993,
      "grad_norm": 0.5615234375,
      "learning_rate": 4.469878027518082e-08,
      "loss": 0.5193,
      "step": 30804
    },
    {
      "epoch": 2.880198112325951,
      "grad_norm": 1.439453125,
      "learning_rate": 4.353818060726878e-08,
      "loss": 0.235,
      "step": 30821
    },
    {
      "epoch": 2.8817867489019715,
      "grad_norm": 2.021484375,
      "learning_rate": 4.239278133887081e-08,
      "loss": 0.4165,
      "step": 30838
    },
    {
      "epoch": 2.8833753854779927,
      "grad_norm": 0.033172607421875,
      "learning_rate": 4.126258598267929e-08,
      "loss": 0.454,
      "step": 30855
    },
    {
      "epoch": 2.884964022054014,
      "grad_norm": 1.341796875,
      "learning_rate": 4.014759800475998e-08,
      "loss": 0.208,
      "step": 30872
    },
    {
      "epoch": 2.8865526586300345,
      "grad_norm": 2.263671875,
      "learning_rate": 3.904782082454039e-08,
      "loss": 0.3744,
      "step": 30889
    },
    {
      "epoch": 2.8881412952060557,
      "grad_norm": 0.60986328125,
      "learning_rate": 3.796325781480037e-08,
      "loss": 0.4375,
      "step": 30906
    },
    {
      "epoch": 2.8897299317820764,
      "grad_norm": 1.482421875,
      "learning_rate": 3.6893912301659837e-08,
      "loss": 0.269,
      "step": 30923
    },
    {
      "epoch": 2.8913185683580975,
      "grad_norm": 2.216796875,
      "learning_rate": 3.583978756457162e-08,
      "loss": 0.42,
      "step": 30940
    },
    {
      "epoch": 2.8929072049341182,
      "grad_norm": 0.7333984375,
      "learning_rate": 3.480088683630867e-08,
      "loss": 0.4479,
      "step": 30957
    },
    {
      "epoch": 2.8944958415101394,
      "grad_norm": 1.357421875,
      "learning_rate": 3.377721330295569e-08,
      "loss": 0.2507,
      "step": 30974
    },
    {
      "epoch": 2.89608447808616,
      "grad_norm": 2.166015625,
      "learning_rate": 3.2768770103898676e-08,
      "loss": 0.4561,
      "step": 30991
    },
    {
      "epoch": 2.8976731146621812,
      "grad_norm": 0.65673828125,
      "learning_rate": 3.177556033181484e-08,
      "loss": 0.4091,
      "step": 31008
    },
    {
      "epoch": 2.899261751238202,
      "grad_norm": 1.294921875,
      "learning_rate": 3.0797587032664886e-08,
      "loss": 0.2405,
      "step": 31025
    },
    {
      "epoch": 2.900850387814223,
      "grad_norm": 2.310546875,
      "learning_rate": 2.983485320568247e-08,
      "loss": 0.4135,
      "step": 31042
    },
    {
      "epoch": 2.902439024390244,
      "grad_norm": 0.7998046875,
      "learning_rate": 2.88873618033636e-08,
      "loss": 0.4004,
      "step": 31059
    },
    {
      "epoch": 2.904027660966265,
      "grad_norm": 1.3408203125,
      "learning_rate": 2.795511573146059e-08,
      "loss": 0.3208,
      "step": 31076
    },
    {
      "epoch": 2.9056162975422857,
      "grad_norm": 2.810546875,
      "learning_rate": 2.7038117848970923e-08,
      "loss": 0.4632,
      "step": 31093
    },
    {
      "epoch": 2.907204934118307,
      "grad_norm": 0.75732421875,
      "learning_rate": 2.6136370968130044e-08,
      "loss": 0.3529,
      "step": 31110
    },
    {
      "epoch": 2.9087935706943275,
      "grad_norm": 1.59375,
      "learning_rate": 2.524987785440025e-08,
      "loss": 0.2788,
      "step": 31127
    },
    {
      "epoch": 2.9103822072703487,
      "grad_norm": 2.994140625,
      "learning_rate": 2.437864122646516e-08,
      "loss": 0.4999,
      "step": 31144
    },
    {
      "epoch": 2.9119708438463694,
      "grad_norm": 0.85888671875,
      "learning_rate": 2.35226637562197e-08,
      "loss": 0.3572,
      "step": 31161
    },
    {
      "epoch": 2.9135594804223905,
      "grad_norm": 1.74609375,
      "learning_rate": 2.2681948068761785e-08,
      "loss": 0.3108,
      "step": 31178
    },
    {
      "epoch": 2.9151481169984113,
      "grad_norm": 2.576171875,
      "learning_rate": 2.1856496742385656e-08,
      "loss": 0.4897,
      "step": 31195
    },
    {
      "epoch": 2.9167367535744324,
      "grad_norm": 0.80029296875,
      "learning_rate": 2.1046312308572457e-08,
      "loss": 0.3421,
      "step": 31212
    },
    {
      "epoch": 2.918325390150453,
      "grad_norm": 1.5986328125,
      "learning_rate": 2.025139725198244e-08,
      "loss": 0.3116,
      "step": 31229
    },
    {
      "epoch": 2.9199140267264743,
      "grad_norm": 2.03125,
      "learning_rate": 1.9471754010449427e-08,
      "loss": 0.4676,
      "step": 31246
    },
    {
      "epoch": 2.921502663302495,
      "grad_norm": 0.888671875,
      "learning_rate": 1.8707384974970822e-08,
      "loss": 0.3508,
      "step": 31263
    },
    {
      "epoch": 2.923091299878516,
      "grad_norm": 1.513671875,
      "learning_rate": 1.795829248970149e-08,
      "loss": 0.3304,
      "step": 31280
    },
    {
      "epoch": 2.924679936454537,
      "grad_norm": 2.2421875,
      "learning_rate": 1.7224478851947114e-08,
      "loss": 0.4933,
      "step": 31297
    },
    {
      "epoch": 2.926268573030558,
      "grad_norm": 0.95654296875,
      "learning_rate": 1.650594631215474e-08,
      "loss": 0.3135,
      "step": 31314
    },
    {
      "epoch": 2.9278572096065787,
      "grad_norm": 1.638671875,
      "learning_rate": 1.5802697073910022e-08,
      "loss": 0.3558,
      "step": 31331
    },
    {
      "epoch": 2.9294458461826,
      "grad_norm": 3.05078125,
      "learning_rate": 1.5114733293925542e-08,
      "loss": 0.4594,
      "step": 31348
    },
    {
      "epoch": 2.9310344827586206,
      "grad_norm": 0.87646484375,
      "learning_rate": 1.4442057082039162e-08,
      "loss": 0.2645,
      "step": 31365
    },
    {
      "epoch": 2.9326231193346417,
      "grad_norm": 1.326171875,
      "learning_rate": 1.3784670501202358e-08,
      "loss": 0.3645,
      "step": 31382
    },
    {
      "epoch": 2.9342117559106624,
      "grad_norm": 3.07421875,
      "learning_rate": 1.3142575567478555e-08,
      "loss": 0.5717,
      "step": 31399
    },
    {
      "epoch": 2.9358003924866836,
      "grad_norm": 1.19140625,
      "learning_rate": 1.2515774250034807e-08,
      "loss": 0.2682,
      "step": 31416
    },
    {
      "epoch": 2.9373890290627043,
      "grad_norm": 1.75,
      "learning_rate": 1.1904268471135127e-08,
      "loss": 0.3623,
      "step": 31433
    },
    {
      "epoch": 2.9389776656387254,
      "grad_norm": 3.646484375,
      "learning_rate": 1.1308060106136608e-08,
      "loss": 0.5035,
      "step": 31450
    },
    {
      "epoch": 2.940566302214746,
      "grad_norm": 1.302734375,
      "learning_rate": 1.0727150983480539e-08,
      "loss": 0.2334,
      "step": 31467
    },
    {
      "epoch": 2.9421549387907673,
      "grad_norm": 1.71875,
      "learning_rate": 1.0161542884690733e-08,
      "loss": 0.3743,
      "step": 31484
    },
    {
      "epoch": 2.943743575366788,
      "grad_norm": 3.25390625,
      "learning_rate": 9.611237544365216e-09,
      "loss": 0.5295,
      "step": 31501
    },
    {
      "epoch": 2.945332211942809,
      "grad_norm": 1.1220703125,
      "learning_rate": 9.076236650171211e-09,
      "loss": 0.2355,
      "step": 31518
    },
    {
      "epoch": 2.94692084851883,
      "grad_norm": 1.6748046875,
      "learning_rate": 8.55654184284238e-09,
      "loss": 0.3964,
      "step": 31535
    },
    {
      "epoch": 2.948509485094851,
      "grad_norm": 3.0078125,
      "learning_rate": 8.052154716168825e-09,
      "loss": 0.5214,
      "step": 31552
    },
    {
      "epoch": 2.950098121670872,
      "grad_norm": 1.3017578125,
      "learning_rate": 7.563076816998194e-09,
      "loss": 0.2055,
      "step": 31569
    },
    {
      "epoch": 2.951686758246893,
      "grad_norm": 2.3515625,
      "learning_rate": 7.08930964522736e-09,
      "loss": 0.3846,
      "step": 31586
    },
    {
      "epoch": 2.9532753948229136,
      "grad_norm": 0.39892578125,
      "learning_rate": 6.63085465379687e-09,
      "loss": 0.4973,
      "step": 31603
    },
    {
      "epoch": 2.9548640313989347,
      "grad_norm": 1.3505859375,
      "learning_rate": 6.1877132486903855e-09,
      "loss": 0.218,
      "step": 31620
    },
    {
      "epoch": 2.956452667974956,
      "grad_norm": 2.296875,
      "learning_rate": 5.759886788926361e-09,
      "loss": 0.4097,
      "step": 31637
    },
    {
      "epoch": 2.9580413045509766,
      "grad_norm": 0.5478515625,
      "learning_rate": 5.3473765865563744e-09,
      "loss": 0.4794,
      "step": 31654
    },
    {
      "epoch": 2.9596299411269973,
      "grad_norm": 1.44140625,
      "learning_rate": 4.950183906660133e-09,
      "loss": 0.2194,
      "step": 31671
    },
    {
      "epoch": 2.9612185777030184,
      "grad_norm": 2.068359375,
      "learning_rate": 4.568309967342699e-09,
      "loss": 0.4274,
      "step": 31688
    },
    {
      "epoch": 2.9628072142790396,
      "grad_norm": 0.32177734375,
      "learning_rate": 4.201755939728381e-09,
      "loss": 0.5013,
      "step": 31705
    },
    {
      "epoch": 2.9643958508550603,
      "grad_norm": 1.5654296875,
      "learning_rate": 3.850522947959068e-09,
      "loss": 0.2621,
      "step": 31722
    },
    {
      "epoch": 2.965984487431081,
      "grad_norm": 2.56640625,
      "learning_rate": 3.5146120691914587e-09,
      "loss": 0.4299,
      "step": 31739
    },
    {
      "epoch": 2.967573124007102,
      "grad_norm": 0.4208984375,
      "learning_rate": 3.1940243335915055e-09,
      "loss": 0.4655,
      "step": 31756
    },
    {
      "epoch": 2.9691617605831233,
      "grad_norm": 1.1064453125,
      "learning_rate": 2.8887607243321957e-09,
      "loss": 0.2343,
      "step": 31773
    },
    {
      "epoch": 2.970750397159144,
      "grad_norm": 1.640625,
      "learning_rate": 2.5988221775918863e-09,
      "loss": 0.3785,
      "step": 31790
    },
    {
      "epoch": 2.9723390337351647,
      "grad_norm": 0.7470703125,
      "learning_rate": 2.324209582548753e-09,
      "loss": 0.4258,
      "step": 31807
    },
    {
      "epoch": 2.973927670311186,
      "grad_norm": 1.4287109375,
      "learning_rate": 2.064923781381345e-09,
      "loss": 0.3122,
      "step": 31824
    },
    {
      "epoch": 2.975516306887207,
      "grad_norm": 2.33203125,
      "learning_rate": 1.8209655692624784e-09,
      "loss": 0.4701,
      "step": 31841
    },
    {
      "epoch": 2.9771049434632277,
      "grad_norm": 0.78125,
      "learning_rate": 1.5923356943592372e-09,
      "loss": 0.4279,
      "step": 31858
    },
    {
      "epoch": 2.9786935800392484,
      "grad_norm": 1.3603515625,
      "learning_rate": 1.3790348578313073e-09,
      "loss": 0.2785,
      "step": 31875
    },
    {
      "epoch": 2.9802822166152696,
      "grad_norm": 2.0859375,
      "learning_rate": 1.1810637138254254e-09,
      "loss": 0.4254,
      "step": 31892
    },
    {
      "epoch": 2.9818708531912907,
      "grad_norm": 0.88916015625,
      "learning_rate": 9.984228694764897e-10,
      "loss": 0.3681,
      "step": 31909
    },
    {
      "epoch": 2.9834594897673115,
      "grad_norm": 1.3779296875,
      "learning_rate": 8.311128849047834e-10,
      "loss": 0.265,
      "step": 31926
    },
    {
      "epoch": 2.985048126343332,
      "grad_norm": 1.970703125,
      "learning_rate": 6.791342732137551e-10,
      "loss": 0.4561,
      "step": 31943
    },
    {
      "epoch": 2.9866367629193533,
      "grad_norm": 0.77978515625,
      "learning_rate": 5.424875004894636e-10,
      "loss": 0.3455,
      "step": 31960
    },
    {
      "epoch": 2.9882253994953745,
      "grad_norm": 1.9794921875,
      "learning_rate": 4.211729857972469e-10,
      "loss": 0.3128,
      "step": 31977
    },
    {
      "epoch": 2.989814036071395,
      "grad_norm": 2.765625,
      "learning_rate": 3.151911011839426e-10,
      "loss": 0.4953,
      "step": 31994
    },
    {
      "epoch": 2.991402672647416,
      "grad_norm": 0.80126953125,
      "learning_rate": 2.2454217167178217e-10,
      "loss": 0.3077,
      "step": 32011
    },
    {
      "epoch": 2.992991309223437,
      "grad_norm": 1.5078125,
      "learning_rate": 1.4922647526172119e-10,
      "loss": 0.3183,
      "step": 32028
    },
    {
      "epoch": 2.994579945799458,
      "grad_norm": 2.740234375,
      "learning_rate": 8.924424293121902e-11,
      "loss": 0.4541,
      "step": 32045
    },
    {
      "epoch": 2.996168582375479,
      "grad_norm": 0.77490234375,
      "learning_rate": 4.4595658632573533e-11,
      "loss": 0.2953,
      "step": 32062
    },
    {
      "epoch": 2.9977572189514996,
      "grad_norm": 1.962890625,
      "learning_rate": 1.5280859294031226e-11,
      "loss": 0.3538,
      "step": 32079
    },
    {
      "epoch": 2.9993458555275208,
      "grad_norm": 2.712890625,
      "learning_rate": 1.2999348164566273e-12,
      "loss": 0.5138,
      "step": 32096
    }
  ],
  "logging_steps": 17,
  "max_steps": 32103,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 3211,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.3414857072530555e+18,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
