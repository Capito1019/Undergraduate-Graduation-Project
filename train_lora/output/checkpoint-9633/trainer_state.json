{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9001962433417438,
  "eval_steps": 6421,
  "global_step": 9633,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015886365760209326,
      "grad_norm": 0.30615234375,
      "learning_rate": 1.0585305105853052e-07,
      "loss": 0.3677,
      "step": 17
    },
    {
      "epoch": 0.003177273152041865,
      "grad_norm": 1.23828125,
      "learning_rate": 2.1170610211706104e-07,
      "loss": 0.5717,
      "step": 34
    },
    {
      "epoch": 0.004765909728062798,
      "grad_norm": 0.280029296875,
      "learning_rate": 3.1755915317559156e-07,
      "loss": 0.8085,
      "step": 51
    },
    {
      "epoch": 0.00635454630408373,
      "grad_norm": 0.34228515625,
      "learning_rate": 4.234122042341221e-07,
      "loss": 0.3141,
      "step": 68
    },
    {
      "epoch": 0.007943182880104663,
      "grad_norm": 0.6669921875,
      "learning_rate": 5.292652552926527e-07,
      "loss": 0.6057,
      "step": 85
    },
    {
      "epoch": 0.009531819456125596,
      "grad_norm": 0.106689453125,
      "learning_rate": 6.351183063511831e-07,
      "loss": 0.7759,
      "step": 102
    },
    {
      "epoch": 0.011120456032146528,
      "grad_norm": 0.41064453125,
      "learning_rate": 7.409713574097137e-07,
      "loss": 0.3873,
      "step": 119
    },
    {
      "epoch": 0.01270909260816746,
      "grad_norm": 0.52392578125,
      "learning_rate": 8.468244084682442e-07,
      "loss": 0.6285,
      "step": 136
    },
    {
      "epoch": 0.014297729184188394,
      "grad_norm": 0.1488037109375,
      "learning_rate": 9.526774595267747e-07,
      "loss": 0.7612,
      "step": 153
    },
    {
      "epoch": 0.015886365760209326,
      "grad_norm": 0.352294921875,
      "learning_rate": 1.0585305105853053e-06,
      "loss": 0.3533,
      "step": 170
    },
    {
      "epoch": 0.01747500233623026,
      "grad_norm": 0.74755859375,
      "learning_rate": 1.1643835616438357e-06,
      "loss": 0.6135,
      "step": 187
    },
    {
      "epoch": 0.019063638912251192,
      "grad_norm": 0.15283203125,
      "learning_rate": 1.2702366127023662e-06,
      "loss": 0.7373,
      "step": 204
    },
    {
      "epoch": 0.020652275488272125,
      "grad_norm": 0.59130859375,
      "learning_rate": 1.3760896637608966e-06,
      "loss": 0.4345,
      "step": 221
    },
    {
      "epoch": 0.022240912064293055,
      "grad_norm": 0.5458984375,
      "learning_rate": 1.4819427148194274e-06,
      "loss": 0.6566,
      "step": 238
    },
    {
      "epoch": 0.02382954864031399,
      "grad_norm": 0.29541015625,
      "learning_rate": 1.5877957658779578e-06,
      "loss": 0.7509,
      "step": 255
    },
    {
      "epoch": 0.02541818521633492,
      "grad_norm": 0.490478515625,
      "learning_rate": 1.6936488169364883e-06,
      "loss": 0.4075,
      "step": 272
    },
    {
      "epoch": 0.027006821792355855,
      "grad_norm": 0.796875,
      "learning_rate": 1.799501867995019e-06,
      "loss": 0.6673,
      "step": 289
    },
    {
      "epoch": 0.028595458368376788,
      "grad_norm": 0.1600341796875,
      "learning_rate": 1.9053549190535495e-06,
      "loss": 0.6821,
      "step": 306
    },
    {
      "epoch": 0.03018409494439772,
      "grad_norm": 0.4326171875,
      "learning_rate": 2.01120797011208e-06,
      "loss": 0.3543,
      "step": 323
    },
    {
      "epoch": 0.03177273152041865,
      "grad_norm": 0.75732421875,
      "learning_rate": 2.1170610211706106e-06,
      "loss": 0.6114,
      "step": 340
    },
    {
      "epoch": 0.03336136809643959,
      "grad_norm": 0.20703125,
      "learning_rate": 2.2229140722291408e-06,
      "loss": 0.5834,
      "step": 357
    },
    {
      "epoch": 0.03495000467246052,
      "grad_norm": 0.326416015625,
      "learning_rate": 2.3287671232876713e-06,
      "loss": 0.3978,
      "step": 374
    },
    {
      "epoch": 0.03653864124848145,
      "grad_norm": 0.62646484375,
      "learning_rate": 2.434620174346202e-06,
      "loss": 0.6366,
      "step": 391
    },
    {
      "epoch": 0.038127277824502384,
      "grad_norm": 0.259765625,
      "learning_rate": 2.5404732254047325e-06,
      "loss": 0.6095,
      "step": 408
    },
    {
      "epoch": 0.039715914400523314,
      "grad_norm": 0.82861328125,
      "learning_rate": 2.646326276463263e-06,
      "loss": 0.4376,
      "step": 425
    },
    {
      "epoch": 0.04130455097654425,
      "grad_norm": 0.97509765625,
      "learning_rate": 2.7521793275217932e-06,
      "loss": 0.7023,
      "step": 442
    },
    {
      "epoch": 0.04289318755256518,
      "grad_norm": 0.2115478515625,
      "learning_rate": 2.858032378580324e-06,
      "loss": 0.5356,
      "step": 459
    },
    {
      "epoch": 0.04448182412858611,
      "grad_norm": 0.83154296875,
      "learning_rate": 2.963885429638855e-06,
      "loss": 0.4777,
      "step": 476
    },
    {
      "epoch": 0.04607046070460705,
      "grad_norm": 0.7978515625,
      "learning_rate": 3.069738480697385e-06,
      "loss": 0.6041,
      "step": 493
    },
    {
      "epoch": 0.04765909728062798,
      "grad_norm": 0.41748046875,
      "learning_rate": 3.1755915317559155e-06,
      "loss": 0.4227,
      "step": 510
    },
    {
      "epoch": 0.04924773385664891,
      "grad_norm": 0.8466796875,
      "learning_rate": 3.281444582814446e-06,
      "loss": 0.443,
      "step": 527
    },
    {
      "epoch": 0.05083637043266984,
      "grad_norm": 0.9345703125,
      "learning_rate": 3.3872976338729767e-06,
      "loss": 0.6736,
      "step": 544
    },
    {
      "epoch": 0.05242500700869078,
      "grad_norm": 0.5810546875,
      "learning_rate": 3.4931506849315072e-06,
      "loss": 0.384,
      "step": 561
    },
    {
      "epoch": 0.05401364358471171,
      "grad_norm": 0.68017578125,
      "learning_rate": 3.599003735990038e-06,
      "loss": 0.3962,
      "step": 578
    },
    {
      "epoch": 0.05560228016073264,
      "grad_norm": 1.443359375,
      "learning_rate": 3.704856787048568e-06,
      "loss": 0.6065,
      "step": 595
    },
    {
      "epoch": 0.057190916736753576,
      "grad_norm": 0.67578125,
      "learning_rate": 3.810709838107099e-06,
      "loss": 0.4176,
      "step": 612
    },
    {
      "epoch": 0.058779553312774506,
      "grad_norm": 0.6826171875,
      "learning_rate": 3.916562889165629e-06,
      "loss": 0.4848,
      "step": 629
    },
    {
      "epoch": 0.06036818988879544,
      "grad_norm": 1.1982421875,
      "learning_rate": 4.02241594022416e-06,
      "loss": 0.6994,
      "step": 646
    },
    {
      "epoch": 0.06195682646481637,
      "grad_norm": 0.52587890625,
      "learning_rate": 4.12826899128269e-06,
      "loss": 0.3928,
      "step": 663
    },
    {
      "epoch": 0.0635454630408373,
      "grad_norm": 1.2802734375,
      "learning_rate": 4.234122042341221e-06,
      "loss": 0.4216,
      "step": 680
    },
    {
      "epoch": 0.06513409961685823,
      "grad_norm": 1.1298828125,
      "learning_rate": 4.339975093399751e-06,
      "loss": 0.618,
      "step": 697
    },
    {
      "epoch": 0.06672273619287918,
      "grad_norm": 0.7412109375,
      "learning_rate": 4.4458281444582815e-06,
      "loss": 0.3223,
      "step": 714
    },
    {
      "epoch": 0.0683113727689001,
      "grad_norm": 1.58984375,
      "learning_rate": 4.5516811955168125e-06,
      "loss": 0.5041,
      "step": 731
    },
    {
      "epoch": 0.06990000934492104,
      "grad_norm": 1.41796875,
      "learning_rate": 4.657534246575343e-06,
      "loss": 0.6834,
      "step": 748
    },
    {
      "epoch": 0.07148864592094197,
      "grad_norm": 0.86083984375,
      "learning_rate": 4.763387297633874e-06,
      "loss": 0.2818,
      "step": 765
    },
    {
      "epoch": 0.0730772824969629,
      "grad_norm": 0.94189453125,
      "learning_rate": 4.869240348692404e-06,
      "loss": 0.431,
      "step": 782
    },
    {
      "epoch": 0.07466591907298384,
      "grad_norm": 1.87109375,
      "learning_rate": 4.975093399750934e-06,
      "loss": 0.632,
      "step": 799
    },
    {
      "epoch": 0.07625455564900477,
      "grad_norm": 0.83203125,
      "learning_rate": 5.080946450809465e-06,
      "loss": 0.3002,
      "step": 816
    },
    {
      "epoch": 0.0778431922250257,
      "grad_norm": 1.318359375,
      "learning_rate": 5.186799501867995e-06,
      "loss": 0.4234,
      "step": 833
    },
    {
      "epoch": 0.07943182880104663,
      "grad_norm": 1.84375,
      "learning_rate": 5.292652552926526e-06,
      "loss": 0.6675,
      "step": 850
    },
    {
      "epoch": 0.08102046537706756,
      "grad_norm": 0.9638671875,
      "learning_rate": 5.398505603985057e-06,
      "loss": 0.2349,
      "step": 867
    },
    {
      "epoch": 0.0826091019530885,
      "grad_norm": 0.955078125,
      "learning_rate": 5.5043586550435864e-06,
      "loss": 0.4604,
      "step": 884
    },
    {
      "epoch": 0.08419773852910943,
      "grad_norm": 0.29052734375,
      "learning_rate": 5.6102117061021174e-06,
      "loss": 0.5977,
      "step": 901
    },
    {
      "epoch": 0.08578637510513036,
      "grad_norm": 0.7275390625,
      "learning_rate": 5.716064757160648e-06,
      "loss": 0.2387,
      "step": 918
    },
    {
      "epoch": 0.08737501168115129,
      "grad_norm": 1.1982421875,
      "learning_rate": 5.821917808219179e-06,
      "loss": 0.4467,
      "step": 935
    },
    {
      "epoch": 0.08896364825717222,
      "grad_norm": 0.444091796875,
      "learning_rate": 5.92777085927771e-06,
      "loss": 0.5707,
      "step": 952
    },
    {
      "epoch": 0.09055228483319316,
      "grad_norm": 0.982421875,
      "learning_rate": 6.033623910336239e-06,
      "loss": 0.3508,
      "step": 969
    },
    {
      "epoch": 0.0921409214092141,
      "grad_norm": 1.3583984375,
      "learning_rate": 6.13947696139477e-06,
      "loss": 0.4969,
      "step": 986
    },
    {
      "epoch": 0.09372955798523502,
      "grad_norm": 0.222412109375,
      "learning_rate": 6.245330012453301e-06,
      "loss": 0.5931,
      "step": 1003
    },
    {
      "epoch": 0.09531819456125595,
      "grad_norm": 0.84619140625,
      "learning_rate": 6.351183063511831e-06,
      "loss": 0.3055,
      "step": 1020
    },
    {
      "epoch": 0.09690683113727688,
      "grad_norm": 1.484375,
      "learning_rate": 6.457036114570362e-06,
      "loss": 0.5078,
      "step": 1037
    },
    {
      "epoch": 0.09849546771329783,
      "grad_norm": 0.6533203125,
      "learning_rate": 6.562889165628892e-06,
      "loss": 0.5422,
      "step": 1054
    },
    {
      "epoch": 0.10008410428931876,
      "grad_norm": 1.162109375,
      "learning_rate": 6.668742216687422e-06,
      "loss": 0.2925,
      "step": 1071
    },
    {
      "epoch": 0.10167274086533969,
      "grad_norm": 1.6494140625,
      "learning_rate": 6.774595267745953e-06,
      "loss": 0.4744,
      "step": 1088
    },
    {
      "epoch": 0.10326137744136062,
      "grad_norm": 0.85009765625,
      "learning_rate": 6.8804483188044835e-06,
      "loss": 0.5842,
      "step": 1105
    },
    {
      "epoch": 0.10485001401738156,
      "grad_norm": 0.99853515625,
      "learning_rate": 6.9863013698630145e-06,
      "loss": 0.361,
      "step": 1122
    },
    {
      "epoch": 0.10643865059340249,
      "grad_norm": 2.166015625,
      "learning_rate": 7.092154420921545e-06,
      "loss": 0.4835,
      "step": 1139
    },
    {
      "epoch": 0.10802728716942342,
      "grad_norm": 0.6533203125,
      "learning_rate": 7.198007471980076e-06,
      "loss": 0.4625,
      "step": 1156
    },
    {
      "epoch": 0.10961592374544435,
      "grad_norm": 0.9951171875,
      "learning_rate": 7.303860523038606e-06,
      "loss": 0.3469,
      "step": 1173
    },
    {
      "epoch": 0.11120456032146528,
      "grad_norm": 3.162109375,
      "learning_rate": 7.409713574097136e-06,
      "loss": 0.5231,
      "step": 1190
    },
    {
      "epoch": 0.11279319689748622,
      "grad_norm": 0.455078125,
      "learning_rate": 7.515566625155667e-06,
      "loss": 0.4403,
      "step": 1207
    },
    {
      "epoch": 0.11438183347350715,
      "grad_norm": 1.091796875,
      "learning_rate": 7.621419676214198e-06,
      "loss": 0.3341,
      "step": 1224
    },
    {
      "epoch": 0.11597047004952808,
      "grad_norm": 2.255859375,
      "learning_rate": 7.727272727272727e-06,
      "loss": 0.5361,
      "step": 1241
    },
    {
      "epoch": 0.11755910662554901,
      "grad_norm": 0.5732421875,
      "learning_rate": 7.833125778331258e-06,
      "loss": 0.4021,
      "step": 1258
    },
    {
      "epoch": 0.11914774320156994,
      "grad_norm": 0.9658203125,
      "learning_rate": 7.93897882938979e-06,
      "loss": 0.3574,
      "step": 1275
    },
    {
      "epoch": 0.12073637977759089,
      "grad_norm": 1.7958984375,
      "learning_rate": 8.04483188044832e-06,
      "loss": 0.5173,
      "step": 1292
    },
    {
      "epoch": 0.12232501635361182,
      "grad_norm": 0.71923828125,
      "learning_rate": 8.150684931506851e-06,
      "loss": 0.4297,
      "step": 1309
    },
    {
      "epoch": 0.12391365292963274,
      "grad_norm": 1.091796875,
      "learning_rate": 8.25653798256538e-06,
      "loss": 0.3493,
      "step": 1326
    },
    {
      "epoch": 0.12550228950565367,
      "grad_norm": 3.525390625,
      "learning_rate": 8.362391033623912e-06,
      "loss": 0.5447,
      "step": 1343
    },
    {
      "epoch": 0.1270909260816746,
      "grad_norm": 0.63623046875,
      "learning_rate": 8.468244084682442e-06,
      "loss": 0.3913,
      "step": 1360
    },
    {
      "epoch": 0.12867956265769553,
      "grad_norm": 1.380859375,
      "learning_rate": 8.574097135740972e-06,
      "loss": 0.3514,
      "step": 1377
    },
    {
      "epoch": 0.13026819923371646,
      "grad_norm": 1.703125,
      "learning_rate": 8.679950186799503e-06,
      "loss": 0.5447,
      "step": 1394
    },
    {
      "epoch": 0.13185683580973742,
      "grad_norm": 0.5234375,
      "learning_rate": 8.785803237858032e-06,
      "loss": 0.3191,
      "step": 1411
    },
    {
      "epoch": 0.13344547238575835,
      "grad_norm": 1.115234375,
      "learning_rate": 8.891656288916563e-06,
      "loss": 0.3458,
      "step": 1428
    },
    {
      "epoch": 0.13503410896177928,
      "grad_norm": 1.392578125,
      "learning_rate": 8.997509339975094e-06,
      "loss": 0.5391,
      "step": 1445
    },
    {
      "epoch": 0.1366227455378002,
      "grad_norm": 0.60888671875,
      "learning_rate": 9.103362391033625e-06,
      "loss": 0.2989,
      "step": 1462
    },
    {
      "epoch": 0.13821138211382114,
      "grad_norm": 1.1220703125,
      "learning_rate": 9.209215442092156e-06,
      "loss": 0.3724,
      "step": 1479
    },
    {
      "epoch": 0.13980001868984207,
      "grad_norm": 2.53125,
      "learning_rate": 9.315068493150685e-06,
      "loss": 0.5454,
      "step": 1496
    },
    {
      "epoch": 0.141388655265863,
      "grad_norm": 0.6748046875,
      "learning_rate": 9.420921544209216e-06,
      "loss": 0.3114,
      "step": 1513
    },
    {
      "epoch": 0.14297729184188393,
      "grad_norm": 1.4423828125,
      "learning_rate": 9.526774595267747e-06,
      "loss": 0.3943,
      "step": 1530
    },
    {
      "epoch": 0.14456592841790486,
      "grad_norm": 2.107421875,
      "learning_rate": 9.632627646326277e-06,
      "loss": 0.62,
      "step": 1547
    },
    {
      "epoch": 0.1461545649939258,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.738480697384808e-06,
      "loss": 0.2803,
      "step": 1564
    },
    {
      "epoch": 0.14774320156994675,
      "grad_norm": 1.455078125,
      "learning_rate": 9.844333748443339e-06,
      "loss": 0.3949,
      "step": 1581
    },
    {
      "epoch": 0.14933183814596768,
      "grad_norm": 2.21875,
      "learning_rate": 9.950186799501868e-06,
      "loss": 0.6392,
      "step": 1598
    },
    {
      "epoch": 0.1509204747219886,
      "grad_norm": 0.765625,
      "learning_rate": 9.999997851128222e-06,
      "loss": 0.2648,
      "step": 1615
    },
    {
      "epoch": 0.15250911129800954,
      "grad_norm": 1.33984375,
      "learning_rate": 9.999982066215332e-06,
      "loss": 0.3933,
      "step": 1632
    },
    {
      "epoch": 0.15409774787403047,
      "grad_norm": 2.046875,
      "learning_rate": 9.999950947435717e-06,
      "loss": 0.6,
      "step": 1649
    },
    {
      "epoch": 0.1556863844500514,
      "grad_norm": 0.65966796875,
      "learning_rate": 9.999904494884808e-06,
      "loss": 0.2117,
      "step": 1666
    },
    {
      "epoch": 0.15727502102607233,
      "grad_norm": 1.177734375,
      "learning_rate": 9.999842708705073e-06,
      "loss": 0.3763,
      "step": 1683
    },
    {
      "epoch": 0.15886365760209326,
      "grad_norm": 2.9765625,
      "learning_rate": 9.999765589085988e-06,
      "loss": 0.5906,
      "step": 1700
    },
    {
      "epoch": 0.16045229417811419,
      "grad_norm": 0.90185546875,
      "learning_rate": 9.999673136264067e-06,
      "loss": 0.265,
      "step": 1717
    },
    {
      "epoch": 0.16204093075413512,
      "grad_norm": 1.48046875,
      "learning_rate": 9.999565350522841e-06,
      "loss": 0.4085,
      "step": 1734
    },
    {
      "epoch": 0.16362956733015607,
      "grad_norm": 0.5478515625,
      "learning_rate": 9.999442232192867e-06,
      "loss": 0.5989,
      "step": 1751
    },
    {
      "epoch": 0.165218203906177,
      "grad_norm": 1.064453125,
      "learning_rate": 9.999303781651722e-06,
      "loss": 0.2099,
      "step": 1768
    },
    {
      "epoch": 0.16680684048219793,
      "grad_norm": 1.28125,
      "learning_rate": 9.999149999324002e-06,
      "loss": 0.4079,
      "step": 1785
    },
    {
      "epoch": 0.16839547705821886,
      "grad_norm": 0.37451171875,
      "learning_rate": 9.998980885681328e-06,
      "loss": 0.5364,
      "step": 1802
    },
    {
      "epoch": 0.1699841136342398,
      "grad_norm": 1.296875,
      "learning_rate": 9.998796441242333e-06,
      "loss": 0.2434,
      "step": 1819
    },
    {
      "epoch": 0.17157275021026072,
      "grad_norm": 1.68359375,
      "learning_rate": 9.998596666572668e-06,
      "loss": 0.4581,
      "step": 1836
    },
    {
      "epoch": 0.17316138678628165,
      "grad_norm": 0.09356689453125,
      "learning_rate": 9.998381562284999e-06,
      "loss": 0.5137,
      "step": 1853
    },
    {
      "epoch": 0.17475002336230258,
      "grad_norm": 1.197265625,
      "learning_rate": 9.998151129039005e-06,
      "loss": 0.2999,
      "step": 1870
    },
    {
      "epoch": 0.1763386599383235,
      "grad_norm": 1.2822265625,
      "learning_rate": 9.997905367541374e-06,
      "loss": 0.4893,
      "step": 1887
    },
    {
      "epoch": 0.17792729651434444,
      "grad_norm": 0.406005859375,
      "learning_rate": 9.997644278545805e-06,
      "loss": 0.4657,
      "step": 1904
    },
    {
      "epoch": 0.1795159330903654,
      "grad_norm": 1.0361328125,
      "learning_rate": 9.997367862853e-06,
      "loss": 0.2577,
      "step": 1921
    },
    {
      "epoch": 0.18110456966638633,
      "grad_norm": 1.94921875,
      "learning_rate": 9.997076121310668e-06,
      "loss": 0.4479,
      "step": 1938
    },
    {
      "epoch": 0.18269320624240726,
      "grad_norm": 0.51708984375,
      "learning_rate": 9.996769054813517e-06,
      "loss": 0.4454,
      "step": 1955
    },
    {
      "epoch": 0.1842818428184282,
      "grad_norm": 1.0224609375,
      "learning_rate": 9.996446664303252e-06,
      "loss": 0.2745,
      "step": 1972
    },
    {
      "epoch": 0.18587047939444912,
      "grad_norm": 1.5078125,
      "learning_rate": 9.996108950768579e-06,
      "loss": 0.5063,
      "step": 1989
    },
    {
      "epoch": 0.18745911597047005,
      "grad_norm": 0.59130859375,
      "learning_rate": 9.995755915245187e-06,
      "loss": 0.4971,
      "step": 2006
    },
    {
      "epoch": 0.18904775254649098,
      "grad_norm": 1.302734375,
      "learning_rate": 9.995387558815764e-06,
      "loss": 0.2852,
      "step": 2023
    },
    {
      "epoch": 0.1906363891225119,
      "grad_norm": 1.7626953125,
      "learning_rate": 9.99500388260998e-06,
      "loss": 0.4934,
      "step": 2040
    },
    {
      "epoch": 0.19222502569853284,
      "grad_norm": 0.47216796875,
      "learning_rate": 9.994604887804484e-06,
      "loss": 0.4508,
      "step": 2057
    },
    {
      "epoch": 0.19381366227455377,
      "grad_norm": 1.041015625,
      "learning_rate": 9.99419057562291e-06,
      "loss": 0.3276,
      "step": 2074
    },
    {
      "epoch": 0.19540229885057472,
      "grad_norm": 1.5029296875,
      "learning_rate": 9.993760947335863e-06,
      "loss": 0.5077,
      "step": 2091
    },
    {
      "epoch": 0.19699093542659565,
      "grad_norm": 0.638671875,
      "learning_rate": 9.99331600426092e-06,
      "loss": 0.4407,
      "step": 2108
    },
    {
      "epoch": 0.19857957200261658,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.992855747762625e-06,
      "loss": 0.3315,
      "step": 2125
    },
    {
      "epoch": 0.2001682085786375,
      "grad_norm": 1.5556640625,
      "learning_rate": 9.992380179252487e-06,
      "loss": 0.5101,
      "step": 2142
    },
    {
      "epoch": 0.20175684515465844,
      "grad_norm": 0.708984375,
      "learning_rate": 9.991889300188971e-06,
      "loss": 0.4032,
      "step": 2159
    },
    {
      "epoch": 0.20334548173067937,
      "grad_norm": 1.126953125,
      "learning_rate": 9.991383112077498e-06,
      "loss": 0.3304,
      "step": 2176
    },
    {
      "epoch": 0.2049341183067003,
      "grad_norm": 1.6201171875,
      "learning_rate": 9.990861616470434e-06,
      "loss": 0.5363,
      "step": 2193
    },
    {
      "epoch": 0.20652275488272123,
      "grad_norm": 0.74267578125,
      "learning_rate": 9.990324814967101e-06,
      "loss": 0.4124,
      "step": 2210
    },
    {
      "epoch": 0.20811139145874216,
      "grad_norm": 1.119140625,
      "learning_rate": 9.989772709213747e-06,
      "loss": 0.3725,
      "step": 2227
    },
    {
      "epoch": 0.20970002803476312,
      "grad_norm": 1.853515625,
      "learning_rate": 9.989205300903563e-06,
      "loss": 0.5147,
      "step": 2244
    },
    {
      "epoch": 0.21128866461078405,
      "grad_norm": 0.66015625,
      "learning_rate": 9.98862259177667e-06,
      "loss": 0.328,
      "step": 2261
    },
    {
      "epoch": 0.21287730118680498,
      "grad_norm": 1.2216796875,
      "learning_rate": 9.988024583620108e-06,
      "loss": 0.3662,
      "step": 2278
    },
    {
      "epoch": 0.2144659377628259,
      "grad_norm": 1.9306640625,
      "learning_rate": 9.987411278267842e-06,
      "loss": 0.5264,
      "step": 2295
    },
    {
      "epoch": 0.21605457433884684,
      "grad_norm": 0.82861328125,
      "learning_rate": 9.986782677600747e-06,
      "loss": 0.3458,
      "step": 2312
    },
    {
      "epoch": 0.21764321091486777,
      "grad_norm": 1.4697265625,
      "learning_rate": 9.986138783546603e-06,
      "loss": 0.4036,
      "step": 2329
    },
    {
      "epoch": 0.2192318474908887,
      "grad_norm": 2.091796875,
      "learning_rate": 9.985479598080095e-06,
      "loss": 0.561,
      "step": 2346
    },
    {
      "epoch": 0.22082048406690963,
      "grad_norm": 0.64453125,
      "learning_rate": 9.984805123222804e-06,
      "loss": 0.2843,
      "step": 2363
    },
    {
      "epoch": 0.22240912064293056,
      "grad_norm": 1.4150390625,
      "learning_rate": 9.9841153610432e-06,
      "loss": 0.3401,
      "step": 2380
    },
    {
      "epoch": 0.2239977572189515,
      "grad_norm": 1.7470703125,
      "learning_rate": 9.983410313656633e-06,
      "loss": 0.5495,
      "step": 2397
    },
    {
      "epoch": 0.22558639379497245,
      "grad_norm": 0.7314453125,
      "learning_rate": 9.98268998322533e-06,
      "loss": 0.2932,
      "step": 2414
    },
    {
      "epoch": 0.22717503037099337,
      "grad_norm": 1.6337890625,
      "learning_rate": 9.981954371958392e-06,
      "loss": 0.4074,
      "step": 2431
    },
    {
      "epoch": 0.2287636669470143,
      "grad_norm": 2.181640625,
      "learning_rate": 9.981203482111779e-06,
      "loss": 0.5556,
      "step": 2448
    },
    {
      "epoch": 0.23035230352303523,
      "grad_norm": 0.88818359375,
      "learning_rate": 9.980437315988307e-06,
      "loss": 0.2335,
      "step": 2465
    },
    {
      "epoch": 0.23194094009905616,
      "grad_norm": 1.58984375,
      "learning_rate": 9.979655875937644e-06,
      "loss": 0.4066,
      "step": 2482
    },
    {
      "epoch": 0.2335295766750771,
      "grad_norm": 3.404296875,
      "learning_rate": 9.978859164356298e-06,
      "loss": 0.5986,
      "step": 2499
    },
    {
      "epoch": 0.23511821325109802,
      "grad_norm": 0.970703125,
      "learning_rate": 9.97804718368761e-06,
      "loss": 0.2273,
      "step": 2516
    },
    {
      "epoch": 0.23670684982711895,
      "grad_norm": 1.6474609375,
      "learning_rate": 9.977219936421749e-06,
      "loss": 0.3798,
      "step": 2533
    },
    {
      "epoch": 0.23829548640313988,
      "grad_norm": 2.923828125,
      "learning_rate": 9.976377425095708e-06,
      "loss": 0.5819,
      "step": 2550
    },
    {
      "epoch": 0.2398841229791608,
      "grad_norm": 0.83837890625,
      "learning_rate": 9.975519652293284e-06,
      "loss": 0.2694,
      "step": 2567
    },
    {
      "epoch": 0.24147275955518177,
      "grad_norm": 1.5986328125,
      "learning_rate": 9.974646620645083e-06,
      "loss": 0.3822,
      "step": 2584
    },
    {
      "epoch": 0.2430613961312027,
      "grad_norm": 0.404052734375,
      "learning_rate": 9.973758332828504e-06,
      "loss": 0.5388,
      "step": 2601
    },
    {
      "epoch": 0.24465003270722363,
      "grad_norm": 1.015625,
      "learning_rate": 9.972854791567734e-06,
      "loss": 0.2384,
      "step": 2618
    },
    {
      "epoch": 0.24623866928324456,
      "grad_norm": 1.779296875,
      "learning_rate": 9.97193599963374e-06,
      "loss": 0.4567,
      "step": 2635
    },
    {
      "epoch": 0.2478273058592655,
      "grad_norm": 0.463134765625,
      "learning_rate": 9.971001959844257e-06,
      "loss": 0.5347,
      "step": 2652
    },
    {
      "epoch": 0.24941594243528642,
      "grad_norm": 1.205078125,
      "learning_rate": 9.970052675063787e-06,
      "loss": 0.2553,
      "step": 2669
    },
    {
      "epoch": 0.25100457901130735,
      "grad_norm": 1.7578125,
      "learning_rate": 9.969088148203579e-06,
      "loss": 0.4713,
      "step": 2686
    },
    {
      "epoch": 0.2525932155873283,
      "grad_norm": 0.403076171875,
      "learning_rate": 9.968108382221627e-06,
      "loss": 0.5314,
      "step": 2703
    },
    {
      "epoch": 0.2541818521633492,
      "grad_norm": 0.98291015625,
      "learning_rate": 9.967113380122666e-06,
      "loss": 0.2274,
      "step": 2720
    },
    {
      "epoch": 0.25577048873937014,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.966103144958152e-06,
      "loss": 0.4455,
      "step": 2737
    },
    {
      "epoch": 0.25735912531539107,
      "grad_norm": 0.466552734375,
      "learning_rate": 9.965077679826256e-06,
      "loss": 0.4896,
      "step": 2754
    },
    {
      "epoch": 0.258947761891412,
      "grad_norm": 1.0419921875,
      "learning_rate": 9.964036987871861e-06,
      "loss": 0.2658,
      "step": 2771
    },
    {
      "epoch": 0.26053639846743293,
      "grad_norm": 2.078125,
      "learning_rate": 9.962981072286545e-06,
      "loss": 0.4868,
      "step": 2788
    },
    {
      "epoch": 0.26212503504345386,
      "grad_norm": 1.203125,
      "learning_rate": 9.96190993630857e-06,
      "loss": 0.4055,
      "step": 2805
    },
    {
      "epoch": 0.26371367161947484,
      "grad_norm": 1.0390625,
      "learning_rate": 9.96082358322288e-06,
      "loss": 0.2543,
      "step": 2822
    },
    {
      "epoch": 0.2653023081954958,
      "grad_norm": 2.037109375,
      "learning_rate": 9.95972201636109e-06,
      "loss": 0.4767,
      "step": 2839
    },
    {
      "epoch": 0.2668909447715167,
      "grad_norm": 0.67431640625,
      "learning_rate": 9.958605239101463e-06,
      "loss": 0.4612,
      "step": 2856
    },
    {
      "epoch": 0.26847958134753763,
      "grad_norm": 1.0087890625,
      "learning_rate": 9.957473254868917e-06,
      "loss": 0.2772,
      "step": 2873
    },
    {
      "epoch": 0.27006821792355856,
      "grad_norm": 1.63671875,
      "learning_rate": 9.956326067135002e-06,
      "loss": 0.5177,
      "step": 2890
    },
    {
      "epoch": 0.2716568544995795,
      "grad_norm": 0.48583984375,
      "learning_rate": 9.955163679417896e-06,
      "loss": 0.4457,
      "step": 2907
    },
    {
      "epoch": 0.2732454910756004,
      "grad_norm": 1.255859375,
      "learning_rate": 9.95398609528239e-06,
      "loss": 0.3055,
      "step": 2924
    },
    {
      "epoch": 0.27483412765162135,
      "grad_norm": 1.7099609375,
      "learning_rate": 9.952793318339884e-06,
      "loss": 0.5562,
      "step": 2941
    },
    {
      "epoch": 0.2764227642276423,
      "grad_norm": 0.6337890625,
      "learning_rate": 9.951585352248365e-06,
      "loss": 0.3751,
      "step": 2958
    },
    {
      "epoch": 0.2780114008036632,
      "grad_norm": 1.15625,
      "learning_rate": 9.950362200712405e-06,
      "loss": 0.2979,
      "step": 2975
    },
    {
      "epoch": 0.27960003737968414,
      "grad_norm": 2.228515625,
      "learning_rate": 9.949123867483146e-06,
      "loss": 0.5297,
      "step": 2992
    },
    {
      "epoch": 0.28118867395570507,
      "grad_norm": 0.65283203125,
      "learning_rate": 9.947870356358287e-06,
      "loss": 0.3912,
      "step": 3009
    },
    {
      "epoch": 0.282777310531726,
      "grad_norm": 1.6064453125,
      "learning_rate": 9.94660167118208e-06,
      "loss": 0.3376,
      "step": 3026
    },
    {
      "epoch": 0.28436594710774693,
      "grad_norm": 2.18359375,
      "learning_rate": 9.945317815845307e-06,
      "loss": 0.5291,
      "step": 3043
    },
    {
      "epoch": 0.28595458368376786,
      "grad_norm": 0.93701171875,
      "learning_rate": 9.944018794285276e-06,
      "loss": 0.4249,
      "step": 3060
    },
    {
      "epoch": 0.2875432202597888,
      "grad_norm": 1.7197265625,
      "learning_rate": 9.942704610485803e-06,
      "loss": 0.3531,
      "step": 3077
    },
    {
      "epoch": 0.2891318568358097,
      "grad_norm": 2.181640625,
      "learning_rate": 9.94137526847721e-06,
      "loss": 0.5112,
      "step": 3094
    },
    {
      "epoch": 0.29072049341183065,
      "grad_norm": 0.533203125,
      "learning_rate": 9.940030772336303e-06,
      "loss": 0.3746,
      "step": 3111
    },
    {
      "epoch": 0.2923091299878516,
      "grad_norm": 1.5009765625,
      "learning_rate": 9.938671126186358e-06,
      "loss": 0.3515,
      "step": 3128
    },
    {
      "epoch": 0.2938977665638725,
      "grad_norm": 1.9814453125,
      "learning_rate": 9.93729633419712e-06,
      "loss": 0.4941,
      "step": 3145
    },
    {
      "epoch": 0.2954864031398935,
      "grad_norm": 0.79736328125,
      "learning_rate": 9.935906400584777e-06,
      "loss": 0.3307,
      "step": 3162
    },
    {
      "epoch": 0.2970750397159144,
      "grad_norm": 1.5244140625,
      "learning_rate": 9.934501329611957e-06,
      "loss": 0.3344,
      "step": 3179
    },
    {
      "epoch": 0.29866367629193535,
      "grad_norm": 2.0078125,
      "learning_rate": 9.933081125587706e-06,
      "loss": 0.5522,
      "step": 3196
    },
    {
      "epoch": 0.3002523128679563,
      "grad_norm": 0.96484375,
      "learning_rate": 9.93164579286749e-06,
      "loss": 0.3031,
      "step": 3213
    },
    {
      "epoch": 0.3018409494439772,
      "grad_norm": 1.4365234375,
      "learning_rate": 9.930195335853161e-06,
      "loss": 0.3945,
      "step": 3230
    },
    {
      "epoch": 0.30342958601999814,
      "grad_norm": 2.33984375,
      "learning_rate": 9.928729758992959e-06,
      "loss": 0.6077,
      "step": 3247
    },
    {
      "epoch": 0.3050182225960191,
      "grad_norm": 0.837890625,
      "learning_rate": 9.92724906678149e-06,
      "loss": 0.287,
      "step": 3264
    },
    {
      "epoch": 0.30660685917204,
      "grad_norm": 1.21875,
      "learning_rate": 9.92575326375972e-06,
      "loss": 0.3536,
      "step": 3281
    },
    {
      "epoch": 0.30819549574806093,
      "grad_norm": 2.48828125,
      "learning_rate": 9.924242354514953e-06,
      "loss": 0.5431,
      "step": 3298
    },
    {
      "epoch": 0.30978413232408186,
      "grad_norm": 0.775390625,
      "learning_rate": 9.922716343680823e-06,
      "loss": 0.2308,
      "step": 3315
    },
    {
      "epoch": 0.3113727689001028,
      "grad_norm": 1.4072265625,
      "learning_rate": 9.921175235937274e-06,
      "loss": 0.3154,
      "step": 3332
    },
    {
      "epoch": 0.3129614054761237,
      "grad_norm": 2.732421875,
      "learning_rate": 9.919619036010556e-06,
      "loss": 0.5608,
      "step": 3349
    },
    {
      "epoch": 0.31455004205214465,
      "grad_norm": 0.85400390625,
      "learning_rate": 9.918047748673194e-06,
      "loss": 0.206,
      "step": 3366
    },
    {
      "epoch": 0.3161386786281656,
      "grad_norm": 1.517578125,
      "learning_rate": 9.916461378743986e-06,
      "loss": 0.408,
      "step": 3383
    },
    {
      "epoch": 0.3177273152041865,
      "grad_norm": 3.0859375,
      "learning_rate": 9.914859931087992e-06,
      "loss": 0.6006,
      "step": 3400
    },
    {
      "epoch": 0.31931595178020744,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.913243410616502e-06,
      "loss": 0.2072,
      "step": 3417
    },
    {
      "epoch": 0.32090458835622837,
      "grad_norm": 1.5771484375,
      "learning_rate": 9.911611822287039e-06,
      "loss": 0.3664,
      "step": 3434
    },
    {
      "epoch": 0.3224932249322493,
      "grad_norm": 0.478271484375,
      "learning_rate": 9.909965171103331e-06,
      "loss": 0.5675,
      "step": 3451
    },
    {
      "epoch": 0.32408186150827023,
      "grad_norm": 1.4599609375,
      "learning_rate": 9.9083034621153e-06,
      "loss": 0.2956,
      "step": 3468
    },
    {
      "epoch": 0.32567049808429116,
      "grad_norm": 1.916015625,
      "learning_rate": 9.906626700419053e-06,
      "loss": 0.508,
      "step": 3485
    },
    {
      "epoch": 0.32725913466031215,
      "grad_norm": 0.2264404296875,
      "learning_rate": 9.904934891156852e-06,
      "loss": 0.5779,
      "step": 3502
    },
    {
      "epoch": 0.3288477712363331,
      "grad_norm": 0.9326171875,
      "learning_rate": 9.903228039517116e-06,
      "loss": 0.2653,
      "step": 3519
    },
    {
      "epoch": 0.330436407812354,
      "grad_norm": 1.8564453125,
      "learning_rate": 9.901506150734388e-06,
      "loss": 0.4316,
      "step": 3536
    },
    {
      "epoch": 0.33202504438837493,
      "grad_norm": 0.2393798828125,
      "learning_rate": 9.89976923008933e-06,
      "loss": 0.5253,
      "step": 3553
    },
    {
      "epoch": 0.33361368096439586,
      "grad_norm": 1.1494140625,
      "learning_rate": 9.898017282908703e-06,
      "loss": 0.2703,
      "step": 3570
    },
    {
      "epoch": 0.3352023175404168,
      "grad_norm": 1.39453125,
      "learning_rate": 9.896250314565353e-06,
      "loss": 0.4118,
      "step": 3587
    },
    {
      "epoch": 0.3367909541164377,
      "grad_norm": 0.1776123046875,
      "learning_rate": 9.894468330478189e-06,
      "loss": 0.4546,
      "step": 3604
    },
    {
      "epoch": 0.33837959069245865,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.892671336112172e-06,
      "loss": 0.2198,
      "step": 3621
    },
    {
      "epoch": 0.3399682272684796,
      "grad_norm": 1.54296875,
      "learning_rate": 9.890859336978295e-06,
      "loss": 0.4696,
      "step": 3638
    },
    {
      "epoch": 0.3415568638445005,
      "grad_norm": 0.5634765625,
      "learning_rate": 9.889032338633571e-06,
      "loss": 0.4633,
      "step": 3655
    },
    {
      "epoch": 0.34314550042052144,
      "grad_norm": 1.216796875,
      "learning_rate": 9.887190346681009e-06,
      "loss": 0.2919,
      "step": 3672
    },
    {
      "epoch": 0.3447341369965424,
      "grad_norm": 1.935546875,
      "learning_rate": 9.8853333667696e-06,
      "loss": 0.4891,
      "step": 3689
    },
    {
      "epoch": 0.3463227735725633,
      "grad_norm": 0.81494140625,
      "learning_rate": 9.883461404594303e-06,
      "loss": 0.4659,
      "step": 3706
    },
    {
      "epoch": 0.34791141014858423,
      "grad_norm": 1.5263671875,
      "learning_rate": 9.881574465896022e-06,
      "loss": 0.3132,
      "step": 3723
    },
    {
      "epoch": 0.34950004672460516,
      "grad_norm": 1.98046875,
      "learning_rate": 9.879672556461588e-06,
      "loss": 0.4814,
      "step": 3740
    },
    {
      "epoch": 0.3510886833006261,
      "grad_norm": 0.77783203125,
      "learning_rate": 9.877755682123751e-06,
      "loss": 0.4218,
      "step": 3757
    },
    {
      "epoch": 0.352677319876647,
      "grad_norm": 1.412109375,
      "learning_rate": 9.875823848761148e-06,
      "loss": 0.3357,
      "step": 3774
    },
    {
      "epoch": 0.35426595645266795,
      "grad_norm": 2.35546875,
      "learning_rate": 9.873877062298298e-06,
      "loss": 0.4997,
      "step": 3791
    },
    {
      "epoch": 0.3558545930286889,
      "grad_norm": 0.751953125,
      "learning_rate": 9.871915328705574e-06,
      "loss": 0.411,
      "step": 3808
    },
    {
      "epoch": 0.35744322960470987,
      "grad_norm": 1.3388671875,
      "learning_rate": 9.869938653999191e-06,
      "loss": 0.3062,
      "step": 3825
    },
    {
      "epoch": 0.3590318661807308,
      "grad_norm": 2.27734375,
      "learning_rate": 9.867947044241182e-06,
      "loss": 0.5262,
      "step": 3842
    },
    {
      "epoch": 0.3606205027567517,
      "grad_norm": 0.72705078125,
      "learning_rate": 9.865940505539386e-06,
      "loss": 0.5616,
      "step": 3859
    },
    {
      "epoch": 0.36220913933277266,
      "grad_norm": 1.3564453125,
      "learning_rate": 9.863919044047423e-06,
      "loss": 0.3186,
      "step": 3876
    },
    {
      "epoch": 0.3637977759087936,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.861882665964681e-06,
      "loss": 0.5198,
      "step": 3893
    },
    {
      "epoch": 0.3653864124848145,
      "grad_norm": 0.69873046875,
      "learning_rate": 9.859831377536293e-06,
      "loss": 0.3628,
      "step": 3910
    },
    {
      "epoch": 0.36697504906083545,
      "grad_norm": 1.1484375,
      "learning_rate": 9.857765185053116e-06,
      "loss": 0.3079,
      "step": 3927
    },
    {
      "epoch": 0.3685636856368564,
      "grad_norm": 2.169921875,
      "learning_rate": 9.85568409485172e-06,
      "loss": 0.545,
      "step": 3944
    },
    {
      "epoch": 0.3701523222128773,
      "grad_norm": 0.6591796875,
      "learning_rate": 9.853588113314354e-06,
      "loss": 0.3379,
      "step": 3961
    },
    {
      "epoch": 0.37174095878889823,
      "grad_norm": 1.201171875,
      "learning_rate": 9.851477246868948e-06,
      "loss": 0.352,
      "step": 3978
    },
    {
      "epoch": 0.37332959536491916,
      "grad_norm": 1.83203125,
      "learning_rate": 9.84935150198907e-06,
      "loss": 0.5088,
      "step": 3995
    },
    {
      "epoch": 0.3749182319409401,
      "grad_norm": 0.7421875,
      "learning_rate": 9.847210885193925e-06,
      "loss": 0.3166,
      "step": 4012
    },
    {
      "epoch": 0.376506868516961,
      "grad_norm": 1.2998046875,
      "learning_rate": 9.845055403048319e-06,
      "loss": 0.3658,
      "step": 4029
    },
    {
      "epoch": 0.37809550509298195,
      "grad_norm": 2.263671875,
      "learning_rate": 9.842885062162653e-06,
      "loss": 0.5306,
      "step": 4046
    },
    {
      "epoch": 0.3796841416690029,
      "grad_norm": 0.77783203125,
      "learning_rate": 9.840699869192894e-06,
      "loss": 0.2993,
      "step": 4063
    },
    {
      "epoch": 0.3812727782450238,
      "grad_norm": 1.36328125,
      "learning_rate": 9.838499830840555e-06,
      "loss": 0.3392,
      "step": 4080
    },
    {
      "epoch": 0.38286141482104474,
      "grad_norm": 2.095703125,
      "learning_rate": 9.836284953852684e-06,
      "loss": 0.5235,
      "step": 4097
    },
    {
      "epoch": 0.3844500513970657,
      "grad_norm": 0.984375,
      "learning_rate": 9.83405524502183e-06,
      "loss": 0.2942,
      "step": 4114
    },
    {
      "epoch": 0.3860386879730866,
      "grad_norm": 1.484375,
      "learning_rate": 9.831810711186025e-06,
      "loss": 0.3817,
      "step": 4131
    },
    {
      "epoch": 0.38762732454910753,
      "grad_norm": 2.125,
      "learning_rate": 9.829551359228774e-06,
      "loss": 0.5732,
      "step": 4148
    },
    {
      "epoch": 0.3892159611251285,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.827277196079024e-06,
      "loss": 0.2473,
      "step": 4165
    },
    {
      "epoch": 0.39080459770114945,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.824988228711138e-06,
      "loss": 0.4134,
      "step": 4182
    },
    {
      "epoch": 0.3923932342771704,
      "grad_norm": 2.427734375,
      "learning_rate": 9.822684464144888e-06,
      "loss": 0.5259,
      "step": 4199
    },
    {
      "epoch": 0.3939818708531913,
      "grad_norm": 0.86669921875,
      "learning_rate": 9.820365909445422e-06,
      "loss": 0.2343,
      "step": 4216
    },
    {
      "epoch": 0.39557050742921224,
      "grad_norm": 1.2109375,
      "learning_rate": 9.818032571723249e-06,
      "loss": 0.3131,
      "step": 4233
    },
    {
      "epoch": 0.39715914400523317,
      "grad_norm": 2.55859375,
      "learning_rate": 9.815684458134212e-06,
      "loss": 0.5624,
      "step": 4250
    },
    {
      "epoch": 0.3987477805812541,
      "grad_norm": 0.87548828125,
      "learning_rate": 9.813321575879466e-06,
      "loss": 0.1775,
      "step": 4267
    },
    {
      "epoch": 0.400336417157275,
      "grad_norm": 1.50390625,
      "learning_rate": 9.810943932205465e-06,
      "loss": 0.4143,
      "step": 4284
    },
    {
      "epoch": 0.40192505373329596,
      "grad_norm": 0.337158203125,
      "learning_rate": 9.808551534403929e-06,
      "loss": 0.5695,
      "step": 4301
    },
    {
      "epoch": 0.4035136903093169,
      "grad_norm": 0.8671875,
      "learning_rate": 9.806144389811824e-06,
      "loss": 0.2241,
      "step": 4318
    },
    {
      "epoch": 0.4051023268853378,
      "grad_norm": 1.6708984375,
      "learning_rate": 9.803722505811348e-06,
      "loss": 0.4214,
      "step": 4335
    },
    {
      "epoch": 0.40669096346135875,
      "grad_norm": 0.418701171875,
      "learning_rate": 9.80128588982989e-06,
      "loss": 0.5379,
      "step": 4352
    },
    {
      "epoch": 0.4082796000373797,
      "grad_norm": 1.02734375,
      "learning_rate": 9.798834549340031e-06,
      "loss": 0.2635,
      "step": 4369
    },
    {
      "epoch": 0.4098682366134006,
      "grad_norm": 1.45703125,
      "learning_rate": 9.796368491859502e-06,
      "loss": 0.4358,
      "step": 4386
    },
    {
      "epoch": 0.41145687318942153,
      "grad_norm": 0.37548828125,
      "learning_rate": 9.79388772495117e-06,
      "loss": 0.4854,
      "step": 4403
    },
    {
      "epoch": 0.41304550976544246,
      "grad_norm": 1.1064453125,
      "learning_rate": 9.791392256223012e-06,
      "loss": 0.2499,
      "step": 4420
    },
    {
      "epoch": 0.4146341463414634,
      "grad_norm": 1.810546875,
      "learning_rate": 9.788882093328089e-06,
      "loss": 0.4545,
      "step": 4437
    },
    {
      "epoch": 0.4162227829174843,
      "grad_norm": 0.265625,
      "learning_rate": 9.786357243964534e-06,
      "loss": 0.4673,
      "step": 4454
    },
    {
      "epoch": 0.41781141949350525,
      "grad_norm": 0.91455078125,
      "learning_rate": 9.783817715875517e-06,
      "loss": 0.2094,
      "step": 4471
    },
    {
      "epoch": 0.41940005606952624,
      "grad_norm": 1.876953125,
      "learning_rate": 9.781263516849216e-06,
      "loss": 0.402,
      "step": 4488
    },
    {
      "epoch": 0.42098869264554717,
      "grad_norm": 0.4345703125,
      "learning_rate": 9.778694654718813e-06,
      "loss": 0.4357,
      "step": 4505
    },
    {
      "epoch": 0.4225773292215681,
      "grad_norm": 0.8837890625,
      "learning_rate": 9.776111137362453e-06,
      "loss": 0.2856,
      "step": 4522
    },
    {
      "epoch": 0.42416596579758903,
      "grad_norm": 1.7802734375,
      "learning_rate": 9.77351297270323e-06,
      "loss": 0.4591,
      "step": 4539
    },
    {
      "epoch": 0.42575460237360996,
      "grad_norm": 0.72216796875,
      "learning_rate": 9.77090016870915e-06,
      "loss": 0.407,
      "step": 4556
    },
    {
      "epoch": 0.4273432389496309,
      "grad_norm": 1.265625,
      "learning_rate": 9.768272733393121e-06,
      "loss": 0.2999,
      "step": 4573
    },
    {
      "epoch": 0.4289318755256518,
      "grad_norm": 1.7109375,
      "learning_rate": 9.765630674812921e-06,
      "loss": 0.4681,
      "step": 4590
    },
    {
      "epoch": 0.43052051210167275,
      "grad_norm": 0.53076171875,
      "learning_rate": 9.762974001071175e-06,
      "loss": 0.363,
      "step": 4607
    },
    {
      "epoch": 0.4321091486776937,
      "grad_norm": 1.25390625,
      "learning_rate": 9.760302720315325e-06,
      "loss": 0.3099,
      "step": 4624
    },
    {
      "epoch": 0.4336977852537146,
      "grad_norm": 1.927734375,
      "learning_rate": 9.757616840737615e-06,
      "loss": 0.5074,
      "step": 4641
    },
    {
      "epoch": 0.43528642182973554,
      "grad_norm": 0.5927734375,
      "learning_rate": 9.75491637057506e-06,
      "loss": 0.4154,
      "step": 4658
    },
    {
      "epoch": 0.43687505840575647,
      "grad_norm": 1.4169921875,
      "learning_rate": 9.752201318109417e-06,
      "loss": 0.2808,
      "step": 4675
    },
    {
      "epoch": 0.4384636949817774,
      "grad_norm": 1.607421875,
      "learning_rate": 9.74947169166717e-06,
      "loss": 0.4569,
      "step": 4692
    },
    {
      "epoch": 0.4400523315577983,
      "grad_norm": 0.8046875,
      "learning_rate": 9.74672749961949e-06,
      "loss": 0.3568,
      "step": 4709
    },
    {
      "epoch": 0.44164096813381926,
      "grad_norm": 1.384765625,
      "learning_rate": 9.743968750382225e-06,
      "loss": 0.3673,
      "step": 4726
    },
    {
      "epoch": 0.4432296047098402,
      "grad_norm": 1.8779296875,
      "learning_rate": 9.741195452415864e-06,
      "loss": 0.4955,
      "step": 4743
    },
    {
      "epoch": 0.4448182412858611,
      "grad_norm": 0.59130859375,
      "learning_rate": 9.738407614225512e-06,
      "loss": 0.3545,
      "step": 4760
    },
    {
      "epoch": 0.44640687786188205,
      "grad_norm": 1.2578125,
      "learning_rate": 9.735605244360868e-06,
      "loss": 0.3063,
      "step": 4777
    },
    {
      "epoch": 0.447995514437903,
      "grad_norm": 2.44921875,
      "learning_rate": 9.732788351416197e-06,
      "loss": 0.5086,
      "step": 4794
    },
    {
      "epoch": 0.4495841510139239,
      "grad_norm": 0.75634765625,
      "learning_rate": 9.729956944030303e-06,
      "loss": 0.324,
      "step": 4811
    },
    {
      "epoch": 0.4511727875899449,
      "grad_norm": 1.388671875,
      "learning_rate": 9.7271110308865e-06,
      "loss": 0.3301,
      "step": 4828
    },
    {
      "epoch": 0.4527614241659658,
      "grad_norm": 2.08984375,
      "learning_rate": 9.724250620712592e-06,
      "loss": 0.5004,
      "step": 4845
    },
    {
      "epoch": 0.45435006074198675,
      "grad_norm": 0.806640625,
      "learning_rate": 9.721375722280837e-06,
      "loss": 0.3057,
      "step": 4862
    },
    {
      "epoch": 0.4559386973180077,
      "grad_norm": 1.91796875,
      "learning_rate": 9.718486344407932e-06,
      "loss": 0.4073,
      "step": 4879
    },
    {
      "epoch": 0.4575273338940286,
      "grad_norm": 2.13671875,
      "learning_rate": 9.715582495954972e-06,
      "loss": 0.5447,
      "step": 4896
    },
    {
      "epoch": 0.45911597047004954,
      "grad_norm": 0.75048828125,
      "learning_rate": 9.712664185827437e-06,
      "loss": 0.2754,
      "step": 4913
    },
    {
      "epoch": 0.46070460704607047,
      "grad_norm": 1.1904296875,
      "learning_rate": 9.709731422975155e-06,
      "loss": 0.3766,
      "step": 4930
    },
    {
      "epoch": 0.4622932436220914,
      "grad_norm": 1.98828125,
      "learning_rate": 9.706784216392274e-06,
      "loss": 0.4748,
      "step": 4947
    },
    {
      "epoch": 0.46388188019811233,
      "grad_norm": 0.8525390625,
      "learning_rate": 9.703822575117243e-06,
      "loss": 0.2786,
      "step": 4964
    },
    {
      "epoch": 0.46547051677413326,
      "grad_norm": 1.5380859375,
      "learning_rate": 9.700846508232778e-06,
      "loss": 0.3988,
      "step": 4981
    },
    {
      "epoch": 0.4670591533501542,
      "grad_norm": 2.5,
      "learning_rate": 9.697856024865835e-06,
      "loss": 0.5408,
      "step": 4998
    },
    {
      "epoch": 0.4686477899261751,
      "grad_norm": 1.01953125,
      "learning_rate": 9.694851134187578e-06,
      "loss": 0.263,
      "step": 5015
    },
    {
      "epoch": 0.47023642650219605,
      "grad_norm": 1.283203125,
      "learning_rate": 9.691831845413362e-06,
      "loss": 0.3988,
      "step": 5032
    },
    {
      "epoch": 0.471825063078217,
      "grad_norm": 2.224609375,
      "learning_rate": 9.688798167802693e-06,
      "loss": 0.616,
      "step": 5049
    },
    {
      "epoch": 0.4734136996542379,
      "grad_norm": 0.822265625,
      "learning_rate": 9.685750110659206e-06,
      "loss": 0.1851,
      "step": 5066
    },
    {
      "epoch": 0.47500233623025884,
      "grad_norm": 1.2666015625,
      "learning_rate": 9.682687683330636e-06,
      "loss": 0.3746,
      "step": 5083
    },
    {
      "epoch": 0.47659097280627977,
      "grad_norm": 2.953125,
      "learning_rate": 9.679610895208785e-06,
      "loss": 0.6085,
      "step": 5100
    },
    {
      "epoch": 0.4781796093823007,
      "grad_norm": 1.01171875,
      "learning_rate": 9.6765197557295e-06,
      "loss": 0.2046,
      "step": 5117
    },
    {
      "epoch": 0.4797682459583216,
      "grad_norm": 1.6572265625,
      "learning_rate": 9.673414274372641e-06,
      "loss": 0.4254,
      "step": 5134
    },
    {
      "epoch": 0.4813568825343426,
      "grad_norm": 0.4345703125,
      "learning_rate": 9.670294460662048e-06,
      "loss": 0.608,
      "step": 5151
    },
    {
      "epoch": 0.48294551911036354,
      "grad_norm": 0.98974609375,
      "learning_rate": 9.667160324165516e-06,
      "loss": 0.2329,
      "step": 5168
    },
    {
      "epoch": 0.48453415568638447,
      "grad_norm": 1.41015625,
      "learning_rate": 9.664011874494766e-06,
      "loss": 0.3831,
      "step": 5185
    },
    {
      "epoch": 0.4861227922624054,
      "grad_norm": 0.304931640625,
      "learning_rate": 9.660849121305414e-06,
      "loss": 0.5174,
      "step": 5202
    },
    {
      "epoch": 0.48771142883842633,
      "grad_norm": 0.875,
      "learning_rate": 9.657672074296944e-06,
      "loss": 0.2318,
      "step": 5219
    },
    {
      "epoch": 0.48930006541444726,
      "grad_norm": 1.623046875,
      "learning_rate": 9.654480743212672e-06,
      "loss": 0.4244,
      "step": 5236
    },
    {
      "epoch": 0.4908887019904682,
      "grad_norm": 0.19677734375,
      "learning_rate": 9.651275137839723e-06,
      "loss": 0.5229,
      "step": 5253
    },
    {
      "epoch": 0.4924773385664891,
      "grad_norm": 0.9189453125,
      "learning_rate": 9.648055268008997e-06,
      "loss": 0.2287,
      "step": 5270
    },
    {
      "epoch": 0.49406597514251005,
      "grad_norm": 1.62109375,
      "learning_rate": 9.64482114359514e-06,
      "loss": 0.4199,
      "step": 5287
    },
    {
      "epoch": 0.495654611718531,
      "grad_norm": 0.2281494140625,
      "learning_rate": 9.641572774516516e-06,
      "loss": 0.4793,
      "step": 5304
    },
    {
      "epoch": 0.4972432482945519,
      "grad_norm": 1.15625,
      "learning_rate": 9.63831017073517e-06,
      "loss": 0.2725,
      "step": 5321
    },
    {
      "epoch": 0.49883188487057284,
      "grad_norm": 1.7001953125,
      "learning_rate": 9.635033342256805e-06,
      "loss": 0.4374,
      "step": 5338
    },
    {
      "epoch": 0.5004205214465938,
      "grad_norm": 0.433349609375,
      "learning_rate": 9.63174229913075e-06,
      "loss": 0.4318,
      "step": 5355
    },
    {
      "epoch": 0.5020091580226147,
      "grad_norm": 1.046875,
      "learning_rate": 9.62843705144992e-06,
      "loss": 0.2716,
      "step": 5372
    },
    {
      "epoch": 0.5035977945986356,
      "grad_norm": 2.1875,
      "learning_rate": 9.6251176093508e-06,
      "loss": 0.4876,
      "step": 5389
    },
    {
      "epoch": 0.5051864311746566,
      "grad_norm": 0.3447265625,
      "learning_rate": 9.621783983013401e-06,
      "loss": 0.4381,
      "step": 5406
    },
    {
      "epoch": 0.5067750677506775,
      "grad_norm": 1.205078125,
      "learning_rate": 9.618436182661237e-06,
      "loss": 0.285,
      "step": 5423
    },
    {
      "epoch": 0.5083637043266984,
      "grad_norm": 2.310546875,
      "learning_rate": 9.615074218561291e-06,
      "loss": 0.4788,
      "step": 5440
    },
    {
      "epoch": 0.5099523409027193,
      "grad_norm": 0.271728515625,
      "learning_rate": 9.61169810102398e-06,
      "loss": 0.4248,
      "step": 5457
    },
    {
      "epoch": 0.5115409774787403,
      "grad_norm": 0.9267578125,
      "learning_rate": 9.60830784040313e-06,
      "loss": 0.2277,
      "step": 5474
    },
    {
      "epoch": 0.5131296140547612,
      "grad_norm": 1.6455078125,
      "learning_rate": 9.604903447095938e-06,
      "loss": 0.4025,
      "step": 5491
    },
    {
      "epoch": 0.5147182506307821,
      "grad_norm": 0.71240234375,
      "learning_rate": 9.601484931542943e-06,
      "loss": 0.4283,
      "step": 5508
    },
    {
      "epoch": 0.5163068872068031,
      "grad_norm": 1.0087890625,
      "learning_rate": 9.598052304227998e-06,
      "loss": 0.2746,
      "step": 5525
    },
    {
      "epoch": 0.517895523782824,
      "grad_norm": 1.572265625,
      "learning_rate": 9.594605575678228e-06,
      "loss": 0.4994,
      "step": 5542
    },
    {
      "epoch": 0.5194841603588449,
      "grad_norm": 0.568359375,
      "learning_rate": 9.591144756464008e-06,
      "loss": 0.3607,
      "step": 5559
    },
    {
      "epoch": 0.5210727969348659,
      "grad_norm": 1.150390625,
      "learning_rate": 9.587669857198925e-06,
      "loss": 0.3021,
      "step": 5576
    },
    {
      "epoch": 0.5226614335108868,
      "grad_norm": 1.5888671875,
      "learning_rate": 9.584180888539741e-06,
      "loss": 0.4276,
      "step": 5593
    },
    {
      "epoch": 0.5242500700869077,
      "grad_norm": 0.71142578125,
      "learning_rate": 9.580677861186377e-06,
      "loss": 0.3128,
      "step": 5610
    },
    {
      "epoch": 0.5258387066629286,
      "grad_norm": 1.201171875,
      "learning_rate": 9.577160785881855e-06,
      "loss": 0.3417,
      "step": 5627
    },
    {
      "epoch": 0.5274273432389497,
      "grad_norm": 2.05859375,
      "learning_rate": 9.573629673412293e-06,
      "loss": 0.5145,
      "step": 5644
    },
    {
      "epoch": 0.5290159798149706,
      "grad_norm": 0.64208984375,
      "learning_rate": 9.57008453460685e-06,
      "loss": 0.3125,
      "step": 5661
    },
    {
      "epoch": 0.5306046163909915,
      "grad_norm": 1.044921875,
      "learning_rate": 9.5665253803377e-06,
      "loss": 0.3029,
      "step": 5678
    },
    {
      "epoch": 0.5321932529670125,
      "grad_norm": 2.09375,
      "learning_rate": 9.56295222152e-06,
      "loss": 0.515,
      "step": 5695
    },
    {
      "epoch": 0.5337818895430334,
      "grad_norm": 1.0810546875,
      "learning_rate": 9.559365069111864e-06,
      "loss": 0.2806,
      "step": 5712
    },
    {
      "epoch": 0.5353705261190543,
      "grad_norm": 1.3232421875,
      "learning_rate": 9.555763934114309e-06,
      "loss": 0.3166,
      "step": 5729
    },
    {
      "epoch": 0.5369591626950753,
      "grad_norm": 2.236328125,
      "learning_rate": 9.552148827571241e-06,
      "loss": 0.512,
      "step": 5746
    },
    {
      "epoch": 0.5385477992710962,
      "grad_norm": 1.1650390625,
      "learning_rate": 9.548519760569415e-06,
      "loss": 0.3119,
      "step": 5763
    },
    {
      "epoch": 0.5401364358471171,
      "grad_norm": 1.5068359375,
      "learning_rate": 9.544876744238394e-06,
      "loss": 0.36,
      "step": 5780
    },
    {
      "epoch": 0.541725072423138,
      "grad_norm": 2.099609375,
      "learning_rate": 9.541219789750523e-06,
      "loss": 0.5053,
      "step": 5797
    },
    {
      "epoch": 0.543313708999159,
      "grad_norm": 0.79296875,
      "learning_rate": 9.537548908320895e-06,
      "loss": 0.2412,
      "step": 5814
    },
    {
      "epoch": 0.5449023455751799,
      "grad_norm": 1.7060546875,
      "learning_rate": 9.53386411120731e-06,
      "loss": 0.365,
      "step": 5831
    },
    {
      "epoch": 0.5464909821512008,
      "grad_norm": 2.990234375,
      "learning_rate": 9.530165409710246e-06,
      "loss": 0.5525,
      "step": 5848
    },
    {
      "epoch": 0.5480796187272218,
      "grad_norm": 0.857421875,
      "learning_rate": 9.526452815172824e-06,
      "loss": 0.3103,
      "step": 5865
    },
    {
      "epoch": 0.5496682553032427,
      "grad_norm": 1.458984375,
      "learning_rate": 9.52272633898077e-06,
      "loss": 0.4252,
      "step": 5882
    },
    {
      "epoch": 0.5512568918792636,
      "grad_norm": 2.52734375,
      "learning_rate": 9.518985992562383e-06,
      "loss": 0.5485,
      "step": 5899
    },
    {
      "epoch": 0.5528455284552846,
      "grad_norm": 1.2783203125,
      "learning_rate": 9.515231787388499e-06,
      "loss": 0.2215,
      "step": 5916
    },
    {
      "epoch": 0.5544341650313055,
      "grad_norm": 1.2705078125,
      "learning_rate": 9.511463734972456e-06,
      "loss": 0.404,
      "step": 5933
    },
    {
      "epoch": 0.5560228016073264,
      "grad_norm": 2.103515625,
      "learning_rate": 9.507681846870058e-06,
      "loss": 0.5888,
      "step": 5950
    },
    {
      "epoch": 0.5576114381833474,
      "grad_norm": 1.064453125,
      "learning_rate": 9.503886134679539e-06,
      "loss": 0.1894,
      "step": 5967
    },
    {
      "epoch": 0.5592000747593683,
      "grad_norm": 1.091796875,
      "learning_rate": 9.500076610041531e-06,
      "loss": 0.3988,
      "step": 5984
    },
    {
      "epoch": 0.5607887113353892,
      "grad_norm": 0.273681640625,
      "learning_rate": 9.496253284639024e-06,
      "loss": 0.5466,
      "step": 6001
    },
    {
      "epoch": 0.5623773479114101,
      "grad_norm": 1.224609375,
      "learning_rate": 9.492416170197333e-06,
      "loss": 0.2423,
      "step": 6018
    },
    {
      "epoch": 0.5639659844874311,
      "grad_norm": 1.2763671875,
      "learning_rate": 9.48856527848406e-06,
      "loss": 0.3584,
      "step": 6035
    },
    {
      "epoch": 0.565554621063452,
      "grad_norm": 0.37841796875,
      "learning_rate": 9.484700621309059e-06,
      "loss": 0.4996,
      "step": 6052
    },
    {
      "epoch": 0.5671432576394729,
      "grad_norm": 0.9658203125,
      "learning_rate": 9.480822210524402e-06,
      "loss": 0.2162,
      "step": 6069
    },
    {
      "epoch": 0.5687318942154939,
      "grad_norm": 1.4443359375,
      "learning_rate": 9.476930058024338e-06,
      "loss": 0.4194,
      "step": 6086
    },
    {
      "epoch": 0.5703205307915148,
      "grad_norm": 0.08843994140625,
      "learning_rate": 9.473024175745258e-06,
      "loss": 0.5071,
      "step": 6103
    },
    {
      "epoch": 0.5719091673675357,
      "grad_norm": 0.99072265625,
      "learning_rate": 9.46910457566566e-06,
      "loss": 0.1799,
      "step": 6120
    },
    {
      "epoch": 0.5734978039435566,
      "grad_norm": 1.7734375,
      "learning_rate": 9.465171269806114e-06,
      "loss": 0.4229,
      "step": 6137
    },
    {
      "epoch": 0.5750864405195776,
      "grad_norm": 0.373046875,
      "learning_rate": 9.46122427022922e-06,
      "loss": 0.4709,
      "step": 6154
    },
    {
      "epoch": 0.5766750770955985,
      "grad_norm": 1.40625,
      "learning_rate": 9.457263589039575e-06,
      "loss": 0.2852,
      "step": 6171
    },
    {
      "epoch": 0.5782637136716194,
      "grad_norm": 1.541015625,
      "learning_rate": 9.453289238383735e-06,
      "loss": 0.447,
      "step": 6188
    },
    {
      "epoch": 0.5798523502476404,
      "grad_norm": 0.724609375,
      "learning_rate": 9.449301230450173e-06,
      "loss": 0.4427,
      "step": 6205
    },
    {
      "epoch": 0.5814409868236613,
      "grad_norm": 1.2216796875,
      "learning_rate": 9.445299577469252e-06,
      "loss": 0.3075,
      "step": 6222
    },
    {
      "epoch": 0.5830296233996822,
      "grad_norm": 1.857421875,
      "learning_rate": 9.44128429171318e-06,
      "loss": 0.5006,
      "step": 6239
    },
    {
      "epoch": 0.5846182599757032,
      "grad_norm": 0.4912109375,
      "learning_rate": 9.437255385495969e-06,
      "loss": 0.4722,
      "step": 6256
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 1.08203125,
      "learning_rate": 9.433212871173407e-06,
      "loss": 0.319,
      "step": 6273
    },
    {
      "epoch": 0.587795533127745,
      "grad_norm": 1.6484375,
      "learning_rate": 9.429156761143014e-06,
      "loss": 0.4377,
      "step": 6290
    },
    {
      "epoch": 0.589384169703766,
      "grad_norm": 0.51416015625,
      "learning_rate": 9.425087067844005e-06,
      "loss": 0.4439,
      "step": 6307
    },
    {
      "epoch": 0.590972806279787,
      "grad_norm": 0.98046875,
      "learning_rate": 9.421003803757251e-06,
      "loss": 0.2866,
      "step": 6324
    },
    {
      "epoch": 0.5925614428558079,
      "grad_norm": 1.53515625,
      "learning_rate": 9.416906981405242e-06,
      "loss": 0.3949,
      "step": 6341
    },
    {
      "epoch": 0.5941500794318288,
      "grad_norm": 0.654296875,
      "learning_rate": 9.41279661335205e-06,
      "loss": 0.3554,
      "step": 6358
    },
    {
      "epoch": 0.5957387160078498,
      "grad_norm": 1.1337890625,
      "learning_rate": 9.408672712203287e-06,
      "loss": 0.3003,
      "step": 6375
    },
    {
      "epoch": 0.5973273525838707,
      "grad_norm": 2.009765625,
      "learning_rate": 9.404535290606068e-06,
      "loss": 0.5044,
      "step": 6392
    },
    {
      "epoch": 0.5989159891598916,
      "grad_norm": 0.494384765625,
      "learning_rate": 9.400384361248973e-06,
      "loss": 0.363,
      "step": 6409
    },
    {
      "epoch": 0.6000373796841416,
      "eval_loss": 0.38770315051078796,
      "eval_runtime": 1038.5043,
      "eval_samples_per_second": 7.727,
      "eval_steps_per_second": 2.576,
      "step": 6421
    },
    {
      "epoch": 0.6005046257359126,
      "grad_norm": 1.0927734375,
      "learning_rate": 9.396219936862008e-06,
      "loss": 0.2706,
      "step": 6426
    },
    {
      "epoch": 0.6020932623119335,
      "grad_norm": 1.9951171875,
      "learning_rate": 9.392042030216561e-06,
      "loss": 0.4537,
      "step": 6443
    },
    {
      "epoch": 0.6036818988879544,
      "grad_norm": 0.90869140625,
      "learning_rate": 9.387850654125375e-06,
      "loss": 0.3885,
      "step": 6460
    },
    {
      "epoch": 0.6052705354639754,
      "grad_norm": 1.44140625,
      "learning_rate": 9.383645821442495e-06,
      "loss": 0.3306,
      "step": 6477
    },
    {
      "epoch": 0.6068591720399963,
      "grad_norm": 1.9736328125,
      "learning_rate": 9.379427545063236e-06,
      "loss": 0.5751,
      "step": 6494
    },
    {
      "epoch": 0.6084478086160172,
      "grad_norm": 0.7861328125,
      "learning_rate": 9.375195837924142e-06,
      "loss": 0.3031,
      "step": 6511
    },
    {
      "epoch": 0.6100364451920381,
      "grad_norm": 1.482421875,
      "learning_rate": 9.370950713002947e-06,
      "loss": 0.3213,
      "step": 6528
    },
    {
      "epoch": 0.6116250817680591,
      "grad_norm": 2.265625,
      "learning_rate": 9.36669218331853e-06,
      "loss": 0.5077,
      "step": 6545
    },
    {
      "epoch": 0.61321371834408,
      "grad_norm": 0.66064453125,
      "learning_rate": 9.362420261930888e-06,
      "loss": 0.3154,
      "step": 6562
    },
    {
      "epoch": 0.6148023549201009,
      "grad_norm": 1.7568359375,
      "learning_rate": 9.358134961941082e-06,
      "loss": 0.3484,
      "step": 6579
    },
    {
      "epoch": 0.6163909914961219,
      "grad_norm": 2.14453125,
      "learning_rate": 9.353836296491198e-06,
      "loss": 0.5259,
      "step": 6596
    },
    {
      "epoch": 0.6179796280721428,
      "grad_norm": 0.82275390625,
      "learning_rate": 9.349524278764321e-06,
      "loss": 0.2758,
      "step": 6613
    },
    {
      "epoch": 0.6195682646481637,
      "grad_norm": 1.365234375,
      "learning_rate": 9.34519892198448e-06,
      "loss": 0.3363,
      "step": 6630
    },
    {
      "epoch": 0.6211569012241847,
      "grad_norm": 2.11328125,
      "learning_rate": 9.340860239416606e-06,
      "loss": 0.5382,
      "step": 6647
    },
    {
      "epoch": 0.6227455378002056,
      "grad_norm": 1.1103515625,
      "learning_rate": 9.336508244366508e-06,
      "loss": 0.3293,
      "step": 6664
    },
    {
      "epoch": 0.6243341743762265,
      "grad_norm": 1.4619140625,
      "learning_rate": 9.332142950180813e-06,
      "loss": 0.4003,
      "step": 6681
    },
    {
      "epoch": 0.6259228109522474,
      "grad_norm": 2.287109375,
      "learning_rate": 9.32776437024694e-06,
      "loss": 0.5724,
      "step": 6698
    },
    {
      "epoch": 0.6275114475282684,
      "grad_norm": 1.0908203125,
      "learning_rate": 9.323372517993048e-06,
      "loss": 0.2507,
      "step": 6715
    },
    {
      "epoch": 0.6291000841042893,
      "grad_norm": 1.697265625,
      "learning_rate": 9.318967406887997e-06,
      "loss": 0.4369,
      "step": 6732
    },
    {
      "epoch": 0.6306887206803102,
      "grad_norm": 2.794921875,
      "learning_rate": 9.31454905044132e-06,
      "loss": 0.5626,
      "step": 6749
    },
    {
      "epoch": 0.6322773572563312,
      "grad_norm": 0.98974609375,
      "learning_rate": 9.310117462203158e-06,
      "loss": 0.2286,
      "step": 6766
    },
    {
      "epoch": 0.6338659938323521,
      "grad_norm": 1.6181640625,
      "learning_rate": 9.305672655764237e-06,
      "loss": 0.417,
      "step": 6783
    },
    {
      "epoch": 0.635454630408373,
      "grad_norm": 2.64453125,
      "learning_rate": 9.301214644755823e-06,
      "loss": 0.5178,
      "step": 6800
    },
    {
      "epoch": 0.637043266984394,
      "grad_norm": 0.8515625,
      "learning_rate": 9.29674344284967e-06,
      "loss": 0.1778,
      "step": 6817
    },
    {
      "epoch": 0.6386319035604149,
      "grad_norm": 1.44140625,
      "learning_rate": 9.292259063757993e-06,
      "loss": 0.4437,
      "step": 6834
    },
    {
      "epoch": 0.6402205401364358,
      "grad_norm": 0.91552734375,
      "learning_rate": 9.287761521233416e-06,
      "loss": 0.5764,
      "step": 6851
    },
    {
      "epoch": 0.6418091767124567,
      "grad_norm": 1.1669921875,
      "learning_rate": 9.28325082906893e-06,
      "loss": 0.2388,
      "step": 6868
    },
    {
      "epoch": 0.6433978132884777,
      "grad_norm": 1.5703125,
      "learning_rate": 9.278727001097855e-06,
      "loss": 0.4473,
      "step": 6885
    },
    {
      "epoch": 0.6449864498644986,
      "grad_norm": 0.226806640625,
      "learning_rate": 9.274190051193797e-06,
      "loss": 0.5338,
      "step": 6902
    },
    {
      "epoch": 0.6465750864405195,
      "grad_norm": 1.0966796875,
      "learning_rate": 9.269639993270602e-06,
      "loss": 0.2211,
      "step": 6919
    },
    {
      "epoch": 0.6481637230165405,
      "grad_norm": 1.3427734375,
      "learning_rate": 9.265076841282318e-06,
      "loss": 0.4037,
      "step": 6936
    },
    {
      "epoch": 0.6497523595925614,
      "grad_norm": 0.267822265625,
      "learning_rate": 9.260500609223149e-06,
      "loss": 0.4799,
      "step": 6953
    },
    {
      "epoch": 0.6513409961685823,
      "grad_norm": 0.85009765625,
      "learning_rate": 9.255911311127406e-06,
      "loss": 0.2615,
      "step": 6970
    },
    {
      "epoch": 0.6529296327446034,
      "grad_norm": 1.35546875,
      "learning_rate": 9.251308961069483e-06,
      "loss": 0.3903,
      "step": 6987
    },
    {
      "epoch": 0.6545182693206243,
      "grad_norm": 0.348388671875,
      "learning_rate": 9.246693573163792e-06,
      "loss": 0.4429,
      "step": 7004
    },
    {
      "epoch": 0.6561069058966452,
      "grad_norm": 1.3681640625,
      "learning_rate": 9.242065161564733e-06,
      "loss": 0.2546,
      "step": 7021
    },
    {
      "epoch": 0.6576955424726662,
      "grad_norm": 1.6494140625,
      "learning_rate": 9.237423740466647e-06,
      "loss": 0.484,
      "step": 7038
    },
    {
      "epoch": 0.6592841790486871,
      "grad_norm": 0.43603515625,
      "learning_rate": 9.23276932410377e-06,
      "loss": 0.4673,
      "step": 7055
    },
    {
      "epoch": 0.660872815624708,
      "grad_norm": 1.17578125,
      "learning_rate": 9.228101926750194e-06,
      "loss": 0.2579,
      "step": 7072
    },
    {
      "epoch": 0.6624614522007289,
      "grad_norm": 2.033203125,
      "learning_rate": 9.223421562719821e-06,
      "loss": 0.4563,
      "step": 7089
    },
    {
      "epoch": 0.6640500887767499,
      "grad_norm": 0.87646484375,
      "learning_rate": 9.218728246366316e-06,
      "loss": 0.4641,
      "step": 7106
    },
    {
      "epoch": 0.6656387253527708,
      "grad_norm": 0.84814453125,
      "learning_rate": 9.214021992083071e-06,
      "loss": 0.2785,
      "step": 7123
    },
    {
      "epoch": 0.6672273619287917,
      "grad_norm": 2.595703125,
      "learning_rate": 9.20930281430315e-06,
      "loss": 0.5061,
      "step": 7140
    },
    {
      "epoch": 0.6688159985048127,
      "grad_norm": 0.55859375,
      "learning_rate": 9.204570727499256e-06,
      "loss": 0.4073,
      "step": 7157
    },
    {
      "epoch": 0.6704046350808336,
      "grad_norm": 1.083984375,
      "learning_rate": 9.199825746183678e-06,
      "loss": 0.291,
      "step": 7174
    },
    {
      "epoch": 0.6719932716568545,
      "grad_norm": 2.955078125,
      "learning_rate": 9.195067884908248e-06,
      "loss": 0.4732,
      "step": 7191
    },
    {
      "epoch": 0.6735819082328754,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.190297158264302e-06,
      "loss": 0.4065,
      "step": 7208
    },
    {
      "epoch": 0.6751705448088964,
      "grad_norm": 1.3232421875,
      "learning_rate": 9.185513580882633e-06,
      "loss": 0.2948,
      "step": 7225
    },
    {
      "epoch": 0.6767591813849173,
      "grad_norm": 2.03515625,
      "learning_rate": 9.180717167433438e-06,
      "loss": 0.4618,
      "step": 7242
    },
    {
      "epoch": 0.6783478179609382,
      "grad_norm": 0.6484375,
      "learning_rate": 9.175907932626283e-06,
      "loss": 0.3842,
      "step": 7259
    },
    {
      "epoch": 0.6799364545369592,
      "grad_norm": 1.416015625,
      "learning_rate": 9.171085891210054e-06,
      "loss": 0.2983,
      "step": 7276
    },
    {
      "epoch": 0.6815250911129801,
      "grad_norm": 2.076171875,
      "learning_rate": 9.166251057972912e-06,
      "loss": 0.4953,
      "step": 7293
    },
    {
      "epoch": 0.683113727689001,
      "grad_norm": 0.7958984375,
      "learning_rate": 9.161403447742248e-06,
      "loss": 0.3542,
      "step": 7310
    },
    {
      "epoch": 0.684702364265022,
      "grad_norm": 1.345703125,
      "learning_rate": 9.156543075384637e-06,
      "loss": 0.333,
      "step": 7327
    },
    {
      "epoch": 0.6862910008410429,
      "grad_norm": 2.484375,
      "learning_rate": 9.151669955805796e-06,
      "loss": 0.5339,
      "step": 7344
    },
    {
      "epoch": 0.6878796374170638,
      "grad_norm": 0.81591796875,
      "learning_rate": 9.146784103950526e-06,
      "loss": 0.3254,
      "step": 7361
    },
    {
      "epoch": 0.6894682739930847,
      "grad_norm": 1.66796875,
      "learning_rate": 9.141885534802686e-06,
      "loss": 0.3474,
      "step": 7378
    },
    {
      "epoch": 0.6910569105691057,
      "grad_norm": 1.9287109375,
      "learning_rate": 9.136974263385128e-06,
      "loss": 0.4733,
      "step": 7395
    },
    {
      "epoch": 0.6926455471451266,
      "grad_norm": 0.783203125,
      "learning_rate": 9.132050304759666e-06,
      "loss": 0.3208,
      "step": 7412
    },
    {
      "epoch": 0.6942341837211475,
      "grad_norm": 1.4931640625,
      "learning_rate": 9.127113674027013e-06,
      "loss": 0.3582,
      "step": 7429
    },
    {
      "epoch": 0.6958228202971685,
      "grad_norm": 2.431640625,
      "learning_rate": 9.122164386326757e-06,
      "loss": 0.5215,
      "step": 7446
    },
    {
      "epoch": 0.6974114568731894,
      "grad_norm": 1.005859375,
      "learning_rate": 9.117202456837293e-06,
      "loss": 0.2535,
      "step": 7463
    },
    {
      "epoch": 0.6990000934492103,
      "grad_norm": 1.603515625,
      "learning_rate": 9.11222790077579e-06,
      "loss": 0.3575,
      "step": 7480
    },
    {
      "epoch": 0.7005887300252313,
      "grad_norm": 2.328125,
      "learning_rate": 9.107240733398139e-06,
      "loss": 0.4937,
      "step": 7497
    },
    {
      "epoch": 0.7021773666012522,
      "grad_norm": 0.84033203125,
      "learning_rate": 9.102240969998904e-06,
      "loss": 0.2808,
      "step": 7514
    },
    {
      "epoch": 0.7037660031772731,
      "grad_norm": 1.3154296875,
      "learning_rate": 9.097228625911283e-06,
      "loss": 0.3629,
      "step": 7531
    },
    {
      "epoch": 0.705354639753294,
      "grad_norm": 2.49609375,
      "learning_rate": 9.092203716507055e-06,
      "loss": 0.5001,
      "step": 7548
    },
    {
      "epoch": 0.706943276329315,
      "grad_norm": 0.7802734375,
      "learning_rate": 9.087166257196534e-06,
      "loss": 0.2256,
      "step": 7565
    },
    {
      "epoch": 0.7085319129053359,
      "grad_norm": 1.2744140625,
      "learning_rate": 9.082116263428518e-06,
      "loss": 0.3411,
      "step": 7582
    },
    {
      "epoch": 0.7101205494813568,
      "grad_norm": 2.5859375,
      "learning_rate": 9.077053750690252e-06,
      "loss": 0.5795,
      "step": 7599
    },
    {
      "epoch": 0.7117091860573778,
      "grad_norm": 1.17578125,
      "learning_rate": 9.07197873450737e-06,
      "loss": 0.2563,
      "step": 7616
    },
    {
      "epoch": 0.7132978226333987,
      "grad_norm": 1.41796875,
      "learning_rate": 9.066891230443851e-06,
      "loss": 0.3713,
      "step": 7633
    },
    {
      "epoch": 0.7148864592094197,
      "grad_norm": 2.435546875,
      "learning_rate": 9.061791254101975e-06,
      "loss": 0.5464,
      "step": 7650
    },
    {
      "epoch": 0.7164750957854407,
      "grad_norm": 1.1220703125,
      "learning_rate": 9.056678821122268e-06,
      "loss": 0.2008,
      "step": 7667
    },
    {
      "epoch": 0.7180637323614616,
      "grad_norm": 1.8505859375,
      "learning_rate": 9.05155394718346e-06,
      "loss": 0.4434,
      "step": 7684
    },
    {
      "epoch": 0.7196523689374825,
      "grad_norm": 0.2333984375,
      "learning_rate": 9.046416648002433e-06,
      "loss": 0.5842,
      "step": 7701
    },
    {
      "epoch": 0.7212410055135035,
      "grad_norm": 1.228515625,
      "learning_rate": 9.04126693933418e-06,
      "loss": 0.1999,
      "step": 7718
    },
    {
      "epoch": 0.7228296420895244,
      "grad_norm": 1.5693359375,
      "learning_rate": 9.03610483697174e-06,
      "loss": 0.4003,
      "step": 7735
    },
    {
      "epoch": 0.7244182786655453,
      "grad_norm": 0.03564453125,
      "learning_rate": 9.030930356746173e-06,
      "loss": 0.5111,
      "step": 7752
    },
    {
      "epoch": 0.7260069152415662,
      "grad_norm": 1.189453125,
      "learning_rate": 9.025743514526493e-06,
      "loss": 0.2424,
      "step": 7769
    },
    {
      "epoch": 0.7275955518175872,
      "grad_norm": 1.7080078125,
      "learning_rate": 9.020544326219625e-06,
      "loss": 0.462,
      "step": 7786
    },
    {
      "epoch": 0.7291841883936081,
      "grad_norm": 0.5263671875,
      "learning_rate": 9.015332807770359e-06,
      "loss": 0.5362,
      "step": 7803
    },
    {
      "epoch": 0.730772824969629,
      "grad_norm": 1.427734375,
      "learning_rate": 9.010108975161297e-06,
      "loss": 0.3223,
      "step": 7820
    },
    {
      "epoch": 0.73236146154565,
      "grad_norm": 1.6904296875,
      "learning_rate": 9.004872844412811e-06,
      "loss": 0.4806,
      "step": 7837
    },
    {
      "epoch": 0.7339500981216709,
      "grad_norm": 0.5634765625,
      "learning_rate": 8.99962443158298e-06,
      "loss": 0.4956,
      "step": 7854
    },
    {
      "epoch": 0.7355387346976918,
      "grad_norm": 1.0185546875,
      "learning_rate": 8.994363752767557e-06,
      "loss": 0.2681,
      "step": 7871
    },
    {
      "epoch": 0.7371273712737128,
      "grad_norm": 1.8310546875,
      "learning_rate": 8.98909082409991e-06,
      "loss": 0.4442,
      "step": 7888
    },
    {
      "epoch": 0.7387160078497337,
      "grad_norm": 0.533203125,
      "learning_rate": 8.983805661750972e-06,
      "loss": 0.4797,
      "step": 7905
    },
    {
      "epoch": 0.7403046444257546,
      "grad_norm": 1.263671875,
      "learning_rate": 8.9785082819292e-06,
      "loss": 0.3004,
      "step": 7922
    },
    {
      "epoch": 0.7418932810017755,
      "grad_norm": 1.8154296875,
      "learning_rate": 8.97319870088051e-06,
      "loss": 0.4745,
      "step": 7939
    },
    {
      "epoch": 0.7434819175777965,
      "grad_norm": 0.6728515625,
      "learning_rate": 8.967876934888245e-06,
      "loss": 0.4404,
      "step": 7956
    },
    {
      "epoch": 0.7450705541538174,
      "grad_norm": 1.1865234375,
      "learning_rate": 8.962543000273113e-06,
      "loss": 0.2779,
      "step": 7973
    },
    {
      "epoch": 0.7466591907298383,
      "grad_norm": 1.8984375,
      "learning_rate": 8.957196913393142e-06,
      "loss": 0.4083,
      "step": 7990
    },
    {
      "epoch": 0.7482478273058593,
      "grad_norm": 0.61328125,
      "learning_rate": 8.951838690643626e-06,
      "loss": 0.4231,
      "step": 8007
    },
    {
      "epoch": 0.7498364638818802,
      "grad_norm": 1.0966796875,
      "learning_rate": 8.946468348457082e-06,
      "loss": 0.2788,
      "step": 8024
    },
    {
      "epoch": 0.7514251004579011,
      "grad_norm": 1.98046875,
      "learning_rate": 8.941085903303188e-06,
      "loss": 0.4474,
      "step": 8041
    },
    {
      "epoch": 0.753013737033922,
      "grad_norm": 0.87255859375,
      "learning_rate": 8.935691371688744e-06,
      "loss": 0.4911,
      "step": 8058
    },
    {
      "epoch": 0.754602373609943,
      "grad_norm": 1.4599609375,
      "learning_rate": 8.930284770157614e-06,
      "loss": 0.299,
      "step": 8075
    },
    {
      "epoch": 0.7561910101859639,
      "grad_norm": 2.228515625,
      "learning_rate": 8.92486611529068e-06,
      "loss": 0.5236,
      "step": 8092
    },
    {
      "epoch": 0.7577796467619848,
      "grad_norm": 0.828125,
      "learning_rate": 8.919435423705786e-06,
      "loss": 0.3771,
      "step": 8109
    },
    {
      "epoch": 0.7593682833380058,
      "grad_norm": 1.833984375,
      "learning_rate": 8.913992712057696e-06,
      "loss": 0.2973,
      "step": 8126
    },
    {
      "epoch": 0.7609569199140267,
      "grad_norm": 1.763671875,
      "learning_rate": 8.908537997038031e-06,
      "loss": 0.4774,
      "step": 8143
    },
    {
      "epoch": 0.7625455564900476,
      "grad_norm": 0.71337890625,
      "learning_rate": 8.903071295375222e-06,
      "loss": 0.3373,
      "step": 8160
    },
    {
      "epoch": 0.7641341930660686,
      "grad_norm": 1.2646484375,
      "learning_rate": 8.897592623834469e-06,
      "loss": 0.3729,
      "step": 8177
    },
    {
      "epoch": 0.7657228296420895,
      "grad_norm": 1.931640625,
      "learning_rate": 8.892101999217673e-06,
      "loss": 0.5125,
      "step": 8194
    },
    {
      "epoch": 0.7673114662181104,
      "grad_norm": 0.646484375,
      "learning_rate": 8.886599438363399e-06,
      "loss": 0.3436,
      "step": 8211
    },
    {
      "epoch": 0.7689001027941313,
      "grad_norm": 1.4443359375,
      "learning_rate": 8.88108495814681e-06,
      "loss": 0.3521,
      "step": 8228
    },
    {
      "epoch": 0.7704887393701523,
      "grad_norm": 2.6796875,
      "learning_rate": 8.875558575479631e-06,
      "loss": 0.4941,
      "step": 8245
    },
    {
      "epoch": 0.7720773759461732,
      "grad_norm": 0.63818359375,
      "learning_rate": 8.870020307310085e-06,
      "loss": 0.2562,
      "step": 8262
    },
    {
      "epoch": 0.7736660125221941,
      "grad_norm": 1.484375,
      "learning_rate": 8.864470170622845e-06,
      "loss": 0.3227,
      "step": 8279
    },
    {
      "epoch": 0.7752546490982151,
      "grad_norm": 1.9404296875,
      "learning_rate": 8.858908182438985e-06,
      "loss": 0.534,
      "step": 8296
    },
    {
      "epoch": 0.7768432856742361,
      "grad_norm": 0.923828125,
      "learning_rate": 8.853334359815922e-06,
      "loss": 0.2681,
      "step": 8313
    },
    {
      "epoch": 0.778431922250257,
      "grad_norm": 1.3388671875,
      "learning_rate": 8.847748719847369e-06,
      "loss": 0.3564,
      "step": 8330
    },
    {
      "epoch": 0.780020558826278,
      "grad_norm": 2.123046875,
      "learning_rate": 8.842151279663278e-06,
      "loss": 0.498,
      "step": 8347
    },
    {
      "epoch": 0.7816091954022989,
      "grad_norm": 0.7080078125,
      "learning_rate": 8.836542056429791e-06,
      "loss": 0.2557,
      "step": 8364
    },
    {
      "epoch": 0.7831978319783198,
      "grad_norm": 1.326171875,
      "learning_rate": 8.830921067349187e-06,
      "loss": 0.3606,
      "step": 8381
    },
    {
      "epoch": 0.7847864685543408,
      "grad_norm": 1.7919921875,
      "learning_rate": 8.82528832965983e-06,
      "loss": 0.5401,
      "step": 8398
    },
    {
      "epoch": 0.7863751051303617,
      "grad_norm": 0.6240234375,
      "learning_rate": 8.819643860636105e-06,
      "loss": 0.2178,
      "step": 8415
    },
    {
      "epoch": 0.7879637417063826,
      "grad_norm": 1.3876953125,
      "learning_rate": 8.813987677588385e-06,
      "loss": 0.358,
      "step": 8432
    },
    {
      "epoch": 0.7895523782824035,
      "grad_norm": 2.900390625,
      "learning_rate": 8.808319797862965e-06,
      "loss": 0.5406,
      "step": 8449
    },
    {
      "epoch": 0.7911410148584245,
      "grad_norm": 1.1181640625,
      "learning_rate": 8.802640238842007e-06,
      "loss": 0.253,
      "step": 8466
    },
    {
      "epoch": 0.7927296514344454,
      "grad_norm": 1.7685546875,
      "learning_rate": 8.796949017943496e-06,
      "loss": 0.4065,
      "step": 8483
    },
    {
      "epoch": 0.7943182880104663,
      "grad_norm": 2.509765625,
      "learning_rate": 8.791246152621177e-06,
      "loss": 0.5664,
      "step": 8500
    },
    {
      "epoch": 0.7959069245864873,
      "grad_norm": 0.93505859375,
      "learning_rate": 8.78553166036451e-06,
      "loss": 0.2357,
      "step": 8517
    },
    {
      "epoch": 0.7974955611625082,
      "grad_norm": 1.353515625,
      "learning_rate": 8.779805558698611e-06,
      "loss": 0.3866,
      "step": 8534
    },
    {
      "epoch": 0.7990841977385291,
      "grad_norm": 0.60888671875,
      "learning_rate": 8.774067865184195e-06,
      "loss": 0.5187,
      "step": 8551
    },
    {
      "epoch": 0.80067283431455,
      "grad_norm": 0.97998046875,
      "learning_rate": 8.768318597417535e-06,
      "loss": 0.2549,
      "step": 8568
    },
    {
      "epoch": 0.802261470890571,
      "grad_norm": 1.6162109375,
      "learning_rate": 8.762557773030393e-06,
      "loss": 0.4058,
      "step": 8585
    },
    {
      "epoch": 0.8038501074665919,
      "grad_norm": 0.2958984375,
      "learning_rate": 8.756785409689977e-06,
      "loss": 0.484,
      "step": 8602
    },
    {
      "epoch": 0.8054387440426128,
      "grad_norm": 1.0068359375,
      "learning_rate": 8.751001525098878e-06,
      "loss": 0.2756,
      "step": 8619
    },
    {
      "epoch": 0.8070273806186338,
      "grad_norm": 1.6484375,
      "learning_rate": 8.745206136995023e-06,
      "loss": 0.4378,
      "step": 8636
    },
    {
      "epoch": 0.8086160171946547,
      "grad_norm": 0.48681640625,
      "learning_rate": 8.73939926315162e-06,
      "loss": 0.4921,
      "step": 8653
    },
    {
      "epoch": 0.8102046537706756,
      "grad_norm": 0.9609375,
      "learning_rate": 8.733580921377098e-06,
      "loss": 0.1957,
      "step": 8670
    },
    {
      "epoch": 0.8117932903466966,
      "grad_norm": 1.970703125,
      "learning_rate": 8.727751129515053e-06,
      "loss": 0.426,
      "step": 8687
    },
    {
      "epoch": 0.8133819269227175,
      "grad_norm": 0.12548828125,
      "learning_rate": 8.721909905444204e-06,
      "loss": 0.4706,
      "step": 8704
    },
    {
      "epoch": 0.8149705634987384,
      "grad_norm": 1.041015625,
      "learning_rate": 8.716057267078323e-06,
      "loss": 0.2678,
      "step": 8721
    },
    {
      "epoch": 0.8165592000747594,
      "grad_norm": 1.8095703125,
      "learning_rate": 8.71019323236619e-06,
      "loss": 0.4182,
      "step": 8738
    },
    {
      "epoch": 0.8181478366507803,
      "grad_norm": 0.356201171875,
      "learning_rate": 8.704317819291536e-06,
      "loss": 0.4573,
      "step": 8755
    },
    {
      "epoch": 0.8197364732268012,
      "grad_norm": 1.056640625,
      "learning_rate": 8.698431045872985e-06,
      "loss": 0.2602,
      "step": 8772
    },
    {
      "epoch": 0.8213251098028221,
      "grad_norm": 1.673828125,
      "learning_rate": 8.692532930164e-06,
      "loss": 0.4398,
      "step": 8789
    },
    {
      "epoch": 0.8229137463788431,
      "grad_norm": 0.67822265625,
      "learning_rate": 8.686623490252835e-06,
      "loss": 0.4097,
      "step": 8806
    },
    {
      "epoch": 0.824502382954864,
      "grad_norm": 1.259765625,
      "learning_rate": 8.680702744262462e-06,
      "loss": 0.2765,
      "step": 8823
    },
    {
      "epoch": 0.8260910195308849,
      "grad_norm": 2.0234375,
      "learning_rate": 8.674770710350535e-06,
      "loss": 0.4465,
      "step": 8840
    },
    {
      "epoch": 0.8276796561069059,
      "grad_norm": 0.72265625,
      "learning_rate": 8.668827406709322e-06,
      "loss": 0.4133,
      "step": 8857
    },
    {
      "epoch": 0.8292682926829268,
      "grad_norm": 1.2802734375,
      "learning_rate": 8.662872851565652e-06,
      "loss": 0.3178,
      "step": 8874
    },
    {
      "epoch": 0.8308569292589477,
      "grad_norm": 1.90234375,
      "learning_rate": 8.656907063180866e-06,
      "loss": 0.4974,
      "step": 8891
    },
    {
      "epoch": 0.8324455658349686,
      "grad_norm": 0.787109375,
      "learning_rate": 8.650930059850746e-06,
      "loss": 0.4093,
      "step": 8908
    },
    {
      "epoch": 0.8340342024109896,
      "grad_norm": 1.111328125,
      "learning_rate": 8.644941859905474e-06,
      "loss": 0.3003,
      "step": 8925
    },
    {
      "epoch": 0.8356228389870105,
      "grad_norm": 1.78515625,
      "learning_rate": 8.63894248170957e-06,
      "loss": 0.504,
      "step": 8942
    },
    {
      "epoch": 0.8372114755630314,
      "grad_norm": 0.77783203125,
      "learning_rate": 8.632931943661829e-06,
      "loss": 0.3659,
      "step": 8959
    },
    {
      "epoch": 0.8388001121390525,
      "grad_norm": 1.4267578125,
      "learning_rate": 8.626910264195276e-06,
      "loss": 0.3546,
      "step": 8976
    },
    {
      "epoch": 0.8403887487150734,
      "grad_norm": 1.94921875,
      "learning_rate": 8.620877461777106e-06,
      "loss": 0.4955,
      "step": 8993
    },
    {
      "epoch": 0.8419773852910943,
      "grad_norm": 0.81103515625,
      "learning_rate": 8.61483355490862e-06,
      "loss": 0.3391,
      "step": 9010
    },
    {
      "epoch": 0.8435660218671153,
      "grad_norm": 1.068359375,
      "learning_rate": 8.60877856212518e-06,
      "loss": 0.34,
      "step": 9027
    },
    {
      "epoch": 0.8451546584431362,
      "grad_norm": 2.029296875,
      "learning_rate": 8.602712501996139e-06,
      "loss": 0.4959,
      "step": 9044
    },
    {
      "epoch": 0.8467432950191571,
      "grad_norm": 0.720703125,
      "learning_rate": 8.596635393124798e-06,
      "loss": 0.325,
      "step": 9061
    },
    {
      "epoch": 0.8483319315951781,
      "grad_norm": 1.3662109375,
      "learning_rate": 8.59054725414834e-06,
      "loss": 0.3572,
      "step": 9078
    },
    {
      "epoch": 0.849920568171199,
      "grad_norm": 2.041015625,
      "learning_rate": 8.584448103737772e-06,
      "loss": 0.5228,
      "step": 9095
    },
    {
      "epoch": 0.8515092047472199,
      "grad_norm": 0.947265625,
      "learning_rate": 8.578337960597875e-06,
      "loss": 0.3448,
      "step": 9112
    },
    {
      "epoch": 0.8530978413232408,
      "grad_norm": 1.5908203125,
      "learning_rate": 8.572216843467138e-06,
      "loss": 0.351,
      "step": 9129
    },
    {
      "epoch": 0.8546864778992618,
      "grad_norm": 2.015625,
      "learning_rate": 8.566084771117711e-06,
      "loss": 0.5239,
      "step": 9146
    },
    {
      "epoch": 0.8562751144752827,
      "grad_norm": 0.9619140625,
      "learning_rate": 8.559941762355333e-06,
      "loss": 0.2353,
      "step": 9163
    },
    {
      "epoch": 0.8578637510513036,
      "grad_norm": 1.5380859375,
      "learning_rate": 8.55378783601929e-06,
      "loss": 0.3201,
      "step": 9180
    },
    {
      "epoch": 0.8594523876273246,
      "grad_norm": 2.658203125,
      "learning_rate": 8.547623010982347e-06,
      "loss": 0.5311,
      "step": 9197
    },
    {
      "epoch": 0.8610410242033455,
      "grad_norm": 0.9345703125,
      "learning_rate": 8.541447306150692e-06,
      "loss": 0.2686,
      "step": 9214
    },
    {
      "epoch": 0.8626296607793664,
      "grad_norm": 1.787109375,
      "learning_rate": 8.535260740463878e-06,
      "loss": 0.3888,
      "step": 9231
    },
    {
      "epoch": 0.8642182973553874,
      "grad_norm": 2.48828125,
      "learning_rate": 8.529063332894771e-06,
      "loss": 0.5565,
      "step": 9248
    },
    {
      "epoch": 0.8658069339314083,
      "grad_norm": 0.84912109375,
      "learning_rate": 8.522855102449483e-06,
      "loss": 0.2693,
      "step": 9265
    },
    {
      "epoch": 0.8673955705074292,
      "grad_norm": 1.65625,
      "learning_rate": 8.516636068167319e-06,
      "loss": 0.358,
      "step": 9282
    },
    {
      "epoch": 0.8689842070834501,
      "grad_norm": 2.63671875,
      "learning_rate": 8.510406249120711e-06,
      "loss": 0.5695,
      "step": 9299
    },
    {
      "epoch": 0.8705728436594711,
      "grad_norm": 0.83642578125,
      "learning_rate": 8.504165664415173e-06,
      "loss": 0.2027,
      "step": 9316
    },
    {
      "epoch": 0.872161480235492,
      "grad_norm": 1.5439453125,
      "learning_rate": 8.497914333189236e-06,
      "loss": 0.3381,
      "step": 9333
    },
    {
      "epoch": 0.8737501168115129,
      "grad_norm": 2.779296875,
      "learning_rate": 8.49165227461438e-06,
      "loss": 0.5968,
      "step": 9350
    },
    {
      "epoch": 0.8753387533875339,
      "grad_norm": 0.9287109375,
      "learning_rate": 8.485379507894993e-06,
      "loss": 0.182,
      "step": 9367
    },
    {
      "epoch": 0.8769273899635548,
      "grad_norm": 1.62890625,
      "learning_rate": 8.479096052268291e-06,
      "loss": 0.3524,
      "step": 9384
    },
    {
      "epoch": 0.8785160265395757,
      "grad_norm": 0.6494140625,
      "learning_rate": 8.472801927004286e-06,
      "loss": 0.5009,
      "step": 9401
    },
    {
      "epoch": 0.8801046631155967,
      "grad_norm": 1.197265625,
      "learning_rate": 8.466497151405695e-06,
      "loss": 0.2639,
      "step": 9418
    },
    {
      "epoch": 0.8816932996916176,
      "grad_norm": 1.53515625,
      "learning_rate": 8.460181744807909e-06,
      "loss": 0.4123,
      "step": 9435
    },
    {
      "epoch": 0.8832819362676385,
      "grad_norm": 0.389892578125,
      "learning_rate": 8.453855726578917e-06,
      "loss": 0.5044,
      "step": 9452
    },
    {
      "epoch": 0.8848705728436594,
      "grad_norm": 1.015625,
      "learning_rate": 8.447519116119252e-06,
      "loss": 0.2229,
      "step": 9469
    },
    {
      "epoch": 0.8864592094196804,
      "grad_norm": 1.7353515625,
      "learning_rate": 8.441171932861934e-06,
      "loss": 0.3896,
      "step": 9486
    },
    {
      "epoch": 0.8880478459957013,
      "grad_norm": 0.2471923828125,
      "learning_rate": 8.434814196272405e-06,
      "loss": 0.451,
      "step": 9503
    },
    {
      "epoch": 0.8896364825717222,
      "grad_norm": 1.1064453125,
      "learning_rate": 8.42844592584847e-06,
      "loss": 0.2668,
      "step": 9520
    },
    {
      "epoch": 0.8912251191477432,
      "grad_norm": 2.224609375,
      "learning_rate": 8.422067141120241e-06,
      "loss": 0.4365,
      "step": 9537
    },
    {
      "epoch": 0.8928137557237641,
      "grad_norm": 0.2099609375,
      "learning_rate": 8.415677861650078e-06,
      "loss": 0.4743,
      "step": 9554
    },
    {
      "epoch": 0.894402392299785,
      "grad_norm": 1.0654296875,
      "learning_rate": 8.40927810703252e-06,
      "loss": 0.2987,
      "step": 9571
    },
    {
      "epoch": 0.895991028875806,
      "grad_norm": 1.984375,
      "learning_rate": 8.402867896894238e-06,
      "loss": 0.4532,
      "step": 9588
    },
    {
      "epoch": 0.8975796654518269,
      "grad_norm": 0.5126953125,
      "learning_rate": 8.39644725089396e-06,
      "loss": 0.4199,
      "step": 9605
    },
    {
      "epoch": 0.8991683020278478,
      "grad_norm": 1.2001953125,
      "learning_rate": 8.390016188722425e-06,
      "loss": 0.3214,
      "step": 9622
    }
  ],
  "logging_steps": 17,
  "max_steps": 32103,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 3211,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.038691915335598e+17,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
