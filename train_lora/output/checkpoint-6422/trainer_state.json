{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6001308288944959,
  "eval_steps": 6421,
  "global_step": 6422,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015886365760209326,
      "grad_norm": 0.30615234375,
      "learning_rate": 1.0585305105853052e-07,
      "loss": 0.3677,
      "step": 17
    },
    {
      "epoch": 0.003177273152041865,
      "grad_norm": 1.23828125,
      "learning_rate": 2.1170610211706104e-07,
      "loss": 0.5717,
      "step": 34
    },
    {
      "epoch": 0.004765909728062798,
      "grad_norm": 0.280029296875,
      "learning_rate": 3.1755915317559156e-07,
      "loss": 0.8085,
      "step": 51
    },
    {
      "epoch": 0.00635454630408373,
      "grad_norm": 0.34228515625,
      "learning_rate": 4.234122042341221e-07,
      "loss": 0.3141,
      "step": 68
    },
    {
      "epoch": 0.007943182880104663,
      "grad_norm": 0.6669921875,
      "learning_rate": 5.292652552926527e-07,
      "loss": 0.6057,
      "step": 85
    },
    {
      "epoch": 0.009531819456125596,
      "grad_norm": 0.106689453125,
      "learning_rate": 6.351183063511831e-07,
      "loss": 0.7759,
      "step": 102
    },
    {
      "epoch": 0.011120456032146528,
      "grad_norm": 0.41064453125,
      "learning_rate": 7.409713574097137e-07,
      "loss": 0.3873,
      "step": 119
    },
    {
      "epoch": 0.01270909260816746,
      "grad_norm": 0.52392578125,
      "learning_rate": 8.468244084682442e-07,
      "loss": 0.6285,
      "step": 136
    },
    {
      "epoch": 0.014297729184188394,
      "grad_norm": 0.1488037109375,
      "learning_rate": 9.526774595267747e-07,
      "loss": 0.7612,
      "step": 153
    },
    {
      "epoch": 0.015886365760209326,
      "grad_norm": 0.352294921875,
      "learning_rate": 1.0585305105853053e-06,
      "loss": 0.3533,
      "step": 170
    },
    {
      "epoch": 0.01747500233623026,
      "grad_norm": 0.74755859375,
      "learning_rate": 1.1643835616438357e-06,
      "loss": 0.6135,
      "step": 187
    },
    {
      "epoch": 0.019063638912251192,
      "grad_norm": 0.15283203125,
      "learning_rate": 1.2702366127023662e-06,
      "loss": 0.7373,
      "step": 204
    },
    {
      "epoch": 0.020652275488272125,
      "grad_norm": 0.59130859375,
      "learning_rate": 1.3760896637608966e-06,
      "loss": 0.4345,
      "step": 221
    },
    {
      "epoch": 0.022240912064293055,
      "grad_norm": 0.5458984375,
      "learning_rate": 1.4819427148194274e-06,
      "loss": 0.6566,
      "step": 238
    },
    {
      "epoch": 0.02382954864031399,
      "grad_norm": 0.29541015625,
      "learning_rate": 1.5877957658779578e-06,
      "loss": 0.7509,
      "step": 255
    },
    {
      "epoch": 0.02541818521633492,
      "grad_norm": 0.490478515625,
      "learning_rate": 1.6936488169364883e-06,
      "loss": 0.4075,
      "step": 272
    },
    {
      "epoch": 0.027006821792355855,
      "grad_norm": 0.796875,
      "learning_rate": 1.799501867995019e-06,
      "loss": 0.6673,
      "step": 289
    },
    {
      "epoch": 0.028595458368376788,
      "grad_norm": 0.1600341796875,
      "learning_rate": 1.9053549190535495e-06,
      "loss": 0.6821,
      "step": 306
    },
    {
      "epoch": 0.03018409494439772,
      "grad_norm": 0.4326171875,
      "learning_rate": 2.01120797011208e-06,
      "loss": 0.3543,
      "step": 323
    },
    {
      "epoch": 0.03177273152041865,
      "grad_norm": 0.75732421875,
      "learning_rate": 2.1170610211706106e-06,
      "loss": 0.6114,
      "step": 340
    },
    {
      "epoch": 0.03336136809643959,
      "grad_norm": 0.20703125,
      "learning_rate": 2.2229140722291408e-06,
      "loss": 0.5834,
      "step": 357
    },
    {
      "epoch": 0.03495000467246052,
      "grad_norm": 0.326416015625,
      "learning_rate": 2.3287671232876713e-06,
      "loss": 0.3978,
      "step": 374
    },
    {
      "epoch": 0.03653864124848145,
      "grad_norm": 0.62646484375,
      "learning_rate": 2.434620174346202e-06,
      "loss": 0.6366,
      "step": 391
    },
    {
      "epoch": 0.038127277824502384,
      "grad_norm": 0.259765625,
      "learning_rate": 2.5404732254047325e-06,
      "loss": 0.6095,
      "step": 408
    },
    {
      "epoch": 0.039715914400523314,
      "grad_norm": 0.82861328125,
      "learning_rate": 2.646326276463263e-06,
      "loss": 0.4376,
      "step": 425
    },
    {
      "epoch": 0.04130455097654425,
      "grad_norm": 0.97509765625,
      "learning_rate": 2.7521793275217932e-06,
      "loss": 0.7023,
      "step": 442
    },
    {
      "epoch": 0.04289318755256518,
      "grad_norm": 0.2115478515625,
      "learning_rate": 2.858032378580324e-06,
      "loss": 0.5356,
      "step": 459
    },
    {
      "epoch": 0.04448182412858611,
      "grad_norm": 0.83154296875,
      "learning_rate": 2.963885429638855e-06,
      "loss": 0.4777,
      "step": 476
    },
    {
      "epoch": 0.04607046070460705,
      "grad_norm": 0.7978515625,
      "learning_rate": 3.069738480697385e-06,
      "loss": 0.6041,
      "step": 493
    },
    {
      "epoch": 0.04765909728062798,
      "grad_norm": 0.41748046875,
      "learning_rate": 3.1755915317559155e-06,
      "loss": 0.4227,
      "step": 510
    },
    {
      "epoch": 0.04924773385664891,
      "grad_norm": 0.8466796875,
      "learning_rate": 3.281444582814446e-06,
      "loss": 0.443,
      "step": 527
    },
    {
      "epoch": 0.05083637043266984,
      "grad_norm": 0.9345703125,
      "learning_rate": 3.3872976338729767e-06,
      "loss": 0.6736,
      "step": 544
    },
    {
      "epoch": 0.05242500700869078,
      "grad_norm": 0.5810546875,
      "learning_rate": 3.4931506849315072e-06,
      "loss": 0.384,
      "step": 561
    },
    {
      "epoch": 0.05401364358471171,
      "grad_norm": 0.68017578125,
      "learning_rate": 3.599003735990038e-06,
      "loss": 0.3962,
      "step": 578
    },
    {
      "epoch": 0.05560228016073264,
      "grad_norm": 1.443359375,
      "learning_rate": 3.704856787048568e-06,
      "loss": 0.6065,
      "step": 595
    },
    {
      "epoch": 0.057190916736753576,
      "grad_norm": 0.67578125,
      "learning_rate": 3.810709838107099e-06,
      "loss": 0.4176,
      "step": 612
    },
    {
      "epoch": 0.058779553312774506,
      "grad_norm": 0.6826171875,
      "learning_rate": 3.916562889165629e-06,
      "loss": 0.4848,
      "step": 629
    },
    {
      "epoch": 0.06036818988879544,
      "grad_norm": 1.1982421875,
      "learning_rate": 4.02241594022416e-06,
      "loss": 0.6994,
      "step": 646
    },
    {
      "epoch": 0.06195682646481637,
      "grad_norm": 0.52587890625,
      "learning_rate": 4.12826899128269e-06,
      "loss": 0.3928,
      "step": 663
    },
    {
      "epoch": 0.0635454630408373,
      "grad_norm": 1.2802734375,
      "learning_rate": 4.234122042341221e-06,
      "loss": 0.4216,
      "step": 680
    },
    {
      "epoch": 0.06513409961685823,
      "grad_norm": 1.1298828125,
      "learning_rate": 4.339975093399751e-06,
      "loss": 0.618,
      "step": 697
    },
    {
      "epoch": 0.06672273619287918,
      "grad_norm": 0.7412109375,
      "learning_rate": 4.4458281444582815e-06,
      "loss": 0.3223,
      "step": 714
    },
    {
      "epoch": 0.0683113727689001,
      "grad_norm": 1.58984375,
      "learning_rate": 4.5516811955168125e-06,
      "loss": 0.5041,
      "step": 731
    },
    {
      "epoch": 0.06990000934492104,
      "grad_norm": 1.41796875,
      "learning_rate": 4.657534246575343e-06,
      "loss": 0.6834,
      "step": 748
    },
    {
      "epoch": 0.07148864592094197,
      "grad_norm": 0.86083984375,
      "learning_rate": 4.763387297633874e-06,
      "loss": 0.2818,
      "step": 765
    },
    {
      "epoch": 0.0730772824969629,
      "grad_norm": 0.94189453125,
      "learning_rate": 4.869240348692404e-06,
      "loss": 0.431,
      "step": 782
    },
    {
      "epoch": 0.07466591907298384,
      "grad_norm": 1.87109375,
      "learning_rate": 4.975093399750934e-06,
      "loss": 0.632,
      "step": 799
    },
    {
      "epoch": 0.07625455564900477,
      "grad_norm": 0.83203125,
      "learning_rate": 5.080946450809465e-06,
      "loss": 0.3002,
      "step": 816
    },
    {
      "epoch": 0.0778431922250257,
      "grad_norm": 1.318359375,
      "learning_rate": 5.186799501867995e-06,
      "loss": 0.4234,
      "step": 833
    },
    {
      "epoch": 0.07943182880104663,
      "grad_norm": 1.84375,
      "learning_rate": 5.292652552926526e-06,
      "loss": 0.6675,
      "step": 850
    },
    {
      "epoch": 0.08102046537706756,
      "grad_norm": 0.9638671875,
      "learning_rate": 5.398505603985057e-06,
      "loss": 0.2349,
      "step": 867
    },
    {
      "epoch": 0.0826091019530885,
      "grad_norm": 0.955078125,
      "learning_rate": 5.5043586550435864e-06,
      "loss": 0.4604,
      "step": 884
    },
    {
      "epoch": 0.08419773852910943,
      "grad_norm": 0.29052734375,
      "learning_rate": 5.6102117061021174e-06,
      "loss": 0.5977,
      "step": 901
    },
    {
      "epoch": 0.08578637510513036,
      "grad_norm": 0.7275390625,
      "learning_rate": 5.716064757160648e-06,
      "loss": 0.2387,
      "step": 918
    },
    {
      "epoch": 0.08737501168115129,
      "grad_norm": 1.1982421875,
      "learning_rate": 5.821917808219179e-06,
      "loss": 0.4467,
      "step": 935
    },
    {
      "epoch": 0.08896364825717222,
      "grad_norm": 0.444091796875,
      "learning_rate": 5.92777085927771e-06,
      "loss": 0.5707,
      "step": 952
    },
    {
      "epoch": 0.09055228483319316,
      "grad_norm": 0.982421875,
      "learning_rate": 6.033623910336239e-06,
      "loss": 0.3508,
      "step": 969
    },
    {
      "epoch": 0.0921409214092141,
      "grad_norm": 1.3583984375,
      "learning_rate": 6.13947696139477e-06,
      "loss": 0.4969,
      "step": 986
    },
    {
      "epoch": 0.09372955798523502,
      "grad_norm": 0.222412109375,
      "learning_rate": 6.245330012453301e-06,
      "loss": 0.5931,
      "step": 1003
    },
    {
      "epoch": 0.09531819456125595,
      "grad_norm": 0.84619140625,
      "learning_rate": 6.351183063511831e-06,
      "loss": 0.3055,
      "step": 1020
    },
    {
      "epoch": 0.09690683113727688,
      "grad_norm": 1.484375,
      "learning_rate": 6.457036114570362e-06,
      "loss": 0.5078,
      "step": 1037
    },
    {
      "epoch": 0.09849546771329783,
      "grad_norm": 0.6533203125,
      "learning_rate": 6.562889165628892e-06,
      "loss": 0.5422,
      "step": 1054
    },
    {
      "epoch": 0.10008410428931876,
      "grad_norm": 1.162109375,
      "learning_rate": 6.668742216687422e-06,
      "loss": 0.2925,
      "step": 1071
    },
    {
      "epoch": 0.10167274086533969,
      "grad_norm": 1.6494140625,
      "learning_rate": 6.774595267745953e-06,
      "loss": 0.4744,
      "step": 1088
    },
    {
      "epoch": 0.10326137744136062,
      "grad_norm": 0.85009765625,
      "learning_rate": 6.8804483188044835e-06,
      "loss": 0.5842,
      "step": 1105
    },
    {
      "epoch": 0.10485001401738156,
      "grad_norm": 0.99853515625,
      "learning_rate": 6.9863013698630145e-06,
      "loss": 0.361,
      "step": 1122
    },
    {
      "epoch": 0.10643865059340249,
      "grad_norm": 2.166015625,
      "learning_rate": 7.092154420921545e-06,
      "loss": 0.4835,
      "step": 1139
    },
    {
      "epoch": 0.10802728716942342,
      "grad_norm": 0.6533203125,
      "learning_rate": 7.198007471980076e-06,
      "loss": 0.4625,
      "step": 1156
    },
    {
      "epoch": 0.10961592374544435,
      "grad_norm": 0.9951171875,
      "learning_rate": 7.303860523038606e-06,
      "loss": 0.3469,
      "step": 1173
    },
    {
      "epoch": 0.11120456032146528,
      "grad_norm": 3.162109375,
      "learning_rate": 7.409713574097136e-06,
      "loss": 0.5231,
      "step": 1190
    },
    {
      "epoch": 0.11279319689748622,
      "grad_norm": 0.455078125,
      "learning_rate": 7.515566625155667e-06,
      "loss": 0.4403,
      "step": 1207
    },
    {
      "epoch": 0.11438183347350715,
      "grad_norm": 1.091796875,
      "learning_rate": 7.621419676214198e-06,
      "loss": 0.3341,
      "step": 1224
    },
    {
      "epoch": 0.11597047004952808,
      "grad_norm": 2.255859375,
      "learning_rate": 7.727272727272727e-06,
      "loss": 0.5361,
      "step": 1241
    },
    {
      "epoch": 0.11755910662554901,
      "grad_norm": 0.5732421875,
      "learning_rate": 7.833125778331258e-06,
      "loss": 0.4021,
      "step": 1258
    },
    {
      "epoch": 0.11914774320156994,
      "grad_norm": 0.9658203125,
      "learning_rate": 7.93897882938979e-06,
      "loss": 0.3574,
      "step": 1275
    },
    {
      "epoch": 0.12073637977759089,
      "grad_norm": 1.7958984375,
      "learning_rate": 8.04483188044832e-06,
      "loss": 0.5173,
      "step": 1292
    },
    {
      "epoch": 0.12232501635361182,
      "grad_norm": 0.71923828125,
      "learning_rate": 8.150684931506851e-06,
      "loss": 0.4297,
      "step": 1309
    },
    {
      "epoch": 0.12391365292963274,
      "grad_norm": 1.091796875,
      "learning_rate": 8.25653798256538e-06,
      "loss": 0.3493,
      "step": 1326
    },
    {
      "epoch": 0.12550228950565367,
      "grad_norm": 3.525390625,
      "learning_rate": 8.362391033623912e-06,
      "loss": 0.5447,
      "step": 1343
    },
    {
      "epoch": 0.1270909260816746,
      "grad_norm": 0.63623046875,
      "learning_rate": 8.468244084682442e-06,
      "loss": 0.3913,
      "step": 1360
    },
    {
      "epoch": 0.12867956265769553,
      "grad_norm": 1.380859375,
      "learning_rate": 8.574097135740972e-06,
      "loss": 0.3514,
      "step": 1377
    },
    {
      "epoch": 0.13026819923371646,
      "grad_norm": 1.703125,
      "learning_rate": 8.679950186799503e-06,
      "loss": 0.5447,
      "step": 1394
    },
    {
      "epoch": 0.13185683580973742,
      "grad_norm": 0.5234375,
      "learning_rate": 8.785803237858032e-06,
      "loss": 0.3191,
      "step": 1411
    },
    {
      "epoch": 0.13344547238575835,
      "grad_norm": 1.115234375,
      "learning_rate": 8.891656288916563e-06,
      "loss": 0.3458,
      "step": 1428
    },
    {
      "epoch": 0.13503410896177928,
      "grad_norm": 1.392578125,
      "learning_rate": 8.997509339975094e-06,
      "loss": 0.5391,
      "step": 1445
    },
    {
      "epoch": 0.1366227455378002,
      "grad_norm": 0.60888671875,
      "learning_rate": 9.103362391033625e-06,
      "loss": 0.2989,
      "step": 1462
    },
    {
      "epoch": 0.13821138211382114,
      "grad_norm": 1.1220703125,
      "learning_rate": 9.209215442092156e-06,
      "loss": 0.3724,
      "step": 1479
    },
    {
      "epoch": 0.13980001868984207,
      "grad_norm": 2.53125,
      "learning_rate": 9.315068493150685e-06,
      "loss": 0.5454,
      "step": 1496
    },
    {
      "epoch": 0.141388655265863,
      "grad_norm": 0.6748046875,
      "learning_rate": 9.420921544209216e-06,
      "loss": 0.3114,
      "step": 1513
    },
    {
      "epoch": 0.14297729184188393,
      "grad_norm": 1.4423828125,
      "learning_rate": 9.526774595267747e-06,
      "loss": 0.3943,
      "step": 1530
    },
    {
      "epoch": 0.14456592841790486,
      "grad_norm": 2.107421875,
      "learning_rate": 9.632627646326277e-06,
      "loss": 0.62,
      "step": 1547
    },
    {
      "epoch": 0.1461545649939258,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.738480697384808e-06,
      "loss": 0.2803,
      "step": 1564
    },
    {
      "epoch": 0.14774320156994675,
      "grad_norm": 1.455078125,
      "learning_rate": 9.844333748443339e-06,
      "loss": 0.3949,
      "step": 1581
    },
    {
      "epoch": 0.14933183814596768,
      "grad_norm": 2.21875,
      "learning_rate": 9.950186799501868e-06,
      "loss": 0.6392,
      "step": 1598
    },
    {
      "epoch": 0.1509204747219886,
      "grad_norm": 0.765625,
      "learning_rate": 9.999997851128222e-06,
      "loss": 0.2648,
      "step": 1615
    },
    {
      "epoch": 0.15250911129800954,
      "grad_norm": 1.33984375,
      "learning_rate": 9.999982066215332e-06,
      "loss": 0.3933,
      "step": 1632
    },
    {
      "epoch": 0.15409774787403047,
      "grad_norm": 2.046875,
      "learning_rate": 9.999950947435717e-06,
      "loss": 0.6,
      "step": 1649
    },
    {
      "epoch": 0.1556863844500514,
      "grad_norm": 0.65966796875,
      "learning_rate": 9.999904494884808e-06,
      "loss": 0.2117,
      "step": 1666
    },
    {
      "epoch": 0.15727502102607233,
      "grad_norm": 1.177734375,
      "learning_rate": 9.999842708705073e-06,
      "loss": 0.3763,
      "step": 1683
    },
    {
      "epoch": 0.15886365760209326,
      "grad_norm": 2.9765625,
      "learning_rate": 9.999765589085988e-06,
      "loss": 0.5906,
      "step": 1700
    },
    {
      "epoch": 0.16045229417811419,
      "grad_norm": 0.90185546875,
      "learning_rate": 9.999673136264067e-06,
      "loss": 0.265,
      "step": 1717
    },
    {
      "epoch": 0.16204093075413512,
      "grad_norm": 1.48046875,
      "learning_rate": 9.999565350522841e-06,
      "loss": 0.4085,
      "step": 1734
    },
    {
      "epoch": 0.16362956733015607,
      "grad_norm": 0.5478515625,
      "learning_rate": 9.999442232192867e-06,
      "loss": 0.5989,
      "step": 1751
    },
    {
      "epoch": 0.165218203906177,
      "grad_norm": 1.064453125,
      "learning_rate": 9.999303781651722e-06,
      "loss": 0.2099,
      "step": 1768
    },
    {
      "epoch": 0.16680684048219793,
      "grad_norm": 1.28125,
      "learning_rate": 9.999149999324002e-06,
      "loss": 0.4079,
      "step": 1785
    },
    {
      "epoch": 0.16839547705821886,
      "grad_norm": 0.37451171875,
      "learning_rate": 9.998980885681328e-06,
      "loss": 0.5364,
      "step": 1802
    },
    {
      "epoch": 0.1699841136342398,
      "grad_norm": 1.296875,
      "learning_rate": 9.998796441242333e-06,
      "loss": 0.2434,
      "step": 1819
    },
    {
      "epoch": 0.17157275021026072,
      "grad_norm": 1.68359375,
      "learning_rate": 9.998596666572668e-06,
      "loss": 0.4581,
      "step": 1836
    },
    {
      "epoch": 0.17316138678628165,
      "grad_norm": 0.09356689453125,
      "learning_rate": 9.998381562284999e-06,
      "loss": 0.5137,
      "step": 1853
    },
    {
      "epoch": 0.17475002336230258,
      "grad_norm": 1.197265625,
      "learning_rate": 9.998151129039005e-06,
      "loss": 0.2999,
      "step": 1870
    },
    {
      "epoch": 0.1763386599383235,
      "grad_norm": 1.2822265625,
      "learning_rate": 9.997905367541374e-06,
      "loss": 0.4893,
      "step": 1887
    },
    {
      "epoch": 0.17792729651434444,
      "grad_norm": 0.406005859375,
      "learning_rate": 9.997644278545805e-06,
      "loss": 0.4657,
      "step": 1904
    },
    {
      "epoch": 0.1795159330903654,
      "grad_norm": 1.0361328125,
      "learning_rate": 9.997367862853e-06,
      "loss": 0.2577,
      "step": 1921
    },
    {
      "epoch": 0.18110456966638633,
      "grad_norm": 1.94921875,
      "learning_rate": 9.997076121310668e-06,
      "loss": 0.4479,
      "step": 1938
    },
    {
      "epoch": 0.18269320624240726,
      "grad_norm": 0.51708984375,
      "learning_rate": 9.996769054813517e-06,
      "loss": 0.4454,
      "step": 1955
    },
    {
      "epoch": 0.1842818428184282,
      "grad_norm": 1.0224609375,
      "learning_rate": 9.996446664303252e-06,
      "loss": 0.2745,
      "step": 1972
    },
    {
      "epoch": 0.18587047939444912,
      "grad_norm": 1.5078125,
      "learning_rate": 9.996108950768579e-06,
      "loss": 0.5063,
      "step": 1989
    },
    {
      "epoch": 0.18745911597047005,
      "grad_norm": 0.59130859375,
      "learning_rate": 9.995755915245187e-06,
      "loss": 0.4971,
      "step": 2006
    },
    {
      "epoch": 0.18904775254649098,
      "grad_norm": 1.302734375,
      "learning_rate": 9.995387558815764e-06,
      "loss": 0.2852,
      "step": 2023
    },
    {
      "epoch": 0.1906363891225119,
      "grad_norm": 1.7626953125,
      "learning_rate": 9.99500388260998e-06,
      "loss": 0.4934,
      "step": 2040
    },
    {
      "epoch": 0.19222502569853284,
      "grad_norm": 0.47216796875,
      "learning_rate": 9.994604887804484e-06,
      "loss": 0.4508,
      "step": 2057
    },
    {
      "epoch": 0.19381366227455377,
      "grad_norm": 1.041015625,
      "learning_rate": 9.99419057562291e-06,
      "loss": 0.3276,
      "step": 2074
    },
    {
      "epoch": 0.19540229885057472,
      "grad_norm": 1.5029296875,
      "learning_rate": 9.993760947335863e-06,
      "loss": 0.5077,
      "step": 2091
    },
    {
      "epoch": 0.19699093542659565,
      "grad_norm": 0.638671875,
      "learning_rate": 9.99331600426092e-06,
      "loss": 0.4407,
      "step": 2108
    },
    {
      "epoch": 0.19857957200261658,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.992855747762625e-06,
      "loss": 0.3315,
      "step": 2125
    },
    {
      "epoch": 0.2001682085786375,
      "grad_norm": 1.5556640625,
      "learning_rate": 9.992380179252487e-06,
      "loss": 0.5101,
      "step": 2142
    },
    {
      "epoch": 0.20175684515465844,
      "grad_norm": 0.708984375,
      "learning_rate": 9.991889300188971e-06,
      "loss": 0.4032,
      "step": 2159
    },
    {
      "epoch": 0.20334548173067937,
      "grad_norm": 1.126953125,
      "learning_rate": 9.991383112077498e-06,
      "loss": 0.3304,
      "step": 2176
    },
    {
      "epoch": 0.2049341183067003,
      "grad_norm": 1.6201171875,
      "learning_rate": 9.990861616470434e-06,
      "loss": 0.5363,
      "step": 2193
    },
    {
      "epoch": 0.20652275488272123,
      "grad_norm": 0.74267578125,
      "learning_rate": 9.990324814967101e-06,
      "loss": 0.4124,
      "step": 2210
    },
    {
      "epoch": 0.20811139145874216,
      "grad_norm": 1.119140625,
      "learning_rate": 9.989772709213747e-06,
      "loss": 0.3725,
      "step": 2227
    },
    {
      "epoch": 0.20970002803476312,
      "grad_norm": 1.853515625,
      "learning_rate": 9.989205300903563e-06,
      "loss": 0.5147,
      "step": 2244
    },
    {
      "epoch": 0.21128866461078405,
      "grad_norm": 0.66015625,
      "learning_rate": 9.98862259177667e-06,
      "loss": 0.328,
      "step": 2261
    },
    {
      "epoch": 0.21287730118680498,
      "grad_norm": 1.2216796875,
      "learning_rate": 9.988024583620108e-06,
      "loss": 0.3662,
      "step": 2278
    },
    {
      "epoch": 0.2144659377628259,
      "grad_norm": 1.9306640625,
      "learning_rate": 9.987411278267842e-06,
      "loss": 0.5264,
      "step": 2295
    },
    {
      "epoch": 0.21605457433884684,
      "grad_norm": 0.82861328125,
      "learning_rate": 9.986782677600747e-06,
      "loss": 0.3458,
      "step": 2312
    },
    {
      "epoch": 0.21764321091486777,
      "grad_norm": 1.4697265625,
      "learning_rate": 9.986138783546603e-06,
      "loss": 0.4036,
      "step": 2329
    },
    {
      "epoch": 0.2192318474908887,
      "grad_norm": 2.091796875,
      "learning_rate": 9.985479598080095e-06,
      "loss": 0.561,
      "step": 2346
    },
    {
      "epoch": 0.22082048406690963,
      "grad_norm": 0.64453125,
      "learning_rate": 9.984805123222804e-06,
      "loss": 0.2843,
      "step": 2363
    },
    {
      "epoch": 0.22240912064293056,
      "grad_norm": 1.4150390625,
      "learning_rate": 9.9841153610432e-06,
      "loss": 0.3401,
      "step": 2380
    },
    {
      "epoch": 0.2239977572189515,
      "grad_norm": 1.7470703125,
      "learning_rate": 9.983410313656633e-06,
      "loss": 0.5495,
      "step": 2397
    },
    {
      "epoch": 0.22558639379497245,
      "grad_norm": 0.7314453125,
      "learning_rate": 9.98268998322533e-06,
      "loss": 0.2932,
      "step": 2414
    },
    {
      "epoch": 0.22717503037099337,
      "grad_norm": 1.6337890625,
      "learning_rate": 9.981954371958392e-06,
      "loss": 0.4074,
      "step": 2431
    },
    {
      "epoch": 0.2287636669470143,
      "grad_norm": 2.181640625,
      "learning_rate": 9.981203482111779e-06,
      "loss": 0.5556,
      "step": 2448
    },
    {
      "epoch": 0.23035230352303523,
      "grad_norm": 0.88818359375,
      "learning_rate": 9.980437315988307e-06,
      "loss": 0.2335,
      "step": 2465
    },
    {
      "epoch": 0.23194094009905616,
      "grad_norm": 1.58984375,
      "learning_rate": 9.979655875937644e-06,
      "loss": 0.4066,
      "step": 2482
    },
    {
      "epoch": 0.2335295766750771,
      "grad_norm": 3.404296875,
      "learning_rate": 9.978859164356298e-06,
      "loss": 0.5986,
      "step": 2499
    },
    {
      "epoch": 0.23511821325109802,
      "grad_norm": 0.970703125,
      "learning_rate": 9.97804718368761e-06,
      "loss": 0.2273,
      "step": 2516
    },
    {
      "epoch": 0.23670684982711895,
      "grad_norm": 1.6474609375,
      "learning_rate": 9.977219936421749e-06,
      "loss": 0.3798,
      "step": 2533
    },
    {
      "epoch": 0.23829548640313988,
      "grad_norm": 2.923828125,
      "learning_rate": 9.976377425095708e-06,
      "loss": 0.5819,
      "step": 2550
    },
    {
      "epoch": 0.2398841229791608,
      "grad_norm": 0.83837890625,
      "learning_rate": 9.975519652293284e-06,
      "loss": 0.2694,
      "step": 2567
    },
    {
      "epoch": 0.24147275955518177,
      "grad_norm": 1.5986328125,
      "learning_rate": 9.974646620645083e-06,
      "loss": 0.3822,
      "step": 2584
    },
    {
      "epoch": 0.2430613961312027,
      "grad_norm": 0.404052734375,
      "learning_rate": 9.973758332828504e-06,
      "loss": 0.5388,
      "step": 2601
    },
    {
      "epoch": 0.24465003270722363,
      "grad_norm": 1.015625,
      "learning_rate": 9.972854791567734e-06,
      "loss": 0.2384,
      "step": 2618
    },
    {
      "epoch": 0.24623866928324456,
      "grad_norm": 1.779296875,
      "learning_rate": 9.97193599963374e-06,
      "loss": 0.4567,
      "step": 2635
    },
    {
      "epoch": 0.2478273058592655,
      "grad_norm": 0.463134765625,
      "learning_rate": 9.971001959844257e-06,
      "loss": 0.5347,
      "step": 2652
    },
    {
      "epoch": 0.24941594243528642,
      "grad_norm": 1.205078125,
      "learning_rate": 9.970052675063787e-06,
      "loss": 0.2553,
      "step": 2669
    },
    {
      "epoch": 0.25100457901130735,
      "grad_norm": 1.7578125,
      "learning_rate": 9.969088148203579e-06,
      "loss": 0.4713,
      "step": 2686
    },
    {
      "epoch": 0.2525932155873283,
      "grad_norm": 0.403076171875,
      "learning_rate": 9.968108382221627e-06,
      "loss": 0.5314,
      "step": 2703
    },
    {
      "epoch": 0.2541818521633492,
      "grad_norm": 0.98291015625,
      "learning_rate": 9.967113380122666e-06,
      "loss": 0.2274,
      "step": 2720
    },
    {
      "epoch": 0.25577048873937014,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.966103144958152e-06,
      "loss": 0.4455,
      "step": 2737
    },
    {
      "epoch": 0.25735912531539107,
      "grad_norm": 0.466552734375,
      "learning_rate": 9.965077679826256e-06,
      "loss": 0.4896,
      "step": 2754
    },
    {
      "epoch": 0.258947761891412,
      "grad_norm": 1.0419921875,
      "learning_rate": 9.964036987871861e-06,
      "loss": 0.2658,
      "step": 2771
    },
    {
      "epoch": 0.26053639846743293,
      "grad_norm": 2.078125,
      "learning_rate": 9.962981072286545e-06,
      "loss": 0.4868,
      "step": 2788
    },
    {
      "epoch": 0.26212503504345386,
      "grad_norm": 1.203125,
      "learning_rate": 9.96190993630857e-06,
      "loss": 0.4055,
      "step": 2805
    },
    {
      "epoch": 0.26371367161947484,
      "grad_norm": 1.0390625,
      "learning_rate": 9.96082358322288e-06,
      "loss": 0.2543,
      "step": 2822
    },
    {
      "epoch": 0.2653023081954958,
      "grad_norm": 2.037109375,
      "learning_rate": 9.95972201636109e-06,
      "loss": 0.4767,
      "step": 2839
    },
    {
      "epoch": 0.2668909447715167,
      "grad_norm": 0.67431640625,
      "learning_rate": 9.958605239101463e-06,
      "loss": 0.4612,
      "step": 2856
    },
    {
      "epoch": 0.26847958134753763,
      "grad_norm": 1.0087890625,
      "learning_rate": 9.957473254868917e-06,
      "loss": 0.2772,
      "step": 2873
    },
    {
      "epoch": 0.27006821792355856,
      "grad_norm": 1.63671875,
      "learning_rate": 9.956326067135002e-06,
      "loss": 0.5177,
      "step": 2890
    },
    {
      "epoch": 0.2716568544995795,
      "grad_norm": 0.48583984375,
      "learning_rate": 9.955163679417896e-06,
      "loss": 0.4457,
      "step": 2907
    },
    {
      "epoch": 0.2732454910756004,
      "grad_norm": 1.255859375,
      "learning_rate": 9.95398609528239e-06,
      "loss": 0.3055,
      "step": 2924
    },
    {
      "epoch": 0.27483412765162135,
      "grad_norm": 1.7099609375,
      "learning_rate": 9.952793318339884e-06,
      "loss": 0.5562,
      "step": 2941
    },
    {
      "epoch": 0.2764227642276423,
      "grad_norm": 0.6337890625,
      "learning_rate": 9.951585352248365e-06,
      "loss": 0.3751,
      "step": 2958
    },
    {
      "epoch": 0.2780114008036632,
      "grad_norm": 1.15625,
      "learning_rate": 9.950362200712405e-06,
      "loss": 0.2979,
      "step": 2975
    },
    {
      "epoch": 0.27960003737968414,
      "grad_norm": 2.228515625,
      "learning_rate": 9.949123867483146e-06,
      "loss": 0.5297,
      "step": 2992
    },
    {
      "epoch": 0.28118867395570507,
      "grad_norm": 0.65283203125,
      "learning_rate": 9.947870356358287e-06,
      "loss": 0.3912,
      "step": 3009
    },
    {
      "epoch": 0.282777310531726,
      "grad_norm": 1.6064453125,
      "learning_rate": 9.94660167118208e-06,
      "loss": 0.3376,
      "step": 3026
    },
    {
      "epoch": 0.28436594710774693,
      "grad_norm": 2.18359375,
      "learning_rate": 9.945317815845307e-06,
      "loss": 0.5291,
      "step": 3043
    },
    {
      "epoch": 0.28595458368376786,
      "grad_norm": 0.93701171875,
      "learning_rate": 9.944018794285276e-06,
      "loss": 0.4249,
      "step": 3060
    },
    {
      "epoch": 0.2875432202597888,
      "grad_norm": 1.7197265625,
      "learning_rate": 9.942704610485803e-06,
      "loss": 0.3531,
      "step": 3077
    },
    {
      "epoch": 0.2891318568358097,
      "grad_norm": 2.181640625,
      "learning_rate": 9.94137526847721e-06,
      "loss": 0.5112,
      "step": 3094
    },
    {
      "epoch": 0.29072049341183065,
      "grad_norm": 0.533203125,
      "learning_rate": 9.940030772336303e-06,
      "loss": 0.3746,
      "step": 3111
    },
    {
      "epoch": 0.2923091299878516,
      "grad_norm": 1.5009765625,
      "learning_rate": 9.938671126186358e-06,
      "loss": 0.3515,
      "step": 3128
    },
    {
      "epoch": 0.2938977665638725,
      "grad_norm": 1.9814453125,
      "learning_rate": 9.93729633419712e-06,
      "loss": 0.4941,
      "step": 3145
    },
    {
      "epoch": 0.2954864031398935,
      "grad_norm": 0.79736328125,
      "learning_rate": 9.935906400584777e-06,
      "loss": 0.3307,
      "step": 3162
    },
    {
      "epoch": 0.2970750397159144,
      "grad_norm": 1.5244140625,
      "learning_rate": 9.934501329611957e-06,
      "loss": 0.3344,
      "step": 3179
    },
    {
      "epoch": 0.29866367629193535,
      "grad_norm": 2.0078125,
      "learning_rate": 9.933081125587706e-06,
      "loss": 0.5522,
      "step": 3196
    },
    {
      "epoch": 0.3002523128679563,
      "grad_norm": 0.96484375,
      "learning_rate": 9.93164579286749e-06,
      "loss": 0.3031,
      "step": 3213
    },
    {
      "epoch": 0.3018409494439772,
      "grad_norm": 1.4365234375,
      "learning_rate": 9.930195335853161e-06,
      "loss": 0.3945,
      "step": 3230
    },
    {
      "epoch": 0.30342958601999814,
      "grad_norm": 2.33984375,
      "learning_rate": 9.928729758992959e-06,
      "loss": 0.6077,
      "step": 3247
    },
    {
      "epoch": 0.3050182225960191,
      "grad_norm": 0.837890625,
      "learning_rate": 9.92724906678149e-06,
      "loss": 0.287,
      "step": 3264
    },
    {
      "epoch": 0.30660685917204,
      "grad_norm": 1.21875,
      "learning_rate": 9.92575326375972e-06,
      "loss": 0.3536,
      "step": 3281
    },
    {
      "epoch": 0.30819549574806093,
      "grad_norm": 2.48828125,
      "learning_rate": 9.924242354514953e-06,
      "loss": 0.5431,
      "step": 3298
    },
    {
      "epoch": 0.30978413232408186,
      "grad_norm": 0.775390625,
      "learning_rate": 9.922716343680823e-06,
      "loss": 0.2308,
      "step": 3315
    },
    {
      "epoch": 0.3113727689001028,
      "grad_norm": 1.4072265625,
      "learning_rate": 9.921175235937274e-06,
      "loss": 0.3154,
      "step": 3332
    },
    {
      "epoch": 0.3129614054761237,
      "grad_norm": 2.732421875,
      "learning_rate": 9.919619036010556e-06,
      "loss": 0.5608,
      "step": 3349
    },
    {
      "epoch": 0.31455004205214465,
      "grad_norm": 0.85400390625,
      "learning_rate": 9.918047748673194e-06,
      "loss": 0.206,
      "step": 3366
    },
    {
      "epoch": 0.3161386786281656,
      "grad_norm": 1.517578125,
      "learning_rate": 9.916461378743986e-06,
      "loss": 0.408,
      "step": 3383
    },
    {
      "epoch": 0.3177273152041865,
      "grad_norm": 3.0859375,
      "learning_rate": 9.914859931087992e-06,
      "loss": 0.6006,
      "step": 3400
    },
    {
      "epoch": 0.31931595178020744,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.913243410616502e-06,
      "loss": 0.2072,
      "step": 3417
    },
    {
      "epoch": 0.32090458835622837,
      "grad_norm": 1.5771484375,
      "learning_rate": 9.911611822287039e-06,
      "loss": 0.3664,
      "step": 3434
    },
    {
      "epoch": 0.3224932249322493,
      "grad_norm": 0.478271484375,
      "learning_rate": 9.909965171103331e-06,
      "loss": 0.5675,
      "step": 3451
    },
    {
      "epoch": 0.32408186150827023,
      "grad_norm": 1.4599609375,
      "learning_rate": 9.9083034621153e-06,
      "loss": 0.2956,
      "step": 3468
    },
    {
      "epoch": 0.32567049808429116,
      "grad_norm": 1.916015625,
      "learning_rate": 9.906626700419053e-06,
      "loss": 0.508,
      "step": 3485
    },
    {
      "epoch": 0.32725913466031215,
      "grad_norm": 0.2264404296875,
      "learning_rate": 9.904934891156852e-06,
      "loss": 0.5779,
      "step": 3502
    },
    {
      "epoch": 0.3288477712363331,
      "grad_norm": 0.9326171875,
      "learning_rate": 9.903228039517116e-06,
      "loss": 0.2653,
      "step": 3519
    },
    {
      "epoch": 0.330436407812354,
      "grad_norm": 1.8564453125,
      "learning_rate": 9.901506150734388e-06,
      "loss": 0.4316,
      "step": 3536
    },
    {
      "epoch": 0.33202504438837493,
      "grad_norm": 0.2393798828125,
      "learning_rate": 9.89976923008933e-06,
      "loss": 0.5253,
      "step": 3553
    },
    {
      "epoch": 0.33361368096439586,
      "grad_norm": 1.1494140625,
      "learning_rate": 9.898017282908703e-06,
      "loss": 0.2703,
      "step": 3570
    },
    {
      "epoch": 0.3352023175404168,
      "grad_norm": 1.39453125,
      "learning_rate": 9.896250314565353e-06,
      "loss": 0.4118,
      "step": 3587
    },
    {
      "epoch": 0.3367909541164377,
      "grad_norm": 0.1776123046875,
      "learning_rate": 9.894468330478189e-06,
      "loss": 0.4546,
      "step": 3604
    },
    {
      "epoch": 0.33837959069245865,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.892671336112172e-06,
      "loss": 0.2198,
      "step": 3621
    },
    {
      "epoch": 0.3399682272684796,
      "grad_norm": 1.54296875,
      "learning_rate": 9.890859336978295e-06,
      "loss": 0.4696,
      "step": 3638
    },
    {
      "epoch": 0.3415568638445005,
      "grad_norm": 0.5634765625,
      "learning_rate": 9.889032338633571e-06,
      "loss": 0.4633,
      "step": 3655
    },
    {
      "epoch": 0.34314550042052144,
      "grad_norm": 1.216796875,
      "learning_rate": 9.887190346681009e-06,
      "loss": 0.2919,
      "step": 3672
    },
    {
      "epoch": 0.3447341369965424,
      "grad_norm": 1.935546875,
      "learning_rate": 9.8853333667696e-06,
      "loss": 0.4891,
      "step": 3689
    },
    {
      "epoch": 0.3463227735725633,
      "grad_norm": 0.81494140625,
      "learning_rate": 9.883461404594303e-06,
      "loss": 0.4659,
      "step": 3706
    },
    {
      "epoch": 0.34791141014858423,
      "grad_norm": 1.5263671875,
      "learning_rate": 9.881574465896022e-06,
      "loss": 0.3132,
      "step": 3723
    },
    {
      "epoch": 0.34950004672460516,
      "grad_norm": 1.98046875,
      "learning_rate": 9.879672556461588e-06,
      "loss": 0.4814,
      "step": 3740
    },
    {
      "epoch": 0.3510886833006261,
      "grad_norm": 0.77783203125,
      "learning_rate": 9.877755682123751e-06,
      "loss": 0.4218,
      "step": 3757
    },
    {
      "epoch": 0.352677319876647,
      "grad_norm": 1.412109375,
      "learning_rate": 9.875823848761148e-06,
      "loss": 0.3357,
      "step": 3774
    },
    {
      "epoch": 0.35426595645266795,
      "grad_norm": 2.35546875,
      "learning_rate": 9.873877062298298e-06,
      "loss": 0.4997,
      "step": 3791
    },
    {
      "epoch": 0.3558545930286889,
      "grad_norm": 0.751953125,
      "learning_rate": 9.871915328705574e-06,
      "loss": 0.411,
      "step": 3808
    },
    {
      "epoch": 0.35744322960470987,
      "grad_norm": 1.3388671875,
      "learning_rate": 9.869938653999191e-06,
      "loss": 0.3062,
      "step": 3825
    },
    {
      "epoch": 0.3590318661807308,
      "grad_norm": 2.27734375,
      "learning_rate": 9.867947044241182e-06,
      "loss": 0.5262,
      "step": 3842
    },
    {
      "epoch": 0.3606205027567517,
      "grad_norm": 0.72705078125,
      "learning_rate": 9.865940505539386e-06,
      "loss": 0.5616,
      "step": 3859
    },
    {
      "epoch": 0.36220913933277266,
      "grad_norm": 1.3564453125,
      "learning_rate": 9.863919044047423e-06,
      "loss": 0.3186,
      "step": 3876
    },
    {
      "epoch": 0.3637977759087936,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.861882665964681e-06,
      "loss": 0.5198,
      "step": 3893
    },
    {
      "epoch": 0.3653864124848145,
      "grad_norm": 0.69873046875,
      "learning_rate": 9.859831377536293e-06,
      "loss": 0.3628,
      "step": 3910
    },
    {
      "epoch": 0.36697504906083545,
      "grad_norm": 1.1484375,
      "learning_rate": 9.857765185053116e-06,
      "loss": 0.3079,
      "step": 3927
    },
    {
      "epoch": 0.3685636856368564,
      "grad_norm": 2.169921875,
      "learning_rate": 9.85568409485172e-06,
      "loss": 0.545,
      "step": 3944
    },
    {
      "epoch": 0.3701523222128773,
      "grad_norm": 0.6591796875,
      "learning_rate": 9.853588113314354e-06,
      "loss": 0.3379,
      "step": 3961
    },
    {
      "epoch": 0.37174095878889823,
      "grad_norm": 1.201171875,
      "learning_rate": 9.851477246868948e-06,
      "loss": 0.352,
      "step": 3978
    },
    {
      "epoch": 0.37332959536491916,
      "grad_norm": 1.83203125,
      "learning_rate": 9.84935150198907e-06,
      "loss": 0.5088,
      "step": 3995
    },
    {
      "epoch": 0.3749182319409401,
      "grad_norm": 0.7421875,
      "learning_rate": 9.847210885193925e-06,
      "loss": 0.3166,
      "step": 4012
    },
    {
      "epoch": 0.376506868516961,
      "grad_norm": 1.2998046875,
      "learning_rate": 9.845055403048319e-06,
      "loss": 0.3658,
      "step": 4029
    },
    {
      "epoch": 0.37809550509298195,
      "grad_norm": 2.263671875,
      "learning_rate": 9.842885062162653e-06,
      "loss": 0.5306,
      "step": 4046
    },
    {
      "epoch": 0.3796841416690029,
      "grad_norm": 0.77783203125,
      "learning_rate": 9.840699869192894e-06,
      "loss": 0.2993,
      "step": 4063
    },
    {
      "epoch": 0.3812727782450238,
      "grad_norm": 1.36328125,
      "learning_rate": 9.838499830840555e-06,
      "loss": 0.3392,
      "step": 4080
    },
    {
      "epoch": 0.38286141482104474,
      "grad_norm": 2.095703125,
      "learning_rate": 9.836284953852684e-06,
      "loss": 0.5235,
      "step": 4097
    },
    {
      "epoch": 0.3844500513970657,
      "grad_norm": 0.984375,
      "learning_rate": 9.83405524502183e-06,
      "loss": 0.2942,
      "step": 4114
    },
    {
      "epoch": 0.3860386879730866,
      "grad_norm": 1.484375,
      "learning_rate": 9.831810711186025e-06,
      "loss": 0.3817,
      "step": 4131
    },
    {
      "epoch": 0.38762732454910753,
      "grad_norm": 2.125,
      "learning_rate": 9.829551359228774e-06,
      "loss": 0.5732,
      "step": 4148
    },
    {
      "epoch": 0.3892159611251285,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.827277196079024e-06,
      "loss": 0.2473,
      "step": 4165
    },
    {
      "epoch": 0.39080459770114945,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.824988228711138e-06,
      "loss": 0.4134,
      "step": 4182
    },
    {
      "epoch": 0.3923932342771704,
      "grad_norm": 2.427734375,
      "learning_rate": 9.822684464144888e-06,
      "loss": 0.5259,
      "step": 4199
    },
    {
      "epoch": 0.3939818708531913,
      "grad_norm": 0.86669921875,
      "learning_rate": 9.820365909445422e-06,
      "loss": 0.2343,
      "step": 4216
    },
    {
      "epoch": 0.39557050742921224,
      "grad_norm": 1.2109375,
      "learning_rate": 9.818032571723249e-06,
      "loss": 0.3131,
      "step": 4233
    },
    {
      "epoch": 0.39715914400523317,
      "grad_norm": 2.55859375,
      "learning_rate": 9.815684458134212e-06,
      "loss": 0.5624,
      "step": 4250
    },
    {
      "epoch": 0.3987477805812541,
      "grad_norm": 0.87548828125,
      "learning_rate": 9.813321575879466e-06,
      "loss": 0.1775,
      "step": 4267
    },
    {
      "epoch": 0.400336417157275,
      "grad_norm": 1.50390625,
      "learning_rate": 9.810943932205465e-06,
      "loss": 0.4143,
      "step": 4284
    },
    {
      "epoch": 0.40192505373329596,
      "grad_norm": 0.337158203125,
      "learning_rate": 9.808551534403929e-06,
      "loss": 0.5695,
      "step": 4301
    },
    {
      "epoch": 0.4035136903093169,
      "grad_norm": 0.8671875,
      "learning_rate": 9.806144389811824e-06,
      "loss": 0.2241,
      "step": 4318
    },
    {
      "epoch": 0.4051023268853378,
      "grad_norm": 1.6708984375,
      "learning_rate": 9.803722505811348e-06,
      "loss": 0.4214,
      "step": 4335
    },
    {
      "epoch": 0.40669096346135875,
      "grad_norm": 0.418701171875,
      "learning_rate": 9.80128588982989e-06,
      "loss": 0.5379,
      "step": 4352
    },
    {
      "epoch": 0.4082796000373797,
      "grad_norm": 1.02734375,
      "learning_rate": 9.798834549340031e-06,
      "loss": 0.2635,
      "step": 4369
    },
    {
      "epoch": 0.4098682366134006,
      "grad_norm": 1.45703125,
      "learning_rate": 9.796368491859502e-06,
      "loss": 0.4358,
      "step": 4386
    },
    {
      "epoch": 0.41145687318942153,
      "grad_norm": 0.37548828125,
      "learning_rate": 9.79388772495117e-06,
      "loss": 0.4854,
      "step": 4403
    },
    {
      "epoch": 0.41304550976544246,
      "grad_norm": 1.1064453125,
      "learning_rate": 9.791392256223012e-06,
      "loss": 0.2499,
      "step": 4420
    },
    {
      "epoch": 0.4146341463414634,
      "grad_norm": 1.810546875,
      "learning_rate": 9.788882093328089e-06,
      "loss": 0.4545,
      "step": 4437
    },
    {
      "epoch": 0.4162227829174843,
      "grad_norm": 0.265625,
      "learning_rate": 9.786357243964534e-06,
      "loss": 0.4673,
      "step": 4454
    },
    {
      "epoch": 0.41781141949350525,
      "grad_norm": 0.91455078125,
      "learning_rate": 9.783817715875517e-06,
      "loss": 0.2094,
      "step": 4471
    },
    {
      "epoch": 0.41940005606952624,
      "grad_norm": 1.876953125,
      "learning_rate": 9.781263516849216e-06,
      "loss": 0.402,
      "step": 4488
    },
    {
      "epoch": 0.42098869264554717,
      "grad_norm": 0.4345703125,
      "learning_rate": 9.778694654718813e-06,
      "loss": 0.4357,
      "step": 4505
    },
    {
      "epoch": 0.4225773292215681,
      "grad_norm": 0.8837890625,
      "learning_rate": 9.776111137362453e-06,
      "loss": 0.2856,
      "step": 4522
    },
    {
      "epoch": 0.42416596579758903,
      "grad_norm": 1.7802734375,
      "learning_rate": 9.77351297270323e-06,
      "loss": 0.4591,
      "step": 4539
    },
    {
      "epoch": 0.42575460237360996,
      "grad_norm": 0.72216796875,
      "learning_rate": 9.77090016870915e-06,
      "loss": 0.407,
      "step": 4556
    },
    {
      "epoch": 0.4273432389496309,
      "grad_norm": 1.265625,
      "learning_rate": 9.768272733393121e-06,
      "loss": 0.2999,
      "step": 4573
    },
    {
      "epoch": 0.4289318755256518,
      "grad_norm": 1.7109375,
      "learning_rate": 9.765630674812921e-06,
      "loss": 0.4681,
      "step": 4590
    },
    {
      "epoch": 0.43052051210167275,
      "grad_norm": 0.53076171875,
      "learning_rate": 9.762974001071175e-06,
      "loss": 0.363,
      "step": 4607
    },
    {
      "epoch": 0.4321091486776937,
      "grad_norm": 1.25390625,
      "learning_rate": 9.760302720315325e-06,
      "loss": 0.3099,
      "step": 4624
    },
    {
      "epoch": 0.4336977852537146,
      "grad_norm": 1.927734375,
      "learning_rate": 9.757616840737615e-06,
      "loss": 0.5074,
      "step": 4641
    },
    {
      "epoch": 0.43528642182973554,
      "grad_norm": 0.5927734375,
      "learning_rate": 9.75491637057506e-06,
      "loss": 0.4154,
      "step": 4658
    },
    {
      "epoch": 0.43687505840575647,
      "grad_norm": 1.4169921875,
      "learning_rate": 9.752201318109417e-06,
      "loss": 0.2808,
      "step": 4675
    },
    {
      "epoch": 0.4384636949817774,
      "grad_norm": 1.607421875,
      "learning_rate": 9.74947169166717e-06,
      "loss": 0.4569,
      "step": 4692
    },
    {
      "epoch": 0.4400523315577983,
      "grad_norm": 0.8046875,
      "learning_rate": 9.74672749961949e-06,
      "loss": 0.3568,
      "step": 4709
    },
    {
      "epoch": 0.44164096813381926,
      "grad_norm": 1.384765625,
      "learning_rate": 9.743968750382225e-06,
      "loss": 0.3673,
      "step": 4726
    },
    {
      "epoch": 0.4432296047098402,
      "grad_norm": 1.8779296875,
      "learning_rate": 9.741195452415864e-06,
      "loss": 0.4955,
      "step": 4743
    },
    {
      "epoch": 0.4448182412858611,
      "grad_norm": 0.59130859375,
      "learning_rate": 9.738407614225512e-06,
      "loss": 0.3545,
      "step": 4760
    },
    {
      "epoch": 0.44640687786188205,
      "grad_norm": 1.2578125,
      "learning_rate": 9.735605244360868e-06,
      "loss": 0.3063,
      "step": 4777
    },
    {
      "epoch": 0.447995514437903,
      "grad_norm": 2.44921875,
      "learning_rate": 9.732788351416197e-06,
      "loss": 0.5086,
      "step": 4794
    },
    {
      "epoch": 0.4495841510139239,
      "grad_norm": 0.75634765625,
      "learning_rate": 9.729956944030303e-06,
      "loss": 0.324,
      "step": 4811
    },
    {
      "epoch": 0.4511727875899449,
      "grad_norm": 1.388671875,
      "learning_rate": 9.7271110308865e-06,
      "loss": 0.3301,
      "step": 4828
    },
    {
      "epoch": 0.4527614241659658,
      "grad_norm": 2.08984375,
      "learning_rate": 9.724250620712592e-06,
      "loss": 0.5004,
      "step": 4845
    },
    {
      "epoch": 0.45435006074198675,
      "grad_norm": 0.806640625,
      "learning_rate": 9.721375722280837e-06,
      "loss": 0.3057,
      "step": 4862
    },
    {
      "epoch": 0.4559386973180077,
      "grad_norm": 1.91796875,
      "learning_rate": 9.718486344407932e-06,
      "loss": 0.4073,
      "step": 4879
    },
    {
      "epoch": 0.4575273338940286,
      "grad_norm": 2.13671875,
      "learning_rate": 9.715582495954972e-06,
      "loss": 0.5447,
      "step": 4896
    },
    {
      "epoch": 0.45911597047004954,
      "grad_norm": 0.75048828125,
      "learning_rate": 9.712664185827437e-06,
      "loss": 0.2754,
      "step": 4913
    },
    {
      "epoch": 0.46070460704607047,
      "grad_norm": 1.1904296875,
      "learning_rate": 9.709731422975155e-06,
      "loss": 0.3766,
      "step": 4930
    },
    {
      "epoch": 0.4622932436220914,
      "grad_norm": 1.98828125,
      "learning_rate": 9.706784216392274e-06,
      "loss": 0.4748,
      "step": 4947
    },
    {
      "epoch": 0.46388188019811233,
      "grad_norm": 0.8525390625,
      "learning_rate": 9.703822575117243e-06,
      "loss": 0.2786,
      "step": 4964
    },
    {
      "epoch": 0.46547051677413326,
      "grad_norm": 1.5380859375,
      "learning_rate": 9.700846508232778e-06,
      "loss": 0.3988,
      "step": 4981
    },
    {
      "epoch": 0.4670591533501542,
      "grad_norm": 2.5,
      "learning_rate": 9.697856024865835e-06,
      "loss": 0.5408,
      "step": 4998
    },
    {
      "epoch": 0.4686477899261751,
      "grad_norm": 1.01953125,
      "learning_rate": 9.694851134187578e-06,
      "loss": 0.263,
      "step": 5015
    },
    {
      "epoch": 0.47023642650219605,
      "grad_norm": 1.283203125,
      "learning_rate": 9.691831845413362e-06,
      "loss": 0.3988,
      "step": 5032
    },
    {
      "epoch": 0.471825063078217,
      "grad_norm": 2.224609375,
      "learning_rate": 9.688798167802693e-06,
      "loss": 0.616,
      "step": 5049
    },
    {
      "epoch": 0.4734136996542379,
      "grad_norm": 0.822265625,
      "learning_rate": 9.685750110659206e-06,
      "loss": 0.1851,
      "step": 5066
    },
    {
      "epoch": 0.47500233623025884,
      "grad_norm": 1.2666015625,
      "learning_rate": 9.682687683330636e-06,
      "loss": 0.3746,
      "step": 5083
    },
    {
      "epoch": 0.47659097280627977,
      "grad_norm": 2.953125,
      "learning_rate": 9.679610895208785e-06,
      "loss": 0.6085,
      "step": 5100
    },
    {
      "epoch": 0.4781796093823007,
      "grad_norm": 1.01171875,
      "learning_rate": 9.6765197557295e-06,
      "loss": 0.2046,
      "step": 5117
    },
    {
      "epoch": 0.4797682459583216,
      "grad_norm": 1.6572265625,
      "learning_rate": 9.673414274372641e-06,
      "loss": 0.4254,
      "step": 5134
    },
    {
      "epoch": 0.4813568825343426,
      "grad_norm": 0.4345703125,
      "learning_rate": 9.670294460662048e-06,
      "loss": 0.608,
      "step": 5151
    },
    {
      "epoch": 0.48294551911036354,
      "grad_norm": 0.98974609375,
      "learning_rate": 9.667160324165516e-06,
      "loss": 0.2329,
      "step": 5168
    },
    {
      "epoch": 0.48453415568638447,
      "grad_norm": 1.41015625,
      "learning_rate": 9.664011874494766e-06,
      "loss": 0.3831,
      "step": 5185
    },
    {
      "epoch": 0.4861227922624054,
      "grad_norm": 0.304931640625,
      "learning_rate": 9.660849121305414e-06,
      "loss": 0.5174,
      "step": 5202
    },
    {
      "epoch": 0.48771142883842633,
      "grad_norm": 0.875,
      "learning_rate": 9.657672074296944e-06,
      "loss": 0.2318,
      "step": 5219
    },
    {
      "epoch": 0.48930006541444726,
      "grad_norm": 1.623046875,
      "learning_rate": 9.654480743212672e-06,
      "loss": 0.4244,
      "step": 5236
    },
    {
      "epoch": 0.4908887019904682,
      "grad_norm": 0.19677734375,
      "learning_rate": 9.651275137839723e-06,
      "loss": 0.5229,
      "step": 5253
    },
    {
      "epoch": 0.4924773385664891,
      "grad_norm": 0.9189453125,
      "learning_rate": 9.648055268008997e-06,
      "loss": 0.2287,
      "step": 5270
    },
    {
      "epoch": 0.49406597514251005,
      "grad_norm": 1.62109375,
      "learning_rate": 9.64482114359514e-06,
      "loss": 0.4199,
      "step": 5287
    },
    {
      "epoch": 0.495654611718531,
      "grad_norm": 0.2281494140625,
      "learning_rate": 9.641572774516516e-06,
      "loss": 0.4793,
      "step": 5304
    },
    {
      "epoch": 0.4972432482945519,
      "grad_norm": 1.15625,
      "learning_rate": 9.63831017073517e-06,
      "loss": 0.2725,
      "step": 5321
    },
    {
      "epoch": 0.49883188487057284,
      "grad_norm": 1.7001953125,
      "learning_rate": 9.635033342256805e-06,
      "loss": 0.4374,
      "step": 5338
    },
    {
      "epoch": 0.5004205214465938,
      "grad_norm": 0.433349609375,
      "learning_rate": 9.63174229913075e-06,
      "loss": 0.4318,
      "step": 5355
    },
    {
      "epoch": 0.5020091580226147,
      "grad_norm": 1.046875,
      "learning_rate": 9.62843705144992e-06,
      "loss": 0.2716,
      "step": 5372
    },
    {
      "epoch": 0.5035977945986356,
      "grad_norm": 2.1875,
      "learning_rate": 9.6251176093508e-06,
      "loss": 0.4876,
      "step": 5389
    },
    {
      "epoch": 0.5051864311746566,
      "grad_norm": 0.3447265625,
      "learning_rate": 9.621783983013401e-06,
      "loss": 0.4381,
      "step": 5406
    },
    {
      "epoch": 0.5067750677506775,
      "grad_norm": 1.205078125,
      "learning_rate": 9.618436182661237e-06,
      "loss": 0.285,
      "step": 5423
    },
    {
      "epoch": 0.5083637043266984,
      "grad_norm": 2.310546875,
      "learning_rate": 9.615074218561291e-06,
      "loss": 0.4788,
      "step": 5440
    },
    {
      "epoch": 0.5099523409027193,
      "grad_norm": 0.271728515625,
      "learning_rate": 9.61169810102398e-06,
      "loss": 0.4248,
      "step": 5457
    },
    {
      "epoch": 0.5115409774787403,
      "grad_norm": 0.9267578125,
      "learning_rate": 9.60830784040313e-06,
      "loss": 0.2277,
      "step": 5474
    },
    {
      "epoch": 0.5131296140547612,
      "grad_norm": 1.6455078125,
      "learning_rate": 9.604903447095938e-06,
      "loss": 0.4025,
      "step": 5491
    },
    {
      "epoch": 0.5147182506307821,
      "grad_norm": 0.71240234375,
      "learning_rate": 9.601484931542943e-06,
      "loss": 0.4283,
      "step": 5508
    },
    {
      "epoch": 0.5163068872068031,
      "grad_norm": 1.0087890625,
      "learning_rate": 9.598052304227998e-06,
      "loss": 0.2746,
      "step": 5525
    },
    {
      "epoch": 0.517895523782824,
      "grad_norm": 1.572265625,
      "learning_rate": 9.594605575678228e-06,
      "loss": 0.4994,
      "step": 5542
    },
    {
      "epoch": 0.5194841603588449,
      "grad_norm": 0.568359375,
      "learning_rate": 9.591144756464008e-06,
      "loss": 0.3607,
      "step": 5559
    },
    {
      "epoch": 0.5210727969348659,
      "grad_norm": 1.150390625,
      "learning_rate": 9.587669857198925e-06,
      "loss": 0.3021,
      "step": 5576
    },
    {
      "epoch": 0.5226614335108868,
      "grad_norm": 1.5888671875,
      "learning_rate": 9.584180888539741e-06,
      "loss": 0.4276,
      "step": 5593
    },
    {
      "epoch": 0.5242500700869077,
      "grad_norm": 0.71142578125,
      "learning_rate": 9.580677861186377e-06,
      "loss": 0.3128,
      "step": 5610
    },
    {
      "epoch": 0.5258387066629286,
      "grad_norm": 1.201171875,
      "learning_rate": 9.577160785881855e-06,
      "loss": 0.3417,
      "step": 5627
    },
    {
      "epoch": 0.5274273432389497,
      "grad_norm": 2.05859375,
      "learning_rate": 9.573629673412293e-06,
      "loss": 0.5145,
      "step": 5644
    },
    {
      "epoch": 0.5290159798149706,
      "grad_norm": 0.64208984375,
      "learning_rate": 9.57008453460685e-06,
      "loss": 0.3125,
      "step": 5661
    },
    {
      "epoch": 0.5306046163909915,
      "grad_norm": 1.044921875,
      "learning_rate": 9.5665253803377e-06,
      "loss": 0.3029,
      "step": 5678
    },
    {
      "epoch": 0.5321932529670125,
      "grad_norm": 2.09375,
      "learning_rate": 9.56295222152e-06,
      "loss": 0.515,
      "step": 5695
    },
    {
      "epoch": 0.5337818895430334,
      "grad_norm": 1.0810546875,
      "learning_rate": 9.559365069111864e-06,
      "loss": 0.2806,
      "step": 5712
    },
    {
      "epoch": 0.5353705261190543,
      "grad_norm": 1.3232421875,
      "learning_rate": 9.555763934114309e-06,
      "loss": 0.3166,
      "step": 5729
    },
    {
      "epoch": 0.5369591626950753,
      "grad_norm": 2.236328125,
      "learning_rate": 9.552148827571241e-06,
      "loss": 0.512,
      "step": 5746
    },
    {
      "epoch": 0.5385477992710962,
      "grad_norm": 1.1650390625,
      "learning_rate": 9.548519760569415e-06,
      "loss": 0.3119,
      "step": 5763
    },
    {
      "epoch": 0.5401364358471171,
      "grad_norm": 1.5068359375,
      "learning_rate": 9.544876744238394e-06,
      "loss": 0.36,
      "step": 5780
    },
    {
      "epoch": 0.541725072423138,
      "grad_norm": 2.099609375,
      "learning_rate": 9.541219789750523e-06,
      "loss": 0.5053,
      "step": 5797
    },
    {
      "epoch": 0.543313708999159,
      "grad_norm": 0.79296875,
      "learning_rate": 9.537548908320895e-06,
      "loss": 0.2412,
      "step": 5814
    },
    {
      "epoch": 0.5449023455751799,
      "grad_norm": 1.7060546875,
      "learning_rate": 9.53386411120731e-06,
      "loss": 0.365,
      "step": 5831
    },
    {
      "epoch": 0.5464909821512008,
      "grad_norm": 2.990234375,
      "learning_rate": 9.530165409710246e-06,
      "loss": 0.5525,
      "step": 5848
    },
    {
      "epoch": 0.5480796187272218,
      "grad_norm": 0.857421875,
      "learning_rate": 9.526452815172824e-06,
      "loss": 0.3103,
      "step": 5865
    },
    {
      "epoch": 0.5496682553032427,
      "grad_norm": 1.458984375,
      "learning_rate": 9.52272633898077e-06,
      "loss": 0.4252,
      "step": 5882
    },
    {
      "epoch": 0.5512568918792636,
      "grad_norm": 2.52734375,
      "learning_rate": 9.518985992562383e-06,
      "loss": 0.5485,
      "step": 5899
    },
    {
      "epoch": 0.5528455284552846,
      "grad_norm": 1.2783203125,
      "learning_rate": 9.515231787388499e-06,
      "loss": 0.2215,
      "step": 5916
    },
    {
      "epoch": 0.5544341650313055,
      "grad_norm": 1.2705078125,
      "learning_rate": 9.511463734972456e-06,
      "loss": 0.404,
      "step": 5933
    },
    {
      "epoch": 0.5560228016073264,
      "grad_norm": 2.103515625,
      "learning_rate": 9.507681846870058e-06,
      "loss": 0.5888,
      "step": 5950
    },
    {
      "epoch": 0.5576114381833474,
      "grad_norm": 1.064453125,
      "learning_rate": 9.503886134679539e-06,
      "loss": 0.1894,
      "step": 5967
    },
    {
      "epoch": 0.5592000747593683,
      "grad_norm": 1.091796875,
      "learning_rate": 9.500076610041531e-06,
      "loss": 0.3988,
      "step": 5984
    },
    {
      "epoch": 0.5607887113353892,
      "grad_norm": 0.273681640625,
      "learning_rate": 9.496253284639024e-06,
      "loss": 0.5466,
      "step": 6001
    },
    {
      "epoch": 0.5623773479114101,
      "grad_norm": 1.224609375,
      "learning_rate": 9.492416170197333e-06,
      "loss": 0.2423,
      "step": 6018
    },
    {
      "epoch": 0.5639659844874311,
      "grad_norm": 1.2763671875,
      "learning_rate": 9.48856527848406e-06,
      "loss": 0.3584,
      "step": 6035
    },
    {
      "epoch": 0.565554621063452,
      "grad_norm": 0.37841796875,
      "learning_rate": 9.484700621309059e-06,
      "loss": 0.4996,
      "step": 6052
    },
    {
      "epoch": 0.5671432576394729,
      "grad_norm": 0.9658203125,
      "learning_rate": 9.480822210524402e-06,
      "loss": 0.2162,
      "step": 6069
    },
    {
      "epoch": 0.5687318942154939,
      "grad_norm": 1.4443359375,
      "learning_rate": 9.476930058024338e-06,
      "loss": 0.4194,
      "step": 6086
    },
    {
      "epoch": 0.5703205307915148,
      "grad_norm": 0.08843994140625,
      "learning_rate": 9.473024175745258e-06,
      "loss": 0.5071,
      "step": 6103
    },
    {
      "epoch": 0.5719091673675357,
      "grad_norm": 0.99072265625,
      "learning_rate": 9.46910457566566e-06,
      "loss": 0.1799,
      "step": 6120
    },
    {
      "epoch": 0.5734978039435566,
      "grad_norm": 1.7734375,
      "learning_rate": 9.465171269806114e-06,
      "loss": 0.4229,
      "step": 6137
    },
    {
      "epoch": 0.5750864405195776,
      "grad_norm": 0.373046875,
      "learning_rate": 9.46122427022922e-06,
      "loss": 0.4709,
      "step": 6154
    },
    {
      "epoch": 0.5766750770955985,
      "grad_norm": 1.40625,
      "learning_rate": 9.457263589039575e-06,
      "loss": 0.2852,
      "step": 6171
    },
    {
      "epoch": 0.5782637136716194,
      "grad_norm": 1.541015625,
      "learning_rate": 9.453289238383735e-06,
      "loss": 0.447,
      "step": 6188
    },
    {
      "epoch": 0.5798523502476404,
      "grad_norm": 0.724609375,
      "learning_rate": 9.449301230450173e-06,
      "loss": 0.4427,
      "step": 6205
    },
    {
      "epoch": 0.5814409868236613,
      "grad_norm": 1.2216796875,
      "learning_rate": 9.445299577469252e-06,
      "loss": 0.3075,
      "step": 6222
    },
    {
      "epoch": 0.5830296233996822,
      "grad_norm": 1.857421875,
      "learning_rate": 9.44128429171318e-06,
      "loss": 0.5006,
      "step": 6239
    },
    {
      "epoch": 0.5846182599757032,
      "grad_norm": 0.4912109375,
      "learning_rate": 9.437255385495969e-06,
      "loss": 0.4722,
      "step": 6256
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 1.08203125,
      "learning_rate": 9.433212871173407e-06,
      "loss": 0.319,
      "step": 6273
    },
    {
      "epoch": 0.587795533127745,
      "grad_norm": 1.6484375,
      "learning_rate": 9.429156761143014e-06,
      "loss": 0.4377,
      "step": 6290
    },
    {
      "epoch": 0.589384169703766,
      "grad_norm": 0.51416015625,
      "learning_rate": 9.425087067844005e-06,
      "loss": 0.4439,
      "step": 6307
    },
    {
      "epoch": 0.590972806279787,
      "grad_norm": 0.98046875,
      "learning_rate": 9.421003803757251e-06,
      "loss": 0.2866,
      "step": 6324
    },
    {
      "epoch": 0.5925614428558079,
      "grad_norm": 1.53515625,
      "learning_rate": 9.416906981405242e-06,
      "loss": 0.3949,
      "step": 6341
    },
    {
      "epoch": 0.5941500794318288,
      "grad_norm": 0.654296875,
      "learning_rate": 9.41279661335205e-06,
      "loss": 0.3554,
      "step": 6358
    },
    {
      "epoch": 0.5957387160078498,
      "grad_norm": 1.1337890625,
      "learning_rate": 9.408672712203287e-06,
      "loss": 0.3003,
      "step": 6375
    },
    {
      "epoch": 0.5973273525838707,
      "grad_norm": 2.009765625,
      "learning_rate": 9.404535290606068e-06,
      "loss": 0.5044,
      "step": 6392
    },
    {
      "epoch": 0.5989159891598916,
      "grad_norm": 0.494384765625,
      "learning_rate": 9.400384361248973e-06,
      "loss": 0.363,
      "step": 6409
    },
    {
      "epoch": 0.6000373796841416,
      "eval_loss": 0.38770315051078796,
      "eval_runtime": 1038.5043,
      "eval_samples_per_second": 7.727,
      "eval_steps_per_second": 2.576,
      "step": 6421
    }
  ],
  "logging_steps": 17,
  "max_steps": 32103,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 3211,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.713583422510858e+17,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
