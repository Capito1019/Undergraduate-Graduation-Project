{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.8003924866834875,
  "eval_steps": 6421,
  "global_step": 19266,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015886365760209326,
      "grad_norm": 0.30615234375,
      "learning_rate": 1.0585305105853052e-07,
      "loss": 0.3677,
      "step": 17
    },
    {
      "epoch": 0.003177273152041865,
      "grad_norm": 1.23828125,
      "learning_rate": 2.1170610211706104e-07,
      "loss": 0.5717,
      "step": 34
    },
    {
      "epoch": 0.004765909728062798,
      "grad_norm": 0.280029296875,
      "learning_rate": 3.1755915317559156e-07,
      "loss": 0.8085,
      "step": 51
    },
    {
      "epoch": 0.00635454630408373,
      "grad_norm": 0.34228515625,
      "learning_rate": 4.234122042341221e-07,
      "loss": 0.3141,
      "step": 68
    },
    {
      "epoch": 0.007943182880104663,
      "grad_norm": 0.6669921875,
      "learning_rate": 5.292652552926527e-07,
      "loss": 0.6057,
      "step": 85
    },
    {
      "epoch": 0.009531819456125596,
      "grad_norm": 0.106689453125,
      "learning_rate": 6.351183063511831e-07,
      "loss": 0.7759,
      "step": 102
    },
    {
      "epoch": 0.011120456032146528,
      "grad_norm": 0.41064453125,
      "learning_rate": 7.409713574097137e-07,
      "loss": 0.3873,
      "step": 119
    },
    {
      "epoch": 0.01270909260816746,
      "grad_norm": 0.52392578125,
      "learning_rate": 8.468244084682442e-07,
      "loss": 0.6285,
      "step": 136
    },
    {
      "epoch": 0.014297729184188394,
      "grad_norm": 0.1488037109375,
      "learning_rate": 9.526774595267747e-07,
      "loss": 0.7612,
      "step": 153
    },
    {
      "epoch": 0.015886365760209326,
      "grad_norm": 0.352294921875,
      "learning_rate": 1.0585305105853053e-06,
      "loss": 0.3533,
      "step": 170
    },
    {
      "epoch": 0.01747500233623026,
      "grad_norm": 0.74755859375,
      "learning_rate": 1.1643835616438357e-06,
      "loss": 0.6135,
      "step": 187
    },
    {
      "epoch": 0.019063638912251192,
      "grad_norm": 0.15283203125,
      "learning_rate": 1.2702366127023662e-06,
      "loss": 0.7373,
      "step": 204
    },
    {
      "epoch": 0.020652275488272125,
      "grad_norm": 0.59130859375,
      "learning_rate": 1.3760896637608966e-06,
      "loss": 0.4345,
      "step": 221
    },
    {
      "epoch": 0.022240912064293055,
      "grad_norm": 0.5458984375,
      "learning_rate": 1.4819427148194274e-06,
      "loss": 0.6566,
      "step": 238
    },
    {
      "epoch": 0.02382954864031399,
      "grad_norm": 0.29541015625,
      "learning_rate": 1.5877957658779578e-06,
      "loss": 0.7509,
      "step": 255
    },
    {
      "epoch": 0.02541818521633492,
      "grad_norm": 0.490478515625,
      "learning_rate": 1.6936488169364883e-06,
      "loss": 0.4075,
      "step": 272
    },
    {
      "epoch": 0.027006821792355855,
      "grad_norm": 0.796875,
      "learning_rate": 1.799501867995019e-06,
      "loss": 0.6673,
      "step": 289
    },
    {
      "epoch": 0.028595458368376788,
      "grad_norm": 0.1600341796875,
      "learning_rate": 1.9053549190535495e-06,
      "loss": 0.6821,
      "step": 306
    },
    {
      "epoch": 0.03018409494439772,
      "grad_norm": 0.4326171875,
      "learning_rate": 2.01120797011208e-06,
      "loss": 0.3543,
      "step": 323
    },
    {
      "epoch": 0.03177273152041865,
      "grad_norm": 0.75732421875,
      "learning_rate": 2.1170610211706106e-06,
      "loss": 0.6114,
      "step": 340
    },
    {
      "epoch": 0.03336136809643959,
      "grad_norm": 0.20703125,
      "learning_rate": 2.2229140722291408e-06,
      "loss": 0.5834,
      "step": 357
    },
    {
      "epoch": 0.03495000467246052,
      "grad_norm": 0.326416015625,
      "learning_rate": 2.3287671232876713e-06,
      "loss": 0.3978,
      "step": 374
    },
    {
      "epoch": 0.03653864124848145,
      "grad_norm": 0.62646484375,
      "learning_rate": 2.434620174346202e-06,
      "loss": 0.6366,
      "step": 391
    },
    {
      "epoch": 0.038127277824502384,
      "grad_norm": 0.259765625,
      "learning_rate": 2.5404732254047325e-06,
      "loss": 0.6095,
      "step": 408
    },
    {
      "epoch": 0.039715914400523314,
      "grad_norm": 0.82861328125,
      "learning_rate": 2.646326276463263e-06,
      "loss": 0.4376,
      "step": 425
    },
    {
      "epoch": 0.04130455097654425,
      "grad_norm": 0.97509765625,
      "learning_rate": 2.7521793275217932e-06,
      "loss": 0.7023,
      "step": 442
    },
    {
      "epoch": 0.04289318755256518,
      "grad_norm": 0.2115478515625,
      "learning_rate": 2.858032378580324e-06,
      "loss": 0.5356,
      "step": 459
    },
    {
      "epoch": 0.04448182412858611,
      "grad_norm": 0.83154296875,
      "learning_rate": 2.963885429638855e-06,
      "loss": 0.4777,
      "step": 476
    },
    {
      "epoch": 0.04607046070460705,
      "grad_norm": 0.7978515625,
      "learning_rate": 3.069738480697385e-06,
      "loss": 0.6041,
      "step": 493
    },
    {
      "epoch": 0.04765909728062798,
      "grad_norm": 0.41748046875,
      "learning_rate": 3.1755915317559155e-06,
      "loss": 0.4227,
      "step": 510
    },
    {
      "epoch": 0.04924773385664891,
      "grad_norm": 0.8466796875,
      "learning_rate": 3.281444582814446e-06,
      "loss": 0.443,
      "step": 527
    },
    {
      "epoch": 0.05083637043266984,
      "grad_norm": 0.9345703125,
      "learning_rate": 3.3872976338729767e-06,
      "loss": 0.6736,
      "step": 544
    },
    {
      "epoch": 0.05242500700869078,
      "grad_norm": 0.5810546875,
      "learning_rate": 3.4931506849315072e-06,
      "loss": 0.384,
      "step": 561
    },
    {
      "epoch": 0.05401364358471171,
      "grad_norm": 0.68017578125,
      "learning_rate": 3.599003735990038e-06,
      "loss": 0.3962,
      "step": 578
    },
    {
      "epoch": 0.05560228016073264,
      "grad_norm": 1.443359375,
      "learning_rate": 3.704856787048568e-06,
      "loss": 0.6065,
      "step": 595
    },
    {
      "epoch": 0.057190916736753576,
      "grad_norm": 0.67578125,
      "learning_rate": 3.810709838107099e-06,
      "loss": 0.4176,
      "step": 612
    },
    {
      "epoch": 0.058779553312774506,
      "grad_norm": 0.6826171875,
      "learning_rate": 3.916562889165629e-06,
      "loss": 0.4848,
      "step": 629
    },
    {
      "epoch": 0.06036818988879544,
      "grad_norm": 1.1982421875,
      "learning_rate": 4.02241594022416e-06,
      "loss": 0.6994,
      "step": 646
    },
    {
      "epoch": 0.06195682646481637,
      "grad_norm": 0.52587890625,
      "learning_rate": 4.12826899128269e-06,
      "loss": 0.3928,
      "step": 663
    },
    {
      "epoch": 0.0635454630408373,
      "grad_norm": 1.2802734375,
      "learning_rate": 4.234122042341221e-06,
      "loss": 0.4216,
      "step": 680
    },
    {
      "epoch": 0.06513409961685823,
      "grad_norm": 1.1298828125,
      "learning_rate": 4.339975093399751e-06,
      "loss": 0.618,
      "step": 697
    },
    {
      "epoch": 0.06672273619287918,
      "grad_norm": 0.7412109375,
      "learning_rate": 4.4458281444582815e-06,
      "loss": 0.3223,
      "step": 714
    },
    {
      "epoch": 0.0683113727689001,
      "grad_norm": 1.58984375,
      "learning_rate": 4.5516811955168125e-06,
      "loss": 0.5041,
      "step": 731
    },
    {
      "epoch": 0.06990000934492104,
      "grad_norm": 1.41796875,
      "learning_rate": 4.657534246575343e-06,
      "loss": 0.6834,
      "step": 748
    },
    {
      "epoch": 0.07148864592094197,
      "grad_norm": 0.86083984375,
      "learning_rate": 4.763387297633874e-06,
      "loss": 0.2818,
      "step": 765
    },
    {
      "epoch": 0.0730772824969629,
      "grad_norm": 0.94189453125,
      "learning_rate": 4.869240348692404e-06,
      "loss": 0.431,
      "step": 782
    },
    {
      "epoch": 0.07466591907298384,
      "grad_norm": 1.87109375,
      "learning_rate": 4.975093399750934e-06,
      "loss": 0.632,
      "step": 799
    },
    {
      "epoch": 0.07625455564900477,
      "grad_norm": 0.83203125,
      "learning_rate": 5.080946450809465e-06,
      "loss": 0.3002,
      "step": 816
    },
    {
      "epoch": 0.0778431922250257,
      "grad_norm": 1.318359375,
      "learning_rate": 5.186799501867995e-06,
      "loss": 0.4234,
      "step": 833
    },
    {
      "epoch": 0.07943182880104663,
      "grad_norm": 1.84375,
      "learning_rate": 5.292652552926526e-06,
      "loss": 0.6675,
      "step": 850
    },
    {
      "epoch": 0.08102046537706756,
      "grad_norm": 0.9638671875,
      "learning_rate": 5.398505603985057e-06,
      "loss": 0.2349,
      "step": 867
    },
    {
      "epoch": 0.0826091019530885,
      "grad_norm": 0.955078125,
      "learning_rate": 5.5043586550435864e-06,
      "loss": 0.4604,
      "step": 884
    },
    {
      "epoch": 0.08419773852910943,
      "grad_norm": 0.29052734375,
      "learning_rate": 5.6102117061021174e-06,
      "loss": 0.5977,
      "step": 901
    },
    {
      "epoch": 0.08578637510513036,
      "grad_norm": 0.7275390625,
      "learning_rate": 5.716064757160648e-06,
      "loss": 0.2387,
      "step": 918
    },
    {
      "epoch": 0.08737501168115129,
      "grad_norm": 1.1982421875,
      "learning_rate": 5.821917808219179e-06,
      "loss": 0.4467,
      "step": 935
    },
    {
      "epoch": 0.08896364825717222,
      "grad_norm": 0.444091796875,
      "learning_rate": 5.92777085927771e-06,
      "loss": 0.5707,
      "step": 952
    },
    {
      "epoch": 0.09055228483319316,
      "grad_norm": 0.982421875,
      "learning_rate": 6.033623910336239e-06,
      "loss": 0.3508,
      "step": 969
    },
    {
      "epoch": 0.0921409214092141,
      "grad_norm": 1.3583984375,
      "learning_rate": 6.13947696139477e-06,
      "loss": 0.4969,
      "step": 986
    },
    {
      "epoch": 0.09372955798523502,
      "grad_norm": 0.222412109375,
      "learning_rate": 6.245330012453301e-06,
      "loss": 0.5931,
      "step": 1003
    },
    {
      "epoch": 0.09531819456125595,
      "grad_norm": 0.84619140625,
      "learning_rate": 6.351183063511831e-06,
      "loss": 0.3055,
      "step": 1020
    },
    {
      "epoch": 0.09690683113727688,
      "grad_norm": 1.484375,
      "learning_rate": 6.457036114570362e-06,
      "loss": 0.5078,
      "step": 1037
    },
    {
      "epoch": 0.09849546771329783,
      "grad_norm": 0.6533203125,
      "learning_rate": 6.562889165628892e-06,
      "loss": 0.5422,
      "step": 1054
    },
    {
      "epoch": 0.10008410428931876,
      "grad_norm": 1.162109375,
      "learning_rate": 6.668742216687422e-06,
      "loss": 0.2925,
      "step": 1071
    },
    {
      "epoch": 0.10167274086533969,
      "grad_norm": 1.6494140625,
      "learning_rate": 6.774595267745953e-06,
      "loss": 0.4744,
      "step": 1088
    },
    {
      "epoch": 0.10326137744136062,
      "grad_norm": 0.85009765625,
      "learning_rate": 6.8804483188044835e-06,
      "loss": 0.5842,
      "step": 1105
    },
    {
      "epoch": 0.10485001401738156,
      "grad_norm": 0.99853515625,
      "learning_rate": 6.9863013698630145e-06,
      "loss": 0.361,
      "step": 1122
    },
    {
      "epoch": 0.10643865059340249,
      "grad_norm": 2.166015625,
      "learning_rate": 7.092154420921545e-06,
      "loss": 0.4835,
      "step": 1139
    },
    {
      "epoch": 0.10802728716942342,
      "grad_norm": 0.6533203125,
      "learning_rate": 7.198007471980076e-06,
      "loss": 0.4625,
      "step": 1156
    },
    {
      "epoch": 0.10961592374544435,
      "grad_norm": 0.9951171875,
      "learning_rate": 7.303860523038606e-06,
      "loss": 0.3469,
      "step": 1173
    },
    {
      "epoch": 0.11120456032146528,
      "grad_norm": 3.162109375,
      "learning_rate": 7.409713574097136e-06,
      "loss": 0.5231,
      "step": 1190
    },
    {
      "epoch": 0.11279319689748622,
      "grad_norm": 0.455078125,
      "learning_rate": 7.515566625155667e-06,
      "loss": 0.4403,
      "step": 1207
    },
    {
      "epoch": 0.11438183347350715,
      "grad_norm": 1.091796875,
      "learning_rate": 7.621419676214198e-06,
      "loss": 0.3341,
      "step": 1224
    },
    {
      "epoch": 0.11597047004952808,
      "grad_norm": 2.255859375,
      "learning_rate": 7.727272727272727e-06,
      "loss": 0.5361,
      "step": 1241
    },
    {
      "epoch": 0.11755910662554901,
      "grad_norm": 0.5732421875,
      "learning_rate": 7.833125778331258e-06,
      "loss": 0.4021,
      "step": 1258
    },
    {
      "epoch": 0.11914774320156994,
      "grad_norm": 0.9658203125,
      "learning_rate": 7.93897882938979e-06,
      "loss": 0.3574,
      "step": 1275
    },
    {
      "epoch": 0.12073637977759089,
      "grad_norm": 1.7958984375,
      "learning_rate": 8.04483188044832e-06,
      "loss": 0.5173,
      "step": 1292
    },
    {
      "epoch": 0.12232501635361182,
      "grad_norm": 0.71923828125,
      "learning_rate": 8.150684931506851e-06,
      "loss": 0.4297,
      "step": 1309
    },
    {
      "epoch": 0.12391365292963274,
      "grad_norm": 1.091796875,
      "learning_rate": 8.25653798256538e-06,
      "loss": 0.3493,
      "step": 1326
    },
    {
      "epoch": 0.12550228950565367,
      "grad_norm": 3.525390625,
      "learning_rate": 8.362391033623912e-06,
      "loss": 0.5447,
      "step": 1343
    },
    {
      "epoch": 0.1270909260816746,
      "grad_norm": 0.63623046875,
      "learning_rate": 8.468244084682442e-06,
      "loss": 0.3913,
      "step": 1360
    },
    {
      "epoch": 0.12867956265769553,
      "grad_norm": 1.380859375,
      "learning_rate": 8.574097135740972e-06,
      "loss": 0.3514,
      "step": 1377
    },
    {
      "epoch": 0.13026819923371646,
      "grad_norm": 1.703125,
      "learning_rate": 8.679950186799503e-06,
      "loss": 0.5447,
      "step": 1394
    },
    {
      "epoch": 0.13185683580973742,
      "grad_norm": 0.5234375,
      "learning_rate": 8.785803237858032e-06,
      "loss": 0.3191,
      "step": 1411
    },
    {
      "epoch": 0.13344547238575835,
      "grad_norm": 1.115234375,
      "learning_rate": 8.891656288916563e-06,
      "loss": 0.3458,
      "step": 1428
    },
    {
      "epoch": 0.13503410896177928,
      "grad_norm": 1.392578125,
      "learning_rate": 8.997509339975094e-06,
      "loss": 0.5391,
      "step": 1445
    },
    {
      "epoch": 0.1366227455378002,
      "grad_norm": 0.60888671875,
      "learning_rate": 9.103362391033625e-06,
      "loss": 0.2989,
      "step": 1462
    },
    {
      "epoch": 0.13821138211382114,
      "grad_norm": 1.1220703125,
      "learning_rate": 9.209215442092156e-06,
      "loss": 0.3724,
      "step": 1479
    },
    {
      "epoch": 0.13980001868984207,
      "grad_norm": 2.53125,
      "learning_rate": 9.315068493150685e-06,
      "loss": 0.5454,
      "step": 1496
    },
    {
      "epoch": 0.141388655265863,
      "grad_norm": 0.6748046875,
      "learning_rate": 9.420921544209216e-06,
      "loss": 0.3114,
      "step": 1513
    },
    {
      "epoch": 0.14297729184188393,
      "grad_norm": 1.4423828125,
      "learning_rate": 9.526774595267747e-06,
      "loss": 0.3943,
      "step": 1530
    },
    {
      "epoch": 0.14456592841790486,
      "grad_norm": 2.107421875,
      "learning_rate": 9.632627646326277e-06,
      "loss": 0.62,
      "step": 1547
    },
    {
      "epoch": 0.1461545649939258,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.738480697384808e-06,
      "loss": 0.2803,
      "step": 1564
    },
    {
      "epoch": 0.14774320156994675,
      "grad_norm": 1.455078125,
      "learning_rate": 9.844333748443339e-06,
      "loss": 0.3949,
      "step": 1581
    },
    {
      "epoch": 0.14933183814596768,
      "grad_norm": 2.21875,
      "learning_rate": 9.950186799501868e-06,
      "loss": 0.6392,
      "step": 1598
    },
    {
      "epoch": 0.1509204747219886,
      "grad_norm": 0.765625,
      "learning_rate": 9.999997851128222e-06,
      "loss": 0.2648,
      "step": 1615
    },
    {
      "epoch": 0.15250911129800954,
      "grad_norm": 1.33984375,
      "learning_rate": 9.999982066215332e-06,
      "loss": 0.3933,
      "step": 1632
    },
    {
      "epoch": 0.15409774787403047,
      "grad_norm": 2.046875,
      "learning_rate": 9.999950947435717e-06,
      "loss": 0.6,
      "step": 1649
    },
    {
      "epoch": 0.1556863844500514,
      "grad_norm": 0.65966796875,
      "learning_rate": 9.999904494884808e-06,
      "loss": 0.2117,
      "step": 1666
    },
    {
      "epoch": 0.15727502102607233,
      "grad_norm": 1.177734375,
      "learning_rate": 9.999842708705073e-06,
      "loss": 0.3763,
      "step": 1683
    },
    {
      "epoch": 0.15886365760209326,
      "grad_norm": 2.9765625,
      "learning_rate": 9.999765589085988e-06,
      "loss": 0.5906,
      "step": 1700
    },
    {
      "epoch": 0.16045229417811419,
      "grad_norm": 0.90185546875,
      "learning_rate": 9.999673136264067e-06,
      "loss": 0.265,
      "step": 1717
    },
    {
      "epoch": 0.16204093075413512,
      "grad_norm": 1.48046875,
      "learning_rate": 9.999565350522841e-06,
      "loss": 0.4085,
      "step": 1734
    },
    {
      "epoch": 0.16362956733015607,
      "grad_norm": 0.5478515625,
      "learning_rate": 9.999442232192867e-06,
      "loss": 0.5989,
      "step": 1751
    },
    {
      "epoch": 0.165218203906177,
      "grad_norm": 1.064453125,
      "learning_rate": 9.999303781651722e-06,
      "loss": 0.2099,
      "step": 1768
    },
    {
      "epoch": 0.16680684048219793,
      "grad_norm": 1.28125,
      "learning_rate": 9.999149999324002e-06,
      "loss": 0.4079,
      "step": 1785
    },
    {
      "epoch": 0.16839547705821886,
      "grad_norm": 0.37451171875,
      "learning_rate": 9.998980885681328e-06,
      "loss": 0.5364,
      "step": 1802
    },
    {
      "epoch": 0.1699841136342398,
      "grad_norm": 1.296875,
      "learning_rate": 9.998796441242333e-06,
      "loss": 0.2434,
      "step": 1819
    },
    {
      "epoch": 0.17157275021026072,
      "grad_norm": 1.68359375,
      "learning_rate": 9.998596666572668e-06,
      "loss": 0.4581,
      "step": 1836
    },
    {
      "epoch": 0.17316138678628165,
      "grad_norm": 0.09356689453125,
      "learning_rate": 9.998381562284999e-06,
      "loss": 0.5137,
      "step": 1853
    },
    {
      "epoch": 0.17475002336230258,
      "grad_norm": 1.197265625,
      "learning_rate": 9.998151129039005e-06,
      "loss": 0.2999,
      "step": 1870
    },
    {
      "epoch": 0.1763386599383235,
      "grad_norm": 1.2822265625,
      "learning_rate": 9.997905367541374e-06,
      "loss": 0.4893,
      "step": 1887
    },
    {
      "epoch": 0.17792729651434444,
      "grad_norm": 0.406005859375,
      "learning_rate": 9.997644278545805e-06,
      "loss": 0.4657,
      "step": 1904
    },
    {
      "epoch": 0.1795159330903654,
      "grad_norm": 1.0361328125,
      "learning_rate": 9.997367862853e-06,
      "loss": 0.2577,
      "step": 1921
    },
    {
      "epoch": 0.18110456966638633,
      "grad_norm": 1.94921875,
      "learning_rate": 9.997076121310668e-06,
      "loss": 0.4479,
      "step": 1938
    },
    {
      "epoch": 0.18269320624240726,
      "grad_norm": 0.51708984375,
      "learning_rate": 9.996769054813517e-06,
      "loss": 0.4454,
      "step": 1955
    },
    {
      "epoch": 0.1842818428184282,
      "grad_norm": 1.0224609375,
      "learning_rate": 9.996446664303252e-06,
      "loss": 0.2745,
      "step": 1972
    },
    {
      "epoch": 0.18587047939444912,
      "grad_norm": 1.5078125,
      "learning_rate": 9.996108950768579e-06,
      "loss": 0.5063,
      "step": 1989
    },
    {
      "epoch": 0.18745911597047005,
      "grad_norm": 0.59130859375,
      "learning_rate": 9.995755915245187e-06,
      "loss": 0.4971,
      "step": 2006
    },
    {
      "epoch": 0.18904775254649098,
      "grad_norm": 1.302734375,
      "learning_rate": 9.995387558815764e-06,
      "loss": 0.2852,
      "step": 2023
    },
    {
      "epoch": 0.1906363891225119,
      "grad_norm": 1.7626953125,
      "learning_rate": 9.99500388260998e-06,
      "loss": 0.4934,
      "step": 2040
    },
    {
      "epoch": 0.19222502569853284,
      "grad_norm": 0.47216796875,
      "learning_rate": 9.994604887804484e-06,
      "loss": 0.4508,
      "step": 2057
    },
    {
      "epoch": 0.19381366227455377,
      "grad_norm": 1.041015625,
      "learning_rate": 9.99419057562291e-06,
      "loss": 0.3276,
      "step": 2074
    },
    {
      "epoch": 0.19540229885057472,
      "grad_norm": 1.5029296875,
      "learning_rate": 9.993760947335863e-06,
      "loss": 0.5077,
      "step": 2091
    },
    {
      "epoch": 0.19699093542659565,
      "grad_norm": 0.638671875,
      "learning_rate": 9.99331600426092e-06,
      "loss": 0.4407,
      "step": 2108
    },
    {
      "epoch": 0.19857957200261658,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.992855747762625e-06,
      "loss": 0.3315,
      "step": 2125
    },
    {
      "epoch": 0.2001682085786375,
      "grad_norm": 1.5556640625,
      "learning_rate": 9.992380179252487e-06,
      "loss": 0.5101,
      "step": 2142
    },
    {
      "epoch": 0.20175684515465844,
      "grad_norm": 0.708984375,
      "learning_rate": 9.991889300188971e-06,
      "loss": 0.4032,
      "step": 2159
    },
    {
      "epoch": 0.20334548173067937,
      "grad_norm": 1.126953125,
      "learning_rate": 9.991383112077498e-06,
      "loss": 0.3304,
      "step": 2176
    },
    {
      "epoch": 0.2049341183067003,
      "grad_norm": 1.6201171875,
      "learning_rate": 9.990861616470434e-06,
      "loss": 0.5363,
      "step": 2193
    },
    {
      "epoch": 0.20652275488272123,
      "grad_norm": 0.74267578125,
      "learning_rate": 9.990324814967101e-06,
      "loss": 0.4124,
      "step": 2210
    },
    {
      "epoch": 0.20811139145874216,
      "grad_norm": 1.119140625,
      "learning_rate": 9.989772709213747e-06,
      "loss": 0.3725,
      "step": 2227
    },
    {
      "epoch": 0.20970002803476312,
      "grad_norm": 1.853515625,
      "learning_rate": 9.989205300903563e-06,
      "loss": 0.5147,
      "step": 2244
    },
    {
      "epoch": 0.21128866461078405,
      "grad_norm": 0.66015625,
      "learning_rate": 9.98862259177667e-06,
      "loss": 0.328,
      "step": 2261
    },
    {
      "epoch": 0.21287730118680498,
      "grad_norm": 1.2216796875,
      "learning_rate": 9.988024583620108e-06,
      "loss": 0.3662,
      "step": 2278
    },
    {
      "epoch": 0.2144659377628259,
      "grad_norm": 1.9306640625,
      "learning_rate": 9.987411278267842e-06,
      "loss": 0.5264,
      "step": 2295
    },
    {
      "epoch": 0.21605457433884684,
      "grad_norm": 0.82861328125,
      "learning_rate": 9.986782677600747e-06,
      "loss": 0.3458,
      "step": 2312
    },
    {
      "epoch": 0.21764321091486777,
      "grad_norm": 1.4697265625,
      "learning_rate": 9.986138783546603e-06,
      "loss": 0.4036,
      "step": 2329
    },
    {
      "epoch": 0.2192318474908887,
      "grad_norm": 2.091796875,
      "learning_rate": 9.985479598080095e-06,
      "loss": 0.561,
      "step": 2346
    },
    {
      "epoch": 0.22082048406690963,
      "grad_norm": 0.64453125,
      "learning_rate": 9.984805123222804e-06,
      "loss": 0.2843,
      "step": 2363
    },
    {
      "epoch": 0.22240912064293056,
      "grad_norm": 1.4150390625,
      "learning_rate": 9.9841153610432e-06,
      "loss": 0.3401,
      "step": 2380
    },
    {
      "epoch": 0.2239977572189515,
      "grad_norm": 1.7470703125,
      "learning_rate": 9.983410313656633e-06,
      "loss": 0.5495,
      "step": 2397
    },
    {
      "epoch": 0.22558639379497245,
      "grad_norm": 0.7314453125,
      "learning_rate": 9.98268998322533e-06,
      "loss": 0.2932,
      "step": 2414
    },
    {
      "epoch": 0.22717503037099337,
      "grad_norm": 1.6337890625,
      "learning_rate": 9.981954371958392e-06,
      "loss": 0.4074,
      "step": 2431
    },
    {
      "epoch": 0.2287636669470143,
      "grad_norm": 2.181640625,
      "learning_rate": 9.981203482111779e-06,
      "loss": 0.5556,
      "step": 2448
    },
    {
      "epoch": 0.23035230352303523,
      "grad_norm": 0.88818359375,
      "learning_rate": 9.980437315988307e-06,
      "loss": 0.2335,
      "step": 2465
    },
    {
      "epoch": 0.23194094009905616,
      "grad_norm": 1.58984375,
      "learning_rate": 9.979655875937644e-06,
      "loss": 0.4066,
      "step": 2482
    },
    {
      "epoch": 0.2335295766750771,
      "grad_norm": 3.404296875,
      "learning_rate": 9.978859164356298e-06,
      "loss": 0.5986,
      "step": 2499
    },
    {
      "epoch": 0.23511821325109802,
      "grad_norm": 0.970703125,
      "learning_rate": 9.97804718368761e-06,
      "loss": 0.2273,
      "step": 2516
    },
    {
      "epoch": 0.23670684982711895,
      "grad_norm": 1.6474609375,
      "learning_rate": 9.977219936421749e-06,
      "loss": 0.3798,
      "step": 2533
    },
    {
      "epoch": 0.23829548640313988,
      "grad_norm": 2.923828125,
      "learning_rate": 9.976377425095708e-06,
      "loss": 0.5819,
      "step": 2550
    },
    {
      "epoch": 0.2398841229791608,
      "grad_norm": 0.83837890625,
      "learning_rate": 9.975519652293284e-06,
      "loss": 0.2694,
      "step": 2567
    },
    {
      "epoch": 0.24147275955518177,
      "grad_norm": 1.5986328125,
      "learning_rate": 9.974646620645083e-06,
      "loss": 0.3822,
      "step": 2584
    },
    {
      "epoch": 0.2430613961312027,
      "grad_norm": 0.404052734375,
      "learning_rate": 9.973758332828504e-06,
      "loss": 0.5388,
      "step": 2601
    },
    {
      "epoch": 0.24465003270722363,
      "grad_norm": 1.015625,
      "learning_rate": 9.972854791567734e-06,
      "loss": 0.2384,
      "step": 2618
    },
    {
      "epoch": 0.24623866928324456,
      "grad_norm": 1.779296875,
      "learning_rate": 9.97193599963374e-06,
      "loss": 0.4567,
      "step": 2635
    },
    {
      "epoch": 0.2478273058592655,
      "grad_norm": 0.463134765625,
      "learning_rate": 9.971001959844257e-06,
      "loss": 0.5347,
      "step": 2652
    },
    {
      "epoch": 0.24941594243528642,
      "grad_norm": 1.205078125,
      "learning_rate": 9.970052675063787e-06,
      "loss": 0.2553,
      "step": 2669
    },
    {
      "epoch": 0.25100457901130735,
      "grad_norm": 1.7578125,
      "learning_rate": 9.969088148203579e-06,
      "loss": 0.4713,
      "step": 2686
    },
    {
      "epoch": 0.2525932155873283,
      "grad_norm": 0.403076171875,
      "learning_rate": 9.968108382221627e-06,
      "loss": 0.5314,
      "step": 2703
    },
    {
      "epoch": 0.2541818521633492,
      "grad_norm": 0.98291015625,
      "learning_rate": 9.967113380122666e-06,
      "loss": 0.2274,
      "step": 2720
    },
    {
      "epoch": 0.25577048873937014,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.966103144958152e-06,
      "loss": 0.4455,
      "step": 2737
    },
    {
      "epoch": 0.25735912531539107,
      "grad_norm": 0.466552734375,
      "learning_rate": 9.965077679826256e-06,
      "loss": 0.4896,
      "step": 2754
    },
    {
      "epoch": 0.258947761891412,
      "grad_norm": 1.0419921875,
      "learning_rate": 9.964036987871861e-06,
      "loss": 0.2658,
      "step": 2771
    },
    {
      "epoch": 0.26053639846743293,
      "grad_norm": 2.078125,
      "learning_rate": 9.962981072286545e-06,
      "loss": 0.4868,
      "step": 2788
    },
    {
      "epoch": 0.26212503504345386,
      "grad_norm": 1.203125,
      "learning_rate": 9.96190993630857e-06,
      "loss": 0.4055,
      "step": 2805
    },
    {
      "epoch": 0.26371367161947484,
      "grad_norm": 1.0390625,
      "learning_rate": 9.96082358322288e-06,
      "loss": 0.2543,
      "step": 2822
    },
    {
      "epoch": 0.2653023081954958,
      "grad_norm": 2.037109375,
      "learning_rate": 9.95972201636109e-06,
      "loss": 0.4767,
      "step": 2839
    },
    {
      "epoch": 0.2668909447715167,
      "grad_norm": 0.67431640625,
      "learning_rate": 9.958605239101463e-06,
      "loss": 0.4612,
      "step": 2856
    },
    {
      "epoch": 0.26847958134753763,
      "grad_norm": 1.0087890625,
      "learning_rate": 9.957473254868917e-06,
      "loss": 0.2772,
      "step": 2873
    },
    {
      "epoch": 0.27006821792355856,
      "grad_norm": 1.63671875,
      "learning_rate": 9.956326067135002e-06,
      "loss": 0.5177,
      "step": 2890
    },
    {
      "epoch": 0.2716568544995795,
      "grad_norm": 0.48583984375,
      "learning_rate": 9.955163679417896e-06,
      "loss": 0.4457,
      "step": 2907
    },
    {
      "epoch": 0.2732454910756004,
      "grad_norm": 1.255859375,
      "learning_rate": 9.95398609528239e-06,
      "loss": 0.3055,
      "step": 2924
    },
    {
      "epoch": 0.27483412765162135,
      "grad_norm": 1.7099609375,
      "learning_rate": 9.952793318339884e-06,
      "loss": 0.5562,
      "step": 2941
    },
    {
      "epoch": 0.2764227642276423,
      "grad_norm": 0.6337890625,
      "learning_rate": 9.951585352248365e-06,
      "loss": 0.3751,
      "step": 2958
    },
    {
      "epoch": 0.2780114008036632,
      "grad_norm": 1.15625,
      "learning_rate": 9.950362200712405e-06,
      "loss": 0.2979,
      "step": 2975
    },
    {
      "epoch": 0.27960003737968414,
      "grad_norm": 2.228515625,
      "learning_rate": 9.949123867483146e-06,
      "loss": 0.5297,
      "step": 2992
    },
    {
      "epoch": 0.28118867395570507,
      "grad_norm": 0.65283203125,
      "learning_rate": 9.947870356358287e-06,
      "loss": 0.3912,
      "step": 3009
    },
    {
      "epoch": 0.282777310531726,
      "grad_norm": 1.6064453125,
      "learning_rate": 9.94660167118208e-06,
      "loss": 0.3376,
      "step": 3026
    },
    {
      "epoch": 0.28436594710774693,
      "grad_norm": 2.18359375,
      "learning_rate": 9.945317815845307e-06,
      "loss": 0.5291,
      "step": 3043
    },
    {
      "epoch": 0.28595458368376786,
      "grad_norm": 0.93701171875,
      "learning_rate": 9.944018794285276e-06,
      "loss": 0.4249,
      "step": 3060
    },
    {
      "epoch": 0.2875432202597888,
      "grad_norm": 1.7197265625,
      "learning_rate": 9.942704610485803e-06,
      "loss": 0.3531,
      "step": 3077
    },
    {
      "epoch": 0.2891318568358097,
      "grad_norm": 2.181640625,
      "learning_rate": 9.94137526847721e-06,
      "loss": 0.5112,
      "step": 3094
    },
    {
      "epoch": 0.29072049341183065,
      "grad_norm": 0.533203125,
      "learning_rate": 9.940030772336303e-06,
      "loss": 0.3746,
      "step": 3111
    },
    {
      "epoch": 0.2923091299878516,
      "grad_norm": 1.5009765625,
      "learning_rate": 9.938671126186358e-06,
      "loss": 0.3515,
      "step": 3128
    },
    {
      "epoch": 0.2938977665638725,
      "grad_norm": 1.9814453125,
      "learning_rate": 9.93729633419712e-06,
      "loss": 0.4941,
      "step": 3145
    },
    {
      "epoch": 0.2954864031398935,
      "grad_norm": 0.79736328125,
      "learning_rate": 9.935906400584777e-06,
      "loss": 0.3307,
      "step": 3162
    },
    {
      "epoch": 0.2970750397159144,
      "grad_norm": 1.5244140625,
      "learning_rate": 9.934501329611957e-06,
      "loss": 0.3344,
      "step": 3179
    },
    {
      "epoch": 0.29866367629193535,
      "grad_norm": 2.0078125,
      "learning_rate": 9.933081125587706e-06,
      "loss": 0.5522,
      "step": 3196
    },
    {
      "epoch": 0.3002523128679563,
      "grad_norm": 0.96484375,
      "learning_rate": 9.93164579286749e-06,
      "loss": 0.3031,
      "step": 3213
    },
    {
      "epoch": 0.3018409494439772,
      "grad_norm": 1.4365234375,
      "learning_rate": 9.930195335853161e-06,
      "loss": 0.3945,
      "step": 3230
    },
    {
      "epoch": 0.30342958601999814,
      "grad_norm": 2.33984375,
      "learning_rate": 9.928729758992959e-06,
      "loss": 0.6077,
      "step": 3247
    },
    {
      "epoch": 0.3050182225960191,
      "grad_norm": 0.837890625,
      "learning_rate": 9.92724906678149e-06,
      "loss": 0.287,
      "step": 3264
    },
    {
      "epoch": 0.30660685917204,
      "grad_norm": 1.21875,
      "learning_rate": 9.92575326375972e-06,
      "loss": 0.3536,
      "step": 3281
    },
    {
      "epoch": 0.30819549574806093,
      "grad_norm": 2.48828125,
      "learning_rate": 9.924242354514953e-06,
      "loss": 0.5431,
      "step": 3298
    },
    {
      "epoch": 0.30978413232408186,
      "grad_norm": 0.775390625,
      "learning_rate": 9.922716343680823e-06,
      "loss": 0.2308,
      "step": 3315
    },
    {
      "epoch": 0.3113727689001028,
      "grad_norm": 1.4072265625,
      "learning_rate": 9.921175235937274e-06,
      "loss": 0.3154,
      "step": 3332
    },
    {
      "epoch": 0.3129614054761237,
      "grad_norm": 2.732421875,
      "learning_rate": 9.919619036010556e-06,
      "loss": 0.5608,
      "step": 3349
    },
    {
      "epoch": 0.31455004205214465,
      "grad_norm": 0.85400390625,
      "learning_rate": 9.918047748673194e-06,
      "loss": 0.206,
      "step": 3366
    },
    {
      "epoch": 0.3161386786281656,
      "grad_norm": 1.517578125,
      "learning_rate": 9.916461378743986e-06,
      "loss": 0.408,
      "step": 3383
    },
    {
      "epoch": 0.3177273152041865,
      "grad_norm": 3.0859375,
      "learning_rate": 9.914859931087992e-06,
      "loss": 0.6006,
      "step": 3400
    },
    {
      "epoch": 0.31931595178020744,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.913243410616502e-06,
      "loss": 0.2072,
      "step": 3417
    },
    {
      "epoch": 0.32090458835622837,
      "grad_norm": 1.5771484375,
      "learning_rate": 9.911611822287039e-06,
      "loss": 0.3664,
      "step": 3434
    },
    {
      "epoch": 0.3224932249322493,
      "grad_norm": 0.478271484375,
      "learning_rate": 9.909965171103331e-06,
      "loss": 0.5675,
      "step": 3451
    },
    {
      "epoch": 0.32408186150827023,
      "grad_norm": 1.4599609375,
      "learning_rate": 9.9083034621153e-06,
      "loss": 0.2956,
      "step": 3468
    },
    {
      "epoch": 0.32567049808429116,
      "grad_norm": 1.916015625,
      "learning_rate": 9.906626700419053e-06,
      "loss": 0.508,
      "step": 3485
    },
    {
      "epoch": 0.32725913466031215,
      "grad_norm": 0.2264404296875,
      "learning_rate": 9.904934891156852e-06,
      "loss": 0.5779,
      "step": 3502
    },
    {
      "epoch": 0.3288477712363331,
      "grad_norm": 0.9326171875,
      "learning_rate": 9.903228039517116e-06,
      "loss": 0.2653,
      "step": 3519
    },
    {
      "epoch": 0.330436407812354,
      "grad_norm": 1.8564453125,
      "learning_rate": 9.901506150734388e-06,
      "loss": 0.4316,
      "step": 3536
    },
    {
      "epoch": 0.33202504438837493,
      "grad_norm": 0.2393798828125,
      "learning_rate": 9.89976923008933e-06,
      "loss": 0.5253,
      "step": 3553
    },
    {
      "epoch": 0.33361368096439586,
      "grad_norm": 1.1494140625,
      "learning_rate": 9.898017282908703e-06,
      "loss": 0.2703,
      "step": 3570
    },
    {
      "epoch": 0.3352023175404168,
      "grad_norm": 1.39453125,
      "learning_rate": 9.896250314565353e-06,
      "loss": 0.4118,
      "step": 3587
    },
    {
      "epoch": 0.3367909541164377,
      "grad_norm": 0.1776123046875,
      "learning_rate": 9.894468330478189e-06,
      "loss": 0.4546,
      "step": 3604
    },
    {
      "epoch": 0.33837959069245865,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.892671336112172e-06,
      "loss": 0.2198,
      "step": 3621
    },
    {
      "epoch": 0.3399682272684796,
      "grad_norm": 1.54296875,
      "learning_rate": 9.890859336978295e-06,
      "loss": 0.4696,
      "step": 3638
    },
    {
      "epoch": 0.3415568638445005,
      "grad_norm": 0.5634765625,
      "learning_rate": 9.889032338633571e-06,
      "loss": 0.4633,
      "step": 3655
    },
    {
      "epoch": 0.34314550042052144,
      "grad_norm": 1.216796875,
      "learning_rate": 9.887190346681009e-06,
      "loss": 0.2919,
      "step": 3672
    },
    {
      "epoch": 0.3447341369965424,
      "grad_norm": 1.935546875,
      "learning_rate": 9.8853333667696e-06,
      "loss": 0.4891,
      "step": 3689
    },
    {
      "epoch": 0.3463227735725633,
      "grad_norm": 0.81494140625,
      "learning_rate": 9.883461404594303e-06,
      "loss": 0.4659,
      "step": 3706
    },
    {
      "epoch": 0.34791141014858423,
      "grad_norm": 1.5263671875,
      "learning_rate": 9.881574465896022e-06,
      "loss": 0.3132,
      "step": 3723
    },
    {
      "epoch": 0.34950004672460516,
      "grad_norm": 1.98046875,
      "learning_rate": 9.879672556461588e-06,
      "loss": 0.4814,
      "step": 3740
    },
    {
      "epoch": 0.3510886833006261,
      "grad_norm": 0.77783203125,
      "learning_rate": 9.877755682123751e-06,
      "loss": 0.4218,
      "step": 3757
    },
    {
      "epoch": 0.352677319876647,
      "grad_norm": 1.412109375,
      "learning_rate": 9.875823848761148e-06,
      "loss": 0.3357,
      "step": 3774
    },
    {
      "epoch": 0.35426595645266795,
      "grad_norm": 2.35546875,
      "learning_rate": 9.873877062298298e-06,
      "loss": 0.4997,
      "step": 3791
    },
    {
      "epoch": 0.3558545930286889,
      "grad_norm": 0.751953125,
      "learning_rate": 9.871915328705574e-06,
      "loss": 0.411,
      "step": 3808
    },
    {
      "epoch": 0.35744322960470987,
      "grad_norm": 1.3388671875,
      "learning_rate": 9.869938653999191e-06,
      "loss": 0.3062,
      "step": 3825
    },
    {
      "epoch": 0.3590318661807308,
      "grad_norm": 2.27734375,
      "learning_rate": 9.867947044241182e-06,
      "loss": 0.5262,
      "step": 3842
    },
    {
      "epoch": 0.3606205027567517,
      "grad_norm": 0.72705078125,
      "learning_rate": 9.865940505539386e-06,
      "loss": 0.5616,
      "step": 3859
    },
    {
      "epoch": 0.36220913933277266,
      "grad_norm": 1.3564453125,
      "learning_rate": 9.863919044047423e-06,
      "loss": 0.3186,
      "step": 3876
    },
    {
      "epoch": 0.3637977759087936,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.861882665964681e-06,
      "loss": 0.5198,
      "step": 3893
    },
    {
      "epoch": 0.3653864124848145,
      "grad_norm": 0.69873046875,
      "learning_rate": 9.859831377536293e-06,
      "loss": 0.3628,
      "step": 3910
    },
    {
      "epoch": 0.36697504906083545,
      "grad_norm": 1.1484375,
      "learning_rate": 9.857765185053116e-06,
      "loss": 0.3079,
      "step": 3927
    },
    {
      "epoch": 0.3685636856368564,
      "grad_norm": 2.169921875,
      "learning_rate": 9.85568409485172e-06,
      "loss": 0.545,
      "step": 3944
    },
    {
      "epoch": 0.3701523222128773,
      "grad_norm": 0.6591796875,
      "learning_rate": 9.853588113314354e-06,
      "loss": 0.3379,
      "step": 3961
    },
    {
      "epoch": 0.37174095878889823,
      "grad_norm": 1.201171875,
      "learning_rate": 9.851477246868948e-06,
      "loss": 0.352,
      "step": 3978
    },
    {
      "epoch": 0.37332959536491916,
      "grad_norm": 1.83203125,
      "learning_rate": 9.84935150198907e-06,
      "loss": 0.5088,
      "step": 3995
    },
    {
      "epoch": 0.3749182319409401,
      "grad_norm": 0.7421875,
      "learning_rate": 9.847210885193925e-06,
      "loss": 0.3166,
      "step": 4012
    },
    {
      "epoch": 0.376506868516961,
      "grad_norm": 1.2998046875,
      "learning_rate": 9.845055403048319e-06,
      "loss": 0.3658,
      "step": 4029
    },
    {
      "epoch": 0.37809550509298195,
      "grad_norm": 2.263671875,
      "learning_rate": 9.842885062162653e-06,
      "loss": 0.5306,
      "step": 4046
    },
    {
      "epoch": 0.3796841416690029,
      "grad_norm": 0.77783203125,
      "learning_rate": 9.840699869192894e-06,
      "loss": 0.2993,
      "step": 4063
    },
    {
      "epoch": 0.3812727782450238,
      "grad_norm": 1.36328125,
      "learning_rate": 9.838499830840555e-06,
      "loss": 0.3392,
      "step": 4080
    },
    {
      "epoch": 0.38286141482104474,
      "grad_norm": 2.095703125,
      "learning_rate": 9.836284953852684e-06,
      "loss": 0.5235,
      "step": 4097
    },
    {
      "epoch": 0.3844500513970657,
      "grad_norm": 0.984375,
      "learning_rate": 9.83405524502183e-06,
      "loss": 0.2942,
      "step": 4114
    },
    {
      "epoch": 0.3860386879730866,
      "grad_norm": 1.484375,
      "learning_rate": 9.831810711186025e-06,
      "loss": 0.3817,
      "step": 4131
    },
    {
      "epoch": 0.38762732454910753,
      "grad_norm": 2.125,
      "learning_rate": 9.829551359228774e-06,
      "loss": 0.5732,
      "step": 4148
    },
    {
      "epoch": 0.3892159611251285,
      "grad_norm": 1.0205078125,
      "learning_rate": 9.827277196079024e-06,
      "loss": 0.2473,
      "step": 4165
    },
    {
      "epoch": 0.39080459770114945,
      "grad_norm": 1.5361328125,
      "learning_rate": 9.824988228711138e-06,
      "loss": 0.4134,
      "step": 4182
    },
    {
      "epoch": 0.3923932342771704,
      "grad_norm": 2.427734375,
      "learning_rate": 9.822684464144888e-06,
      "loss": 0.5259,
      "step": 4199
    },
    {
      "epoch": 0.3939818708531913,
      "grad_norm": 0.86669921875,
      "learning_rate": 9.820365909445422e-06,
      "loss": 0.2343,
      "step": 4216
    },
    {
      "epoch": 0.39557050742921224,
      "grad_norm": 1.2109375,
      "learning_rate": 9.818032571723249e-06,
      "loss": 0.3131,
      "step": 4233
    },
    {
      "epoch": 0.39715914400523317,
      "grad_norm": 2.55859375,
      "learning_rate": 9.815684458134212e-06,
      "loss": 0.5624,
      "step": 4250
    },
    {
      "epoch": 0.3987477805812541,
      "grad_norm": 0.87548828125,
      "learning_rate": 9.813321575879466e-06,
      "loss": 0.1775,
      "step": 4267
    },
    {
      "epoch": 0.400336417157275,
      "grad_norm": 1.50390625,
      "learning_rate": 9.810943932205465e-06,
      "loss": 0.4143,
      "step": 4284
    },
    {
      "epoch": 0.40192505373329596,
      "grad_norm": 0.337158203125,
      "learning_rate": 9.808551534403929e-06,
      "loss": 0.5695,
      "step": 4301
    },
    {
      "epoch": 0.4035136903093169,
      "grad_norm": 0.8671875,
      "learning_rate": 9.806144389811824e-06,
      "loss": 0.2241,
      "step": 4318
    },
    {
      "epoch": 0.4051023268853378,
      "grad_norm": 1.6708984375,
      "learning_rate": 9.803722505811348e-06,
      "loss": 0.4214,
      "step": 4335
    },
    {
      "epoch": 0.40669096346135875,
      "grad_norm": 0.418701171875,
      "learning_rate": 9.80128588982989e-06,
      "loss": 0.5379,
      "step": 4352
    },
    {
      "epoch": 0.4082796000373797,
      "grad_norm": 1.02734375,
      "learning_rate": 9.798834549340031e-06,
      "loss": 0.2635,
      "step": 4369
    },
    {
      "epoch": 0.4098682366134006,
      "grad_norm": 1.45703125,
      "learning_rate": 9.796368491859502e-06,
      "loss": 0.4358,
      "step": 4386
    },
    {
      "epoch": 0.41145687318942153,
      "grad_norm": 0.37548828125,
      "learning_rate": 9.79388772495117e-06,
      "loss": 0.4854,
      "step": 4403
    },
    {
      "epoch": 0.41304550976544246,
      "grad_norm": 1.1064453125,
      "learning_rate": 9.791392256223012e-06,
      "loss": 0.2499,
      "step": 4420
    },
    {
      "epoch": 0.4146341463414634,
      "grad_norm": 1.810546875,
      "learning_rate": 9.788882093328089e-06,
      "loss": 0.4545,
      "step": 4437
    },
    {
      "epoch": 0.4162227829174843,
      "grad_norm": 0.265625,
      "learning_rate": 9.786357243964534e-06,
      "loss": 0.4673,
      "step": 4454
    },
    {
      "epoch": 0.41781141949350525,
      "grad_norm": 0.91455078125,
      "learning_rate": 9.783817715875517e-06,
      "loss": 0.2094,
      "step": 4471
    },
    {
      "epoch": 0.41940005606952624,
      "grad_norm": 1.876953125,
      "learning_rate": 9.781263516849216e-06,
      "loss": 0.402,
      "step": 4488
    },
    {
      "epoch": 0.42098869264554717,
      "grad_norm": 0.4345703125,
      "learning_rate": 9.778694654718813e-06,
      "loss": 0.4357,
      "step": 4505
    },
    {
      "epoch": 0.4225773292215681,
      "grad_norm": 0.8837890625,
      "learning_rate": 9.776111137362453e-06,
      "loss": 0.2856,
      "step": 4522
    },
    {
      "epoch": 0.42416596579758903,
      "grad_norm": 1.7802734375,
      "learning_rate": 9.77351297270323e-06,
      "loss": 0.4591,
      "step": 4539
    },
    {
      "epoch": 0.42575460237360996,
      "grad_norm": 0.72216796875,
      "learning_rate": 9.77090016870915e-06,
      "loss": 0.407,
      "step": 4556
    },
    {
      "epoch": 0.4273432389496309,
      "grad_norm": 1.265625,
      "learning_rate": 9.768272733393121e-06,
      "loss": 0.2999,
      "step": 4573
    },
    {
      "epoch": 0.4289318755256518,
      "grad_norm": 1.7109375,
      "learning_rate": 9.765630674812921e-06,
      "loss": 0.4681,
      "step": 4590
    },
    {
      "epoch": 0.43052051210167275,
      "grad_norm": 0.53076171875,
      "learning_rate": 9.762974001071175e-06,
      "loss": 0.363,
      "step": 4607
    },
    {
      "epoch": 0.4321091486776937,
      "grad_norm": 1.25390625,
      "learning_rate": 9.760302720315325e-06,
      "loss": 0.3099,
      "step": 4624
    },
    {
      "epoch": 0.4336977852537146,
      "grad_norm": 1.927734375,
      "learning_rate": 9.757616840737615e-06,
      "loss": 0.5074,
      "step": 4641
    },
    {
      "epoch": 0.43528642182973554,
      "grad_norm": 0.5927734375,
      "learning_rate": 9.75491637057506e-06,
      "loss": 0.4154,
      "step": 4658
    },
    {
      "epoch": 0.43687505840575647,
      "grad_norm": 1.4169921875,
      "learning_rate": 9.752201318109417e-06,
      "loss": 0.2808,
      "step": 4675
    },
    {
      "epoch": 0.4384636949817774,
      "grad_norm": 1.607421875,
      "learning_rate": 9.74947169166717e-06,
      "loss": 0.4569,
      "step": 4692
    },
    {
      "epoch": 0.4400523315577983,
      "grad_norm": 0.8046875,
      "learning_rate": 9.74672749961949e-06,
      "loss": 0.3568,
      "step": 4709
    },
    {
      "epoch": 0.44164096813381926,
      "grad_norm": 1.384765625,
      "learning_rate": 9.743968750382225e-06,
      "loss": 0.3673,
      "step": 4726
    },
    {
      "epoch": 0.4432296047098402,
      "grad_norm": 1.8779296875,
      "learning_rate": 9.741195452415864e-06,
      "loss": 0.4955,
      "step": 4743
    },
    {
      "epoch": 0.4448182412858611,
      "grad_norm": 0.59130859375,
      "learning_rate": 9.738407614225512e-06,
      "loss": 0.3545,
      "step": 4760
    },
    {
      "epoch": 0.44640687786188205,
      "grad_norm": 1.2578125,
      "learning_rate": 9.735605244360868e-06,
      "loss": 0.3063,
      "step": 4777
    },
    {
      "epoch": 0.447995514437903,
      "grad_norm": 2.44921875,
      "learning_rate": 9.732788351416197e-06,
      "loss": 0.5086,
      "step": 4794
    },
    {
      "epoch": 0.4495841510139239,
      "grad_norm": 0.75634765625,
      "learning_rate": 9.729956944030303e-06,
      "loss": 0.324,
      "step": 4811
    },
    {
      "epoch": 0.4511727875899449,
      "grad_norm": 1.388671875,
      "learning_rate": 9.7271110308865e-06,
      "loss": 0.3301,
      "step": 4828
    },
    {
      "epoch": 0.4527614241659658,
      "grad_norm": 2.08984375,
      "learning_rate": 9.724250620712592e-06,
      "loss": 0.5004,
      "step": 4845
    },
    {
      "epoch": 0.45435006074198675,
      "grad_norm": 0.806640625,
      "learning_rate": 9.721375722280837e-06,
      "loss": 0.3057,
      "step": 4862
    },
    {
      "epoch": 0.4559386973180077,
      "grad_norm": 1.91796875,
      "learning_rate": 9.718486344407932e-06,
      "loss": 0.4073,
      "step": 4879
    },
    {
      "epoch": 0.4575273338940286,
      "grad_norm": 2.13671875,
      "learning_rate": 9.715582495954972e-06,
      "loss": 0.5447,
      "step": 4896
    },
    {
      "epoch": 0.45911597047004954,
      "grad_norm": 0.75048828125,
      "learning_rate": 9.712664185827437e-06,
      "loss": 0.2754,
      "step": 4913
    },
    {
      "epoch": 0.46070460704607047,
      "grad_norm": 1.1904296875,
      "learning_rate": 9.709731422975155e-06,
      "loss": 0.3766,
      "step": 4930
    },
    {
      "epoch": 0.4622932436220914,
      "grad_norm": 1.98828125,
      "learning_rate": 9.706784216392274e-06,
      "loss": 0.4748,
      "step": 4947
    },
    {
      "epoch": 0.46388188019811233,
      "grad_norm": 0.8525390625,
      "learning_rate": 9.703822575117243e-06,
      "loss": 0.2786,
      "step": 4964
    },
    {
      "epoch": 0.46547051677413326,
      "grad_norm": 1.5380859375,
      "learning_rate": 9.700846508232778e-06,
      "loss": 0.3988,
      "step": 4981
    },
    {
      "epoch": 0.4670591533501542,
      "grad_norm": 2.5,
      "learning_rate": 9.697856024865835e-06,
      "loss": 0.5408,
      "step": 4998
    },
    {
      "epoch": 0.4686477899261751,
      "grad_norm": 1.01953125,
      "learning_rate": 9.694851134187578e-06,
      "loss": 0.263,
      "step": 5015
    },
    {
      "epoch": 0.47023642650219605,
      "grad_norm": 1.283203125,
      "learning_rate": 9.691831845413362e-06,
      "loss": 0.3988,
      "step": 5032
    },
    {
      "epoch": 0.471825063078217,
      "grad_norm": 2.224609375,
      "learning_rate": 9.688798167802693e-06,
      "loss": 0.616,
      "step": 5049
    },
    {
      "epoch": 0.4734136996542379,
      "grad_norm": 0.822265625,
      "learning_rate": 9.685750110659206e-06,
      "loss": 0.1851,
      "step": 5066
    },
    {
      "epoch": 0.47500233623025884,
      "grad_norm": 1.2666015625,
      "learning_rate": 9.682687683330636e-06,
      "loss": 0.3746,
      "step": 5083
    },
    {
      "epoch": 0.47659097280627977,
      "grad_norm": 2.953125,
      "learning_rate": 9.679610895208785e-06,
      "loss": 0.6085,
      "step": 5100
    },
    {
      "epoch": 0.4781796093823007,
      "grad_norm": 1.01171875,
      "learning_rate": 9.6765197557295e-06,
      "loss": 0.2046,
      "step": 5117
    },
    {
      "epoch": 0.4797682459583216,
      "grad_norm": 1.6572265625,
      "learning_rate": 9.673414274372641e-06,
      "loss": 0.4254,
      "step": 5134
    },
    {
      "epoch": 0.4813568825343426,
      "grad_norm": 0.4345703125,
      "learning_rate": 9.670294460662048e-06,
      "loss": 0.608,
      "step": 5151
    },
    {
      "epoch": 0.48294551911036354,
      "grad_norm": 0.98974609375,
      "learning_rate": 9.667160324165516e-06,
      "loss": 0.2329,
      "step": 5168
    },
    {
      "epoch": 0.48453415568638447,
      "grad_norm": 1.41015625,
      "learning_rate": 9.664011874494766e-06,
      "loss": 0.3831,
      "step": 5185
    },
    {
      "epoch": 0.4861227922624054,
      "grad_norm": 0.304931640625,
      "learning_rate": 9.660849121305414e-06,
      "loss": 0.5174,
      "step": 5202
    },
    {
      "epoch": 0.48771142883842633,
      "grad_norm": 0.875,
      "learning_rate": 9.657672074296944e-06,
      "loss": 0.2318,
      "step": 5219
    },
    {
      "epoch": 0.48930006541444726,
      "grad_norm": 1.623046875,
      "learning_rate": 9.654480743212672e-06,
      "loss": 0.4244,
      "step": 5236
    },
    {
      "epoch": 0.4908887019904682,
      "grad_norm": 0.19677734375,
      "learning_rate": 9.651275137839723e-06,
      "loss": 0.5229,
      "step": 5253
    },
    {
      "epoch": 0.4924773385664891,
      "grad_norm": 0.9189453125,
      "learning_rate": 9.648055268008997e-06,
      "loss": 0.2287,
      "step": 5270
    },
    {
      "epoch": 0.49406597514251005,
      "grad_norm": 1.62109375,
      "learning_rate": 9.64482114359514e-06,
      "loss": 0.4199,
      "step": 5287
    },
    {
      "epoch": 0.495654611718531,
      "grad_norm": 0.2281494140625,
      "learning_rate": 9.641572774516516e-06,
      "loss": 0.4793,
      "step": 5304
    },
    {
      "epoch": 0.4972432482945519,
      "grad_norm": 1.15625,
      "learning_rate": 9.63831017073517e-06,
      "loss": 0.2725,
      "step": 5321
    },
    {
      "epoch": 0.49883188487057284,
      "grad_norm": 1.7001953125,
      "learning_rate": 9.635033342256805e-06,
      "loss": 0.4374,
      "step": 5338
    },
    {
      "epoch": 0.5004205214465938,
      "grad_norm": 0.433349609375,
      "learning_rate": 9.63174229913075e-06,
      "loss": 0.4318,
      "step": 5355
    },
    {
      "epoch": 0.5020091580226147,
      "grad_norm": 1.046875,
      "learning_rate": 9.62843705144992e-06,
      "loss": 0.2716,
      "step": 5372
    },
    {
      "epoch": 0.5035977945986356,
      "grad_norm": 2.1875,
      "learning_rate": 9.6251176093508e-06,
      "loss": 0.4876,
      "step": 5389
    },
    {
      "epoch": 0.5051864311746566,
      "grad_norm": 0.3447265625,
      "learning_rate": 9.621783983013401e-06,
      "loss": 0.4381,
      "step": 5406
    },
    {
      "epoch": 0.5067750677506775,
      "grad_norm": 1.205078125,
      "learning_rate": 9.618436182661237e-06,
      "loss": 0.285,
      "step": 5423
    },
    {
      "epoch": 0.5083637043266984,
      "grad_norm": 2.310546875,
      "learning_rate": 9.615074218561291e-06,
      "loss": 0.4788,
      "step": 5440
    },
    {
      "epoch": 0.5099523409027193,
      "grad_norm": 0.271728515625,
      "learning_rate": 9.61169810102398e-06,
      "loss": 0.4248,
      "step": 5457
    },
    {
      "epoch": 0.5115409774787403,
      "grad_norm": 0.9267578125,
      "learning_rate": 9.60830784040313e-06,
      "loss": 0.2277,
      "step": 5474
    },
    {
      "epoch": 0.5131296140547612,
      "grad_norm": 1.6455078125,
      "learning_rate": 9.604903447095938e-06,
      "loss": 0.4025,
      "step": 5491
    },
    {
      "epoch": 0.5147182506307821,
      "grad_norm": 0.71240234375,
      "learning_rate": 9.601484931542943e-06,
      "loss": 0.4283,
      "step": 5508
    },
    {
      "epoch": 0.5163068872068031,
      "grad_norm": 1.0087890625,
      "learning_rate": 9.598052304227998e-06,
      "loss": 0.2746,
      "step": 5525
    },
    {
      "epoch": 0.517895523782824,
      "grad_norm": 1.572265625,
      "learning_rate": 9.594605575678228e-06,
      "loss": 0.4994,
      "step": 5542
    },
    {
      "epoch": 0.5194841603588449,
      "grad_norm": 0.568359375,
      "learning_rate": 9.591144756464008e-06,
      "loss": 0.3607,
      "step": 5559
    },
    {
      "epoch": 0.5210727969348659,
      "grad_norm": 1.150390625,
      "learning_rate": 9.587669857198925e-06,
      "loss": 0.3021,
      "step": 5576
    },
    {
      "epoch": 0.5226614335108868,
      "grad_norm": 1.5888671875,
      "learning_rate": 9.584180888539741e-06,
      "loss": 0.4276,
      "step": 5593
    },
    {
      "epoch": 0.5242500700869077,
      "grad_norm": 0.71142578125,
      "learning_rate": 9.580677861186377e-06,
      "loss": 0.3128,
      "step": 5610
    },
    {
      "epoch": 0.5258387066629286,
      "grad_norm": 1.201171875,
      "learning_rate": 9.577160785881855e-06,
      "loss": 0.3417,
      "step": 5627
    },
    {
      "epoch": 0.5274273432389497,
      "grad_norm": 2.05859375,
      "learning_rate": 9.573629673412293e-06,
      "loss": 0.5145,
      "step": 5644
    },
    {
      "epoch": 0.5290159798149706,
      "grad_norm": 0.64208984375,
      "learning_rate": 9.57008453460685e-06,
      "loss": 0.3125,
      "step": 5661
    },
    {
      "epoch": 0.5306046163909915,
      "grad_norm": 1.044921875,
      "learning_rate": 9.5665253803377e-06,
      "loss": 0.3029,
      "step": 5678
    },
    {
      "epoch": 0.5321932529670125,
      "grad_norm": 2.09375,
      "learning_rate": 9.56295222152e-06,
      "loss": 0.515,
      "step": 5695
    },
    {
      "epoch": 0.5337818895430334,
      "grad_norm": 1.0810546875,
      "learning_rate": 9.559365069111864e-06,
      "loss": 0.2806,
      "step": 5712
    },
    {
      "epoch": 0.5353705261190543,
      "grad_norm": 1.3232421875,
      "learning_rate": 9.555763934114309e-06,
      "loss": 0.3166,
      "step": 5729
    },
    {
      "epoch": 0.5369591626950753,
      "grad_norm": 2.236328125,
      "learning_rate": 9.552148827571241e-06,
      "loss": 0.512,
      "step": 5746
    },
    {
      "epoch": 0.5385477992710962,
      "grad_norm": 1.1650390625,
      "learning_rate": 9.548519760569415e-06,
      "loss": 0.3119,
      "step": 5763
    },
    {
      "epoch": 0.5401364358471171,
      "grad_norm": 1.5068359375,
      "learning_rate": 9.544876744238394e-06,
      "loss": 0.36,
      "step": 5780
    },
    {
      "epoch": 0.541725072423138,
      "grad_norm": 2.099609375,
      "learning_rate": 9.541219789750523e-06,
      "loss": 0.5053,
      "step": 5797
    },
    {
      "epoch": 0.543313708999159,
      "grad_norm": 0.79296875,
      "learning_rate": 9.537548908320895e-06,
      "loss": 0.2412,
      "step": 5814
    },
    {
      "epoch": 0.5449023455751799,
      "grad_norm": 1.7060546875,
      "learning_rate": 9.53386411120731e-06,
      "loss": 0.365,
      "step": 5831
    },
    {
      "epoch": 0.5464909821512008,
      "grad_norm": 2.990234375,
      "learning_rate": 9.530165409710246e-06,
      "loss": 0.5525,
      "step": 5848
    },
    {
      "epoch": 0.5480796187272218,
      "grad_norm": 0.857421875,
      "learning_rate": 9.526452815172824e-06,
      "loss": 0.3103,
      "step": 5865
    },
    {
      "epoch": 0.5496682553032427,
      "grad_norm": 1.458984375,
      "learning_rate": 9.52272633898077e-06,
      "loss": 0.4252,
      "step": 5882
    },
    {
      "epoch": 0.5512568918792636,
      "grad_norm": 2.52734375,
      "learning_rate": 9.518985992562383e-06,
      "loss": 0.5485,
      "step": 5899
    },
    {
      "epoch": 0.5528455284552846,
      "grad_norm": 1.2783203125,
      "learning_rate": 9.515231787388499e-06,
      "loss": 0.2215,
      "step": 5916
    },
    {
      "epoch": 0.5544341650313055,
      "grad_norm": 1.2705078125,
      "learning_rate": 9.511463734972456e-06,
      "loss": 0.404,
      "step": 5933
    },
    {
      "epoch": 0.5560228016073264,
      "grad_norm": 2.103515625,
      "learning_rate": 9.507681846870058e-06,
      "loss": 0.5888,
      "step": 5950
    },
    {
      "epoch": 0.5576114381833474,
      "grad_norm": 1.064453125,
      "learning_rate": 9.503886134679539e-06,
      "loss": 0.1894,
      "step": 5967
    },
    {
      "epoch": 0.5592000747593683,
      "grad_norm": 1.091796875,
      "learning_rate": 9.500076610041531e-06,
      "loss": 0.3988,
      "step": 5984
    },
    {
      "epoch": 0.5607887113353892,
      "grad_norm": 0.273681640625,
      "learning_rate": 9.496253284639024e-06,
      "loss": 0.5466,
      "step": 6001
    },
    {
      "epoch": 0.5623773479114101,
      "grad_norm": 1.224609375,
      "learning_rate": 9.492416170197333e-06,
      "loss": 0.2423,
      "step": 6018
    },
    {
      "epoch": 0.5639659844874311,
      "grad_norm": 1.2763671875,
      "learning_rate": 9.48856527848406e-06,
      "loss": 0.3584,
      "step": 6035
    },
    {
      "epoch": 0.565554621063452,
      "grad_norm": 0.37841796875,
      "learning_rate": 9.484700621309059e-06,
      "loss": 0.4996,
      "step": 6052
    },
    {
      "epoch": 0.5671432576394729,
      "grad_norm": 0.9658203125,
      "learning_rate": 9.480822210524402e-06,
      "loss": 0.2162,
      "step": 6069
    },
    {
      "epoch": 0.5687318942154939,
      "grad_norm": 1.4443359375,
      "learning_rate": 9.476930058024338e-06,
      "loss": 0.4194,
      "step": 6086
    },
    {
      "epoch": 0.5703205307915148,
      "grad_norm": 0.08843994140625,
      "learning_rate": 9.473024175745258e-06,
      "loss": 0.5071,
      "step": 6103
    },
    {
      "epoch": 0.5719091673675357,
      "grad_norm": 0.99072265625,
      "learning_rate": 9.46910457566566e-06,
      "loss": 0.1799,
      "step": 6120
    },
    {
      "epoch": 0.5734978039435566,
      "grad_norm": 1.7734375,
      "learning_rate": 9.465171269806114e-06,
      "loss": 0.4229,
      "step": 6137
    },
    {
      "epoch": 0.5750864405195776,
      "grad_norm": 0.373046875,
      "learning_rate": 9.46122427022922e-06,
      "loss": 0.4709,
      "step": 6154
    },
    {
      "epoch": 0.5766750770955985,
      "grad_norm": 1.40625,
      "learning_rate": 9.457263589039575e-06,
      "loss": 0.2852,
      "step": 6171
    },
    {
      "epoch": 0.5782637136716194,
      "grad_norm": 1.541015625,
      "learning_rate": 9.453289238383735e-06,
      "loss": 0.447,
      "step": 6188
    },
    {
      "epoch": 0.5798523502476404,
      "grad_norm": 0.724609375,
      "learning_rate": 9.449301230450173e-06,
      "loss": 0.4427,
      "step": 6205
    },
    {
      "epoch": 0.5814409868236613,
      "grad_norm": 1.2216796875,
      "learning_rate": 9.445299577469252e-06,
      "loss": 0.3075,
      "step": 6222
    },
    {
      "epoch": 0.5830296233996822,
      "grad_norm": 1.857421875,
      "learning_rate": 9.44128429171318e-06,
      "loss": 0.5006,
      "step": 6239
    },
    {
      "epoch": 0.5846182599757032,
      "grad_norm": 0.4912109375,
      "learning_rate": 9.437255385495969e-06,
      "loss": 0.4722,
      "step": 6256
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 1.08203125,
      "learning_rate": 9.433212871173407e-06,
      "loss": 0.319,
      "step": 6273
    },
    {
      "epoch": 0.587795533127745,
      "grad_norm": 1.6484375,
      "learning_rate": 9.429156761143014e-06,
      "loss": 0.4377,
      "step": 6290
    },
    {
      "epoch": 0.589384169703766,
      "grad_norm": 0.51416015625,
      "learning_rate": 9.425087067844005e-06,
      "loss": 0.4439,
      "step": 6307
    },
    {
      "epoch": 0.590972806279787,
      "grad_norm": 0.98046875,
      "learning_rate": 9.421003803757251e-06,
      "loss": 0.2866,
      "step": 6324
    },
    {
      "epoch": 0.5925614428558079,
      "grad_norm": 1.53515625,
      "learning_rate": 9.416906981405242e-06,
      "loss": 0.3949,
      "step": 6341
    },
    {
      "epoch": 0.5941500794318288,
      "grad_norm": 0.654296875,
      "learning_rate": 9.41279661335205e-06,
      "loss": 0.3554,
      "step": 6358
    },
    {
      "epoch": 0.5957387160078498,
      "grad_norm": 1.1337890625,
      "learning_rate": 9.408672712203287e-06,
      "loss": 0.3003,
      "step": 6375
    },
    {
      "epoch": 0.5973273525838707,
      "grad_norm": 2.009765625,
      "learning_rate": 9.404535290606068e-06,
      "loss": 0.5044,
      "step": 6392
    },
    {
      "epoch": 0.5989159891598916,
      "grad_norm": 0.494384765625,
      "learning_rate": 9.400384361248973e-06,
      "loss": 0.363,
      "step": 6409
    },
    {
      "epoch": 0.6000373796841416,
      "eval_loss": 0.38770315051078796,
      "eval_runtime": 1038.5043,
      "eval_samples_per_second": 7.727,
      "eval_steps_per_second": 2.576,
      "step": 6421
    },
    {
      "epoch": 0.6005046257359126,
      "grad_norm": 1.0927734375,
      "learning_rate": 9.396219936862008e-06,
      "loss": 0.2706,
      "step": 6426
    },
    {
      "epoch": 0.6020932623119335,
      "grad_norm": 1.9951171875,
      "learning_rate": 9.392042030216561e-06,
      "loss": 0.4537,
      "step": 6443
    },
    {
      "epoch": 0.6036818988879544,
      "grad_norm": 0.90869140625,
      "learning_rate": 9.387850654125375e-06,
      "loss": 0.3885,
      "step": 6460
    },
    {
      "epoch": 0.6052705354639754,
      "grad_norm": 1.44140625,
      "learning_rate": 9.383645821442495e-06,
      "loss": 0.3306,
      "step": 6477
    },
    {
      "epoch": 0.6068591720399963,
      "grad_norm": 1.9736328125,
      "learning_rate": 9.379427545063236e-06,
      "loss": 0.5751,
      "step": 6494
    },
    {
      "epoch": 0.6084478086160172,
      "grad_norm": 0.7861328125,
      "learning_rate": 9.375195837924142e-06,
      "loss": 0.3031,
      "step": 6511
    },
    {
      "epoch": 0.6100364451920381,
      "grad_norm": 1.482421875,
      "learning_rate": 9.370950713002947e-06,
      "loss": 0.3213,
      "step": 6528
    },
    {
      "epoch": 0.6116250817680591,
      "grad_norm": 2.265625,
      "learning_rate": 9.36669218331853e-06,
      "loss": 0.5077,
      "step": 6545
    },
    {
      "epoch": 0.61321371834408,
      "grad_norm": 0.66064453125,
      "learning_rate": 9.362420261930888e-06,
      "loss": 0.3154,
      "step": 6562
    },
    {
      "epoch": 0.6148023549201009,
      "grad_norm": 1.7568359375,
      "learning_rate": 9.358134961941082e-06,
      "loss": 0.3484,
      "step": 6579
    },
    {
      "epoch": 0.6163909914961219,
      "grad_norm": 2.14453125,
      "learning_rate": 9.353836296491198e-06,
      "loss": 0.5259,
      "step": 6596
    },
    {
      "epoch": 0.6179796280721428,
      "grad_norm": 0.82275390625,
      "learning_rate": 9.349524278764321e-06,
      "loss": 0.2758,
      "step": 6613
    },
    {
      "epoch": 0.6195682646481637,
      "grad_norm": 1.365234375,
      "learning_rate": 9.34519892198448e-06,
      "loss": 0.3363,
      "step": 6630
    },
    {
      "epoch": 0.6211569012241847,
      "grad_norm": 2.11328125,
      "learning_rate": 9.340860239416606e-06,
      "loss": 0.5382,
      "step": 6647
    },
    {
      "epoch": 0.6227455378002056,
      "grad_norm": 1.1103515625,
      "learning_rate": 9.336508244366508e-06,
      "loss": 0.3293,
      "step": 6664
    },
    {
      "epoch": 0.6243341743762265,
      "grad_norm": 1.4619140625,
      "learning_rate": 9.332142950180813e-06,
      "loss": 0.4003,
      "step": 6681
    },
    {
      "epoch": 0.6259228109522474,
      "grad_norm": 2.287109375,
      "learning_rate": 9.32776437024694e-06,
      "loss": 0.5724,
      "step": 6698
    },
    {
      "epoch": 0.6275114475282684,
      "grad_norm": 1.0908203125,
      "learning_rate": 9.323372517993048e-06,
      "loss": 0.2507,
      "step": 6715
    },
    {
      "epoch": 0.6291000841042893,
      "grad_norm": 1.697265625,
      "learning_rate": 9.318967406887997e-06,
      "loss": 0.4369,
      "step": 6732
    },
    {
      "epoch": 0.6306887206803102,
      "grad_norm": 2.794921875,
      "learning_rate": 9.31454905044132e-06,
      "loss": 0.5626,
      "step": 6749
    },
    {
      "epoch": 0.6322773572563312,
      "grad_norm": 0.98974609375,
      "learning_rate": 9.310117462203158e-06,
      "loss": 0.2286,
      "step": 6766
    },
    {
      "epoch": 0.6338659938323521,
      "grad_norm": 1.6181640625,
      "learning_rate": 9.305672655764237e-06,
      "loss": 0.417,
      "step": 6783
    },
    {
      "epoch": 0.635454630408373,
      "grad_norm": 2.64453125,
      "learning_rate": 9.301214644755823e-06,
      "loss": 0.5178,
      "step": 6800
    },
    {
      "epoch": 0.637043266984394,
      "grad_norm": 0.8515625,
      "learning_rate": 9.29674344284967e-06,
      "loss": 0.1778,
      "step": 6817
    },
    {
      "epoch": 0.6386319035604149,
      "grad_norm": 1.44140625,
      "learning_rate": 9.292259063757993e-06,
      "loss": 0.4437,
      "step": 6834
    },
    {
      "epoch": 0.6402205401364358,
      "grad_norm": 0.91552734375,
      "learning_rate": 9.287761521233416e-06,
      "loss": 0.5764,
      "step": 6851
    },
    {
      "epoch": 0.6418091767124567,
      "grad_norm": 1.1669921875,
      "learning_rate": 9.28325082906893e-06,
      "loss": 0.2388,
      "step": 6868
    },
    {
      "epoch": 0.6433978132884777,
      "grad_norm": 1.5703125,
      "learning_rate": 9.278727001097855e-06,
      "loss": 0.4473,
      "step": 6885
    },
    {
      "epoch": 0.6449864498644986,
      "grad_norm": 0.226806640625,
      "learning_rate": 9.274190051193797e-06,
      "loss": 0.5338,
      "step": 6902
    },
    {
      "epoch": 0.6465750864405195,
      "grad_norm": 1.0966796875,
      "learning_rate": 9.269639993270602e-06,
      "loss": 0.2211,
      "step": 6919
    },
    {
      "epoch": 0.6481637230165405,
      "grad_norm": 1.3427734375,
      "learning_rate": 9.265076841282318e-06,
      "loss": 0.4037,
      "step": 6936
    },
    {
      "epoch": 0.6497523595925614,
      "grad_norm": 0.267822265625,
      "learning_rate": 9.260500609223149e-06,
      "loss": 0.4799,
      "step": 6953
    },
    {
      "epoch": 0.6513409961685823,
      "grad_norm": 0.85009765625,
      "learning_rate": 9.255911311127406e-06,
      "loss": 0.2615,
      "step": 6970
    },
    {
      "epoch": 0.6529296327446034,
      "grad_norm": 1.35546875,
      "learning_rate": 9.251308961069483e-06,
      "loss": 0.3903,
      "step": 6987
    },
    {
      "epoch": 0.6545182693206243,
      "grad_norm": 0.348388671875,
      "learning_rate": 9.246693573163792e-06,
      "loss": 0.4429,
      "step": 7004
    },
    {
      "epoch": 0.6561069058966452,
      "grad_norm": 1.3681640625,
      "learning_rate": 9.242065161564733e-06,
      "loss": 0.2546,
      "step": 7021
    },
    {
      "epoch": 0.6576955424726662,
      "grad_norm": 1.6494140625,
      "learning_rate": 9.237423740466647e-06,
      "loss": 0.484,
      "step": 7038
    },
    {
      "epoch": 0.6592841790486871,
      "grad_norm": 0.43603515625,
      "learning_rate": 9.23276932410377e-06,
      "loss": 0.4673,
      "step": 7055
    },
    {
      "epoch": 0.660872815624708,
      "grad_norm": 1.17578125,
      "learning_rate": 9.228101926750194e-06,
      "loss": 0.2579,
      "step": 7072
    },
    {
      "epoch": 0.6624614522007289,
      "grad_norm": 2.033203125,
      "learning_rate": 9.223421562719821e-06,
      "loss": 0.4563,
      "step": 7089
    },
    {
      "epoch": 0.6640500887767499,
      "grad_norm": 0.87646484375,
      "learning_rate": 9.218728246366316e-06,
      "loss": 0.4641,
      "step": 7106
    },
    {
      "epoch": 0.6656387253527708,
      "grad_norm": 0.84814453125,
      "learning_rate": 9.214021992083071e-06,
      "loss": 0.2785,
      "step": 7123
    },
    {
      "epoch": 0.6672273619287917,
      "grad_norm": 2.595703125,
      "learning_rate": 9.20930281430315e-06,
      "loss": 0.5061,
      "step": 7140
    },
    {
      "epoch": 0.6688159985048127,
      "grad_norm": 0.55859375,
      "learning_rate": 9.204570727499256e-06,
      "loss": 0.4073,
      "step": 7157
    },
    {
      "epoch": 0.6704046350808336,
      "grad_norm": 1.083984375,
      "learning_rate": 9.199825746183678e-06,
      "loss": 0.291,
      "step": 7174
    },
    {
      "epoch": 0.6719932716568545,
      "grad_norm": 2.955078125,
      "learning_rate": 9.195067884908248e-06,
      "loss": 0.4732,
      "step": 7191
    },
    {
      "epoch": 0.6735819082328754,
      "grad_norm": 0.81884765625,
      "learning_rate": 9.190297158264302e-06,
      "loss": 0.4065,
      "step": 7208
    },
    {
      "epoch": 0.6751705448088964,
      "grad_norm": 1.3232421875,
      "learning_rate": 9.185513580882633e-06,
      "loss": 0.2948,
      "step": 7225
    },
    {
      "epoch": 0.6767591813849173,
      "grad_norm": 2.03515625,
      "learning_rate": 9.180717167433438e-06,
      "loss": 0.4618,
      "step": 7242
    },
    {
      "epoch": 0.6783478179609382,
      "grad_norm": 0.6484375,
      "learning_rate": 9.175907932626283e-06,
      "loss": 0.3842,
      "step": 7259
    },
    {
      "epoch": 0.6799364545369592,
      "grad_norm": 1.416015625,
      "learning_rate": 9.171085891210054e-06,
      "loss": 0.2983,
      "step": 7276
    },
    {
      "epoch": 0.6815250911129801,
      "grad_norm": 2.076171875,
      "learning_rate": 9.166251057972912e-06,
      "loss": 0.4953,
      "step": 7293
    },
    {
      "epoch": 0.683113727689001,
      "grad_norm": 0.7958984375,
      "learning_rate": 9.161403447742248e-06,
      "loss": 0.3542,
      "step": 7310
    },
    {
      "epoch": 0.684702364265022,
      "grad_norm": 1.345703125,
      "learning_rate": 9.156543075384637e-06,
      "loss": 0.333,
      "step": 7327
    },
    {
      "epoch": 0.6862910008410429,
      "grad_norm": 2.484375,
      "learning_rate": 9.151669955805796e-06,
      "loss": 0.5339,
      "step": 7344
    },
    {
      "epoch": 0.6878796374170638,
      "grad_norm": 0.81591796875,
      "learning_rate": 9.146784103950526e-06,
      "loss": 0.3254,
      "step": 7361
    },
    {
      "epoch": 0.6894682739930847,
      "grad_norm": 1.66796875,
      "learning_rate": 9.141885534802686e-06,
      "loss": 0.3474,
      "step": 7378
    },
    {
      "epoch": 0.6910569105691057,
      "grad_norm": 1.9287109375,
      "learning_rate": 9.136974263385128e-06,
      "loss": 0.4733,
      "step": 7395
    },
    {
      "epoch": 0.6926455471451266,
      "grad_norm": 0.783203125,
      "learning_rate": 9.132050304759666e-06,
      "loss": 0.3208,
      "step": 7412
    },
    {
      "epoch": 0.6942341837211475,
      "grad_norm": 1.4931640625,
      "learning_rate": 9.127113674027013e-06,
      "loss": 0.3582,
      "step": 7429
    },
    {
      "epoch": 0.6958228202971685,
      "grad_norm": 2.431640625,
      "learning_rate": 9.122164386326757e-06,
      "loss": 0.5215,
      "step": 7446
    },
    {
      "epoch": 0.6974114568731894,
      "grad_norm": 1.005859375,
      "learning_rate": 9.117202456837293e-06,
      "loss": 0.2535,
      "step": 7463
    },
    {
      "epoch": 0.6990000934492103,
      "grad_norm": 1.603515625,
      "learning_rate": 9.11222790077579e-06,
      "loss": 0.3575,
      "step": 7480
    },
    {
      "epoch": 0.7005887300252313,
      "grad_norm": 2.328125,
      "learning_rate": 9.107240733398139e-06,
      "loss": 0.4937,
      "step": 7497
    },
    {
      "epoch": 0.7021773666012522,
      "grad_norm": 0.84033203125,
      "learning_rate": 9.102240969998904e-06,
      "loss": 0.2808,
      "step": 7514
    },
    {
      "epoch": 0.7037660031772731,
      "grad_norm": 1.3154296875,
      "learning_rate": 9.097228625911283e-06,
      "loss": 0.3629,
      "step": 7531
    },
    {
      "epoch": 0.705354639753294,
      "grad_norm": 2.49609375,
      "learning_rate": 9.092203716507055e-06,
      "loss": 0.5001,
      "step": 7548
    },
    {
      "epoch": 0.706943276329315,
      "grad_norm": 0.7802734375,
      "learning_rate": 9.087166257196534e-06,
      "loss": 0.2256,
      "step": 7565
    },
    {
      "epoch": 0.7085319129053359,
      "grad_norm": 1.2744140625,
      "learning_rate": 9.082116263428518e-06,
      "loss": 0.3411,
      "step": 7582
    },
    {
      "epoch": 0.7101205494813568,
      "grad_norm": 2.5859375,
      "learning_rate": 9.077053750690252e-06,
      "loss": 0.5795,
      "step": 7599
    },
    {
      "epoch": 0.7117091860573778,
      "grad_norm": 1.17578125,
      "learning_rate": 9.07197873450737e-06,
      "loss": 0.2563,
      "step": 7616
    },
    {
      "epoch": 0.7132978226333987,
      "grad_norm": 1.41796875,
      "learning_rate": 9.066891230443851e-06,
      "loss": 0.3713,
      "step": 7633
    },
    {
      "epoch": 0.7148864592094197,
      "grad_norm": 2.435546875,
      "learning_rate": 9.061791254101975e-06,
      "loss": 0.5464,
      "step": 7650
    },
    {
      "epoch": 0.7164750957854407,
      "grad_norm": 1.1220703125,
      "learning_rate": 9.056678821122268e-06,
      "loss": 0.2008,
      "step": 7667
    },
    {
      "epoch": 0.7180637323614616,
      "grad_norm": 1.8505859375,
      "learning_rate": 9.05155394718346e-06,
      "loss": 0.4434,
      "step": 7684
    },
    {
      "epoch": 0.7196523689374825,
      "grad_norm": 0.2333984375,
      "learning_rate": 9.046416648002433e-06,
      "loss": 0.5842,
      "step": 7701
    },
    {
      "epoch": 0.7212410055135035,
      "grad_norm": 1.228515625,
      "learning_rate": 9.04126693933418e-06,
      "loss": 0.1999,
      "step": 7718
    },
    {
      "epoch": 0.7228296420895244,
      "grad_norm": 1.5693359375,
      "learning_rate": 9.03610483697174e-06,
      "loss": 0.4003,
      "step": 7735
    },
    {
      "epoch": 0.7244182786655453,
      "grad_norm": 0.03564453125,
      "learning_rate": 9.030930356746173e-06,
      "loss": 0.5111,
      "step": 7752
    },
    {
      "epoch": 0.7260069152415662,
      "grad_norm": 1.189453125,
      "learning_rate": 9.025743514526493e-06,
      "loss": 0.2424,
      "step": 7769
    },
    {
      "epoch": 0.7275955518175872,
      "grad_norm": 1.7080078125,
      "learning_rate": 9.020544326219625e-06,
      "loss": 0.462,
      "step": 7786
    },
    {
      "epoch": 0.7291841883936081,
      "grad_norm": 0.5263671875,
      "learning_rate": 9.015332807770359e-06,
      "loss": 0.5362,
      "step": 7803
    },
    {
      "epoch": 0.730772824969629,
      "grad_norm": 1.427734375,
      "learning_rate": 9.010108975161297e-06,
      "loss": 0.3223,
      "step": 7820
    },
    {
      "epoch": 0.73236146154565,
      "grad_norm": 1.6904296875,
      "learning_rate": 9.004872844412811e-06,
      "loss": 0.4806,
      "step": 7837
    },
    {
      "epoch": 0.7339500981216709,
      "grad_norm": 0.5634765625,
      "learning_rate": 8.99962443158298e-06,
      "loss": 0.4956,
      "step": 7854
    },
    {
      "epoch": 0.7355387346976918,
      "grad_norm": 1.0185546875,
      "learning_rate": 8.994363752767557e-06,
      "loss": 0.2681,
      "step": 7871
    },
    {
      "epoch": 0.7371273712737128,
      "grad_norm": 1.8310546875,
      "learning_rate": 8.98909082409991e-06,
      "loss": 0.4442,
      "step": 7888
    },
    {
      "epoch": 0.7387160078497337,
      "grad_norm": 0.533203125,
      "learning_rate": 8.983805661750972e-06,
      "loss": 0.4797,
      "step": 7905
    },
    {
      "epoch": 0.7403046444257546,
      "grad_norm": 1.263671875,
      "learning_rate": 8.9785082819292e-06,
      "loss": 0.3004,
      "step": 7922
    },
    {
      "epoch": 0.7418932810017755,
      "grad_norm": 1.8154296875,
      "learning_rate": 8.97319870088051e-06,
      "loss": 0.4745,
      "step": 7939
    },
    {
      "epoch": 0.7434819175777965,
      "grad_norm": 0.6728515625,
      "learning_rate": 8.967876934888245e-06,
      "loss": 0.4404,
      "step": 7956
    },
    {
      "epoch": 0.7450705541538174,
      "grad_norm": 1.1865234375,
      "learning_rate": 8.962543000273113e-06,
      "loss": 0.2779,
      "step": 7973
    },
    {
      "epoch": 0.7466591907298383,
      "grad_norm": 1.8984375,
      "learning_rate": 8.957196913393142e-06,
      "loss": 0.4083,
      "step": 7990
    },
    {
      "epoch": 0.7482478273058593,
      "grad_norm": 0.61328125,
      "learning_rate": 8.951838690643626e-06,
      "loss": 0.4231,
      "step": 8007
    },
    {
      "epoch": 0.7498364638818802,
      "grad_norm": 1.0966796875,
      "learning_rate": 8.946468348457082e-06,
      "loss": 0.2788,
      "step": 8024
    },
    {
      "epoch": 0.7514251004579011,
      "grad_norm": 1.98046875,
      "learning_rate": 8.941085903303188e-06,
      "loss": 0.4474,
      "step": 8041
    },
    {
      "epoch": 0.753013737033922,
      "grad_norm": 0.87255859375,
      "learning_rate": 8.935691371688744e-06,
      "loss": 0.4911,
      "step": 8058
    },
    {
      "epoch": 0.754602373609943,
      "grad_norm": 1.4599609375,
      "learning_rate": 8.930284770157614e-06,
      "loss": 0.299,
      "step": 8075
    },
    {
      "epoch": 0.7561910101859639,
      "grad_norm": 2.228515625,
      "learning_rate": 8.92486611529068e-06,
      "loss": 0.5236,
      "step": 8092
    },
    {
      "epoch": 0.7577796467619848,
      "grad_norm": 0.828125,
      "learning_rate": 8.919435423705786e-06,
      "loss": 0.3771,
      "step": 8109
    },
    {
      "epoch": 0.7593682833380058,
      "grad_norm": 1.833984375,
      "learning_rate": 8.913992712057696e-06,
      "loss": 0.2973,
      "step": 8126
    },
    {
      "epoch": 0.7609569199140267,
      "grad_norm": 1.763671875,
      "learning_rate": 8.908537997038031e-06,
      "loss": 0.4774,
      "step": 8143
    },
    {
      "epoch": 0.7625455564900476,
      "grad_norm": 0.71337890625,
      "learning_rate": 8.903071295375222e-06,
      "loss": 0.3373,
      "step": 8160
    },
    {
      "epoch": 0.7641341930660686,
      "grad_norm": 1.2646484375,
      "learning_rate": 8.897592623834469e-06,
      "loss": 0.3729,
      "step": 8177
    },
    {
      "epoch": 0.7657228296420895,
      "grad_norm": 1.931640625,
      "learning_rate": 8.892101999217673e-06,
      "loss": 0.5125,
      "step": 8194
    },
    {
      "epoch": 0.7673114662181104,
      "grad_norm": 0.646484375,
      "learning_rate": 8.886599438363399e-06,
      "loss": 0.3436,
      "step": 8211
    },
    {
      "epoch": 0.7689001027941313,
      "grad_norm": 1.4443359375,
      "learning_rate": 8.88108495814681e-06,
      "loss": 0.3521,
      "step": 8228
    },
    {
      "epoch": 0.7704887393701523,
      "grad_norm": 2.6796875,
      "learning_rate": 8.875558575479631e-06,
      "loss": 0.4941,
      "step": 8245
    },
    {
      "epoch": 0.7720773759461732,
      "grad_norm": 0.63818359375,
      "learning_rate": 8.870020307310085e-06,
      "loss": 0.2562,
      "step": 8262
    },
    {
      "epoch": 0.7736660125221941,
      "grad_norm": 1.484375,
      "learning_rate": 8.864470170622845e-06,
      "loss": 0.3227,
      "step": 8279
    },
    {
      "epoch": 0.7752546490982151,
      "grad_norm": 1.9404296875,
      "learning_rate": 8.858908182438985e-06,
      "loss": 0.534,
      "step": 8296
    },
    {
      "epoch": 0.7768432856742361,
      "grad_norm": 0.923828125,
      "learning_rate": 8.853334359815922e-06,
      "loss": 0.2681,
      "step": 8313
    },
    {
      "epoch": 0.778431922250257,
      "grad_norm": 1.3388671875,
      "learning_rate": 8.847748719847369e-06,
      "loss": 0.3564,
      "step": 8330
    },
    {
      "epoch": 0.780020558826278,
      "grad_norm": 2.123046875,
      "learning_rate": 8.842151279663278e-06,
      "loss": 0.498,
      "step": 8347
    },
    {
      "epoch": 0.7816091954022989,
      "grad_norm": 0.7080078125,
      "learning_rate": 8.836542056429791e-06,
      "loss": 0.2557,
      "step": 8364
    },
    {
      "epoch": 0.7831978319783198,
      "grad_norm": 1.326171875,
      "learning_rate": 8.830921067349187e-06,
      "loss": 0.3606,
      "step": 8381
    },
    {
      "epoch": 0.7847864685543408,
      "grad_norm": 1.7919921875,
      "learning_rate": 8.82528832965983e-06,
      "loss": 0.5401,
      "step": 8398
    },
    {
      "epoch": 0.7863751051303617,
      "grad_norm": 0.6240234375,
      "learning_rate": 8.819643860636105e-06,
      "loss": 0.2178,
      "step": 8415
    },
    {
      "epoch": 0.7879637417063826,
      "grad_norm": 1.3876953125,
      "learning_rate": 8.813987677588385e-06,
      "loss": 0.358,
      "step": 8432
    },
    {
      "epoch": 0.7895523782824035,
      "grad_norm": 2.900390625,
      "learning_rate": 8.808319797862965e-06,
      "loss": 0.5406,
      "step": 8449
    },
    {
      "epoch": 0.7911410148584245,
      "grad_norm": 1.1181640625,
      "learning_rate": 8.802640238842007e-06,
      "loss": 0.253,
      "step": 8466
    },
    {
      "epoch": 0.7927296514344454,
      "grad_norm": 1.7685546875,
      "learning_rate": 8.796949017943496e-06,
      "loss": 0.4065,
      "step": 8483
    },
    {
      "epoch": 0.7943182880104663,
      "grad_norm": 2.509765625,
      "learning_rate": 8.791246152621177e-06,
      "loss": 0.5664,
      "step": 8500
    },
    {
      "epoch": 0.7959069245864873,
      "grad_norm": 0.93505859375,
      "learning_rate": 8.78553166036451e-06,
      "loss": 0.2357,
      "step": 8517
    },
    {
      "epoch": 0.7974955611625082,
      "grad_norm": 1.353515625,
      "learning_rate": 8.779805558698611e-06,
      "loss": 0.3866,
      "step": 8534
    },
    {
      "epoch": 0.7990841977385291,
      "grad_norm": 0.60888671875,
      "learning_rate": 8.774067865184195e-06,
      "loss": 0.5187,
      "step": 8551
    },
    {
      "epoch": 0.80067283431455,
      "grad_norm": 0.97998046875,
      "learning_rate": 8.768318597417535e-06,
      "loss": 0.2549,
      "step": 8568
    },
    {
      "epoch": 0.802261470890571,
      "grad_norm": 1.6162109375,
      "learning_rate": 8.762557773030393e-06,
      "loss": 0.4058,
      "step": 8585
    },
    {
      "epoch": 0.8038501074665919,
      "grad_norm": 0.2958984375,
      "learning_rate": 8.756785409689977e-06,
      "loss": 0.484,
      "step": 8602
    },
    {
      "epoch": 0.8054387440426128,
      "grad_norm": 1.0068359375,
      "learning_rate": 8.751001525098878e-06,
      "loss": 0.2756,
      "step": 8619
    },
    {
      "epoch": 0.8070273806186338,
      "grad_norm": 1.6484375,
      "learning_rate": 8.745206136995023e-06,
      "loss": 0.4378,
      "step": 8636
    },
    {
      "epoch": 0.8086160171946547,
      "grad_norm": 0.48681640625,
      "learning_rate": 8.73939926315162e-06,
      "loss": 0.4921,
      "step": 8653
    },
    {
      "epoch": 0.8102046537706756,
      "grad_norm": 0.9609375,
      "learning_rate": 8.733580921377098e-06,
      "loss": 0.1957,
      "step": 8670
    },
    {
      "epoch": 0.8117932903466966,
      "grad_norm": 1.970703125,
      "learning_rate": 8.727751129515053e-06,
      "loss": 0.426,
      "step": 8687
    },
    {
      "epoch": 0.8133819269227175,
      "grad_norm": 0.12548828125,
      "learning_rate": 8.721909905444204e-06,
      "loss": 0.4706,
      "step": 8704
    },
    {
      "epoch": 0.8149705634987384,
      "grad_norm": 1.041015625,
      "learning_rate": 8.716057267078323e-06,
      "loss": 0.2678,
      "step": 8721
    },
    {
      "epoch": 0.8165592000747594,
      "grad_norm": 1.8095703125,
      "learning_rate": 8.71019323236619e-06,
      "loss": 0.4182,
      "step": 8738
    },
    {
      "epoch": 0.8181478366507803,
      "grad_norm": 0.356201171875,
      "learning_rate": 8.704317819291536e-06,
      "loss": 0.4573,
      "step": 8755
    },
    {
      "epoch": 0.8197364732268012,
      "grad_norm": 1.056640625,
      "learning_rate": 8.698431045872985e-06,
      "loss": 0.2602,
      "step": 8772
    },
    {
      "epoch": 0.8213251098028221,
      "grad_norm": 1.673828125,
      "learning_rate": 8.692532930164e-06,
      "loss": 0.4398,
      "step": 8789
    },
    {
      "epoch": 0.8229137463788431,
      "grad_norm": 0.67822265625,
      "learning_rate": 8.686623490252835e-06,
      "loss": 0.4097,
      "step": 8806
    },
    {
      "epoch": 0.824502382954864,
      "grad_norm": 1.259765625,
      "learning_rate": 8.680702744262462e-06,
      "loss": 0.2765,
      "step": 8823
    },
    {
      "epoch": 0.8260910195308849,
      "grad_norm": 2.0234375,
      "learning_rate": 8.674770710350535e-06,
      "loss": 0.4465,
      "step": 8840
    },
    {
      "epoch": 0.8276796561069059,
      "grad_norm": 0.72265625,
      "learning_rate": 8.668827406709322e-06,
      "loss": 0.4133,
      "step": 8857
    },
    {
      "epoch": 0.8292682926829268,
      "grad_norm": 1.2802734375,
      "learning_rate": 8.662872851565652e-06,
      "loss": 0.3178,
      "step": 8874
    },
    {
      "epoch": 0.8308569292589477,
      "grad_norm": 1.90234375,
      "learning_rate": 8.656907063180866e-06,
      "loss": 0.4974,
      "step": 8891
    },
    {
      "epoch": 0.8324455658349686,
      "grad_norm": 0.787109375,
      "learning_rate": 8.650930059850746e-06,
      "loss": 0.4093,
      "step": 8908
    },
    {
      "epoch": 0.8340342024109896,
      "grad_norm": 1.111328125,
      "learning_rate": 8.644941859905474e-06,
      "loss": 0.3003,
      "step": 8925
    },
    {
      "epoch": 0.8356228389870105,
      "grad_norm": 1.78515625,
      "learning_rate": 8.63894248170957e-06,
      "loss": 0.504,
      "step": 8942
    },
    {
      "epoch": 0.8372114755630314,
      "grad_norm": 0.77783203125,
      "learning_rate": 8.632931943661829e-06,
      "loss": 0.3659,
      "step": 8959
    },
    {
      "epoch": 0.8388001121390525,
      "grad_norm": 1.4267578125,
      "learning_rate": 8.626910264195276e-06,
      "loss": 0.3546,
      "step": 8976
    },
    {
      "epoch": 0.8403887487150734,
      "grad_norm": 1.94921875,
      "learning_rate": 8.620877461777106e-06,
      "loss": 0.4955,
      "step": 8993
    },
    {
      "epoch": 0.8419773852910943,
      "grad_norm": 0.81103515625,
      "learning_rate": 8.61483355490862e-06,
      "loss": 0.3391,
      "step": 9010
    },
    {
      "epoch": 0.8435660218671153,
      "grad_norm": 1.068359375,
      "learning_rate": 8.60877856212518e-06,
      "loss": 0.34,
      "step": 9027
    },
    {
      "epoch": 0.8451546584431362,
      "grad_norm": 2.029296875,
      "learning_rate": 8.602712501996139e-06,
      "loss": 0.4959,
      "step": 9044
    },
    {
      "epoch": 0.8467432950191571,
      "grad_norm": 0.720703125,
      "learning_rate": 8.596635393124798e-06,
      "loss": 0.325,
      "step": 9061
    },
    {
      "epoch": 0.8483319315951781,
      "grad_norm": 1.3662109375,
      "learning_rate": 8.59054725414834e-06,
      "loss": 0.3572,
      "step": 9078
    },
    {
      "epoch": 0.849920568171199,
      "grad_norm": 2.041015625,
      "learning_rate": 8.584448103737772e-06,
      "loss": 0.5228,
      "step": 9095
    },
    {
      "epoch": 0.8515092047472199,
      "grad_norm": 0.947265625,
      "learning_rate": 8.578337960597875e-06,
      "loss": 0.3448,
      "step": 9112
    },
    {
      "epoch": 0.8530978413232408,
      "grad_norm": 1.5908203125,
      "learning_rate": 8.572216843467138e-06,
      "loss": 0.351,
      "step": 9129
    },
    {
      "epoch": 0.8546864778992618,
      "grad_norm": 2.015625,
      "learning_rate": 8.566084771117711e-06,
      "loss": 0.5239,
      "step": 9146
    },
    {
      "epoch": 0.8562751144752827,
      "grad_norm": 0.9619140625,
      "learning_rate": 8.559941762355333e-06,
      "loss": 0.2353,
      "step": 9163
    },
    {
      "epoch": 0.8578637510513036,
      "grad_norm": 1.5380859375,
      "learning_rate": 8.55378783601929e-06,
      "loss": 0.3201,
      "step": 9180
    },
    {
      "epoch": 0.8594523876273246,
      "grad_norm": 2.658203125,
      "learning_rate": 8.547623010982347e-06,
      "loss": 0.5311,
      "step": 9197
    },
    {
      "epoch": 0.8610410242033455,
      "grad_norm": 0.9345703125,
      "learning_rate": 8.541447306150692e-06,
      "loss": 0.2686,
      "step": 9214
    },
    {
      "epoch": 0.8626296607793664,
      "grad_norm": 1.787109375,
      "learning_rate": 8.535260740463878e-06,
      "loss": 0.3888,
      "step": 9231
    },
    {
      "epoch": 0.8642182973553874,
      "grad_norm": 2.48828125,
      "learning_rate": 8.529063332894771e-06,
      "loss": 0.5565,
      "step": 9248
    },
    {
      "epoch": 0.8658069339314083,
      "grad_norm": 0.84912109375,
      "learning_rate": 8.522855102449483e-06,
      "loss": 0.2693,
      "step": 9265
    },
    {
      "epoch": 0.8673955705074292,
      "grad_norm": 1.65625,
      "learning_rate": 8.516636068167319e-06,
      "loss": 0.358,
      "step": 9282
    },
    {
      "epoch": 0.8689842070834501,
      "grad_norm": 2.63671875,
      "learning_rate": 8.510406249120711e-06,
      "loss": 0.5695,
      "step": 9299
    },
    {
      "epoch": 0.8705728436594711,
      "grad_norm": 0.83642578125,
      "learning_rate": 8.504165664415173e-06,
      "loss": 0.2027,
      "step": 9316
    },
    {
      "epoch": 0.872161480235492,
      "grad_norm": 1.5439453125,
      "learning_rate": 8.497914333189236e-06,
      "loss": 0.3381,
      "step": 9333
    },
    {
      "epoch": 0.8737501168115129,
      "grad_norm": 2.779296875,
      "learning_rate": 8.49165227461438e-06,
      "loss": 0.5968,
      "step": 9350
    },
    {
      "epoch": 0.8753387533875339,
      "grad_norm": 0.9287109375,
      "learning_rate": 8.485379507894993e-06,
      "loss": 0.182,
      "step": 9367
    },
    {
      "epoch": 0.8769273899635548,
      "grad_norm": 1.62890625,
      "learning_rate": 8.479096052268291e-06,
      "loss": 0.3524,
      "step": 9384
    },
    {
      "epoch": 0.8785160265395757,
      "grad_norm": 0.6494140625,
      "learning_rate": 8.472801927004286e-06,
      "loss": 0.5009,
      "step": 9401
    },
    {
      "epoch": 0.8801046631155967,
      "grad_norm": 1.197265625,
      "learning_rate": 8.466497151405695e-06,
      "loss": 0.2639,
      "step": 9418
    },
    {
      "epoch": 0.8816932996916176,
      "grad_norm": 1.53515625,
      "learning_rate": 8.460181744807909e-06,
      "loss": 0.4123,
      "step": 9435
    },
    {
      "epoch": 0.8832819362676385,
      "grad_norm": 0.389892578125,
      "learning_rate": 8.453855726578917e-06,
      "loss": 0.5044,
      "step": 9452
    },
    {
      "epoch": 0.8848705728436594,
      "grad_norm": 1.015625,
      "learning_rate": 8.447519116119252e-06,
      "loss": 0.2229,
      "step": 9469
    },
    {
      "epoch": 0.8864592094196804,
      "grad_norm": 1.7353515625,
      "learning_rate": 8.441171932861934e-06,
      "loss": 0.3896,
      "step": 9486
    },
    {
      "epoch": 0.8880478459957013,
      "grad_norm": 0.2471923828125,
      "learning_rate": 8.434814196272405e-06,
      "loss": 0.451,
      "step": 9503
    },
    {
      "epoch": 0.8896364825717222,
      "grad_norm": 1.1064453125,
      "learning_rate": 8.42844592584847e-06,
      "loss": 0.2668,
      "step": 9520
    },
    {
      "epoch": 0.8912251191477432,
      "grad_norm": 2.224609375,
      "learning_rate": 8.422067141120241e-06,
      "loss": 0.4365,
      "step": 9537
    },
    {
      "epoch": 0.8928137557237641,
      "grad_norm": 0.2099609375,
      "learning_rate": 8.415677861650078e-06,
      "loss": 0.4743,
      "step": 9554
    },
    {
      "epoch": 0.894402392299785,
      "grad_norm": 1.0654296875,
      "learning_rate": 8.40927810703252e-06,
      "loss": 0.2987,
      "step": 9571
    },
    {
      "epoch": 0.895991028875806,
      "grad_norm": 1.984375,
      "learning_rate": 8.402867896894238e-06,
      "loss": 0.4532,
      "step": 9588
    },
    {
      "epoch": 0.8975796654518269,
      "grad_norm": 0.5126953125,
      "learning_rate": 8.39644725089396e-06,
      "loss": 0.4199,
      "step": 9605
    },
    {
      "epoch": 0.8991683020278478,
      "grad_norm": 1.2001953125,
      "learning_rate": 8.390016188722425e-06,
      "loss": 0.3214,
      "step": 9622
    },
    {
      "epoch": 0.9007569386038689,
      "grad_norm": 1.8583984375,
      "learning_rate": 8.383574730102313e-06,
      "loss": 0.4627,
      "step": 9639
    },
    {
      "epoch": 0.9023455751798898,
      "grad_norm": 0.6298828125,
      "learning_rate": 8.377122894788187e-06,
      "loss": 0.4102,
      "step": 9656
    },
    {
      "epoch": 0.9039342117559107,
      "grad_norm": 1.732421875,
      "learning_rate": 8.37066070256644e-06,
      "loss": 0.2948,
      "step": 9673
    },
    {
      "epoch": 0.9055228483319316,
      "grad_norm": 1.96875,
      "learning_rate": 8.364188173255215e-06,
      "loss": 0.4904,
      "step": 9690
    },
    {
      "epoch": 0.9071114849079526,
      "grad_norm": 0.55126953125,
      "learning_rate": 8.357705326704369e-06,
      "loss": 0.4154,
      "step": 9707
    },
    {
      "epoch": 0.9087001214839735,
      "grad_norm": 1.177734375,
      "learning_rate": 8.35121218279539e-06,
      "loss": 0.2688,
      "step": 9724
    },
    {
      "epoch": 0.9102887580599944,
      "grad_norm": 1.98046875,
      "learning_rate": 8.344708761441354e-06,
      "loss": 0.5225,
      "step": 9741
    },
    {
      "epoch": 0.9118773946360154,
      "grad_norm": 0.7529296875,
      "learning_rate": 8.33819508258685e-06,
      "loss": 0.403,
      "step": 9758
    },
    {
      "epoch": 0.9134660312120363,
      "grad_norm": 1.22265625,
      "learning_rate": 8.331671166207925e-06,
      "loss": 0.3208,
      "step": 9775
    },
    {
      "epoch": 0.9150546677880572,
      "grad_norm": 1.673828125,
      "learning_rate": 8.325137032312026e-06,
      "loss": 0.4742,
      "step": 9792
    },
    {
      "epoch": 0.9166433043640781,
      "grad_norm": 0.765625,
      "learning_rate": 8.318592700937931e-06,
      "loss": 0.3824,
      "step": 9809
    },
    {
      "epoch": 0.9182319409400991,
      "grad_norm": 1.1904296875,
      "learning_rate": 8.312038192155694e-06,
      "loss": 0.3472,
      "step": 9826
    },
    {
      "epoch": 0.91982057751612,
      "grad_norm": 1.916015625,
      "learning_rate": 8.305473526066578e-06,
      "loss": 0.5098,
      "step": 9843
    },
    {
      "epoch": 0.9214092140921409,
      "grad_norm": 0.7109375,
      "learning_rate": 8.298898722803001e-06,
      "loss": 0.3959,
      "step": 9860
    },
    {
      "epoch": 0.9229978506681619,
      "grad_norm": 1.41015625,
      "learning_rate": 8.292313802528465e-06,
      "loss": 0.3406,
      "step": 9877
    },
    {
      "epoch": 0.9245864872441828,
      "grad_norm": 2.078125,
      "learning_rate": 8.2857187854375e-06,
      "loss": 0.4848,
      "step": 9894
    },
    {
      "epoch": 0.9261751238202037,
      "grad_norm": 0.71923828125,
      "learning_rate": 8.279113691755603e-06,
      "loss": 0.3017,
      "step": 9911
    },
    {
      "epoch": 0.9277637603962247,
      "grad_norm": 1.3134765625,
      "learning_rate": 8.27249854173917e-06,
      "loss": 0.3627,
      "step": 9928
    },
    {
      "epoch": 0.9293523969722456,
      "grad_norm": 2.4609375,
      "learning_rate": 8.26587335567544e-06,
      "loss": 0.5503,
      "step": 9945
    },
    {
      "epoch": 0.9309410335482665,
      "grad_norm": 1.017578125,
      "learning_rate": 8.259238153882432e-06,
      "loss": 0.3352,
      "step": 9962
    },
    {
      "epoch": 0.9325296701242874,
      "grad_norm": 1.4345703125,
      "learning_rate": 8.252592956708875e-06,
      "loss": 0.336,
      "step": 9979
    },
    {
      "epoch": 0.9341183067003084,
      "grad_norm": 2.05859375,
      "learning_rate": 8.245937784534157e-06,
      "loss": 0.5158,
      "step": 9996
    },
    {
      "epoch": 0.9357069432763293,
      "grad_norm": 0.8251953125,
      "learning_rate": 8.239272657768261e-06,
      "loss": 0.3373,
      "step": 10013
    },
    {
      "epoch": 0.9372955798523502,
      "grad_norm": 1.5078125,
      "learning_rate": 8.232597596851686e-06,
      "loss": 0.3714,
      "step": 10030
    },
    {
      "epoch": 0.9388842164283712,
      "grad_norm": 2.259765625,
      "learning_rate": 8.225912622255407e-06,
      "loss": 0.4965,
      "step": 10047
    },
    {
      "epoch": 0.9404728530043921,
      "grad_norm": 0.91455078125,
      "learning_rate": 8.219217754480802e-06,
      "loss": 0.2676,
      "step": 10064
    },
    {
      "epoch": 0.942061489580413,
      "grad_norm": 1.7705078125,
      "learning_rate": 8.212513014059582e-06,
      "loss": 0.3456,
      "step": 10081
    },
    {
      "epoch": 0.943650126156434,
      "grad_norm": 2.388671875,
      "learning_rate": 8.205798421553744e-06,
      "loss": 0.5135,
      "step": 10098
    },
    {
      "epoch": 0.9452387627324549,
      "grad_norm": 0.970703125,
      "learning_rate": 8.199073997555495e-06,
      "loss": 0.2468,
      "step": 10115
    },
    {
      "epoch": 0.9468273993084758,
      "grad_norm": 1.337890625,
      "learning_rate": 8.19233976268719e-06,
      "loss": 0.3404,
      "step": 10132
    },
    {
      "epoch": 0.9484160358844967,
      "grad_norm": 2.314453125,
      "learning_rate": 8.185595737601277e-06,
      "loss": 0.5087,
      "step": 10149
    },
    {
      "epoch": 0.9500046724605177,
      "grad_norm": 0.77978515625,
      "learning_rate": 8.178841942980227e-06,
      "loss": 0.2138,
      "step": 10166
    },
    {
      "epoch": 0.9515933090365386,
      "grad_norm": 1.6552734375,
      "learning_rate": 8.172078399536472e-06,
      "loss": 0.4236,
      "step": 10183
    },
    {
      "epoch": 0.9531819456125595,
      "grad_norm": 2.796875,
      "learning_rate": 8.16530512801234e-06,
      "loss": 0.6091,
      "step": 10200
    },
    {
      "epoch": 0.9547705821885805,
      "grad_norm": 1.0302734375,
      "learning_rate": 8.158522149179993e-06,
      "loss": 0.2437,
      "step": 10217
    },
    {
      "epoch": 0.9563592187646014,
      "grad_norm": 1.7001953125,
      "learning_rate": 8.151729483841367e-06,
      "loss": 0.4341,
      "step": 10234
    },
    {
      "epoch": 0.9579478553406223,
      "grad_norm": 0.30712890625,
      "learning_rate": 8.1449271528281e-06,
      "loss": 0.5646,
      "step": 10251
    },
    {
      "epoch": 0.9595364919166433,
      "grad_norm": 0.9833984375,
      "learning_rate": 8.138115177001475e-06,
      "loss": 0.2454,
      "step": 10268
    },
    {
      "epoch": 0.9611251284926642,
      "grad_norm": 1.8056640625,
      "learning_rate": 8.131293577252353e-06,
      "loss": 0.4145,
      "step": 10285
    },
    {
      "epoch": 0.9627137650686852,
      "grad_norm": 0.402099609375,
      "learning_rate": 8.124462374501107e-06,
      "loss": 0.4938,
      "step": 10302
    },
    {
      "epoch": 0.9643024016447062,
      "grad_norm": 1.1181640625,
      "learning_rate": 8.117621589697566e-06,
      "loss": 0.245,
      "step": 10319
    },
    {
      "epoch": 0.9658910382207271,
      "grad_norm": 1.85546875,
      "learning_rate": 8.11077124382094e-06,
      "loss": 0.463,
      "step": 10336
    },
    {
      "epoch": 0.967479674796748,
      "grad_norm": 0.238525390625,
      "learning_rate": 8.103911357879762e-06,
      "loss": 0.5053,
      "step": 10353
    },
    {
      "epoch": 0.9690683113727689,
      "grad_norm": 1.0244140625,
      "learning_rate": 8.097041952911824e-06,
      "loss": 0.2083,
      "step": 10370
    },
    {
      "epoch": 0.9706569479487899,
      "grad_norm": 1.65625,
      "learning_rate": 8.09016304998411e-06,
      "loss": 0.3777,
      "step": 10387
    },
    {
      "epoch": 0.9722455845248108,
      "grad_norm": 0.56298828125,
      "learning_rate": 8.083274670192729e-06,
      "loss": 0.4496,
      "step": 10404
    },
    {
      "epoch": 0.9738342211008317,
      "grad_norm": 1.1865234375,
      "learning_rate": 8.07637683466286e-06,
      "loss": 0.2883,
      "step": 10421
    },
    {
      "epoch": 0.9754228576768527,
      "grad_norm": 1.6396484375,
      "learning_rate": 8.069469564548675e-06,
      "loss": 0.4145,
      "step": 10438
    },
    {
      "epoch": 0.9770114942528736,
      "grad_norm": 0.46923828125,
      "learning_rate": 8.06255288103328e-06,
      "loss": 0.4098,
      "step": 10455
    },
    {
      "epoch": 0.9786001308288945,
      "grad_norm": 1.12109375,
      "learning_rate": 8.055626805328657e-06,
      "loss": 0.2896,
      "step": 10472
    },
    {
      "epoch": 0.9801887674049155,
      "grad_norm": 1.8798828125,
      "learning_rate": 8.048691358675582e-06,
      "loss": 0.4423,
      "step": 10489
    },
    {
      "epoch": 0.9817774039809364,
      "grad_norm": 0.6298828125,
      "learning_rate": 8.041746562343575e-06,
      "loss": 0.4246,
      "step": 10506
    },
    {
      "epoch": 0.9833660405569573,
      "grad_norm": 1.1259765625,
      "learning_rate": 8.034792437630829e-06,
      "loss": 0.2856,
      "step": 10523
    },
    {
      "epoch": 0.9849546771329782,
      "grad_norm": 1.9150390625,
      "learning_rate": 8.027829005864147e-06,
      "loss": 0.4293,
      "step": 10540
    },
    {
      "epoch": 0.9865433137089992,
      "grad_norm": 0.669921875,
      "learning_rate": 8.02085628839887e-06,
      "loss": 0.3968,
      "step": 10557
    },
    {
      "epoch": 0.9881319502850201,
      "grad_norm": 1.2373046875,
      "learning_rate": 8.013874306618819e-06,
      "loss": 0.2945,
      "step": 10574
    },
    {
      "epoch": 0.989720586861041,
      "grad_norm": 1.9794921875,
      "learning_rate": 8.006883081936228e-06,
      "loss": 0.4689,
      "step": 10591
    },
    {
      "epoch": 0.991309223437062,
      "grad_norm": 0.76171875,
      "learning_rate": 7.999882635791672e-06,
      "loss": 0.4204,
      "step": 10608
    },
    {
      "epoch": 0.9928978600130829,
      "grad_norm": 1.2578125,
      "learning_rate": 7.992872989654013e-06,
      "loss": 0.3296,
      "step": 10625
    },
    {
      "epoch": 0.9944864965891038,
      "grad_norm": 1.9404296875,
      "learning_rate": 7.985854165020324e-06,
      "loss": 0.4805,
      "step": 10642
    },
    {
      "epoch": 0.9960751331651247,
      "grad_norm": 0.625,
      "learning_rate": 7.978826183415822e-06,
      "loss": 0.396,
      "step": 10659
    },
    {
      "epoch": 0.9976637697411457,
      "grad_norm": 1.4072265625,
      "learning_rate": 7.971789066393817e-06,
      "loss": 0.3129,
      "step": 10676
    },
    {
      "epoch": 0.9992524063171666,
      "grad_norm": 2.091796875,
      "learning_rate": 7.964742835535625e-06,
      "loss": 0.4779,
      "step": 10693
    },
    {
      "epoch": 1.0008410428931875,
      "grad_norm": 0.69482421875,
      "learning_rate": 7.957687512450521e-06,
      "loss": 0.307,
      "step": 10710
    },
    {
      "epoch": 1.0024296794692085,
      "grad_norm": 1.1591796875,
      "learning_rate": 7.950623118775655e-06,
      "loss": 0.3115,
      "step": 10727
    },
    {
      "epoch": 1.0040183160452294,
      "grad_norm": 2.220703125,
      "learning_rate": 7.943549676175999e-06,
      "loss": 0.4948,
      "step": 10744
    },
    {
      "epoch": 1.0056069526212503,
      "grad_norm": 0.71533203125,
      "learning_rate": 7.936467206344279e-06,
      "loss": 0.3006,
      "step": 10761
    },
    {
      "epoch": 1.0071955891972713,
      "grad_norm": 1.39453125,
      "learning_rate": 7.929375731000901e-06,
      "loss": 0.3034,
      "step": 10778
    },
    {
      "epoch": 1.0087842257732922,
      "grad_norm": 2.28125,
      "learning_rate": 7.922275271893892e-06,
      "loss": 0.4842,
      "step": 10795
    },
    {
      "epoch": 1.0103728623493131,
      "grad_norm": 0.83203125,
      "learning_rate": 7.915165850798825e-06,
      "loss": 0.3426,
      "step": 10812
    },
    {
      "epoch": 1.011961498925334,
      "grad_norm": 1.5791015625,
      "learning_rate": 7.908047489518765e-06,
      "loss": 0.3368,
      "step": 10829
    },
    {
      "epoch": 1.013550135501355,
      "grad_norm": 2.2890625,
      "learning_rate": 7.90092020988419e-06,
      "loss": 0.5083,
      "step": 10846
    },
    {
      "epoch": 1.015138772077376,
      "grad_norm": 0.8310546875,
      "learning_rate": 7.893784033752928e-06,
      "loss": 0.2786,
      "step": 10863
    },
    {
      "epoch": 1.0167274086533968,
      "grad_norm": 1.833984375,
      "learning_rate": 7.886638983010095e-06,
      "loss": 0.3228,
      "step": 10880
    },
    {
      "epoch": 1.0183160452294178,
      "grad_norm": 2.255859375,
      "learning_rate": 7.879485079568019e-06,
      "loss": 0.5258,
      "step": 10897
    },
    {
      "epoch": 1.0199046818054387,
      "grad_norm": 0.939453125,
      "learning_rate": 7.87232234536618e-06,
      "loss": 0.2831,
      "step": 10914
    },
    {
      "epoch": 1.0214933183814596,
      "grad_norm": 1.515625,
      "learning_rate": 7.865150802371138e-06,
      "loss": 0.3507,
      "step": 10931
    },
    {
      "epoch": 1.0230819549574806,
      "grad_norm": 1.970703125,
      "learning_rate": 7.857970472576469e-06,
      "loss": 0.5338,
      "step": 10948
    },
    {
      "epoch": 1.0246705915335015,
      "grad_norm": 0.931640625,
      "learning_rate": 7.850781378002697e-06,
      "loss": 0.3034,
      "step": 10965
    },
    {
      "epoch": 1.0262592281095224,
      "grad_norm": 1.67578125,
      "learning_rate": 7.843583540697223e-06,
      "loss": 0.3575,
      "step": 10982
    },
    {
      "epoch": 1.0278478646855433,
      "grad_norm": 2.203125,
      "learning_rate": 7.836376982734264e-06,
      "loss": 0.5187,
      "step": 10999
    },
    {
      "epoch": 1.0294365012615643,
      "grad_norm": 1.0185546875,
      "learning_rate": 7.829161726214778e-06,
      "loss": 0.2878,
      "step": 11016
    },
    {
      "epoch": 1.0310251378375852,
      "grad_norm": 1.517578125,
      "learning_rate": 7.8219377932664e-06,
      "loss": 0.3427,
      "step": 11033
    },
    {
      "epoch": 1.0326137744136061,
      "grad_norm": 2.595703125,
      "learning_rate": 7.814705206043375e-06,
      "loss": 0.6171,
      "step": 11050
    },
    {
      "epoch": 1.034202410989627,
      "grad_norm": 1.052734375,
      "learning_rate": 7.80746398672649e-06,
      "loss": 0.1955,
      "step": 11067
    },
    {
      "epoch": 1.035791047565648,
      "grad_norm": 1.4130859375,
      "learning_rate": 7.800214157522999e-06,
      "loss": 0.3548,
      "step": 11084
    },
    {
      "epoch": 1.037379684141669,
      "grad_norm": 4.0859375,
      "learning_rate": 7.79295574066657e-06,
      "loss": 0.5652,
      "step": 11101
    },
    {
      "epoch": 1.0389683207176899,
      "grad_norm": 1.1025390625,
      "learning_rate": 7.785688758417197e-06,
      "loss": 0.2248,
      "step": 11118
    },
    {
      "epoch": 1.0405569572937108,
      "grad_norm": 1.591796875,
      "learning_rate": 7.77841323306115e-06,
      "loss": 0.4066,
      "step": 11135
    },
    {
      "epoch": 1.0421455938697317,
      "grad_norm": 0.416015625,
      "learning_rate": 7.771129186910898e-06,
      "loss": 0.5519,
      "step": 11152
    },
    {
      "epoch": 1.0437342304457526,
      "grad_norm": 1.1171875,
      "learning_rate": 7.763836642305037e-06,
      "loss": 0.2155,
      "step": 11169
    },
    {
      "epoch": 1.0453228670217736,
      "grad_norm": 1.73828125,
      "learning_rate": 7.756535621608227e-06,
      "loss": 0.4098,
      "step": 11186
    },
    {
      "epoch": 1.0469115035977945,
      "grad_norm": 0.447265625,
      "learning_rate": 7.749226147211128e-06,
      "loss": 0.496,
      "step": 11203
    },
    {
      "epoch": 1.0485001401738154,
      "grad_norm": 1.041015625,
      "learning_rate": 7.74190824153032e-06,
      "loss": 0.2178,
      "step": 11220
    },
    {
      "epoch": 1.0500887767498364,
      "grad_norm": 1.5703125,
      "learning_rate": 7.734581927008243e-06,
      "loss": 0.3809,
      "step": 11237
    },
    {
      "epoch": 1.0516774133258573,
      "grad_norm": 0.30712890625,
      "learning_rate": 7.727247226113119e-06,
      "loss": 0.4879,
      "step": 11254
    },
    {
      "epoch": 1.0532660499018784,
      "grad_norm": 0.98583984375,
      "learning_rate": 7.719904161338898e-06,
      "loss": 0.2356,
      "step": 11271
    },
    {
      "epoch": 1.0548546864778992,
      "grad_norm": 1.54296875,
      "learning_rate": 7.712552755205179e-06,
      "loss": 0.3932,
      "step": 11288
    },
    {
      "epoch": 1.0564433230539203,
      "grad_norm": 0.2117919921875,
      "learning_rate": 7.705193030257133e-06,
      "loss": 0.473,
      "step": 11305
    },
    {
      "epoch": 1.0580319596299412,
      "grad_norm": 1.1455078125,
      "learning_rate": 7.697825009065451e-06,
      "loss": 0.2548,
      "step": 11322
    },
    {
      "epoch": 1.0596205962059622,
      "grad_norm": 2.00390625,
      "learning_rate": 7.690448714226265e-06,
      "loss": 0.4138,
      "step": 11339
    },
    {
      "epoch": 1.061209232781983,
      "grad_norm": 0.493896484375,
      "learning_rate": 7.683064168361082e-06,
      "loss": 0.4121,
      "step": 11356
    },
    {
      "epoch": 1.062797869358004,
      "grad_norm": 1.1748046875,
      "learning_rate": 7.675671394116711e-06,
      "loss": 0.2854,
      "step": 11373
    },
    {
      "epoch": 1.064386505934025,
      "grad_norm": 2.24609375,
      "learning_rate": 7.668270414165198e-06,
      "loss": 0.4399,
      "step": 11390
    },
    {
      "epoch": 1.0659751425100459,
      "grad_norm": 0.55078125,
      "learning_rate": 7.660861251203748e-06,
      "loss": 0.3967,
      "step": 11407
    },
    {
      "epoch": 1.0675637790860668,
      "grad_norm": 1.4990234375,
      "learning_rate": 7.653443927954671e-06,
      "loss": 0.2596,
      "step": 11424
    },
    {
      "epoch": 1.0691524156620877,
      "grad_norm": 2.189453125,
      "learning_rate": 7.646018467165295e-06,
      "loss": 0.4387,
      "step": 11441
    },
    {
      "epoch": 1.0707410522381087,
      "grad_norm": 0.6025390625,
      "learning_rate": 7.638584891607908e-06,
      "loss": 0.3772,
      "step": 11458
    },
    {
      "epoch": 1.0723296888141296,
      "grad_norm": 1.330078125,
      "learning_rate": 7.631143224079681e-06,
      "loss": 0.2985,
      "step": 11475
    },
    {
      "epoch": 1.0739183253901505,
      "grad_norm": 1.9697265625,
      "learning_rate": 7.623693487402606e-06,
      "loss": 0.5358,
      "step": 11492
    },
    {
      "epoch": 1.0755069619661715,
      "grad_norm": 0.69970703125,
      "learning_rate": 7.616235704423418e-06,
      "loss": 0.4083,
      "step": 11509
    },
    {
      "epoch": 1.0770955985421924,
      "grad_norm": 1.22265625,
      "learning_rate": 7.6087698980135286e-06,
      "loss": 0.327,
      "step": 11526
    },
    {
      "epoch": 1.0786842351182133,
      "grad_norm": 1.9443359375,
      "learning_rate": 7.601296091068955e-06,
      "loss": 0.4458,
      "step": 11543
    },
    {
      "epoch": 1.0802728716942342,
      "grad_norm": 0.69482421875,
      "learning_rate": 7.593814306510254e-06,
      "loss": 0.3461,
      "step": 11560
    },
    {
      "epoch": 1.0818615082702552,
      "grad_norm": 1.693359375,
      "learning_rate": 7.586324567282445e-06,
      "loss": 0.2826,
      "step": 11577
    },
    {
      "epoch": 1.083450144846276,
      "grad_norm": 2.220703125,
      "learning_rate": 7.578826896354942e-06,
      "loss": 0.4753,
      "step": 11594
    },
    {
      "epoch": 1.085038781422297,
      "grad_norm": 0.9189453125,
      "learning_rate": 7.571321316721483e-06,
      "loss": 0.3364,
      "step": 11611
    },
    {
      "epoch": 1.086627417998318,
      "grad_norm": 1.1572265625,
      "learning_rate": 7.563807851400066e-06,
      "loss": 0.3201,
      "step": 11628
    },
    {
      "epoch": 1.088216054574339,
      "grad_norm": 2.248046875,
      "learning_rate": 7.5562865234328655e-06,
      "loss": 0.494,
      "step": 11645
    },
    {
      "epoch": 1.0898046911503598,
      "grad_norm": 0.82763671875,
      "learning_rate": 7.5487573558861735e-06,
      "loss": 0.3451,
      "step": 11662
    },
    {
      "epoch": 1.0913933277263808,
      "grad_norm": 1.599609375,
      "learning_rate": 7.541220371850324e-06,
      "loss": 0.3644,
      "step": 11679
    },
    {
      "epoch": 1.0929819643024017,
      "grad_norm": 1.8330078125,
      "learning_rate": 7.5336755944396225e-06,
      "loss": 0.5386,
      "step": 11696
    },
    {
      "epoch": 1.0945706008784226,
      "grad_norm": 0.83642578125,
      "learning_rate": 7.526123046792271e-06,
      "loss": 0.2857,
      "step": 11713
    },
    {
      "epoch": 1.0961592374544435,
      "grad_norm": 1.77734375,
      "learning_rate": 7.518562752070306e-06,
      "loss": 0.3344,
      "step": 11730
    },
    {
      "epoch": 1.0977478740304645,
      "grad_norm": 2.169921875,
      "learning_rate": 7.510994733459522e-06,
      "loss": 0.4948,
      "step": 11747
    },
    {
      "epoch": 1.0993365106064854,
      "grad_norm": 0.8671875,
      "learning_rate": 7.503419014169399e-06,
      "loss": 0.265,
      "step": 11764
    },
    {
      "epoch": 1.1009251471825063,
      "grad_norm": 1.4345703125,
      "learning_rate": 7.495835617433034e-06,
      "loss": 0.3476,
      "step": 11781
    },
    {
      "epoch": 1.1025137837585273,
      "grad_norm": 2.822265625,
      "learning_rate": 7.48824456650707e-06,
      "loss": 0.4714,
      "step": 11798
    },
    {
      "epoch": 1.1041024203345482,
      "grad_norm": 1.0888671875,
      "learning_rate": 7.4806458846716234e-06,
      "loss": 0.2834,
      "step": 11815
    },
    {
      "epoch": 1.1056910569105691,
      "grad_norm": 1.802734375,
      "learning_rate": 7.473039595230212e-06,
      "loss": 0.3939,
      "step": 11832
    },
    {
      "epoch": 1.10727969348659,
      "grad_norm": 2.61328125,
      "learning_rate": 7.465425721509686e-06,
      "loss": 0.5345,
      "step": 11849
    },
    {
      "epoch": 1.108868330062611,
      "grad_norm": 0.7802734375,
      "learning_rate": 7.457804286860153e-06,
      "loss": 0.2006,
      "step": 11866
    },
    {
      "epoch": 1.110456966638632,
      "grad_norm": 1.6953125,
      "learning_rate": 7.450175314654912e-06,
      "loss": 0.3586,
      "step": 11883
    },
    {
      "epoch": 1.1120456032146528,
      "grad_norm": 2.197265625,
      "learning_rate": 7.442538828290371e-06,
      "loss": 0.4907,
      "step": 11900
    },
    {
      "epoch": 1.1136342397906738,
      "grad_norm": 1.2666015625,
      "learning_rate": 7.43489485118599e-06,
      "loss": 0.2453,
      "step": 11917
    },
    {
      "epoch": 1.1152228763666947,
      "grad_norm": 1.318359375,
      "learning_rate": 7.427243406784198e-06,
      "loss": 0.3638,
      "step": 11934
    },
    {
      "epoch": 1.1168115129427156,
      "grad_norm": 2.912109375,
      "learning_rate": 7.419584518550325e-06,
      "loss": 0.535,
      "step": 11951
    },
    {
      "epoch": 1.1184001495187366,
      "grad_norm": 0.91845703125,
      "learning_rate": 7.411918209972528e-06,
      "loss": 0.2143,
      "step": 11968
    },
    {
      "epoch": 1.1199887860947575,
      "grad_norm": 1.634765625,
      "learning_rate": 7.404244504561725e-06,
      "loss": 0.3509,
      "step": 11985
    },
    {
      "epoch": 1.1215774226707784,
      "grad_norm": 0.1953125,
      "learning_rate": 7.396563425851514e-06,
      "loss": 0.5083,
      "step": 12002
    },
    {
      "epoch": 1.1231660592467994,
      "grad_norm": 1.025390625,
      "learning_rate": 7.388874997398107e-06,
      "loss": 0.2424,
      "step": 12019
    },
    {
      "epoch": 1.1247546958228203,
      "grad_norm": 1.56640625,
      "learning_rate": 7.381179242780255e-06,
      "loss": 0.4055,
      "step": 12036
    },
    {
      "epoch": 1.1263433323988412,
      "grad_norm": 0.27587890625,
      "learning_rate": 7.3734761855991785e-06,
      "loss": 0.4897,
      "step": 12053
    },
    {
      "epoch": 1.1279319689748621,
      "grad_norm": 0.85302734375,
      "learning_rate": 7.365765849478492e-06,
      "loss": 0.1958,
      "step": 12070
    },
    {
      "epoch": 1.129520605550883,
      "grad_norm": 1.5869140625,
      "learning_rate": 7.3580482580641365e-06,
      "loss": 0.4108,
      "step": 12087
    },
    {
      "epoch": 1.131109242126904,
      "grad_norm": 0.32666015625,
      "learning_rate": 7.350323435024298e-06,
      "loss": 0.4951,
      "step": 12104
    },
    {
      "epoch": 1.132697878702925,
      "grad_norm": 1.1943359375,
      "learning_rate": 7.342591404049343e-06,
      "loss": 0.24,
      "step": 12121
    },
    {
      "epoch": 1.1342865152789459,
      "grad_norm": 2.279296875,
      "learning_rate": 7.334852188851743e-06,
      "loss": 0.4216,
      "step": 12138
    },
    {
      "epoch": 1.1358751518549668,
      "grad_norm": 0.26171875,
      "learning_rate": 7.3271058131660036e-06,
      "loss": 0.4272,
      "step": 12155
    },
    {
      "epoch": 1.1374637884309877,
      "grad_norm": 1.5859375,
      "learning_rate": 7.319352300748588e-06,
      "loss": 0.2654,
      "step": 12172
    },
    {
      "epoch": 1.1390524250070087,
      "grad_norm": 2.1171875,
      "learning_rate": 7.3115916753778444e-06,
      "loss": 0.4304,
      "step": 12189
    },
    {
      "epoch": 1.1406410615830296,
      "grad_norm": 0.751953125,
      "learning_rate": 7.303823960853939e-06,
      "loss": 0.4446,
      "step": 12206
    },
    {
      "epoch": 1.1422296981590505,
      "grad_norm": 1.18359375,
      "learning_rate": 7.296049180998777e-06,
      "loss": 0.2652,
      "step": 12223
    },
    {
      "epoch": 1.1438183347350714,
      "grad_norm": 1.7744140625,
      "learning_rate": 7.288267359655931e-06,
      "loss": 0.3833,
      "step": 12240
    },
    {
      "epoch": 1.1454069713110924,
      "grad_norm": 0.556640625,
      "learning_rate": 7.280478520690571e-06,
      "loss": 0.3797,
      "step": 12257
    },
    {
      "epoch": 1.1469956078871133,
      "grad_norm": 1.154296875,
      "learning_rate": 7.272682687989383e-06,
      "loss": 0.2619,
      "step": 12274
    },
    {
      "epoch": 1.1485842444631342,
      "grad_norm": 1.6923828125,
      "learning_rate": 7.264879885460506e-06,
      "loss": 0.4565,
      "step": 12291
    },
    {
      "epoch": 1.1501728810391552,
      "grad_norm": 0.6904296875,
      "learning_rate": 7.257070137033455e-06,
      "loss": 0.4118,
      "step": 12308
    },
    {
      "epoch": 1.151761517615176,
      "grad_norm": 1.541015625,
      "learning_rate": 7.249253466659042e-06,
      "loss": 0.3148,
      "step": 12325
    },
    {
      "epoch": 1.153350154191197,
      "grad_norm": 1.6904296875,
      "learning_rate": 7.241429898309309e-06,
      "loss": 0.4355,
      "step": 12342
    },
    {
      "epoch": 1.154938790767218,
      "grad_norm": 0.765625,
      "learning_rate": 7.233599455977454e-06,
      "loss": 0.3971,
      "step": 12359
    },
    {
      "epoch": 1.1565274273432389,
      "grad_norm": 1.4931640625,
      "learning_rate": 7.225762163677754e-06,
      "loss": 0.2935,
      "step": 12376
    },
    {
      "epoch": 1.1581160639192598,
      "grad_norm": 1.8916015625,
      "learning_rate": 7.2179180454454945e-06,
      "loss": 0.4941,
      "step": 12393
    },
    {
      "epoch": 1.1597047004952807,
      "grad_norm": 0.82373046875,
      "learning_rate": 7.2100671253368945e-06,
      "loss": 0.3138,
      "step": 12410
    },
    {
      "epoch": 1.1612933370713017,
      "grad_norm": 1.486328125,
      "learning_rate": 7.202209427429035e-06,
      "loss": 0.298,
      "step": 12427
    },
    {
      "epoch": 1.1628819736473226,
      "grad_norm": 1.7890625,
      "learning_rate": 7.194344975819777e-06,
      "loss": 0.4171,
      "step": 12444
    },
    {
      "epoch": 1.1644706102233435,
      "grad_norm": 0.763671875,
      "learning_rate": 7.1864737946277015e-06,
      "loss": 0.3061,
      "step": 12461
    },
    {
      "epoch": 1.1660592467993645,
      "grad_norm": 1.4736328125,
      "learning_rate": 7.178595907992021e-06,
      "loss": 0.3356,
      "step": 12478
    },
    {
      "epoch": 1.1676478833753854,
      "grad_norm": 2.349609375,
      "learning_rate": 7.170711340072517e-06,
      "loss": 0.4678,
      "step": 12495
    },
    {
      "epoch": 1.1692365199514063,
      "grad_norm": 1.0888671875,
      "learning_rate": 7.162820115049457e-06,
      "loss": 0.3107,
      "step": 12512
    },
    {
      "epoch": 1.1708251565274272,
      "grad_norm": 1.474609375,
      "learning_rate": 7.1549222571235275e-06,
      "loss": 0.3037,
      "step": 12529
    },
    {
      "epoch": 1.1724137931034484,
      "grad_norm": 2.255859375,
      "learning_rate": 7.147017790515755e-06,
      "loss": 0.486,
      "step": 12546
    },
    {
      "epoch": 1.174002429679469,
      "grad_norm": 0.86474609375,
      "learning_rate": 7.139106739467434e-06,
      "loss": 0.2866,
      "step": 12563
    },
    {
      "epoch": 1.1755910662554903,
      "grad_norm": 1.68359375,
      "learning_rate": 7.131189128240052e-06,
      "loss": 0.3379,
      "step": 12580
    },
    {
      "epoch": 1.177179702831511,
      "grad_norm": 2.1953125,
      "learning_rate": 7.123264981115217e-06,
      "loss": 0.4976,
      "step": 12597
    },
    {
      "epoch": 1.1787683394075321,
      "grad_norm": 0.87255859375,
      "learning_rate": 7.115334322394576e-06,
      "loss": 0.2788,
      "step": 12614
    },
    {
      "epoch": 1.1803569759835528,
      "grad_norm": 1.265625,
      "learning_rate": 7.107397176399751e-06,
      "loss": 0.3375,
      "step": 12631
    },
    {
      "epoch": 1.181945612559574,
      "grad_norm": 2.478515625,
      "learning_rate": 7.0994535674722575e-06,
      "loss": 0.5168,
      "step": 12648
    },
    {
      "epoch": 1.1835342491355947,
      "grad_norm": 0.9921875,
      "learning_rate": 7.091503519973428e-06,
      "loss": 0.2396,
      "step": 12665
    },
    {
      "epoch": 1.1851228857116158,
      "grad_norm": 1.578125,
      "learning_rate": 7.083547058284349e-06,
      "loss": 0.4086,
      "step": 12682
    },
    {
      "epoch": 1.1867115222876368,
      "grad_norm": 2.16796875,
      "learning_rate": 7.075584206805768e-06,
      "loss": 0.5858,
      "step": 12699
    },
    {
      "epoch": 1.1883001588636577,
      "grad_norm": 0.96044921875,
      "learning_rate": 7.067614989958036e-06,
      "loss": 0.2382,
      "step": 12716
    },
    {
      "epoch": 1.1898887954396786,
      "grad_norm": 1.8857421875,
      "learning_rate": 7.05963943218102e-06,
      "loss": 0.3839,
      "step": 12733
    },
    {
      "epoch": 1.1914774320156996,
      "grad_norm": 3.056640625,
      "learning_rate": 7.05165755793404e-06,
      "loss": 0.5271,
      "step": 12750
    },
    {
      "epoch": 1.1930660685917205,
      "grad_norm": 0.78369140625,
      "learning_rate": 7.043669391695778e-06,
      "loss": 0.1857,
      "step": 12767
    },
    {
      "epoch": 1.1946547051677414,
      "grad_norm": 1.91796875,
      "learning_rate": 7.035674957964218e-06,
      "loss": 0.379,
      "step": 12784
    },
    {
      "epoch": 1.1962433417437623,
      "grad_norm": 3.716796875,
      "learning_rate": 7.027674281256568e-06,
      "loss": 0.5485,
      "step": 12801
    },
    {
      "epoch": 1.1978319783197833,
      "grad_norm": 1.1279296875,
      "learning_rate": 7.019667386109173e-06,
      "loss": 0.188,
      "step": 12818
    },
    {
      "epoch": 1.1994206148958042,
      "grad_norm": 1.658203125,
      "learning_rate": 7.011654297077459e-06,
      "loss": 0.3974,
      "step": 12835
    },
    {
      "epoch": 1.2000747593682832,
      "eval_loss": 0.3795914947986603,
      "eval_runtime": 1038.76,
      "eval_samples_per_second": 7.726,
      "eval_steps_per_second": 2.575,
      "step": 12842
    },
    {
      "epoch": 1.2010092514718251,
      "grad_norm": 0.3876953125,
      "learning_rate": 7.0036350387358374e-06,
      "loss": 0.5274,
      "step": 12852
    },
    {
      "epoch": 1.202597888047846,
      "grad_norm": 0.99462890625,
      "learning_rate": 6.9956096356776474e-06,
      "loss": 0.2221,
      "step": 12869
    },
    {
      "epoch": 1.204186524623867,
      "grad_norm": 1.5673828125,
      "learning_rate": 6.987578112515066e-06,
      "loss": 0.3991,
      "step": 12886
    },
    {
      "epoch": 1.205775161199888,
      "grad_norm": 0.56005859375,
      "learning_rate": 6.979540493879047e-06,
      "loss": 0.5019,
      "step": 12903
    },
    {
      "epoch": 1.2073637977759089,
      "grad_norm": 1.181640625,
      "learning_rate": 6.971496804419231e-06,
      "loss": 0.2578,
      "step": 12920
    },
    {
      "epoch": 1.2089524343519298,
      "grad_norm": 2.013671875,
      "learning_rate": 6.963447068803877e-06,
      "loss": 0.4037,
      "step": 12937
    },
    {
      "epoch": 1.2105410709279507,
      "grad_norm": 0.371826171875,
      "learning_rate": 6.955391311719792e-06,
      "loss": 0.5013,
      "step": 12954
    },
    {
      "epoch": 1.2121297075039716,
      "grad_norm": 1.1318359375,
      "learning_rate": 6.947329557872243e-06,
      "loss": 0.2541,
      "step": 12971
    },
    {
      "epoch": 1.2137183440799926,
      "grad_norm": 1.8056640625,
      "learning_rate": 6.9392618319848926e-06,
      "loss": 0.4242,
      "step": 12988
    },
    {
      "epoch": 1.2153069806560135,
      "grad_norm": 0.68408203125,
      "learning_rate": 6.9311881587997146e-06,
      "loss": 0.4894,
      "step": 13005
    },
    {
      "epoch": 1.2168956172320344,
      "grad_norm": 1.271484375,
      "learning_rate": 6.923108563076924e-06,
      "loss": 0.2698,
      "step": 13022
    },
    {
      "epoch": 1.2184842538080554,
      "grad_norm": 1.626953125,
      "learning_rate": 6.915023069594897e-06,
      "loss": 0.455,
      "step": 13039
    },
    {
      "epoch": 1.2200728903840763,
      "grad_norm": 0.7734375,
      "learning_rate": 6.906931703150101e-06,
      "loss": 0.4212,
      "step": 13056
    },
    {
      "epoch": 1.2216615269600972,
      "grad_norm": 1.4501953125,
      "learning_rate": 6.898834488557013e-06,
      "loss": 0.2509,
      "step": 13073
    },
    {
      "epoch": 1.2232501635361182,
      "grad_norm": 1.734375,
      "learning_rate": 6.890731450648041e-06,
      "loss": 0.3582,
      "step": 13090
    },
    {
      "epoch": 1.224838800112139,
      "grad_norm": 0.6435546875,
      "learning_rate": 6.882622614273453e-06,
      "loss": 0.381,
      "step": 13107
    },
    {
      "epoch": 1.22642743668816,
      "grad_norm": 1.1279296875,
      "learning_rate": 6.8745080043013055e-06,
      "loss": 0.2658,
      "step": 13124
    },
    {
      "epoch": 1.228016073264181,
      "grad_norm": 1.7255859375,
      "learning_rate": 6.8663876456173566e-06,
      "loss": 0.4445,
      "step": 13141
    },
    {
      "epoch": 1.2296047098402019,
      "grad_norm": 0.673828125,
      "learning_rate": 6.858261563124993e-06,
      "loss": 0.4028,
      "step": 13158
    },
    {
      "epoch": 1.2311933464162228,
      "grad_norm": 1.2802734375,
      "learning_rate": 6.8501297817451605e-06,
      "loss": 0.2751,
      "step": 13175
    },
    {
      "epoch": 1.2327819829922437,
      "grad_norm": 2.01953125,
      "learning_rate": 6.841992326416275e-06,
      "loss": 0.4528,
      "step": 13192
    },
    {
      "epoch": 1.2343706195682647,
      "grad_norm": 1.359375,
      "learning_rate": 6.833849222094162e-06,
      "loss": 0.378,
      "step": 13209
    },
    {
      "epoch": 1.2359592561442856,
      "grad_norm": 1.4921875,
      "learning_rate": 6.825700493751963e-06,
      "loss": 0.2893,
      "step": 13226
    },
    {
      "epoch": 1.2375478927203065,
      "grad_norm": 2.029296875,
      "learning_rate": 6.817546166380072e-06,
      "loss": 0.4539,
      "step": 13243
    },
    {
      "epoch": 1.2391365292963274,
      "grad_norm": 0.77197265625,
      "learning_rate": 6.8093862649860485e-06,
      "loss": 0.3487,
      "step": 13260
    },
    {
      "epoch": 1.2407251658723484,
      "grad_norm": 1.5341796875,
      "learning_rate": 6.801220814594556e-06,
      "loss": 0.3286,
      "step": 13277
    },
    {
      "epoch": 1.2423138024483693,
      "grad_norm": 2.20703125,
      "learning_rate": 6.793049840247266e-06,
      "loss": 0.4547,
      "step": 13294
    },
    {
      "epoch": 1.2439024390243902,
      "grad_norm": 0.740234375,
      "learning_rate": 6.784873367002797e-06,
      "loss": 0.3541,
      "step": 13311
    },
    {
      "epoch": 1.2454910756004112,
      "grad_norm": 1.4375,
      "learning_rate": 6.77669141993663e-06,
      "loss": 0.2878,
      "step": 13328
    },
    {
      "epoch": 1.247079712176432,
      "grad_norm": 2.083984375,
      "learning_rate": 6.768504024141028e-06,
      "loss": 0.5297,
      "step": 13345
    },
    {
      "epoch": 1.248668348752453,
      "grad_norm": 0.73388671875,
      "learning_rate": 6.760311204724972e-06,
      "loss": 0.3146,
      "step": 13362
    },
    {
      "epoch": 1.250256985328474,
      "grad_norm": 1.25,
      "learning_rate": 6.752112986814071e-06,
      "loss": 0.2836,
      "step": 13379
    },
    {
      "epoch": 1.2518456219044949,
      "grad_norm": 2.337890625,
      "learning_rate": 6.743909395550492e-06,
      "loss": 0.4845,
      "step": 13396
    },
    {
      "epoch": 1.2534342584805158,
      "grad_norm": 0.7998046875,
      "learning_rate": 6.7357004560928785e-06,
      "loss": 0.3223,
      "step": 13413
    },
    {
      "epoch": 1.2550228950565367,
      "grad_norm": 1.37109375,
      "learning_rate": 6.72748619361628e-06,
      "loss": 0.3468,
      "step": 13430
    },
    {
      "epoch": 1.2566115316325577,
      "grad_norm": 2.458984375,
      "learning_rate": 6.7192666333120645e-06,
      "loss": 0.4935,
      "step": 13447
    },
    {
      "epoch": 1.2582001682085786,
      "grad_norm": 0.85400390625,
      "learning_rate": 6.711041800387855e-06,
      "loss": 0.2711,
      "step": 13464
    },
    {
      "epoch": 1.2597888047845995,
      "grad_norm": 1.5322265625,
      "learning_rate": 6.702811720067439e-06,
      "loss": 0.344,
      "step": 13481
    },
    {
      "epoch": 1.2613774413606205,
      "grad_norm": 2.20703125,
      "learning_rate": 6.694576417590696e-06,
      "loss": 0.5246,
      "step": 13498
    },
    {
      "epoch": 1.2629660779366414,
      "grad_norm": 0.98779296875,
      "learning_rate": 6.686335918213524e-06,
      "loss": 0.2756,
      "step": 13515
    },
    {
      "epoch": 1.2645547145126623,
      "grad_norm": 1.9072265625,
      "learning_rate": 6.678090247207761e-06,
      "loss": 0.383,
      "step": 13532
    },
    {
      "epoch": 1.2661433510886833,
      "grad_norm": 2.6015625,
      "learning_rate": 6.669839429861096e-06,
      "loss": 0.5081,
      "step": 13549
    },
    {
      "epoch": 1.2677319876647042,
      "grad_norm": 1.142578125,
      "learning_rate": 6.6615834914770085e-06,
      "loss": 0.2559,
      "step": 13566
    },
    {
      "epoch": 1.2693206242407251,
      "grad_norm": 1.6943359375,
      "learning_rate": 6.653322457374682e-06,
      "loss": 0.3575,
      "step": 13583
    },
    {
      "epoch": 1.270909260816746,
      "grad_norm": 3.048828125,
      "learning_rate": 6.645056352888926e-06,
      "loss": 0.5099,
      "step": 13600
    },
    {
      "epoch": 1.272497897392767,
      "grad_norm": 0.96728515625,
      "learning_rate": 6.6367852033700995e-06,
      "loss": 0.2207,
      "step": 13617
    },
    {
      "epoch": 1.274086533968788,
      "grad_norm": 1.6015625,
      "learning_rate": 6.628509034184036e-06,
      "loss": 0.41,
      "step": 13634
    },
    {
      "epoch": 1.2756751705448088,
      "grad_norm": 2.892578125,
      "learning_rate": 6.620227870711962e-06,
      "loss": 0.5572,
      "step": 13651
    },
    {
      "epoch": 1.2772638071208298,
      "grad_norm": 1.1025390625,
      "learning_rate": 6.611941738350417e-06,
      "loss": 0.2306,
      "step": 13668
    },
    {
      "epoch": 1.2788524436968507,
      "grad_norm": 1.99609375,
      "learning_rate": 6.603650662511185e-06,
      "loss": 0.3919,
      "step": 13685
    },
    {
      "epoch": 1.2804410802728716,
      "grad_norm": 0.301025390625,
      "learning_rate": 6.595354668621207e-06,
      "loss": 0.4825,
      "step": 13702
    },
    {
      "epoch": 1.2820297168488926,
      "grad_norm": 1.1357421875,
      "learning_rate": 6.587053782122504e-06,
      "loss": 0.2365,
      "step": 13719
    },
    {
      "epoch": 1.2836183534249135,
      "grad_norm": 1.6669921875,
      "learning_rate": 6.57874802847211e-06,
      "loss": 0.3961,
      "step": 13736
    },
    {
      "epoch": 1.2852069900009344,
      "grad_norm": 0.37646484375,
      "learning_rate": 6.570437433141977e-06,
      "loss": 0.4984,
      "step": 13753
    },
    {
      "epoch": 1.2867956265769553,
      "grad_norm": 1.2783203125,
      "learning_rate": 6.562122021618909e-06,
      "loss": 0.2459,
      "step": 13770
    },
    {
      "epoch": 1.2883842631529765,
      "grad_norm": 2.029296875,
      "learning_rate": 6.553801819404479e-06,
      "loss": 0.4271,
      "step": 13787
    },
    {
      "epoch": 1.2899728997289972,
      "grad_norm": 0.75048828125,
      "learning_rate": 6.545476852014956e-06,
      "loss": 0.4857,
      "step": 13804
    },
    {
      "epoch": 1.2915615363050184,
      "grad_norm": 1.345703125,
      "learning_rate": 6.537147144981218e-06,
      "loss": 0.2486,
      "step": 13821
    },
    {
      "epoch": 1.293150172881039,
      "grad_norm": 2.294921875,
      "learning_rate": 6.528812723848678e-06,
      "loss": 0.4263,
      "step": 13838
    },
    {
      "epoch": 1.2947388094570602,
      "grad_norm": 0.54931640625,
      "learning_rate": 6.520473614177212e-06,
      "loss": 0.4839,
      "step": 13855
    },
    {
      "epoch": 1.296327446033081,
      "grad_norm": 1.333984375,
      "learning_rate": 6.512129841541067e-06,
      "loss": 0.3074,
      "step": 13872
    },
    {
      "epoch": 1.297916082609102,
      "grad_norm": 1.908203125,
      "learning_rate": 6.503781431528798e-06,
      "loss": 0.4178,
      "step": 13889
    },
    {
      "epoch": 1.2995047191851228,
      "grad_norm": 0.693359375,
      "learning_rate": 6.495428409743176e-06,
      "loss": 0.4279,
      "step": 13906
    },
    {
      "epoch": 1.301093355761144,
      "grad_norm": 0.99365234375,
      "learning_rate": 6.487070801801118e-06,
      "loss": 0.2228,
      "step": 13923
    },
    {
      "epoch": 1.3026819923371646,
      "grad_norm": 1.9697265625,
      "learning_rate": 6.478708633333605e-06,
      "loss": 0.4495,
      "step": 13940
    },
    {
      "epoch": 1.3042706289131858,
      "grad_norm": 0.5693359375,
      "learning_rate": 6.4703419299856055e-06,
      "loss": 0.3705,
      "step": 13957
    },
    {
      "epoch": 1.3058592654892065,
      "grad_norm": 1.10546875,
      "learning_rate": 6.461970717415993e-06,
      "loss": 0.2536,
      "step": 13974
    },
    {
      "epoch": 1.3074479020652277,
      "grad_norm": 2.14453125,
      "learning_rate": 6.45359502129747e-06,
      "loss": 0.4457,
      "step": 13991
    },
    {
      "epoch": 1.3090365386412484,
      "grad_norm": 0.705078125,
      "learning_rate": 6.445214867316495e-06,
      "loss": 0.4011,
      "step": 14008
    },
    {
      "epoch": 1.3106251752172695,
      "grad_norm": 2.06640625,
      "learning_rate": 6.436830281173188e-06,
      "loss": 0.2763,
      "step": 14025
    },
    {
      "epoch": 1.3122138117932902,
      "grad_norm": 2.109375,
      "learning_rate": 6.428441288581268e-06,
      "loss": 0.4674,
      "step": 14042
    },
    {
      "epoch": 1.3138024483693114,
      "grad_norm": 0.7265625,
      "learning_rate": 6.420047915267966e-06,
      "loss": 0.3664,
      "step": 14059
    },
    {
      "epoch": 1.315391084945332,
      "grad_norm": 1.033203125,
      "learning_rate": 6.411650186973949e-06,
      "loss": 0.276,
      "step": 14076
    },
    {
      "epoch": 1.3169797215213532,
      "grad_norm": 2.201171875,
      "learning_rate": 6.4032481294532375e-06,
      "loss": 0.4681,
      "step": 14093
    },
    {
      "epoch": 1.3185683580973742,
      "grad_norm": 0.69580078125,
      "learning_rate": 6.394841768473132e-06,
      "loss": 0.3287,
      "step": 14110
    },
    {
      "epoch": 1.320156994673395,
      "grad_norm": 1.529296875,
      "learning_rate": 6.386431129814127e-06,
      "loss": 0.2696,
      "step": 14127
    },
    {
      "epoch": 1.321745631249416,
      "grad_norm": 2.462890625,
      "learning_rate": 6.378016239269837e-06,
      "loss": 0.4664,
      "step": 14144
    },
    {
      "epoch": 1.323334267825437,
      "grad_norm": 0.74951171875,
      "learning_rate": 6.3695971226469175e-06,
      "loss": 0.3279,
      "step": 14161
    },
    {
      "epoch": 1.3249229044014579,
      "grad_norm": 1.46875,
      "learning_rate": 6.361173805764982e-06,
      "loss": 0.2847,
      "step": 14178
    },
    {
      "epoch": 1.3265115409774788,
      "grad_norm": 1.794921875,
      "learning_rate": 6.352746314456531e-06,
      "loss": 0.4675,
      "step": 14195
    },
    {
      "epoch": 1.3281001775534997,
      "grad_norm": 0.84326171875,
      "learning_rate": 6.344314674566858e-06,
      "loss": 0.3128,
      "step": 14212
    },
    {
      "epoch": 1.3296888141295207,
      "grad_norm": 1.91015625,
      "learning_rate": 6.335878911953988e-06,
      "loss": 0.3677,
      "step": 14229
    },
    {
      "epoch": 1.3312774507055416,
      "grad_norm": 2.060546875,
      "learning_rate": 6.327439052488582e-06,
      "loss": 0.4926,
      "step": 14246
    },
    {
      "epoch": 1.3328660872815625,
      "grad_norm": 0.9580078125,
      "learning_rate": 6.318995122053873e-06,
      "loss": 0.289,
      "step": 14263
    },
    {
      "epoch": 1.3344547238575835,
      "grad_norm": 1.7783203125,
      "learning_rate": 6.310547146545571e-06,
      "loss": 0.3204,
      "step": 14280
    },
    {
      "epoch": 1.3360433604336044,
      "grad_norm": 2.275390625,
      "learning_rate": 6.302095151871798e-06,
      "loss": 0.5622,
      "step": 14297
    },
    {
      "epoch": 1.3376319970096253,
      "grad_norm": 1.029296875,
      "learning_rate": 6.293639163952996e-06,
      "loss": 0.2684,
      "step": 14314
    },
    {
      "epoch": 1.3392206335856462,
      "grad_norm": 1.7470703125,
      "learning_rate": 6.285179208721859e-06,
      "loss": 0.3178,
      "step": 14331
    },
    {
      "epoch": 1.3408092701616672,
      "grad_norm": 2.453125,
      "learning_rate": 6.276715312123244e-06,
      "loss": 0.5155,
      "step": 14348
    },
    {
      "epoch": 1.342397906737688,
      "grad_norm": 0.71435546875,
      "learning_rate": 6.2682475001140965e-06,
      "loss": 0.2613,
      "step": 14365
    },
    {
      "epoch": 1.343986543313709,
      "grad_norm": 1.611328125,
      "learning_rate": 6.25977579866337e-06,
      "loss": 0.3473,
      "step": 14382
    },
    {
      "epoch": 1.34557517988973,
      "grad_norm": 3.1796875,
      "learning_rate": 6.251300233751947e-06,
      "loss": 0.48,
      "step": 14399
    },
    {
      "epoch": 1.347163816465751,
      "grad_norm": 1.0654296875,
      "learning_rate": 6.242820831372556e-06,
      "loss": 0.2246,
      "step": 14416
    },
    {
      "epoch": 1.3487524530417718,
      "grad_norm": 1.462890625,
      "learning_rate": 6.234337617529696e-06,
      "loss": 0.3645,
      "step": 14433
    },
    {
      "epoch": 1.3503410896177928,
      "grad_norm": 2.978515625,
      "learning_rate": 6.225850618239554e-06,
      "loss": 0.528,
      "step": 14450
    },
    {
      "epoch": 1.3519297261938137,
      "grad_norm": 1.1171875,
      "learning_rate": 6.217359859529926e-06,
      "loss": 0.2103,
      "step": 14467
    },
    {
      "epoch": 1.3535183627698346,
      "grad_norm": 1.2607421875,
      "learning_rate": 6.208865367440139e-06,
      "loss": 0.4161,
      "step": 14484
    },
    {
      "epoch": 1.3551069993458555,
      "grad_norm": 2.921875,
      "learning_rate": 6.200367168020968e-06,
      "loss": 0.5296,
      "step": 14501
    },
    {
      "epoch": 1.3566956359218765,
      "grad_norm": 0.90673828125,
      "learning_rate": 6.191865287334558e-06,
      "loss": 0.1648,
      "step": 14518
    },
    {
      "epoch": 1.3582842724978974,
      "grad_norm": 2.060546875,
      "learning_rate": 6.183359751454343e-06,
      "loss": 0.3659,
      "step": 14535
    },
    {
      "epoch": 1.3598729090739183,
      "grad_norm": 0.457763671875,
      "learning_rate": 6.174850586464968e-06,
      "loss": 0.5812,
      "step": 14552
    },
    {
      "epoch": 1.3614615456499393,
      "grad_norm": 0.904296875,
      "learning_rate": 6.166337818462207e-06,
      "loss": 0.1595,
      "step": 14569
    },
    {
      "epoch": 1.3630501822259602,
      "grad_norm": 1.802734375,
      "learning_rate": 6.157821473552884e-06,
      "loss": 0.3823,
      "step": 14586
    },
    {
      "epoch": 1.3646388188019811,
      "grad_norm": 0.1177978515625,
      "learning_rate": 6.149301577854792e-06,
      "loss": 0.4866,
      "step": 14603
    },
    {
      "epoch": 1.366227455378002,
      "grad_norm": 1.244140625,
      "learning_rate": 6.140778157496612e-06,
      "loss": 0.2177,
      "step": 14620
    },
    {
      "epoch": 1.367816091954023,
      "grad_norm": 2.396484375,
      "learning_rate": 6.132251238617838e-06,
      "loss": 0.4241,
      "step": 14637
    },
    {
      "epoch": 1.369404728530044,
      "grad_norm": 0.229248046875,
      "learning_rate": 6.123720847368691e-06,
      "loss": 0.506,
      "step": 14654
    },
    {
      "epoch": 1.3709933651060648,
      "grad_norm": 1.3544921875,
      "learning_rate": 6.11518700991004e-06,
      "loss": 0.2616,
      "step": 14671
    },
    {
      "epoch": 1.3725820016820858,
      "grad_norm": 1.791015625,
      "learning_rate": 6.106649752413326e-06,
      "loss": 0.3821,
      "step": 14688
    },
    {
      "epoch": 1.3741706382581067,
      "grad_norm": 0.6923828125,
      "learning_rate": 6.0981091010604764e-06,
      "loss": 0.481,
      "step": 14705
    },
    {
      "epoch": 1.3757592748341276,
      "grad_norm": 1.2138671875,
      "learning_rate": 6.089565082043827e-06,
      "loss": 0.2808,
      "step": 14722
    },
    {
      "epoch": 1.3773479114101486,
      "grad_norm": 1.8466796875,
      "learning_rate": 6.08101772156604e-06,
      "loss": 0.4308,
      "step": 14739
    },
    {
      "epoch": 1.3789365479861695,
      "grad_norm": 0.470703125,
      "learning_rate": 6.072467045840029e-06,
      "loss": 0.4504,
      "step": 14756
    },
    {
      "epoch": 1.3805251845621904,
      "grad_norm": 1.4443359375,
      "learning_rate": 6.0639130810888715e-06,
      "loss": 0.2486,
      "step": 14773
    },
    {
      "epoch": 1.3821138211382114,
      "grad_norm": 2.193359375,
      "learning_rate": 6.055355853545733e-06,
      "loss": 0.4612,
      "step": 14790
    },
    {
      "epoch": 1.3837024577142323,
      "grad_norm": 0.625,
      "learning_rate": 6.046795389453781e-06,
      "loss": 0.441,
      "step": 14807
    },
    {
      "epoch": 1.3852910942902532,
      "grad_norm": 1.5810546875,
      "learning_rate": 6.038231715066119e-06,
      "loss": 0.2764,
      "step": 14824
    },
    {
      "epoch": 1.3868797308662741,
      "grad_norm": 2.041015625,
      "learning_rate": 6.029664856645687e-06,
      "loss": 0.4507,
      "step": 14841
    },
    {
      "epoch": 1.388468367442295,
      "grad_norm": 0.8662109375,
      "learning_rate": 6.021094840465191e-06,
      "loss": 0.4188,
      "step": 14858
    },
    {
      "epoch": 1.390057004018316,
      "grad_norm": 1.3876953125,
      "learning_rate": 6.012521692807025e-06,
      "loss": 0.3199,
      "step": 14875
    },
    {
      "epoch": 1.391645640594337,
      "grad_norm": 2.04296875,
      "learning_rate": 6.003945439963181e-06,
      "loss": 0.4747,
      "step": 14892
    },
    {
      "epoch": 1.3932342771703579,
      "grad_norm": 0.826171875,
      "learning_rate": 5.99536610823518e-06,
      "loss": 0.353,
      "step": 14909
    },
    {
      "epoch": 1.3948229137463788,
      "grad_norm": 1.2724609375,
      "learning_rate": 5.9867837239339795e-06,
      "loss": 0.3237,
      "step": 14926
    },
    {
      "epoch": 1.3964115503223997,
      "grad_norm": 2.369140625,
      "learning_rate": 5.9781983133799035e-06,
      "loss": 0.4762,
      "step": 14943
    },
    {
      "epoch": 1.3980001868984206,
      "grad_norm": 0.6103515625,
      "learning_rate": 5.969609902902553e-06,
      "loss": 0.3515,
      "step": 14960
    },
    {
      "epoch": 1.3995888234744416,
      "grad_norm": 1.5712890625,
      "learning_rate": 5.9610185188407325e-06,
      "loss": 0.338,
      "step": 14977
    },
    {
      "epoch": 1.4011774600504625,
      "grad_norm": 2.37109375,
      "learning_rate": 5.952424187542362e-06,
      "loss": 0.4391,
      "step": 14994
    },
    {
      "epoch": 1.4027660966264834,
      "grad_norm": 0.72265625,
      "learning_rate": 5.943826935364404e-06,
      "loss": 0.3283,
      "step": 15011
    },
    {
      "epoch": 1.4043547332025044,
      "grad_norm": 2.115234375,
      "learning_rate": 5.935226788672777e-06,
      "loss": 0.3072,
      "step": 15028
    },
    {
      "epoch": 1.4059433697785253,
      "grad_norm": 2.341796875,
      "learning_rate": 5.926623773842274e-06,
      "loss": 0.5041,
      "step": 15045
    },
    {
      "epoch": 1.4075320063545462,
      "grad_norm": 0.8828125,
      "learning_rate": 5.918017917256489e-06,
      "loss": 0.2725,
      "step": 15062
    },
    {
      "epoch": 1.4091206429305672,
      "grad_norm": 1.5478515625,
      "learning_rate": 5.9094092453077255e-06,
      "loss": 0.3567,
      "step": 15079
    },
    {
      "epoch": 1.410709279506588,
      "grad_norm": 2.296875,
      "learning_rate": 5.900797784396926e-06,
      "loss": 0.5107,
      "step": 15096
    },
    {
      "epoch": 1.412297916082609,
      "grad_norm": 0.77392578125,
      "learning_rate": 5.892183560933583e-06,
      "loss": 0.2742,
      "step": 15113
    },
    {
      "epoch": 1.4138865526586302,
      "grad_norm": 1.3857421875,
      "learning_rate": 5.883566601335664e-06,
      "loss": 0.3273,
      "step": 15130
    },
    {
      "epoch": 1.4154751892346509,
      "grad_norm": 2.349609375,
      "learning_rate": 5.874946932029522e-06,
      "loss": 0.5161,
      "step": 15147
    },
    {
      "epoch": 1.417063825810672,
      "grad_norm": 0.85205078125,
      "learning_rate": 5.866324579449829e-06,
      "loss": 0.2592,
      "step": 15164
    },
    {
      "epoch": 1.4186524623866927,
      "grad_norm": 1.5478515625,
      "learning_rate": 5.857699570039477e-06,
      "loss": 0.3146,
      "step": 15181
    },
    {
      "epoch": 1.4202410989627139,
      "grad_norm": 2.353515625,
      "learning_rate": 5.8490719302495106e-06,
      "loss": 0.4906,
      "step": 15198
    },
    {
      "epoch": 1.4218297355387346,
      "grad_norm": 0.880859375,
      "learning_rate": 5.8404416865390414e-06,
      "loss": 0.3252,
      "step": 15215
    },
    {
      "epoch": 1.4234183721147557,
      "grad_norm": 1.880859375,
      "learning_rate": 5.831808865375164e-06,
      "loss": 0.4085,
      "step": 15232
    },
    {
      "epoch": 1.4250070086907765,
      "grad_norm": 2.556640625,
      "learning_rate": 5.8231734932328806e-06,
      "loss": 0.5274,
      "step": 15249
    },
    {
      "epoch": 1.4265956452667976,
      "grad_norm": 1.1748046875,
      "learning_rate": 5.814535596595014e-06,
      "loss": 0.2379,
      "step": 15266
    },
    {
      "epoch": 1.4281842818428183,
      "grad_norm": 1.7275390625,
      "learning_rate": 5.805895201952133e-06,
      "loss": 0.3429,
      "step": 15283
    },
    {
      "epoch": 1.4297729184188395,
      "grad_norm": 2.76953125,
      "learning_rate": 5.797252335802462e-06,
      "loss": 0.5217,
      "step": 15300
    },
    {
      "epoch": 1.4313615549948602,
      "grad_norm": 0.87841796875,
      "learning_rate": 5.788607024651809e-06,
      "loss": 0.2199,
      "step": 15317
    },
    {
      "epoch": 1.4329501915708813,
      "grad_norm": 2.58984375,
      "learning_rate": 5.77995929501348e-06,
      "loss": 0.3381,
      "step": 15334
    },
    {
      "epoch": 1.434538828146902,
      "grad_norm": 2.736328125,
      "learning_rate": 5.771309173408194e-06,
      "loss": 0.5164,
      "step": 15351
    },
    {
      "epoch": 1.4361274647229232,
      "grad_norm": 1.0869140625,
      "learning_rate": 5.762656686364009e-06,
      "loss": 0.1842,
      "step": 15368
    },
    {
      "epoch": 1.437716101298944,
      "grad_norm": 2.005859375,
      "learning_rate": 5.754001860416237e-06,
      "loss": 0.3505,
      "step": 15385
    },
    {
      "epoch": 1.439304737874965,
      "grad_norm": 0.58642578125,
      "learning_rate": 5.745344722107366e-06,
      "loss": 0.5094,
      "step": 15402
    },
    {
      "epoch": 1.4408933744509858,
      "grad_norm": 0.9833984375,
      "learning_rate": 5.736685297986968e-06,
      "loss": 0.1658,
      "step": 15419
    },
    {
      "epoch": 1.442482011027007,
      "grad_norm": 1.51171875,
      "learning_rate": 5.728023614611632e-06,
      "loss": 0.3594,
      "step": 15436
    },
    {
      "epoch": 1.4440706476030278,
      "grad_norm": 0.35302734375,
      "learning_rate": 5.719359698544871e-06,
      "loss": 0.478,
      "step": 15453
    },
    {
      "epoch": 1.4456592841790488,
      "grad_norm": 0.9892578125,
      "learning_rate": 5.710693576357048e-06,
      "loss": 0.2286,
      "step": 15470
    },
    {
      "epoch": 1.4472479207550697,
      "grad_norm": 2.291015625,
      "learning_rate": 5.702025274625292e-06,
      "loss": 0.4044,
      "step": 15487
    },
    {
      "epoch": 1.4488365573310906,
      "grad_norm": 0.56884765625,
      "learning_rate": 5.693354819933414e-06,
      "loss": 0.4948,
      "step": 15504
    },
    {
      "epoch": 1.4504251939071116,
      "grad_norm": 1.134765625,
      "learning_rate": 5.684682238871828e-06,
      "loss": 0.2392,
      "step": 15521
    },
    {
      "epoch": 1.4520138304831325,
      "grad_norm": 1.896484375,
      "learning_rate": 5.676007558037469e-06,
      "loss": 0.3929,
      "step": 15538
    },
    {
      "epoch": 1.4536024670591534,
      "grad_norm": 0.58984375,
      "learning_rate": 5.667330804033717e-06,
      "loss": 0.4856,
      "step": 15555
    },
    {
      "epoch": 1.4551911036351743,
      "grad_norm": 1.1396484375,
      "learning_rate": 5.658652003470301e-06,
      "loss": 0.2563,
      "step": 15572
    },
    {
      "epoch": 1.4567797402111953,
      "grad_norm": 1.947265625,
      "learning_rate": 5.649971182963232e-06,
      "loss": 0.4019,
      "step": 15589
    },
    {
      "epoch": 1.4583683767872162,
      "grad_norm": 0.83544921875,
      "learning_rate": 5.641288369134713e-06,
      "loss": 0.4449,
      "step": 15606
    },
    {
      "epoch": 1.4599570133632371,
      "grad_norm": 1.373046875,
      "learning_rate": 5.632603588613065e-06,
      "loss": 0.2957,
      "step": 15623
    },
    {
      "epoch": 1.461545649939258,
      "grad_norm": 1.6875,
      "learning_rate": 5.623916868032635e-06,
      "loss": 0.4386,
      "step": 15640
    },
    {
      "epoch": 1.463134286515279,
      "grad_norm": 0.59130859375,
      "learning_rate": 5.61522823403372e-06,
      "loss": 0.4349,
      "step": 15657
    },
    {
      "epoch": 1.4647229230913,
      "grad_norm": 1.2783203125,
      "learning_rate": 5.60653771326249e-06,
      "loss": 0.2711,
      "step": 15674
    },
    {
      "epoch": 1.4663115596673209,
      "grad_norm": 1.875,
      "learning_rate": 5.597845332370895e-06,
      "loss": 0.4419,
      "step": 15691
    },
    {
      "epoch": 1.4679001962433418,
      "grad_norm": 0.6357421875,
      "learning_rate": 5.589151118016594e-06,
      "loss": 0.3355,
      "step": 15708
    },
    {
      "epoch": 1.4694888328193627,
      "grad_norm": 1.3251953125,
      "learning_rate": 5.5804550968628665e-06,
      "loss": 0.2883,
      "step": 15725
    },
    {
      "epoch": 1.4710774693953836,
      "grad_norm": 1.6796875,
      "learning_rate": 5.5717572955785374e-06,
      "loss": 0.4214,
      "step": 15742
    },
    {
      "epoch": 1.4726661059714046,
      "grad_norm": 0.63037109375,
      "learning_rate": 5.563057740837884e-06,
      "loss": 0.3976,
      "step": 15759
    },
    {
      "epoch": 1.4742547425474255,
      "grad_norm": 1.1328125,
      "learning_rate": 5.554356459320566e-06,
      "loss": 0.2648,
      "step": 15776
    },
    {
      "epoch": 1.4758433791234464,
      "grad_norm": 2.443359375,
      "learning_rate": 5.545653477711537e-06,
      "loss": 0.4546,
      "step": 15793
    },
    {
      "epoch": 1.4774320156994674,
      "grad_norm": 0.78076171875,
      "learning_rate": 5.536948822700965e-06,
      "loss": 0.3532,
      "step": 15810
    },
    {
      "epoch": 1.4790206522754883,
      "grad_norm": 1.1982421875,
      "learning_rate": 5.528242520984148e-06,
      "loss": 0.2723,
      "step": 15827
    },
    {
      "epoch": 1.4806092888515092,
      "grad_norm": 2.349609375,
      "learning_rate": 5.519534599261439e-06,
      "loss": 0.4543,
      "step": 15844
    },
    {
      "epoch": 1.4821979254275301,
      "grad_norm": 0.77587890625,
      "learning_rate": 5.510825084238152e-06,
      "loss": 0.3221,
      "step": 15861
    },
    {
      "epoch": 1.483786562003551,
      "grad_norm": 1.455078125,
      "learning_rate": 5.502114002624495e-06,
      "loss": 0.3739,
      "step": 15878
    },
    {
      "epoch": 1.485375198579572,
      "grad_norm": 2.17578125,
      "learning_rate": 5.493401381135477e-06,
      "loss": 0.5235,
      "step": 15895
    },
    {
      "epoch": 1.486963835155593,
      "grad_norm": 0.884765625,
      "learning_rate": 5.484687246490827e-06,
      "loss": 0.333,
      "step": 15912
    },
    {
      "epoch": 1.4885524717316139,
      "grad_norm": 1.771484375,
      "learning_rate": 5.475971625414916e-06,
      "loss": 0.3447,
      "step": 15929
    },
    {
      "epoch": 1.4901411083076348,
      "grad_norm": 2.666015625,
      "learning_rate": 5.467254544636675e-06,
      "loss": 0.4616,
      "step": 15946
    },
    {
      "epoch": 1.4917297448836557,
      "grad_norm": 0.8388671875,
      "learning_rate": 5.458536030889514e-06,
      "loss": 0.3294,
      "step": 15963
    },
    {
      "epoch": 1.4933183814596767,
      "grad_norm": 1.65625,
      "learning_rate": 5.449816110911229e-06,
      "loss": 0.341,
      "step": 15980
    },
    {
      "epoch": 1.4949070180356976,
      "grad_norm": 2.658203125,
      "learning_rate": 5.441094811443939e-06,
      "loss": 0.4877,
      "step": 15997
    },
    {
      "epoch": 1.4964956546117185,
      "grad_norm": 0.828125,
      "learning_rate": 5.432372159233985e-06,
      "loss": 0.2805,
      "step": 16014
    },
    {
      "epoch": 1.4980842911877394,
      "grad_norm": 1.4853515625,
      "learning_rate": 5.423648181031863e-06,
      "loss": 0.3095,
      "step": 16031
    },
    {
      "epoch": 1.4996729277637604,
      "grad_norm": 2.6328125,
      "learning_rate": 5.414922903592131e-06,
      "loss": 0.5203,
      "step": 16048
    },
    {
      "epoch": 1.5012615643397813,
      "grad_norm": 0.95556640625,
      "learning_rate": 5.406196353673334e-06,
      "loss": 0.2503,
      "step": 16065
    },
    {
      "epoch": 1.5028502009158022,
      "grad_norm": 1.53125,
      "learning_rate": 5.397468558037919e-06,
      "loss": 0.3618,
      "step": 16082
    },
    {
      "epoch": 1.5044388374918232,
      "grad_norm": 2.681640625,
      "learning_rate": 5.388739543452153e-06,
      "loss": 0.5703,
      "step": 16099
    },
    {
      "epoch": 1.506027474067844,
      "grad_norm": 1.1328125,
      "learning_rate": 5.380009336686041e-06,
      "loss": 0.2635,
      "step": 16116
    },
    {
      "epoch": 1.507616110643865,
      "grad_norm": 1.61328125,
      "learning_rate": 5.3712779645132425e-06,
      "loss": 0.3584,
      "step": 16133
    },
    {
      "epoch": 1.509204747219886,
      "grad_norm": 2.728515625,
      "learning_rate": 5.362545453710996e-06,
      "loss": 0.5587,
      "step": 16150
    },
    {
      "epoch": 1.5107933837959069,
      "grad_norm": 1.3642578125,
      "learning_rate": 5.353811831060027e-06,
      "loss": 0.2635,
      "step": 16167
    },
    {
      "epoch": 1.5123820203719278,
      "grad_norm": 1.8896484375,
      "learning_rate": 5.345077123344476e-06,
      "loss": 0.4036,
      "step": 16184
    },
    {
      "epoch": 1.5139706569479487,
      "grad_norm": 3.486328125,
      "learning_rate": 5.336341357351802e-06,
      "loss": 0.5284,
      "step": 16201
    },
    {
      "epoch": 1.5155592935239697,
      "grad_norm": 0.90625,
      "learning_rate": 5.32760455987272e-06,
      "loss": 0.2062,
      "step": 16218
    },
    {
      "epoch": 1.5171479300999906,
      "grad_norm": 1.9580078125,
      "learning_rate": 5.318866757701103e-06,
      "loss": 0.3607,
      "step": 16235
    },
    {
      "epoch": 1.5187365666760115,
      "grad_norm": 0.298095703125,
      "learning_rate": 5.3101279776339046e-06,
      "loss": 0.4917,
      "step": 16252
    },
    {
      "epoch": 1.5203252032520327,
      "grad_norm": 1.0908203125,
      "learning_rate": 5.30138824647108e-06,
      "loss": 0.1962,
      "step": 16269
    },
    {
      "epoch": 1.5219138398280534,
      "grad_norm": 1.78125,
      "learning_rate": 5.2926475910154985e-06,
      "loss": 0.4381,
      "step": 16286
    },
    {
      "epoch": 1.5235024764040745,
      "grad_norm": 0.2034912109375,
      "learning_rate": 5.283906038072868e-06,
      "loss": 0.5217,
      "step": 16303
    },
    {
      "epoch": 1.5250911129800953,
      "grad_norm": 1.11328125,
      "learning_rate": 5.2751636144516425e-06,
      "loss": 0.2035,
      "step": 16320
    },
    {
      "epoch": 1.5266797495561164,
      "grad_norm": 1.568359375,
      "learning_rate": 5.266420346962953e-06,
      "loss": 0.402,
      "step": 16337
    },
    {
      "epoch": 1.5282683861321371,
      "grad_norm": 0.5283203125,
      "learning_rate": 5.257676262420514e-06,
      "loss": 0.4975,
      "step": 16354
    },
    {
      "epoch": 1.5298570227081583,
      "grad_norm": 1.37109375,
      "learning_rate": 5.248931387640548e-06,
      "loss": 0.2909,
      "step": 16371
    },
    {
      "epoch": 1.531445659284179,
      "grad_norm": 2.748046875,
      "learning_rate": 5.240185749441698e-06,
      "loss": 0.4285,
      "step": 16388
    },
    {
      "epoch": 1.5330342958602001,
      "grad_norm": 0.40771484375,
      "learning_rate": 5.231439374644953e-06,
      "loss": 0.4394,
      "step": 16405
    },
    {
      "epoch": 1.5346229324362208,
      "grad_norm": 1.3828125,
      "learning_rate": 5.222692290073557e-06,
      "loss": 0.2013,
      "step": 16422
    },
    {
      "epoch": 1.536211569012242,
      "grad_norm": 2.3125,
      "learning_rate": 5.213944522552931e-06,
      "loss": 0.3947,
      "step": 16439
    },
    {
      "epoch": 1.5378002055882627,
      "grad_norm": 0.446533203125,
      "learning_rate": 5.205196098910593e-06,
      "loss": 0.4405,
      "step": 16456
    },
    {
      "epoch": 1.5393888421642838,
      "grad_norm": 1.306640625,
      "learning_rate": 5.196447045976072e-06,
      "loss": 0.2431,
      "step": 16473
    },
    {
      "epoch": 1.5409774787403046,
      "grad_norm": 2.232421875,
      "learning_rate": 5.1876973905808244e-06,
      "loss": 0.4323,
      "step": 16490
    },
    {
      "epoch": 1.5425661153163257,
      "grad_norm": 0.48095703125,
      "learning_rate": 5.1789471595581584e-06,
      "loss": 0.4386,
      "step": 16507
    },
    {
      "epoch": 1.5441547518923464,
      "grad_norm": 0.953125,
      "learning_rate": 5.170196379743145e-06,
      "loss": 0.2616,
      "step": 16524
    },
    {
      "epoch": 1.5457433884683676,
      "grad_norm": 2.0625,
      "learning_rate": 5.16144507797254e-06,
      "loss": 0.4225,
      "step": 16541
    },
    {
      "epoch": 1.5473320250443883,
      "grad_norm": 0.69287109375,
      "learning_rate": 5.152693281084696e-06,
      "loss": 0.3347,
      "step": 16558
    },
    {
      "epoch": 1.5489206616204094,
      "grad_norm": 1.248046875,
      "learning_rate": 5.143941015919488e-06,
      "loss": 0.3083,
      "step": 16575
    },
    {
      "epoch": 1.5505092981964301,
      "grad_norm": 2.228515625,
      "learning_rate": 5.1351883093182254e-06,
      "loss": 0.4747,
      "step": 16592
    },
    {
      "epoch": 1.5520979347724513,
      "grad_norm": 0.8671875,
      "learning_rate": 5.126435188123573e-06,
      "loss": 0.3693,
      "step": 16609
    },
    {
      "epoch": 1.553686571348472,
      "grad_norm": 1.4013671875,
      "learning_rate": 5.117681679179464e-06,
      "loss": 0.3204,
      "step": 16626
    },
    {
      "epoch": 1.5552752079244931,
      "grad_norm": 1.9423828125,
      "learning_rate": 5.108927809331025e-06,
      "loss": 0.4683,
      "step": 16643
    },
    {
      "epoch": 1.5568638445005138,
      "grad_norm": 0.8505859375,
      "learning_rate": 5.1001736054244835e-06,
      "loss": 0.3558,
      "step": 16660
    },
    {
      "epoch": 1.558452481076535,
      "grad_norm": 1.73046875,
      "learning_rate": 5.091419094307099e-06,
      "loss": 0.3213,
      "step": 16677
    },
    {
      "epoch": 1.5600411176525557,
      "grad_norm": 2.412109375,
      "learning_rate": 5.0826643028270675e-06,
      "loss": 0.5085,
      "step": 16694
    },
    {
      "epoch": 1.5616297542285769,
      "grad_norm": 0.81640625,
      "learning_rate": 5.073909257833445e-06,
      "loss": 0.3424,
      "step": 16711
    },
    {
      "epoch": 1.5632183908045976,
      "grad_norm": 1.6572265625,
      "learning_rate": 5.065153986176068e-06,
      "loss": 0.296,
      "step": 16728
    },
    {
      "epoch": 1.5648070273806187,
      "grad_norm": 2.177734375,
      "learning_rate": 5.056398514705465e-06,
      "loss": 0.4882,
      "step": 16745
    },
    {
      "epoch": 1.5663956639566394,
      "grad_norm": 1.0361328125,
      "learning_rate": 5.047642870272782e-06,
      "loss": 0.3124,
      "step": 16762
    },
    {
      "epoch": 1.5679843005326606,
      "grad_norm": 1.3955078125,
      "learning_rate": 5.038887079729689e-06,
      "loss": 0.3115,
      "step": 16779
    },
    {
      "epoch": 1.5695729371086813,
      "grad_norm": 2.6171875,
      "learning_rate": 5.030131169928309e-06,
      "loss": 0.5079,
      "step": 16796
    },
    {
      "epoch": 1.5711615736847024,
      "grad_norm": 0.93701171875,
      "learning_rate": 5.021375167721128e-06,
      "loss": 0.3369,
      "step": 16813
    },
    {
      "epoch": 1.5727502102607231,
      "grad_norm": 1.466796875,
      "learning_rate": 5.012619099960919e-06,
      "loss": 0.3847,
      "step": 16830
    },
    {
      "epoch": 1.5743388468367443,
      "grad_norm": 2.5390625,
      "learning_rate": 5.003862993500651e-06,
      "loss": 0.5206,
      "step": 16847
    },
    {
      "epoch": 1.575927483412765,
      "grad_norm": 0.96142578125,
      "learning_rate": 4.995106875193416e-06,
      "loss": 0.2724,
      "step": 16864
    },
    {
      "epoch": 1.5775161199887862,
      "grad_norm": 2.029296875,
      "learning_rate": 4.986350771892339e-06,
      "loss": 0.3639,
      "step": 16881
    },
    {
      "epoch": 1.5791047565648069,
      "grad_norm": 2.576171875,
      "learning_rate": 4.977594710450499e-06,
      "loss": 0.5595,
      "step": 16898
    },
    {
      "epoch": 1.580693393140828,
      "grad_norm": 1.181640625,
      "learning_rate": 4.968838717720852e-06,
      "loss": 0.2371,
      "step": 16915
    },
    {
      "epoch": 1.582282029716849,
      "grad_norm": 1.7236328125,
      "learning_rate": 4.960082820556138e-06,
      "loss": 0.3789,
      "step": 16932
    },
    {
      "epoch": 1.5838706662928699,
      "grad_norm": 2.580078125,
      "learning_rate": 4.951327045808804e-06,
      "loss": 0.5512,
      "step": 16949
    },
    {
      "epoch": 1.5854593028688908,
      "grad_norm": 1.04296875,
      "learning_rate": 4.942571420330925e-06,
      "loss": 0.2278,
      "step": 16966
    },
    {
      "epoch": 1.5870479394449117,
      "grad_norm": 1.96484375,
      "learning_rate": 4.933815970974114e-06,
      "loss": 0.3609,
      "step": 16983
    },
    {
      "epoch": 1.5886365760209327,
      "grad_norm": 2.828125,
      "learning_rate": 4.9250607245894484e-06,
      "loss": 0.5036,
      "step": 17000
    },
    {
      "epoch": 1.5902252125969536,
      "grad_norm": 0.92626953125,
      "learning_rate": 4.916305708027378e-06,
      "loss": 0.2242,
      "step": 17017
    },
    {
      "epoch": 1.5918138491729745,
      "grad_norm": 1.42578125,
      "learning_rate": 4.907550948137653e-06,
      "loss": 0.3554,
      "step": 17034
    },
    {
      "epoch": 1.5934024857489955,
      "grad_norm": 3.298828125,
      "learning_rate": 4.898796471769233e-06,
      "loss": 0.5669,
      "step": 17051
    },
    {
      "epoch": 1.5949911223250164,
      "grad_norm": 0.83642578125,
      "learning_rate": 4.890042305770209e-06,
      "loss": 0.1582,
      "step": 17068
    },
    {
      "epoch": 1.5965797589010373,
      "grad_norm": 1.6162109375,
      "learning_rate": 4.881288476987718e-06,
      "loss": 0.3528,
      "step": 17085
    },
    {
      "epoch": 1.5981683954770582,
      "grad_norm": 0.3330078125,
      "learning_rate": 4.87253501226787e-06,
      "loss": 0.5019,
      "step": 17102
    },
    {
      "epoch": 1.5997570320530792,
      "grad_norm": 0.98291015625,
      "learning_rate": 4.863781938455651e-06,
      "loss": 0.2364,
      "step": 17119
    },
    {
      "epoch": 1.6013456686291,
      "grad_norm": 1.9404296875,
      "learning_rate": 4.855029282394849e-06,
      "loss": 0.3943,
      "step": 17136
    },
    {
      "epoch": 1.602934305205121,
      "grad_norm": 1.0625,
      "learning_rate": 4.846277070927975e-06,
      "loss": 0.4679,
      "step": 17153
    },
    {
      "epoch": 1.604522941781142,
      "grad_norm": 1.259765625,
      "learning_rate": 4.837525330896174e-06,
      "loss": 0.226,
      "step": 17170
    },
    {
      "epoch": 1.606111578357163,
      "grad_norm": 2.095703125,
      "learning_rate": 4.828774089139144e-06,
      "loss": 0.4095,
      "step": 17187
    },
    {
      "epoch": 1.6077002149331838,
      "grad_norm": 0.315185546875,
      "learning_rate": 4.820023372495055e-06,
      "loss": 0.444,
      "step": 17204
    },
    {
      "epoch": 1.6092888515092048,
      "grad_norm": 1.251953125,
      "learning_rate": 4.811273207800472e-06,
      "loss": 0.2766,
      "step": 17221
    },
    {
      "epoch": 1.6108774880852257,
      "grad_norm": 1.576171875,
      "learning_rate": 4.8025236218902615e-06,
      "loss": 0.4249,
      "step": 17238
    },
    {
      "epoch": 1.6124661246612466,
      "grad_norm": 0.75146484375,
      "learning_rate": 4.793774641597515e-06,
      "loss": 0.4755,
      "step": 17255
    },
    {
      "epoch": 1.6140547612372675,
      "grad_norm": 1.3798828125,
      "learning_rate": 4.785026293753468e-06,
      "loss": 0.274,
      "step": 17272
    },
    {
      "epoch": 1.6156433978132885,
      "grad_norm": 3.283203125,
      "learning_rate": 4.77627860518742e-06,
      "loss": 0.4221,
      "step": 17289
    },
    {
      "epoch": 1.6172320343893094,
      "grad_norm": 0.79931640625,
      "learning_rate": 4.767531602726643e-06,
      "loss": 0.4743,
      "step": 17306
    },
    {
      "epoch": 1.6188206709653303,
      "grad_norm": 1.4140625,
      "learning_rate": 4.758785313196305e-06,
      "loss": 0.3245,
      "step": 17323
    },
    {
      "epoch": 1.6204093075413513,
      "grad_norm": 2.224609375,
      "learning_rate": 4.750039763419394e-06,
      "loss": 0.4545,
      "step": 17340
    },
    {
      "epoch": 1.6219979441173722,
      "grad_norm": 0.736328125,
      "learning_rate": 4.741294980216623e-06,
      "loss": 0.3768,
      "step": 17357
    },
    {
      "epoch": 1.6235865806933931,
      "grad_norm": 1.2490234375,
      "learning_rate": 4.732550990406359e-06,
      "loss": 0.3033,
      "step": 17374
    },
    {
      "epoch": 1.625175217269414,
      "grad_norm": 2.51171875,
      "learning_rate": 4.723807820804526e-06,
      "loss": 0.5007,
      "step": 17391
    },
    {
      "epoch": 1.626763853845435,
      "grad_norm": 0.6728515625,
      "learning_rate": 4.715065498224547e-06,
      "loss": 0.4145,
      "step": 17408
    },
    {
      "epoch": 1.628352490421456,
      "grad_norm": 1.2744140625,
      "learning_rate": 4.7063240494772375e-06,
      "loss": 0.3099,
      "step": 17425
    },
    {
      "epoch": 1.6299411269974768,
      "grad_norm": 2.46484375,
      "learning_rate": 4.697583501370735e-06,
      "loss": 0.4696,
      "step": 17442
    },
    {
      "epoch": 1.6315297635734978,
      "grad_norm": 0.7119140625,
      "learning_rate": 4.688843880710417e-06,
      "loss": 0.3615,
      "step": 17459
    },
    {
      "epoch": 1.6331184001495187,
      "grad_norm": 1.509765625,
      "learning_rate": 4.6801052142988145e-06,
      "loss": 0.3573,
      "step": 17476
    },
    {
      "epoch": 1.6347070367255396,
      "grad_norm": 1.9345703125,
      "learning_rate": 4.671367528935533e-06,
      "loss": 0.4747,
      "step": 17493
    },
    {
      "epoch": 1.6362956733015606,
      "grad_norm": 0.86279296875,
      "learning_rate": 4.6626308514171665e-06,
      "loss": 0.3427,
      "step": 17510
    },
    {
      "epoch": 1.6378843098775815,
      "grad_norm": 1.388671875,
      "learning_rate": 4.6538952085372256e-06,
      "loss": 0.2839,
      "step": 17527
    },
    {
      "epoch": 1.6394729464536024,
      "grad_norm": 1.8642578125,
      "learning_rate": 4.645160627086041e-06,
      "loss": 0.4094,
      "step": 17544
    },
    {
      "epoch": 1.6410615830296233,
      "grad_norm": 0.74609375,
      "learning_rate": 4.63642713385069e-06,
      "loss": 0.3273,
      "step": 17561
    },
    {
      "epoch": 1.6426502196056443,
      "grad_norm": 1.498046875,
      "learning_rate": 4.627694755614912e-06,
      "loss": 0.307,
      "step": 17578
    },
    {
      "epoch": 1.6442388561816652,
      "grad_norm": 2.33984375,
      "learning_rate": 4.61896351915903e-06,
      "loss": 0.4779,
      "step": 17595
    },
    {
      "epoch": 1.6458274927576864,
      "grad_norm": 0.83984375,
      "learning_rate": 4.610233451259864e-06,
      "loss": 0.273,
      "step": 17612
    },
    {
      "epoch": 1.647416129333707,
      "grad_norm": 1.3642578125,
      "learning_rate": 4.601504578690644e-06,
      "loss": 0.3002,
      "step": 17629
    },
    {
      "epoch": 1.6490047659097282,
      "grad_norm": 2.482421875,
      "learning_rate": 4.592776928220946e-06,
      "loss": 0.478,
      "step": 17646
    },
    {
      "epoch": 1.650593402485749,
      "grad_norm": 0.84375,
      "learning_rate": 4.584050526616589e-06,
      "loss": 0.257,
      "step": 17663
    },
    {
      "epoch": 1.65218203906177,
      "grad_norm": 1.3955078125,
      "learning_rate": 4.575325400639566e-06,
      "loss": 0.3331,
      "step": 17680
    },
    {
      "epoch": 1.6537706756377908,
      "grad_norm": 3.080078125,
      "learning_rate": 4.566601577047954e-06,
      "loss": 0.5352,
      "step": 17697
    },
    {
      "epoch": 1.655359312213812,
      "grad_norm": 0.69091796875,
      "learning_rate": 4.557879082595842e-06,
      "loss": 0.2319,
      "step": 17714
    },
    {
      "epoch": 1.6569479487898326,
      "grad_norm": 1.4423828125,
      "learning_rate": 4.549157944033239e-06,
      "loss": 0.3432,
      "step": 17731
    },
    {
      "epoch": 1.6585365853658538,
      "grad_norm": 2.296875,
      "learning_rate": 4.540438188105994e-06,
      "loss": 0.4595,
      "step": 17748
    },
    {
      "epoch": 1.6601252219418745,
      "grad_norm": 1.029296875,
      "learning_rate": 4.531719841555719e-06,
      "loss": 0.2731,
      "step": 17765
    },
    {
      "epoch": 1.6617138585178957,
      "grad_norm": 1.486328125,
      "learning_rate": 4.523002931119705e-06,
      "loss": 0.3928,
      "step": 17782
    },
    {
      "epoch": 1.6633024950939164,
      "grad_norm": 2.388671875,
      "learning_rate": 4.514287483530833e-06,
      "loss": 0.5295,
      "step": 17799
    },
    {
      "epoch": 1.6648911316699375,
      "grad_norm": 0.994140625,
      "learning_rate": 4.5055735255175e-06,
      "loss": 0.1826,
      "step": 17816
    },
    {
      "epoch": 1.6664797682459582,
      "grad_norm": 1.240234375,
      "learning_rate": 4.4968610838035425e-06,
      "loss": 0.3421,
      "step": 17833
    },
    {
      "epoch": 1.6680684048219794,
      "grad_norm": 2.34765625,
      "learning_rate": 4.488150185108135e-06,
      "loss": 0.5292,
      "step": 17850
    },
    {
      "epoch": 1.669657041398,
      "grad_norm": 1.224609375,
      "learning_rate": 4.4794408561457284e-06,
      "loss": 0.2351,
      "step": 17867
    },
    {
      "epoch": 1.6712456779740212,
      "grad_norm": 2.1640625,
      "learning_rate": 4.4707331236259525e-06,
      "loss": 0.4172,
      "step": 17884
    },
    {
      "epoch": 1.672834314550042,
      "grad_norm": 3.0859375,
      "learning_rate": 4.46202701425355e-06,
      "loss": 0.5688,
      "step": 17901
    },
    {
      "epoch": 1.674422951126063,
      "grad_norm": 1.08984375,
      "learning_rate": 4.453322554728277e-06,
      "loss": 0.1846,
      "step": 17918
    },
    {
      "epoch": 1.6760115877020838,
      "grad_norm": 1.8125,
      "learning_rate": 4.444619771744834e-06,
      "loss": 0.3756,
      "step": 17935
    },
    {
      "epoch": 1.677600224278105,
      "grad_norm": 0.342529296875,
      "learning_rate": 4.43591869199278e-06,
      "loss": 0.5025,
      "step": 17952
    },
    {
      "epoch": 1.6791888608541257,
      "grad_norm": 1.234375,
      "learning_rate": 4.427219342156452e-06,
      "loss": 0.2225,
      "step": 17969
    },
    {
      "epoch": 1.6807774974301468,
      "grad_norm": 2.455078125,
      "learning_rate": 4.418521748914878e-06,
      "loss": 0.4101,
      "step": 17986
    },
    {
      "epoch": 1.6823661340061675,
      "grad_norm": 0.464111328125,
      "learning_rate": 4.409825938941701e-06,
      "loss": 0.4983,
      "step": 18003
    },
    {
      "epoch": 1.6839547705821887,
      "grad_norm": 1.154296875,
      "learning_rate": 4.401131938905097e-06,
      "loss": 0.2291,
      "step": 18020
    },
    {
      "epoch": 1.6855434071582094,
      "grad_norm": 2.087890625,
      "learning_rate": 4.392439775467686e-06,
      "loss": 0.4443,
      "step": 18037
    },
    {
      "epoch": 1.6871320437342305,
      "grad_norm": 0.2105712890625,
      "learning_rate": 4.3837494752864615e-06,
      "loss": 0.4796,
      "step": 18054
    },
    {
      "epoch": 1.6887206803102512,
      "grad_norm": 1.0615234375,
      "learning_rate": 4.3750610650126965e-06,
      "loss": 0.2439,
      "step": 18071
    },
    {
      "epoch": 1.6903093168862724,
      "grad_norm": 2.080078125,
      "learning_rate": 4.366374571291875e-06,
      "loss": 0.3926,
      "step": 18088
    },
    {
      "epoch": 1.691897953462293,
      "grad_norm": 0.351806640625,
      "learning_rate": 4.3576900207636e-06,
      "loss": 0.4314,
      "step": 18105
    },
    {
      "epoch": 1.6934865900383143,
      "grad_norm": 1.2978515625,
      "learning_rate": 4.349007440061513e-06,
      "loss": 0.2174,
      "step": 18122
    },
    {
      "epoch": 1.695075226614335,
      "grad_norm": 2.322265625,
      "learning_rate": 4.340326855813216e-06,
      "loss": 0.499,
      "step": 18139
    },
    {
      "epoch": 1.6966638631903561,
      "grad_norm": 0.312255859375,
      "learning_rate": 4.331648294640192e-06,
      "loss": 0.4278,
      "step": 18156
    },
    {
      "epoch": 1.6982524997663768,
      "grad_norm": 1.5,
      "learning_rate": 4.322971783157716e-06,
      "loss": 0.2806,
      "step": 18173
    },
    {
      "epoch": 1.699841136342398,
      "grad_norm": 1.92578125,
      "learning_rate": 4.314297347974774e-06,
      "loss": 0.4334,
      "step": 18190
    },
    {
      "epoch": 1.7014297729184187,
      "grad_norm": 0.501953125,
      "learning_rate": 4.3056250156939924e-06,
      "loss": 0.4082,
      "step": 18207
    },
    {
      "epoch": 1.7030184094944398,
      "grad_norm": 1.310546875,
      "learning_rate": 4.296954812911542e-06,
      "loss": 0.2716,
      "step": 18224
    },
    {
      "epoch": 1.7046070460704605,
      "grad_norm": 2.34375,
      "learning_rate": 4.2882867662170655e-06,
      "loss": 0.4807,
      "step": 18241
    },
    {
      "epoch": 1.7061956826464817,
      "grad_norm": 0.8447265625,
      "learning_rate": 4.27962090219359e-06,
      "loss": 0.3743,
      "step": 18258
    },
    {
      "epoch": 1.7077843192225026,
      "grad_norm": 1.541015625,
      "learning_rate": 4.270957247417456e-06,
      "loss": 0.2792,
      "step": 18275
    },
    {
      "epoch": 1.7093729557985236,
      "grad_norm": 2.67578125,
      "learning_rate": 4.262295828458223e-06,
      "loss": 0.4596,
      "step": 18292
    },
    {
      "epoch": 1.7109615923745445,
      "grad_norm": 0.8125,
      "learning_rate": 4.2536366718785925e-06,
      "loss": 0.4049,
      "step": 18309
    },
    {
      "epoch": 1.7125502289505654,
      "grad_norm": 1.6220703125,
      "learning_rate": 4.244979804234333e-06,
      "loss": 0.2971,
      "step": 18326
    },
    {
      "epoch": 1.7141388655265863,
      "grad_norm": 2.083984375,
      "learning_rate": 4.236325252074192e-06,
      "loss": 0.4808,
      "step": 18343
    },
    {
      "epoch": 1.7157275021026073,
      "grad_norm": 1.0,
      "learning_rate": 4.227673041939811e-06,
      "loss": 0.3686,
      "step": 18360
    },
    {
      "epoch": 1.7173161386786282,
      "grad_norm": 1.40625,
      "learning_rate": 4.219023200365653e-06,
      "loss": 0.3087,
      "step": 18377
    },
    {
      "epoch": 1.7189047752546491,
      "grad_norm": 2.06640625,
      "learning_rate": 4.2103757538789195e-06,
      "loss": 0.4861,
      "step": 18394
    },
    {
      "epoch": 1.72049341183067,
      "grad_norm": 1.0732421875,
      "learning_rate": 4.201730728999463e-06,
      "loss": 0.3667,
      "step": 18411
    },
    {
      "epoch": 1.722082048406691,
      "grad_norm": 1.33203125,
      "learning_rate": 4.193088152239709e-06,
      "loss": 0.313,
      "step": 18428
    },
    {
      "epoch": 1.723670684982712,
      "grad_norm": 2.5859375,
      "learning_rate": 4.184448050104576e-06,
      "loss": 0.5256,
      "step": 18445
    },
    {
      "epoch": 1.7252593215587329,
      "grad_norm": 0.83740234375,
      "learning_rate": 4.175810449091397e-06,
      "loss": 0.2924,
      "step": 18462
    },
    {
      "epoch": 1.7268479581347538,
      "grad_norm": 1.4482421875,
      "learning_rate": 4.16717537568983e-06,
      "loss": 0.3087,
      "step": 18479
    },
    {
      "epoch": 1.7284365947107747,
      "grad_norm": 2.22265625,
      "learning_rate": 4.158542856381783e-06,
      "loss": 0.5215,
      "step": 18496
    },
    {
      "epoch": 1.7300252312867956,
      "grad_norm": 0.93408203125,
      "learning_rate": 4.149912917641331e-06,
      "loss": 0.2695,
      "step": 18513
    },
    {
      "epoch": 1.7316138678628166,
      "grad_norm": 1.275390625,
      "learning_rate": 4.141285585934635e-06,
      "loss": 0.307,
      "step": 18530
    },
    {
      "epoch": 1.7332025044388375,
      "grad_norm": 2.1875,
      "learning_rate": 4.1326608877198615e-06,
      "loss": 0.5367,
      "step": 18547
    },
    {
      "epoch": 1.7347911410148584,
      "grad_norm": 0.833984375,
      "learning_rate": 4.124038849447097e-06,
      "loss": 0.2833,
      "step": 18564
    },
    {
      "epoch": 1.7363797775908794,
      "grad_norm": 1.990234375,
      "learning_rate": 4.115419497558277e-06,
      "loss": 0.3832,
      "step": 18581
    },
    {
      "epoch": 1.7379684141669003,
      "grad_norm": 2.4296875,
      "learning_rate": 4.106802858487095e-06,
      "loss": 0.5257,
      "step": 18598
    },
    {
      "epoch": 1.7395570507429212,
      "grad_norm": 0.9306640625,
      "learning_rate": 4.098188958658923e-06,
      "loss": 0.3223,
      "step": 18615
    },
    {
      "epoch": 1.7411456873189421,
      "grad_norm": 1.548828125,
      "learning_rate": 4.089577824490733e-06,
      "loss": 0.3767,
      "step": 18632
    },
    {
      "epoch": 1.742734323894963,
      "grad_norm": 2.6015625,
      "learning_rate": 4.0809694823910205e-06,
      "loss": 0.4954,
      "step": 18649
    },
    {
      "epoch": 1.744322960470984,
      "grad_norm": 1.20703125,
      "learning_rate": 4.0723639587597116e-06,
      "loss": 0.2428,
      "step": 18666
    },
    {
      "epoch": 1.745911597047005,
      "grad_norm": 1.5224609375,
      "learning_rate": 4.063761279988089e-06,
      "loss": 0.3748,
      "step": 18683
    },
    {
      "epoch": 1.7475002336230259,
      "grad_norm": 2.841796875,
      "learning_rate": 4.055161472458719e-06,
      "loss": 0.5908,
      "step": 18700
    },
    {
      "epoch": 1.7490888701990468,
      "grad_norm": 1.0576171875,
      "learning_rate": 4.046564562545353e-06,
      "loss": 0.1854,
      "step": 18717
    },
    {
      "epoch": 1.7506775067750677,
      "grad_norm": 2.01953125,
      "learning_rate": 4.037970576612861e-06,
      "loss": 0.3492,
      "step": 18734
    },
    {
      "epoch": 1.7522661433510887,
      "grad_norm": 3.720703125,
      "learning_rate": 4.0293795410171415e-06,
      "loss": 0.5344,
      "step": 18751
    },
    {
      "epoch": 1.7538547799271096,
      "grad_norm": 0.9775390625,
      "learning_rate": 4.020791482105053e-06,
      "loss": 0.185,
      "step": 18768
    },
    {
      "epoch": 1.7554434165031305,
      "grad_norm": 1.8955078125,
      "learning_rate": 4.012206426214318e-06,
      "loss": 0.3872,
      "step": 18785
    },
    {
      "epoch": 1.7570320530791514,
      "grad_norm": 0.8720703125,
      "learning_rate": 4.003624399673451e-06,
      "loss": 0.563,
      "step": 18802
    },
    {
      "epoch": 1.7586206896551724,
      "grad_norm": 1.013671875,
      "learning_rate": 3.995045428801674e-06,
      "loss": 0.2086,
      "step": 18819
    },
    {
      "epoch": 1.7602093262311933,
      "grad_norm": 1.9150390625,
      "learning_rate": 3.986469539908846e-06,
      "loss": 0.3939,
      "step": 18836
    },
    {
      "epoch": 1.7617979628072142,
      "grad_norm": 0.373779296875,
      "learning_rate": 3.977896759295366e-06,
      "loss": 0.4711,
      "step": 18853
    },
    {
      "epoch": 1.7633865993832352,
      "grad_norm": 1.328125,
      "learning_rate": 3.969327113252101e-06,
      "loss": 0.2401,
      "step": 18870
    },
    {
      "epoch": 1.764975235959256,
      "grad_norm": 1.96484375,
      "learning_rate": 3.960760628060313e-06,
      "loss": 0.4163,
      "step": 18887
    },
    {
      "epoch": 1.766563872535277,
      "grad_norm": 0.53955078125,
      "learning_rate": 3.9521973299915605e-06,
      "loss": 0.4618,
      "step": 18904
    },
    {
      "epoch": 1.768152509111298,
      "grad_norm": 1.23046875,
      "learning_rate": 3.943637245307633e-06,
      "loss": 0.3054,
      "step": 18921
    },
    {
      "epoch": 1.7697411456873189,
      "grad_norm": 2.435546875,
      "learning_rate": 3.935080400260463e-06,
      "loss": 0.3827,
      "step": 18938
    },
    {
      "epoch": 1.77132978226334,
      "grad_norm": 0.258056640625,
      "learning_rate": 3.926526821092052e-06,
      "loss": 0.4477,
      "step": 18955
    },
    {
      "epoch": 1.7729184188393607,
      "grad_norm": 1.1328125,
      "learning_rate": 3.9179765340343804e-06,
      "loss": 0.2761,
      "step": 18972
    },
    {
      "epoch": 1.774507055415382,
      "grad_norm": 1.8388671875,
      "learning_rate": 3.909429565309334e-06,
      "loss": 0.4409,
      "step": 18989
    },
    {
      "epoch": 1.7760956919914026,
      "grad_norm": 0.7119140625,
      "learning_rate": 3.900885941128624e-06,
      "loss": 0.4154,
      "step": 19006
    },
    {
      "epoch": 1.7776843285674238,
      "grad_norm": 1.1357421875,
      "learning_rate": 3.892345687693704e-06,
      "loss": 0.2408,
      "step": 19023
    },
    {
      "epoch": 1.7792729651434445,
      "grad_norm": 1.908203125,
      "learning_rate": 3.883808831195689e-06,
      "loss": 0.4266,
      "step": 19040
    },
    {
      "epoch": 1.7808616017194656,
      "grad_norm": 0.54638671875,
      "learning_rate": 3.875275397815275e-06,
      "loss": 0.3744,
      "step": 19057
    },
    {
      "epoch": 1.7824502382954863,
      "grad_norm": 1.2109375,
      "learning_rate": 3.866745413722664e-06,
      "loss": 0.2631,
      "step": 19074
    },
    {
      "epoch": 1.7840388748715075,
      "grad_norm": 2.06640625,
      "learning_rate": 3.858218905077477e-06,
      "loss": 0.4382,
      "step": 19091
    },
    {
      "epoch": 1.7856275114475282,
      "grad_norm": 0.85595703125,
      "learning_rate": 3.849695898028678e-06,
      "loss": 0.4065,
      "step": 19108
    },
    {
      "epoch": 1.7872161480235493,
      "grad_norm": 1.3037109375,
      "learning_rate": 3.841176418714489e-06,
      "loss": 0.2912,
      "step": 19125
    },
    {
      "epoch": 1.78880478459957,
      "grad_norm": 2.5859375,
      "learning_rate": 3.832660493262319e-06,
      "loss": 0.5211,
      "step": 19142
    },
    {
      "epoch": 1.7903934211755912,
      "grad_norm": 0.7783203125,
      "learning_rate": 3.824148147788674e-06,
      "loss": 0.3868,
      "step": 19159
    },
    {
      "epoch": 1.791982057751612,
      "grad_norm": 1.783203125,
      "learning_rate": 3.815639408399079e-06,
      "loss": 0.3025,
      "step": 19176
    },
    {
      "epoch": 1.793570694327633,
      "grad_norm": 2.193359375,
      "learning_rate": 3.8071343011880068e-06,
      "loss": 0.4971,
      "step": 19193
    },
    {
      "epoch": 1.7951593309036538,
      "grad_norm": 0.80078125,
      "learning_rate": 3.798632852238786e-06,
      "loss": 0.346,
      "step": 19210
    },
    {
      "epoch": 1.796747967479675,
      "grad_norm": 1.5341796875,
      "learning_rate": 3.790135087623526e-06,
      "loss": 0.3101,
      "step": 19227
    },
    {
      "epoch": 1.7983366040556956,
      "grad_norm": 2.00390625,
      "learning_rate": 3.7816410334030378e-06,
      "loss": 0.4789,
      "step": 19244
    },
    {
      "epoch": 1.7999252406317168,
      "grad_norm": 0.90966796875,
      "learning_rate": 3.7731507156267567e-06,
      "loss": 0.3528,
      "step": 19261
    },
    {
      "epoch": 1.800112139052425,
      "eval_loss": 0.37429991364479065,
      "eval_runtime": 1039.9788,
      "eval_samples_per_second": 7.717,
      "eval_steps_per_second": 2.572,
      "step": 19263
    }
  ],
  "logging_steps": 17,
  "max_steps": 32103,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 3211,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.406145398729343e+18,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
