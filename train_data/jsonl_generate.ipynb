{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            rem  \\\n",
      "0                    print \"di\"   \n",
      "1  print self.x, self.y, self.z   \n",
      "2                                 \n",
      "3      M = amax(new.rowind) + 1   \n",
      "4   new.data = new.data * other   \n",
      "\n",
      "                                                 add  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2  expr = numexpr(\"2.0*a+3.0*c\",[('a',float),('c'...   \n",
      "3                      M = int(amax(new.rowind)) + 1   \n",
      "4                                  new.data *= other   \n",
      "\n",
      "                                             context  \n",
      "0  def __init__(self, x, y, z, kind='linear', cop...  \n",
      "1  def __init__(self, x, y, z, kind='linear', cop...  \n",
      "2  def check_broadcasting(self): a = arange(100)....  \n",
      "3  def Construct(s, ij=None, M=None ,N=None, nzma...  \n",
      "4  def __mul__(self, other):  # implement matrix ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 指定包含 parquet 文件的目录\n",
    "#directory = r\"F:\\Desktop\\yjs\\a毕业设计论文进行\\a_dataset\\apr_original_data\\raw_dataset\\coconut_c2005_preprocessed\\data\"\n",
    "directory = r\"F:\\Desktop\\yjs\\a毕业设计论文进行\\a_dataset\\apr_original_data\\raw_dataset\\coconut_python2010_preprocessed\\data\"\n",
    "\n",
    "# 获取所有 parquet 文件路径\n",
    "parquet_files = glob.glob(os.path.join(directory, \"*.parquet\"))\n",
    "\n",
    "# 读取并合并所有 parquet 文件\n",
    "df_list = [pd.read_parquet(file, engine=\"pyarrow\") for file in parquet_files]\n",
    "df = pd.concat(df_list, ignore_index=True)  # 合并成一个 DataFrame\n",
    "\n",
    "# 打印前 5 行\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终 JSONL 文件行数: 119610\n",
      "数据处理完成，已保存为 processed_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "# # 仅处理前 100 行\n",
    "# df_subset = df.head(100).copy()\n",
    "df_subset = df.copy()\n",
    "\n",
    "# 处理逻辑\n",
    "def process_row(rem, add, context):\n",
    "    \"\"\" 根据 rem 和 add 规则处理 context \"\"\"\n",
    "    if pd.isna(rem) or pd.isna(add) or pd.isna(context):\n",
    "        return None  # 跳过\n",
    "\n",
    "    # 统计 rem 出现的次数\n",
    "    rem_occurrences = len(re.findall(re.escape(rem), context))\n",
    "    if rem_occurrences != 1 :\n",
    "        return None  # rem 多次匹配，跳过\n",
    "\n",
    "    # 3.1 rem:xxx, add: xxx，直接替换\n",
    "    if rem != \"\" and add != \"\":\n",
    "        return context.replace(rem, add)\n",
    "\n",
    "    # 3.2 rem:xxx, add: 空，替换为空\n",
    "    if rem != \"\" and add == \"\":\n",
    "        return context.replace(rem, \"\")\n",
    "\n",
    "    # 3.3 rem:{} , add:{xxx}，替换 { // FIXME: not implemented}\n",
    "    if rem == \"{}\" and add.startswith(\"{\") and add.endswith(\"}\"):\n",
    "        return context.replace(\"{ // FIXME: not implemented }\", add)\n",
    "\n",
    "    # 3.4 rem:}, add: xxx}，替换\n",
    "    if rem == \"}\" and add.endswith(\"}\"):\n",
    "        return context.replace(rem, add)\n",
    "\n",
    "    # 3.5 rem:{, add:{xxx，替换\n",
    "    if rem == \"{\" and add.startswith(\"{\"):\n",
    "        return context.replace(rem, add)\n",
    "\n",
    "    # 3.6 rem:{xxx}, add:任意，替换 { // FIXME: not implemented xxx}\n",
    "    if rem.startswith(\"{\") and rem.endswith(\"}\"):\n",
    "        return context.replace(f\"{{ // FIXME: not implemented {rem.strip('{}')} }}\", add)\n",
    "\n",
    "    # 3.7 其他情况，跳过\n",
    "    return None\n",
    "\n",
    "# 处理数据并去重\n",
    "output_data = []\n",
    "seen_entries = set()  # 用于去重\n",
    "\n",
    "for _, row in df_subset.iterrows():\n",
    "    buggy_code = row[\"context\"]\n",
    "    fix_code = process_row(row[\"rem\"], row[\"add\"], row[\"context\"])\n",
    "\n",
    "    if fix_code is not None and fix_code.strip() != \"\":  # 仅保留符合规则的数据\n",
    "        entry = (row[\"rem\"], row[\"add\"], row[\"context\"])  # 作为唯一标识\n",
    "        if entry not in seen_entries:\n",
    "            seen_entries.add(entry)\n",
    "            output_data.append({\"buggy_code\": buggy_code, \"fix_code\": fix_code})\n",
    "\n",
    "# 导出 JSONL 文件\n",
    "output_path = \"processed_data.jsonl\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in output_data:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 统计 JSONL 文件的行数\n",
    "line_count = len(output_data)\n",
    "print(f\"最终 JSONL 文件行数: {line_count}\")\n",
    "print(f\"数据处理完成，已保存为 {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] `black` 解析失败，尝试使用 `autopep8` 进行格式化...\n",
      "# implement matrix multiplication and matrix-vector multiplication if isspmatrix(other): return self.matmat(other) elif isscalar(other): new = self.copy() new.data = new.data * other new._dtypechar = new.data.dtypechar new.ftype = _transtabl[new._dtypechar] return new else: return self.matvec(other)\n",
      "def __mul__(self, other):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import black\n",
    "import autopep8\n",
    "import textwrap\n",
    "\n",
    "def format_python_code(code: str, max_width=80) -> str:\n",
    "    \"\"\"\n",
    "    格式化 Python 代码，自动换行并使用 `black` 和 `autopep8` 标准化。\n",
    "    \n",
    "    参数：\n",
    "    - code (str): 需要格式化的 Python 代码\n",
    "    - max_width (int): 代码最大行宽，超过此宽度的行会自动换行\n",
    "\n",
    "    返回：\n",
    "    - 格式化后的 Python 代码 (str)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. 先用 textwrap 进行简单换行\n",
    "        wrapped_code = \"\\n\".join(textwrap.wrap(code, width=max_width))\n",
    "\n",
    "        # 2. 使用 black 进行标准化\n",
    "        formatted_code = black.format_str(wrapped_code, mode=black.FileMode())\n",
    "        return formatted_code\n",
    "    except black.InvalidInput:\n",
    "        print(\"[Warning] `black` 解析失败，尝试使用 `autopep8` 进行格式化...\")\n",
    "        try:\n",
    "            # 3. 如果 black 失败，尝试用 autopep8\n",
    "            return autopep8.fix_code(code)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] `autopep8` 也失败了: {e}\")\n",
    "            return code  # 返回原始代码，避免丢失数据\n",
    "\n",
    "# 示例：需要格式化的 Python 代码（超长单行）\n",
    "sample_code = \"def __mul__(self, other):  # implement matrix multiplication and matrix-vector multiplication if isspmatrix(other): return self.matmat(other) elif isscalar(other): new = self.copy() new.data = new.data * other new._dtypechar = new.data.dtypechar new.ftype = _transtabl[new._dtypechar] return new else: return self.matvec(other)\"\n",
    "\n",
    "# 运行格式化\n",
    "formatted_result = format_python_code(sample_code)\n",
    "print(formatted_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
